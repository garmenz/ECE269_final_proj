{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import *\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import copy\n",
    "import os\n",
    "\n",
    "import pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images-size: torch.Size([32, 3, 32, 32])\n",
      "out-size: torch.Size([3, 138, 274])\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAFX8AAADYCAYAAAAdBVTMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nOydd5hkVZn/P9/qnsQMSVCRIKhgAHPARUXHrCjiimtCcDBnXV3D8nN3MaCYw5rFdQAFxRxWV0R2UAHFhAHDShiC5IEBBgZmuvv8/njP7b51+8aqW11d3e/neeaZrrq37knvec973vOecxVCwHEcx3Ecx3Ecx3Ecx3Ecx3Ecx3Ecx3Ecx3Ecx3Ecx3Ecx3Ecx3Ecx3Ecx3Ecx3Ecx3Ecx3Ecx3Ecx3Ecx3Ecx2mXzrAz4DiO4ziO4ziO4ziO4ziO4ziO4ziO4ziO4ziO4ziO4ziO4ziO4ziO4ziO4ziO4ziO4ziO4ziO4ziO4ziO4ziOsxDxw18dx3Ecx3Ecx3Ecx3Ecx3Ecx3Ecx3Ecx3Ecx3Ecx3Ecx3Ecx3Ecx3Ecx3Ecx3Ecx3Ecx3Ecx3Ecx3Ecx3Ecx3EGgB/+6jiO4ziO4ziO4ziO4ziO4ziO4ziO4ziO4ziO4ziO4ziO4ziO4ziO4ziO4ziO4ziO4ziO4ziO4ziO4ziO4ziOMwD88FfHcRzHcRzHcRzHcRzHcRzHcRzHcRzHcRzHcRzHcRzHcRzHcRzHcRzHcRzHcRzHcRzHcRzHcRzHcRzHcRzHcZwB4Ie/Oo7jOI7jOI7jOI7jOI7jOI7jOI7jOI7jOI7jOI7jOI7jOI7jOI7jOI7jOI7jOI7jOI7jOI7jOI7jOI7jOI7jDAA//NVxHMdxHMdxHMdxHMdxHMdxHMdxHMdxHMdxHMdxHMdxHMdxHMdxHMdxHMdxHMdxHMdxHMdxHMdxHMdxHMdxHGcAVB7+KilIulnSMXORofmApL1iucf7/a2kdZJe3H4u5y+SNkm6a437eq5nZ/BIWi/pcf3+VtLRkr7Ybu7mN5J+IOkFNe/tuZ4dZ9Ck++8o6WxJ75J0raQrh50XaK/umugWx3Hmjti/9+73t5LWSnpXy3lbLemyNp+ZenbpPGcQ5XHapQ07vUz+Ja2R9LPU51rzxKrnOnPHXNpUVTrDZWI0kHSgpL/WvLdLRzjOfGPQdtogkHQPSb+VdJOk1w47P9BO3TXRLU5/+Nym8PpI6ABnNBjFtRNJd5T0kzi+fHDY+YHW5rN3jvPUsbby5cx/JB0m6dSa945EH3UWJ6MakyLp4ZL+FvXv04edH2in7proFmdhUOXXSstVw7HH/WULBJeRhUu/axVVNmZmzniUpOPaeK7jOP0xKP9gnXgyXyNdmEg6T9Lqmve6DDjzlrR+HOQ6TpvI+IKk6yWdM+z8QHt110S3OMPD4/WcuaCNNbA29fp89As784+q+ZG69zXVlvE68y6nm0GtOVXpFW+r0cX7r1MHj9VwnHwGGWvgcQyLD1+jduog6dOS/q3mvSMRj+aUo4q9OINaB21CG74spx0GrfPL/NXzZbzxtRanTXLWbEZiHUbSKyRdFfvsTsPOD7RTd03sIGe0mI9rp5IeF9OaUsWZgpWHv0buF0L4f/Hhe0lan0psvaTNMcGrYkDEql4y7tQjCtZkrPNNki6U9IoWntuKUzyEsCqEcGG/+RkkeU7gOAldXfP36yXtFf9eK2lLbIvrJP1I0j1bz7QzTUpWN6V0zyclLWnh2dOB9L0SQnhyCOH4fvMySPIWTmO/OLrm79dGXXRUqh1uzeim8waS+dl5GdiiTjTgkvJskbQ19fkHg0gzJw99O04kvUTSnyUtS323k6SrJT2p/1z2nK/WnUKS9gDeCOwbQtilx2csjXL1N9kB+Osl/Vei9weBpM9IOiHn+/tKuk3S7QalW2JfXlvz3qPjv8NSfWFzNDqTz5vazmNBXgbmyJkPui3mo7aDXNIhks6VdKPsoL4ftyGzef00bQfV+H1I/b0u1uemmMdvSLpTv3l0hk/b/XGuZaxJX4v3DyWgJKabtkU2Sdo41/nolbbmiXnyltimNX+/LtrCC8LOa/M5mWfWsqk0Mzf7Teb7nWO9rm8zX/HZ3t4zPoibJP1a0qNaeG7fujyE8NMQwj36zcugydP76fGk4rfTftGMPp7SjH90k6TDBpD1vPwMZNFHM4vnyb/k5WDJ5wPbTjMnD337KSWtkM3rjsh8/x+SzpRU1zfeKm2UrYA3A+tCCNuGED7WY972l/R9SRtlfs5zJB3Zcj7T6e0maULS3XKufVPSBwapW3xu42SZD3MbWcBIom8nU7K2SdJRbeWtIi99+8hLnj3y46eMn0j698z3L5B0gaRt+s9lz3kbhG3wUuBaYLsQwht7eYCku0v6atSZN0j6vaQ3aECBepKWx7HsMTnXPizpayGES+I8dXIA6Tdeb5S9+CvpC1tTNv8mSZ9uO48FeWnkH6l4TqK7boj95T4tPLdvf0wI4UshhCf0m5dBk9XDysRnVPx2dWyDBWHTlzz7wFRZblb3uvEmSXduO82cPKxWn5vfZQdsX5vVGbKYm5P7ymAftFG2At4BfDzq32/18gBJT9TMoeTXSDpD0tNazmc6vQOijG2bc+23kl49SN2iHvwV8fN69RDH1dQO1JA2APSabhtjSVPalI+8sdplpN10XUYWnt8zxwbaJOnNbeRx0IQQ3h1CaGUznduXtZ49dPsy5qO2HpK0n6RTZYfXbZStFx3UQh5m+ce0yNfm5oo8Pd7Hs1ZLWlfz3jWxrobeD9TeAYir1R3L9ndJb28pj32PUSGE/UII69rIz6BwXVD72QvCpyfpGEk/znx3d1kcYt9+vT7y1ZpeTPEI4PHA7iGE/Xt5gKTtJH1E0iWxrc+Pn3duN6tdaf5Q0jtyvj9E0pWSxgelW7TI9xbI4/UAHxcKnrO7pK9rZu3rD3Xro+K5fc97BrkG1iN9+4V7JU8XaI73DTaVubz+Nhf0mm5bNnwT2pTxtmRkodiFc4lajEvRIt8P5f2367tF3X/lsRp9k9VNcl963rMXjA9xPjDIvuFxDL5GXYavURfmZxBr1NdKOlnSDi08t2+bIYTw8hDCO/vNyyDJG8fc5tdSSR+UdFnM/0WSPlznt6Owzy87T2jLPs5jPshFW5TMieatb2AUziFLr7U0HaMXu64qePaCWC+S9Phov+6c+m6Z7Pyml/Wfy57z1bodKTuz7UPAE2Kf3dDDMyTptZL+GG2iy2R7iQa27izpXyX9JOf7nWW+nnsPyg6Sx+f09Jw8m28umKu10xDCaSGEVcAlVc9qa4P7wTHBBwIPAd7W0nP7Zq4beQ45OwrUKuCZwPskPWCYGVrAdV2H98W22B24Glg73OzMsMDbZYdY7/cBDgBeNczMRCNkKAeHDIu42SDRRS8npZtCCPsNO3/9Eg24pHzvBr6SKt+Th52/uoQQPgdcBqQPJPgI8P0Qwv8MJ1cDY09gQwjh6j6e8TXgacDzgO2B+wG/Bh7b9EENdPBa4BmSVma+PwL4XgjhupbSaYXo4E/6xpOBy1N9Y+RfAtCWbpurdpEtKpyAHdK3PXAX4JPA1Fyk35BXx3q9O7ADUMvJPBcscJtpMTFvZawl0rbIqhBCT4t/Lu8Lx84bIE1tqpWS7p36/Dzgovaz1RsLsL0TH8T2wKeAb2jIb7hcjHolY/9eQvSPxn9fGnb++iG1eJ627++X+u6nQ81gTUIIm4EXAR+SdEcASfcC3gC8KIQwH+3lftgT6HnxU9IBwOnAGcDewE7AK7A5Xy/Pq9RLIYS/Az8GDs/89nbAQUDpC1CGrHvmrd25GHXyQiIGjCT696dEWYv/3j3s/PXLQhg/QwgBG1/eIGk/AEm3Bz4AvDiEcMsw8zcA9gT+FMvdGNkB378ALgXuE0LYHvgn4MHArIP0ajyvUseFEG4FvoL5VtO/HQOeS/X4MudrPcFe/JX0jS8Rbf747+VzmZeWSMbJnYB1wInDzc7iGx8Xik1fRAxKTsqW+Ox3SJWvMlBmPhBCuAr4Z+BzklYASHos8BTgtcPM24Dod87yTOCr2HrI7sAdsbXPg3t4Vi1dH0I4G1tjPTTz+3sD+wKlh/QOWffM2zguZ97gMuLkshDmbRnSNtCqEML7mj5gsdmSebh9Wc++nGNZ+S7wI8wmugNmP944h+mXsgDX5hY8C2WeleLyVHkeAbxI0tOHmaHFOJ4sdF2wgHx67wB2kfQSsDkz8DngQyGEPww1Z+2zJ7A+hHBzLz+WtBRb29wPeBKwHfAwYAPQ+DDZhvHFh8e2SXM48KUQwkRL6bRCWHh7CzxeryUW2LhwIrb2tSe2FnIEcNVQc8S8lbO+/MLzjHm7b9AZLgvILlw0hAW+H8qpzwLsvx6rMWTclz5yPsRFiccxOPORhbpGDdwV2BE4erjZqbe3YyGxwGz+f8VirvfH4q4fDfx2mBkaVRtvgcmFExll/bbQZXKhrBeFEH4EfA/4aOrrtwFXAJ8dSqYGxx2B5fTn0/8o8Dosjul22L7Lb2Gx8Y1oMN6cCDxM0l0y3z8H+EMI4Y8tpdMKPrd20rS6cS3YZu0fAPcGkPQPks6SvVn+d0q9OUt2avx7JJ0je5PUt+Om7vTpvC+VdLmkKyS9MfXbjqS3SrpA0gZJp+T89kWSLsE2rPfKC5umPwxCCL8B/gzcK5XHr8re5Ju8pWu/1LUVsrc7XByv/yxuJkpOsd4oOwn6gHj/C2Unjl8ve3PwnqlnBUmvkvQ34G+p7/aOfz9F0m9lb3++VDXf/JtGdtrxhZJukr2J4rDU92dK+s9Yjr/EzVDJ73aV9B3ZWzXPTwUlPQk4Cnh2LOfvmuapiGCbek9ipg/sKnuj6zUx79ObtGSnqH9N0ldi2X4j6X6p6+tlp4v/Kdb9FyQtT11/qqRzY/86S9J9M799i6TfAzf3MdA8pJf055pgBxL9CNtgleQv6aM3xTL8Y/o3kl4S5Tq5/kBJJwJ3Br4bZePN8d4qXXaMpDOBW4C7KvVWDEl3k3R61BXXSvqSGr6hR9L+kn4V+9FVkj4Uv6/SlctkbxO/PP77SPxuJaard9XMye+7Nqr0evl+mKRfxv75S0kPS11bJ+ldsV43SfqupJ1i/dwY798rdf9How65UdKvFd9yV9Sfi/p/y+V7mqTzolyskx0gk1xbL+lNkn4vO2n/85LuKHsj5E2STpO0Y+r+XJ0t6aXAYcCbk3qK398rprkx5uFpNbL8EuCVku4v6QnYQab/rBI9VVH+Ih27XPZmkZ3j57dJmpC0Xfz8LkkfqfH8Mh2X279lb3D7ETOyvbZOWTLpPg54PHBICOGXIYSJEMINIYRPhBA+H+9Zr+43OR6t+FYM9WiHBNs8+ndSm0dlzobnEQ8jyOiWZAz8sKTrgKOVeTuHMm87UMF42jZl8il7W8EnNfN21DMl7SLTT9fLxvIHpO4vaut7AZ8GDojP2Ri/317SCVGeL47y16q9qwJ9FK8lY/sXJd0IrJF0l9ivk77/iUw75Y4xko4BDgQ+Hsv48ZJs3R+4KITw42DcFEL4ejKxU7XNkdtmKtBBbRDsQOOvM2Mz3VP2FvTrJP1V0rNS+Vsr6dPx+k2SztBse/S1Ub6vlfT+dLuroS3bIwf1kv5cIemNkq6W2QpHpr5fJukDki6R2Rif1swhAztK+l7sT9fHv3fPeXZuf4zsKOm/Y7v9QnbgC7EffDDznO9Ken1bZc6RsVy7pKivFfV1DdH2qKKpfsr89r8lvSbz3e9Vb/NTofxnnpeeJ+4U2zyx+96l2W8He5ykv0X5+4SMMnlrDY2enVdWlrmyqU4EXpD6fAR2EEc6L7XLFuv4Ctk85oUNityYUW7vYAdXnoQ5wZODLUvnoJL2kPQNmX7fIOnjRX1L5ePEatlb194i6UrgC8q8patIxhq0jWT27tWxTn+veMiwqu2DRnq/TVQwF4/Xknp7s2bG5qdLOkjS/8nGkaNSz9pf0tlRRq6I7bU0Xkv8eL+LZXl2/P4lsrHoOtnY1Op8XyU2t7rnKRtl48PD4veXxjK/IPWsMr/hLD+lzCf7tpju1TEf25flN4TwE+zwt49L0xsV3xNC+It6tNOK6ljS2yX9Z/x7iUxvvC9+XiF7S+WOFc/eXqZrrpD0d9kYORavFfZvSadjQRyJbN+9TlkyvB84PoTw3hDCtXFu8esQwrNiGms0+4106fF9raRPSfq+pJtjfupwPJnDX7HFtfNCCH/QbN2yXhm/pzJv2lbq7emytzR+L8rkdZJ+qhbniT63mVu0COc2qecW6kDN+ICOlOnT6yW9XNJDZOPnRqXGvAp9UuQjL7SZWirfSI2fIYS/AccAn4/95GPA10MI/6se106K6ji263dT950v6ZTU50sl3b9G/TbuI7K5wAuYsWMfV5JMEW8HzgohvCGEcAVACOGvIYTnhRA2KudNr0r5X1Uxny3heOBQSdukvnsitjb+A832na7T7LWe9Sr2Ay+PedoQ2+yXiofNt02ZfMYyvFI2f75J0jtjHz9bZmOdkpL/srYu8o8UrvPUIdihA1+me/2usI/G6/tpZiy9SvbW7yJ/TJntlLZNEx96lz2jEl9KzbYplAOVxELE60V9PlcPt4lGzKbvoXyFfrrYj78a2+0mSX+QdHfZmvzVsQxPSN1/pGbWky9UfEO7CtZaVTKeFRFCOBH4K/AOmW7+DBbwtkE9xKSU1bGk4xXXkiXtpqhD4ue9Y51lDxHJq9+i+IeyMfgCbENDItul9ZKTrrC3yb8zhHBcXLubCiGcEUJI1iin9XT8XKnrayZ/PJkDxePn/w4hbNBs3dJlm2fzkcpLsua3t2xucIPMNvtKk7qpIieOq5H+0ZD9m01Rc99+4VhSnVR+rFLmpqx8PEE2V7xBtmZ6RiILqXs+IBurL5L05PjdwHxaLiMuI3XRiM3bapSnyi4t9LXI5ttXqVu3Hyrp3BpJL1fBun0mjey4doRsfN8g6d+Uma8AS2Xj/k2xbz04/s7ty/7Ld6RybMJ4LZH99FrJCpnddX383ZvV7d/MtafUIKZVFpN1F+BzIYQt8d+ZIYSfZfJ1lMy+WK9UjFBRm8nXYsvI9Q/GZ5b5hGvFT6tcj+etmy+L6d0n9Yw7yGL2bl+zTLXRiM2zsoQQLgLOots/URZfMRb7T7LO+WvZGmvRGNUollvdvq/S8agOsvH2TzGvf5f0L/F71wVDtEk1Qj69EMJtwAuBYyXtBrwUO5DgGJXouIryF8Uj3iV+l9gKx0m6OvW7L6rGGovK18yKbP4XAccxI9tvr1OWDEdgttU/hhD+FH0TV4cQ3hlC+H5Mp2zdcpbtUDPdb2FxIWldtSPwVGJsjir86ul8pPOS+vyWqENuim2dO4fplzL51AjuLSjKQ7w2qx0yv/V4ve68jtq48BBgbQjh5rjX4LchhB+k8tDTXkoaznuUs29Bs/2iR6pgTtOgfQbuF9Zo7xtsFIevebg/oowiGVKxDd/PntvcfbyZ/GRl/C4q2asROUy2Vn6tpP8XfzcwGcnkd2TswhR7xn53k6RTFfeGxWeW6bdcWcmpkzJ/VV5b7SLpFkk7pZ7xoFgXS2qWqTZFfTpeW6sR2g/l/bc/RrT/Ah6rIY/V8FiNGj5ENV/bKlsnK4xTVsl+ipy+MasfVtT35ox8P0CmL5fkPNvjGHyNOn1TVj58jXpAa9QhhBuB79A9Jh+pErtZ0iGyNYcbo/54UlFdq3rfQtfeDnX7KmvF15dRpitUsi9C5eNS7nlHbVKmEzQ/bf6HAN8MIVwe9/isDyFM79lUyZlEmu0HfoAsTuGm2F7L0wmppfOL1MCfp9SY1KOs566TNUENYvXVg62uOfB79Vh3O8Xn3yjpHOBuVCCj172eWX91YdoV+Z6l30ry27RPr5f0uLw6jtd7HaMbo9HTVU3LN2rrRW8AHiWbi90beDV2ftN2vchEWR3Hzw+Kfz8/9p194+cXS/pWjec39uHJ9qL+Nd62UbZXtRGS9gFeBTw3hHB6COG2EMIt8aDjY+M90/OO+Ll07lIn3RDCZdi5Ttn9qUcwc1ZT2g5K7Mh0vFdXPlJ5SfRW3+NNHcrkU/Nwbl1Rlka+i/ibXveuju7aaQih9B8QgL1Lrq8HHhf/3gM7vfmdwG7YW2wPwjbSPT5+vn28dx12yNm9gZXYBukvxmt7xXRPjtfuA1yTSuf1wM+xtyUuwzbAnJz57QnxtyuqyphTpjbSH0+V88VN81CRvzXAz1KfHwJsBO6e+u6F2JsblgEfAc5NXftEzNduwBj2xuFl2bzHe58OnI8dLDuOnT5+VkY+foQFlKzIygywOtZfB7gv9jbTp+fVVUFZVwI3AveIn+8E7Jeqhwngn4ElwLOBG4DbxetnAJ/EJh33j2342HjtaKK8tdAea4F3xb9XYYu4P41l/jXw78BSbNH6QuCJqTxsBZ4Z8/8vwEXAklTf+iPWr24HnJlK54HYm0IfGtvwBfH+Zanfnht/27gPtJT+41LlbKWuc/po0s92BX4HvDB1zz/F7ztRNm4G7pS69nes7wjYG9gzm/f4uY4uuwQ7TX08tuU6Yr+Pz3481sdujw1AH8nU8+Mqyns2cHhKxv6hpq56B6ar7hDTPgvbEAfWNy8blG6KMnM9ZhyNA8+Nn3dK1dv52ERse+BPwP8Bj4v3nwB8IfXs52NvHRwH3ghcCSwvkjFK+n8f5ZtOB3u7wM2xbZcAb47lWZpq159jBzDthvWX3wAPiLJwOvAfqWeX6ey1xL4XPy+JaR2F6ZbHADcR9WRFGV4T83ERpt/r6Kns2Jz0uzId+xPg0Pj3qcAFwJNT1/4xr2ypfFbpmLL+vZo+ZBs4Fjij4p71dOuJvHqatkOydVfy3P8HnJb6/MRYr8m4sI4Z3bIGGwNfg/WLFWT6QjpdSsbTFvr+dJ1XyWds82uBB0XZOR2TxyNiW78L+N/Us8vaeg0peyh+dwLwbaw/7YXplRf1Wb6udKjWR1uZ6V8rMB3+gVgfj4jtkMhLnTGm0o7E+u6twIcxJ9WqHP2Va3PUbLNZ/bTHupwuD7BzbP8To3xeChwZ6/WBUU72S+XhJuCRmJ78aKZNAvC/2Nhz59juSTqNbdkeytVv+nunytlKXWf65wRmEyyJsnYLsGO8/hFsAel2WL/5LnYYGpicHwpsE699FfhWQXuuYXZ/XAtch71Rbhx7E/KX47X9gcuBTkoebgHuOCAZq2OXvDjzrKHbHjnlm5Vuwzxn9dP084BnAb9IPet+mD5a2of8d8kF3fL+5fhvG2wB89Kce78H7BCfew3wpCJ5a7NuGUE7L/uc1PcDt6mYsTf2iu04hum8v2K2/fo6ZaN7Xv0kzHeQ+ItOosI3tVjbO9b3yzEbfix+VzgHjff/DrMZVmI66xFFfYvycWI1Nsa8N6a1Iis3NLTlcsr6RGy+sgM2d79X6vdrKbAP6EHvtyBX66k/F5/A5mBLsEWeazA53xbzLdwK3DXe/yDgH2I59sJe/vT6VLpdfSPK0bVY/18G/CfwkxbKl9bhhTY3M/OUI5mx7y/BfJHLgCfEdluVqo/afkOsj52P2b+rgG8AJ9bI/6rYRt8AfhXz1pOdVlbH8dof4t8Pw+bCv0hd+11R2VLpfgvzNa+MMnQO8LKq/t2vbGNj8iTw6JJ71jBbT2Tr6Qbg4bFNl1PDxsX0xw1EfRS/O5so68zWLevJ+D2Z3RfSbfYebEElmf8cCKjPPjFd1/jcprTPtPWPRTa3KchboQ5kRq98Gut7T8DGk29huiSxYx4V72/ks6bCZuqjfNPpMILjJzae/CK2xSUxLz2tnZTVcWzzjZhuvRNwMfD3+Lu7YnZOJ69sqbz200fW0kefxuamR1b078sy32XrqXA+W5H2/wHPT30+mRnbeC9mr+dm13qm85HTZi+L9bhNbOsHAdu11Pen67xKPmMZvgNsF/N+G/DjKBvJ2ssLarb1OlK2BBV2dU3dtRQ7KDmd58I+GvN1BebXWB4/PzRb/6lnldlOa5jtQ19DM19vqZyVyQHlsRB15qKla4c9yNVI2/QVZetKh+oYgVux+WayHnkRtj6TjDEXpZ79FGwtU8CjsHH+gSX6q3A8qyjD7pgv7tvEfkmPMSlldRyvfTf+/TxszvKV1LVvF5Utfl+1rlg1Bq+nR9kG7hnLfJeSe46mYJ0sVU+F6/olz90DG4vunKqHy5iR9TXMtuunbfNsPnLa7GRMBpN51CPq1ElFnqfrmu44rsb6hzlax25Yvq50M9ea+vYLx5KS9NdQHquUbt9p+cDmCzcCz4j5e12UrfS9WzFdNAa8AptvKPtclxGXkUHLSIGsjOK8LXeO1CAPZTGRfyLGwcTP3wTeWJGfo6mOFcybM+4LbMLiDZZi8QdbM/feivlLxjB/2M/z2rFF2VhM9mWVTZhdKzkWs0l3xGy53zMTU1M7Tqsij8I2OHwPmy/fMXM9ydeHYr4ehen3ZF2uqs18LbY7/2sp9g9W+YRXU1OmyY9bCBSvm38SeG/q3tcR7f0W2iybt5GaZ2WfA+yDzdEfk/quzCZ4E/AH4B4xn/djZp0xO0Y1juWmW983GhMLynsFcGD8e0dm6yjXBXNgkzLiPr342w/GfFwLPJh6615JmVdTP4b0EuBB8e+/YmPhvVLXHpBXtlQ+q9asyvr3GvqQbSzW6fiKe7J6IltPpXEWJc/9HHBc6vPL6Jb19ZT71afzkdNm94htvWv8vBdwt5b6/nSdV8kn83BvQd5zMtc9Xq932UjXxciNC8Bp2P6q5xD9hqlrbeylrDXvSd1fuG+BEvurpHyrqT+P6dsvzGjvG2wch8882B+RU75Z6aauNbXhC9c3StJP5LZob9x0WzJbxsv2aiT3fg7rH/fDbK97ZZ/bYl2mZWXk7ML4nAsw3bwifj42XqvSb7Vlhdlr8VVt9X3gFan7Pwz8Z0ttNp03RnA/VN5zvP8u6v7rsRoeqwEeq9HEh9hkbatsnawwTpmaYwEl/bCkDKcDL0l9fj/w6eyzU7LocQy+Ru1r1HO8Ro357E8F3pG6Xqbj9o/t9nis/+0G3DOvrqnnvy3c20FDG6WgrIW6gsyfbyYAACAASURBVHIfVh1fx3hVXTeQqdWMts3/NswueCU2/itzfT3FZwKly74Ui0FP9MQzsf6d3Nva+UU08Odl25zmsp67TtZQLmrF6tODrc4c+r16qLsvA6fE++6N2dGlfmB63OuZox8L066R77Vk9FtJftfSrE+vp+ScLHoYoxeLrqpRvul0GMH1ovi7g6NsnsPMfLpqflzUB8rmhycQY9CAz2K+ulekrv1zUdni9/348Paij3EY2+t+ccU96+jWVXn1VBizV/Lcw4C/pT7fA9iSKvdaytdsu/KR02Y9jTc16qyrzsvkk/k7t85d66a576I0DqAkD2V2Z558zdnaKXXWyGoWsLADxEQ2YcbMxVGAVgBvIeP8AX7IjNNyHdH5Hz/vi3WasVQD3TN1/X3A5+PffyalODEDZyszk61AnIj12TH6ST/XuGyp467BlMjGWPcBmzDmblqPQhSwQa0DbAbuV6UQ4nc/IDUIx9/fwsxBmYFUQFyVzGBOlA8XpZdz/8pYzkPJTAJiPUw7COJ352AD/B7YgQXbpq69B3u7KrS/iHtrzOeVmOP+btjE5pLMvf9KNCJiHtKB1h26lf164OWp6wcBF8S/P0VGQWIBUI9K/faFfZar3/QLjdoW6jyRnY3xX8AGjcKNtdhk8pD49w+B15WUO72AWEeXvSNzfR0F/R4bbH5blF7Bb34CvB3YuaAeinTVBcBBqWtPZObwpdUM9vDXw4FzMtfPBtak6uj/pa59EPhB6vPBpByuOWldT9RjWRmjov/3Ub7pdIB/A05JXetgk8rVqXY9LHX968CnUp9fQ8oJlklnWmfHz2vpdjYfiOmaTuq7k4Gja5RB2IEE34yf6+ipWYusVXWMOd0/Fu+9EnP4HosZmJsTWc6WLfWsUh2Tc3+6f/cl29jC8Jcr7llP9eGvd01dn667iufeGbMndo+fvwR8NHV9Hd1GZrbtpvOR02aF42m//+h2JpTKZ2zzz2X6wp9Tn+8DbCxJK93Wa+g2nsewBfN9U9+9DFjXZ/m60sm5ntVH6cXxO2M22zap776Ykpc6Y0wtOxJbeDgFmzTcGut6VSpfuTZHzTbLXXjqoS7XYXbkRkxnfgmb+D0b+Gnm3s8w47xdS6pfYg79SWCP+DkQJ0rx8yuBH8e/G9uyPZSr3/STCWJrdZ1KbzWmd9P2/dVRXoQ56O6WunYAqUl95ln3B67PtGfuxDdVnnTA+UHAX1Kf/ww8Pv79auD7A5SxOnZJ1WLUnNseOXk4Gpszb0z9+98Gef5JzvMSfbQM27C2T/z8AeCTfcp/l1wk8o7p662kFsoxZ3L23vSC3ynAW4vkraW6HVk7L/uc1PcDt6notjdOw+Ycx2LOwscxM/+oPd4A/0W3v+juVPimFmF7Jz6IW+O/w0run56DYnr+GvIPnFxDdz8sHSeijGwhtUBWJTeU2HIF9z8Gc7T+Q7qeUvWQax/Qgt7vQa7WM+MHqZqLb2bmsN5to5w8NHX/r4lO7Jx0Xk+cz8XPXX0D+Dzwvky9bAX26rN8aR1eaHPHdk0vktwn/vaOqe82APcvSKfUb4gFx74y9fkesXyVC0rYYkVgZmzsyU4rq2PMJ34rtmD4VmyR9bJ4z9uBjxWVLX5/x1i/K1LfPZeC8Z7ZPqaeZRtb2AukfEw596yh+vDXEzLXp+uuIv3jgM/Gv/fB9MsdUv3mstS968n4PZndF9Jt9g5sQbSVcSRV1z638blN8rn1uU1B3gp1IDN6ZbfU9Q3As1Ofv04qSDGTTqnPmgqbqY/yTafDiI6fWHBoYMbG6WntpKqOsUXkB2IbSD+LrYXdEwtq+k5R2eJ3/faRtfR3+OtWUrol5/pqqg9/LZzPVqT9NuDU+Pd2mN5KDg7Yi9nrudm1nul85LTZC7F1qfv20w8K8j1d51XyGcvw8ExfeEvq8wdJHe5c0dbr6A6kKbWrS/K/jplxcgsWYFcYEEWqj2K2z28L7utqdypsJ/J96Gto5ustlbMyOaA8FqLOXLR07bAHuQqMuE1fUrbpdKgXI/Cj1LWDsXiL7BizQ0Fa3yKuMZOvvwrHsxrleBXdAZU9xaSU1TEWw5AEKX86tn2yvnM88IaissXvS9cVc+7PjsE9yzYWqBsoD9Q9murDX2uv62fuOw04Kv79eCxwNjmobw2zfZuPKcpHTpudgI3vu/faD3Lyu578OK6+9A8DXMduWL6udCvuLfPtN5qHp+5ZQ0GsUk77TssHFlx9duo3wuy89L3np65vE+t7lyby6jLiMtJyXU63OSM4b4vPuZHutbUnNshDYUwkttb/pfj37TAb+E4V+Tma6ljBvDnjv5M6ZCG2/ZbMvekXDe8LbM5rxxZlY1HYlwXXszZhdq1k+hCk+PnFzNhcteO0auRzd+DjWN+cwuIL90nlawJYmbr/FEzP12kzX4vtfu5aCvyDVPiEm8g0xYe/Fq2bPxQbJ5KXAv0KeFZLbTadN0ZwnhWfM4Xp/Rtj+t+g5DA9um2CvxL9fTn3ZceoxrHclOhlKsbEgt9cgvXj7TLfr8Z1AcyRTcqI+/TifSuw+UGip+qseyVlXk39GNITgTcAu2D95X3YRsC7EP0WeWVLPat0zSrn/nT/7ku2sY2Gx1bck9UT2XpqFGeRuu8RmK812eR4JnFzZ6rflPnVp/OR02Z7Y+tujyP6O9r6R/ecZ+T2FuDxeh6vV5z/HbEYufOibJ0LPCRea2MvZa15Dz3sWyBlf5WUbzU15zE5v23sF2a09w32HYfPEPZH5OShK92Ke6ts+ML1jZJnJnJbtDduui3pnq9U7dVI7t09df0c4Dlty0hGVkbWLozPeVvq8yuB/4l/l+q3JrJC8eGvRW31bODMVL+4Eti/pTabzhsjuB8q+5yKe73/ltfPWka//3qshsdqgMdqQH0fYu21rbI0aBCnTMFYQEk/LHnWi4HT49/JuuIj8/odHsfga9S+Rp2XzlysUU8CfyEV351zf1rHfYaoz3Pu66pr6vlva+/toMJGKfhNoa6g3IdVx9fR8xiVk5fVjLbNP4bFFp4Zf385qXkY5WcCpcv+SGbribOYsYFbO7+IBv68bJtnZY9qWc9dJ2siF/FzZaw+PdjqzKHfq0ndMeMzTs/l3s2A9nrGz4Fuf3Vu2jXafC0Z/VaS37U06NOUnJNFj2N0LzLJCOqqGuWbTocRXC9K3ftVLDajUyUTOXWb7gNl88MXMaN3/ozZ/ckLii9m5vDOrrKlntWPD28v+hiHsXMFfl5xzzqqD3+tfY5h6p5tMBvsYfHzMcC3U9fXUr5m25WPbLr0ON7UqLPpOq+ST+bv3LpyrTveW+W7aBQHkGmnebl2Sg1fU4d2eHoIYYcQwp4hhFeGEDYDewL/JGlj8g8LOrhT6neXpv6+GDtFeOeS67vGv/cEvpl67p8x4b1jwW97pZ/0B83PY52vwoJf9sMMGiSNSTpW0gWSbsQEAaxud8YO37ugZjp7Ah9NlfU6bOK+W+qewrqW9FBJ/yvpGkk3YME5OxfdnyWEcDNmnL0cuELSf0u6Z+qWv4co7ZGknXYFrgsh3JS5ls53m3wgtscuIYSnhRAuwOpu10wfOIoCOQ0hTGEHQuyad53ZMvjGzLP3KPltr/ST/lywcwhhB2wQPhP4n+SCpCMknZvK372Zkb09aNYHmuiyLiTdQdKXJf099scv0qAPRF6EHXj0F0m/lPTUzPWidto1fs67NmiyaSfpp/vgVam/N+d8XpV8kPRGSX+WdENsg+0prse56P9d5Yv991J6KF+Fzi5K+9KYZkKt8kV9+Wcs0Ajq6amiPJTV8RmYkfZA4A9YwOOjsIn8+SGEayueX6pjKvp3v2ygu3/3SmMdHEK4BNuM8XxJq7CDN45vI40a42lb1JHPJn2/SVvvzMybp4rS7psa+ijdLklfuaXgep0xphYhhJ+HEJ4VQrg95tR5JDZBnpVuxuboWaf0yGujzbRbCOGwEMI1WD08NFMPh2E2bl7+N2E2aV2bqWdbtgH9pD9oNoQQJlKfb8H62e0xG+rXqfz9T/weSdtI+oyki+P49BNgB0ljDdK+MifdhOOxtykR/z+xSaFKyJOxOnZJF/PQ9kg4JZYv+ffoBnkulPUQwm2Y0+H5kjqYg7FumxTJfxG3x5xQ6d/l5a1MfgbJSNp5Bcy1TXUC5rB6LjbvSdOkbLsyW64Gxai29wfiXHgF8GDg/ZKeHPNRNgfdA3tz2kTuU7spHSci14QQbi16QL8yFkI4Hdu4/AngKkmflbRd6pYi+6Cx3m+Zqrn4hhDCZPx7c/y/SK7uLul7kq6M7fluyuswK9ObsDlOW2WvY3Nny0IIoah8Tf2GeXU7Tj2f7HmZ/3u10wrrOPrEf4XNfx+JzY3Pwg4pelT8XMaemH/8ilS+PoO9La8tH1MR12MbofudD/dqWx8PPEvScmwR939CCFe3lM77sbf+nSrpQklv7TGPWXxu43ObhEHNbbLU0YF17Zam+qSOzdQvIzl+hhDyxpde1k6q6jjxtybjyzpsbKkzvsxFHymjDX9rr/rtBODRknbD3lB/fgjhty2lcyIWBPNlSZdLep+kJT3ms4w68lm37zdt637s6tfGOcty4KnA1yTdN+ajrI82Xb8rtJ0ipW3a0P+TR5UcFMVCzIVeLWKUbfo61PHTZctybc4Yk5TvyZJ+Lum6KCMH0bx8dddmz8MC6K+In3uNSSms4xjDsAkL1j8Qexv15ZLuQf05S+G6Yg9jcBM2xP+HOWc5Iv59OHBSCGFrS+m8GbOtz5F0nqQX9pjHLHlxXI30zzzwbzamoW6vM5YUURSrVEaX3zP+/rLMPVemrifri4PyjbuMuIw0ZSTnbVjAe3pt7YcN8lCmz78IHCyL7XgWtvHkipL7Zz2zIFYwj6xs3MLM2JiQ9V0slzReIz/9stDtyzo2YXatJLvOlY0R6SVOaxYhhMtCCK8OIdwtPvdmbB6ccH2MFUpI+uycxNaUMKprc0X+wVKfcA8yXTvtEMIvsHZ/lCwGbG/sAKq2GdV51uVR72+Hbf7fTCoOr8ImaOqf6DmWu6V51KFYPV4s6QxJB6SuuS7IT3vQNulI+vTinOAiuv3dVeteRXkoq+O0v/sndPu7f5r5XR6la1Yt+PzKaMPfXRpnUUQI4WfYy34PkXRX4CHASSU/aRJffD522MXRwNWyNaRB7DcY1b0FHq83eEZuXAghXB9CeGsIYT/Mnj8X+JYk0c5eymweq+Y9ZfZGU/sry8D9wjX2OcznfYONZUjzcH9EGT3IUD97bpvqt6q9GgnzRb+NhF1I+Ry4UL+1oG/K0v42sG+0gx4P3BBCOKfhs+uwoPZDef/ti1Htvx6rMTt9j9UwPFYjn9prWxVpFMYpNxgLmvTDhK8BB8Q5/COxg2l+WnK/xzHM4GvUM/gadc20e1mjxsbkTwE/le2TqNJxTcfk2vsWsvRgo+RRpSuanH/S6hpvCSNn84cQJkMInwghPBxb8zoG+C9J90rdVsce35V8PZHQ9vlFteuxgipZL1sna0KdWP3GtvqQ/V5ldZfnM86WLa88ve71TFOVdl/6LYc2ZbHXMbopI6erGjKq60Vg66h/iW3Tq0xU1fEZwIGSdsEOqPwK8HBJe2FlO7fi+XPhwytimGc13YIdznuEJGF64/iSnzRds21rvCljVOfWufTgu+hn7+rIrp22dfhrHpdiJ0GnF7pXhhCOTd2zR+rvO2Mn4l5bcv3y1LOfnHn28hDC31P3pw2cXukn/TkjOvC+jp3IDPA84BDs7bvbY6cdgwn0tdjbJu+W96ic7y4FXpYp64oQwlkVv0s4CQso3COEsD3w6ZiP2oQQfhhCeDym4P8CfC51ebeodBOSdrocuJ2kbTPXkjZqQz6quBS4KFN324YQDkrdMy1jsqCN3ZmRs67rzJbBYzLP3iaEcHLq/kH3gar054zo4FuLOSp3lrQnJievBnaKDpI/MiN7l5LfB2B2vdXRZWV1/Z54/b4xkPT5NO8DfwshPBcz8t6LLbysTN1S1E6XY4Nb3rVB94Fs2kn6jfWkpAOxtws8C9gxtucNzNRjtixV/b8NusoX9dAePaZRprMhv3x7RJ2R0Gv56uipPKrq+CzsTUv/CJwRQvhTvP4UqjeOJvnK1TE1+ne/nAbsL2n3kntuxg5MSMgLZu21jyWbRw/F2uY3Jfdm0yjNV8V42hatyWeNts6W/1rMlszqvdb6fg19lM3XFVhfSbdLWmdXjTE9yVEI4ZfANzDny6x0MzZHVZvNlc10RqYeVoUQXpG6J53/VcDtqG8z9WPL1qWf9IfFtdgkfr9U3rYP9nIJgDdiuvyh0YZ5ZPw+T9/2UodfxILR7wfcC3tbzKCosku68j9PbY9SetBPeRyPObMeC9wSQji7ZvJF8l/ENdibutNj7R4F9+Yxp3bsCNt5MPc21dcxe+/CEELW+d6kbFcwW64GxUi3dzD+iL0M5Snx67I56KXAnZW/4TvPtiobJ/J+M01bMhZC+FgI4UHYS4/uDrwpdbnIPmik9wdA2Vy8KZ/CbPd9YnseRXkdZmV6JbAT7Y1JbdvcZX7DvHbKq9sJuhct6tKrnVZVx2dgbzJ9APDL+PmJwP5YQExVnm4jvuwo/tsu2GYhaMHHVESwBa6zsbloEV1zzriIOOtRPab/U2yB7xCsXCeU/2JWOrdQMB8OIdwUQnhjCOGumP/8DZIe20s+a+Bzm+GwWOY2berAKn2SZ7e0ZTMVsVDGz17XTqrqOAkoOzD+fQb1D39ts4/0wmk0G1/G6H7hAPQ+vlyCBbQfhh3U13R8KfS3hhC2hhDeHkLYF3gYtmnmCNqnTfmsauvSvh9pOmeZiuP8+cAT4tdlfbTp+l2Z7ZT3m2lq+lKqylclB0WxEFV9fpBzloVk0+fRmp9O0jLM1/EB7ODUHYDv07x8vY5nvcakVNXxGdiB2Evjs87A5HZHqgMCq9YVm47BTfhrTL/2mEK763ffwGJTHg08g2ZjSnLQUtGYcmUI4SUhhF2xt8J/UtLePeaziqb6Z9j+zUb04NuvM5YUURSrVMYVpPzi8fdla9JZ5mLNzmWkG5eRbhbKvK1JHgrrNI6jZ2NxMYdT/5CmqljBPLKysQIrf13cvuyRGjZhXr662ovZMSJl9lSv899Lsc1V6RiRHTPxhUmfrWozX4ttRpVPuEn8dC91fzzm2zsc+Fro4TDBGoz8PCuEcAPWFgfHfFTZBGX+iSz9xnL3PY8KIfwyhHAIFl/8LewgwQTXBcOxSUfap5eizrpXHlV1fAbm614d//4Z9V+mmeQrd82qDZ9fBacBT8z0qyyF65aRfvrXCZgf53Dg1NB9CFCWpvHFJ4UQHoHJT8D2K7TNgtpb4PF6rTLS40II4VrMvtkVW//vZy9lr/Oe3DaqOaepYk78wmF09w02isOfj/sjyujRhu9nz21T/Va1V6OKudZvo2oXJhTqtx70TaO6j/PdU5hZ+x/Ui5kXzH4o7799M9L912M1PFYj536P1eifwjRCQZxyw/0UTXySxHQ3Aqdi/el5wMkhhDI59jiGGXyNegZfo66Zdi/2QLAXSx8H3AW4dw0d13RMrvLflrVP37HDNXRFk/NPknFpLmRqZG3+EMLmEMIngOuBfVOX6tjjV5CvJxLm6vyiKhrJesU6WRPqxOr3ZKvPod+rSd0lPuPGe3hDb3s901Sl3a9+a4s2x+imjLSuqsFCWS/qVSZK6zjYSxtvAV4L/CTYQaBXAi8FfhaqX6TZpg+vKT8Gdpf04JJ7Bn1W07Owl0dtC3yv5N7StdTsvtkWx5syFtrcuqnvop+9qyO7djrIw1+/CBws6Ymyt6gsl7Ra3YepPV/SvtFJ+w4s+Gwydf3fZG+N2A84EjuNGqwxj4mDDJJuL+mQAZRh2OnXQtJOWCBx8qblbbEBYgOmWN6d3BuV+H8BH5K0a2ybA2KnvQaYAu6aevyngX+NdYCk7SX9U4PsbYudKn2rpP0xp0qTst1R0tPihPg2YBP2xriEOwCvlbQk5utewPeDBbSeBbwnyt59gRcBX4q/uwrYK2PspNNdLanfjnYOcKOkt0haEev63pIekrrnQZKeITt45fWxjD9PXX+VpN0l3Q5zIiQy+Dng5bJTriVppaSnZBR4Gww7/VpE+T0cM1g2ACsxRXlNvH4k3cHNxwH/IulBMf97J/0Zk410H6ijy8rYFpPbjZJ2o3vyUrd8z5d0+9h/N8av6+jKk4G3RR21M/DvsTxJOXeStH1JukHS6qb5jXwfuLuk50kal/RszIlQZhwVsS02aF4DjEv6dyD9BpCu/lyj/7fBKcBTohN+Cebkui2m25RCnR3JyuQvMMPxzVH3rcYWBb7cQ9p19NQsquo42KExvwZexYxD4yzMeZcNzkz6VfJvKeU6pqp/90UI4TTgR9jbSh8U5XdbSS/XzFunzgWeE+v/wdgm2bb4OmYUvp3yN0nkcS7wSEl3jn37X5MLNcZTUveul7Sml8zTrnxWtfVV2ORvKUC0IU/BbLRto15/AzN6rw2q9FEXwQ6++xVwtKSlsjd4HJy6pWqMyfb/XCQ9QtJLJN0hfr4n8DS6bYoim6OqzUrzIGmNpPVVeazge9iYcXjMwxJJD1H3m8cOiuVcCrwT+EXURQlvkrSjpD2A19Ftt/djy9Zl2Ok3JtoVnwM+nJKd3SQ9Md6yLXY4zMZoC/5HyeO6+mPN9C/DDkQ7Efh6sMP8Z9GSjFXZJVk5n4+2RxWN9FMewYLHp4AP0iworkj+i9KZxA5LODrasPek2QE5pfImaa9ox+7V4JlpRtXOG7pNFexNhI8BXpxzuUnZTgHWaMZfVKh/FnF7TxP70CPo9gkVzUHPwRZrj43ysFzSw1P5S9tWVeNEFX3LWLQHHhrb5mbsZUZpG7bIPmiq97PpHi1pXZO8ZiibizdlW+BGYFNs6+xGumxZTgKOlHR/ma/k3Vi9rO8x/S4GYHOX+Q3z/JQnA/8s6S6yReB3A18JIUz0kHavdlpVHScHJ/0phLAFe9vri7GNMNdknrUsrbux9jwV+KCk7SR1JN1N0qPi/X37mCp4M6Z/3yTzNyPpfpISvfQ7YL9Y9uXA0S2nfwK2iXAH4LsNf3su8DzZvOpJWIAFAJKeKvP9CetPk+TMh31uM2/Sb8wimtu0qQOr9El2fGnTZipioYyfva6dVNXxGcCjgRVR5n4KPAkLJP1t5llLM+OLaK+P9MJ/AA+T9H7FAIiol78oaQfg/4DlsZ6WAG8DlrWY/vFYsNLDaT5PL/QDS3q0pPvIDqu9EQvAyRtf+l1vbFM+q9o62zdaWeeR+UT3pXvOUtRHvwfsIun1kpZFm/Ohqfyl/TFXUG47VdG3L6WGHBTFQlT1+ao5y1pJa5vkNWGB2fSzaNlPtxTTR9cAE5KezMzGOMhfa21zPOs1JqWqjs/A9GLycop1wGuwgMAuPaZuX9NyqtcVq8bgnokblN6ArYsfmer3j5D02Xhb4TpZC+nfDHwN+AJwcQjhVw1+ew0WePf8WGcvJLVRQ9I/aWZd6HrMn5I3pvTrr4Dm+meY69hV5PlDm/r2+xlLcmOVKn7z38B9JD1dtl73KvIDV4sYtE8LXEZcRspZKPO2unmowwmYT+0+wDdr/qYqVjCPr2FxBQ+Lsvx2mgXdu33ZO1U2YR6nYH60HWV+l1enrlXZU6UxrQnx2W+Xza87sU++kNmy9HZZrMqB2AEIX63RZr4W24wqn3CT+OlaMUIZTsRix0tfqiZpnaSjGz4bWBjzrKgfnkO3b6LMJjgOeKekfWTcV3HdhNnt1G8sdV/jUezjh0naPm4iT9ZB0rgumHubdOR9epE66155lNZxCOFvsUzPxzYs3hjLcSiz44vHM3b9EsrXrPr2+VVwIrbp7OuS7hnH4Z0kHSUpOQSxcN2yBU7ADjZ5Cb3FFx8k6XYyX/3rkwuS7iHpMVFeb8Xapyi+2PcW1M9DJR6vN83IjQuS3htt+fE47r8COD+EsIH+9lK2Pe/pZU6TZeB+YY32vsGmcfjzcX9EgjR7XaAXG76fPbdFe+NyqbFXo4pBy8hCsQsTyvRbU33Tyxz4BGANtk+msA9oce6H8v6bwfuvx2oU2Foeq+GxGv1QmIaK45Sb7Kco64dlnITN7w6Nf9fC4xh8jTqFr1HP0PoadRyrjsRsgQup1nGfj2k+Nrb9bjGvefnr1X+b0HfscA1dUeTDKhuX8saxbLqLyuaPY8NqmV9mXNILsPZLx48XnQmU5mxMH702PucZwP6p6/Pl/KDasq5662R1qROr39hW19z6vWrXXY7PeF/gBVWVpN73ek5TI+1+9Vtb9DVGLzZd1ZAFsV7Uq91Ws46TWO9k7XRd5nNCR9325zLa9eE1Iq4DfxI4OaaZ7G16jqS3xtvOBZ4R+//eWP23xU+xM9k+C3w57u2tS+G+2SbjjRZpfE5GDpdLEs19F/3sXZ1Xa6dNGNjhr1GgDsGMw2uwQIc3ZdI8EViLHdi4HDt1Os0Z2Nulfgx8IIRwavz+o9jJvqdKugkLWqzjxGjKsNMv4wBJmyRtAv6M1fFr4rUTgIsxx8ufmB3U+S/AH7ANyddhm+o78bC+Y4AzJW2U9A8hhG/G61+WdCN2gvuTG+TzlcA7Yj39O81Pru5gjprLY14fFZ+Z8AtgH+xk82OAZ8YFc4DnYm/suRwLsP6PEMKP4rWvxv83SPpNTrp7YBOYnokd/WDg/sBFMY/HYW8SSvg28GxsQns48Iyo6BNOwgb7C+O/d8Vn/woL3Pl4/O352AJW2ww7/So2xj5wFXAA8LRg/AkLgjk7XrsPcGbyoxDCVzF5OQm4CTtV/Xbx8nuwwWijpH+pqcvKeDvwQOztAP+NKf+mPAk4L5b1o8Bzgr21MqFIV70LWwj7Pdbnf8NMG/4FG3gvjGXdNZ1gNNw2xd81JvbDp2L9cgQJ2wAAIABJREFUdwO22eGpwd5s3JQfAj/ANoFfjE0C05O8vP5c1v/7JoTwVyzw8D+xvn0wcHBD4y+hSmd/Htg3ttO3YhpPw3TxtZjxe0Rs06blqKOniqiq4zOAJVjAT/J5W2Y2kya8FXMQJv9OL9MxVf27JZ6JTRq/gvXdPwIPBk6L1/8NW8y4HuvjtRdGqoibR5MDYBsZ4bH+v4L1+V/TPcGtGk8Bm3hgjqiqzUVFeWhTPqva+nRsEfpKSYlueQ3mzLgQ+BnWNv/VS1kKqNJHeRyGjVEbMB38FcxBV8de/ijwTEnXS/pYSRobsXr/Qxwr/gfrl+9L3ZNrc9Rosy4dlJP2HvTZB4O9ceYJ2EaLy7G5wXvpPujjJGwB4TrgQVi9pvk2JvfnYuPt5+Oz+7Vl6zLs9HvlLZiO/XnM32nYG/sAPgKswOTi55hcFZHXH+twPNa3ywKX25CxKrsk29fmne2R4tnJPDD17w418lyXE7A2aeKIzZX/Cl6N2RtXYu1/MlE31qBK3vZgxrZqzAjbefPCpgoh/CqEcEHO97XLFkL4AaaDTo95Pr0kycXa3m+O/f9mbM7+BeAz8VrhHDRl/+8NXAJchtkHkN+3ysaJUlqSse2wxePrsbrdgL1pLCHXPuhB72fpd+wpnIv3wL9gTu2bsLrIOp2PBo6PcvWsEMKPsfnK17GDfu+G2Vht0qbNXeg3zPNTxnROxOaVF2Hj3WtmPbUGvdppNer4LMyGSua+f4r5zM6Fwfwuad39GGyRYGn83fXYwQ53ive34WMqJNhb8B4T/10o6Tpssev78fr/YYGwpwF/w9q/TU7A3qz3lRBCXbsg4XWYftuI6YL03GUfLM+bMJ30yRDCupxn+NxmfqTfK4thbtOaDqRan2R95G3aTEUsiPGz17WTqjqOOngTFoxAsM3wFwJnhsxBfZgMp8eXI2mvjzQmzg8OwObM50m6AavrXwE3hRBuwGyC4zBb+mbMTm2LrwE7Aj+OATZNKPMD7xKffSO2TnsG+XPpvtYbW7bvqtq6y07uc53n46l17BOBt8W5HpT00TiWPh7rA1diNsej4+U8f0yZ7VRFG76UKjnIjYWooVe79HBOuv2OKQvCpi+hFT9dlMfXYmW6HpPb76Su5621tjme9RqTUlXH2fW6n2GbYbJzlt3oHk82A3ehfF2xagzuixDC1zA/xgux9r0Kq99vx+tl62RtcDz2RvPCQ7VKeAm2/rMB2I/ugyseAvwi6szvAK8LIVyU84w25ixN9c/Q1rFrMMsfSm++/V7HkrJYpVziGPpP2PrdBixg+VfU940P2qflMuIyUsWoztt+l1lX+0jNPNThm9jY8M0Y61GHqljBWYQQzsPG8y9j5b8JuJr6suH2ZY9U2YQFvAOb116Ezb+/xkyMSFWcVlVMa8IWzOY9DZuP/DGmsSZ1z5Uxz5dj8UcvT+nbsjbztdgG1PAJN4mfrhsjlE7/MkwfB6LfqIB++/kozrN2TfkmLsbigxN/fJVN8KGYx1OxPvZ5zKcCs8eofmOp2xiPDgfWR7/fy7E+luC6YAg26Qj79LLlqLPulfe7OnV8BrAhhHBJ6rOY/bKzT9Ft13+hYs2qrfiporLdhh2++hfgR5iOOAfYGZsDQPm6Zb/pr8d8CiuptkmynIhtWlyP6be0vlkGHIu115XYZvOjsg9YxHsLPF7Px4U8tsHkaCM2lu4Zn9PXXsq25z09zmmyz6iax7Rhz4zyvsFGcfg1YuqGsT8i4WHMXhfYTHMbvp89t0V748oo3KtRg4HKyEKxCxPK9FsP+qbKX5WX/pnYgQC/CQUHbmnx7ofy/jubxdp/PVbD8FgNj9XoZw2riLI0cuOUa4wF01T0wzK+E9O/KoTwu4Zl8jiG9vE16tks6jVqrP1eAPxjCOG6GjruHCzm98NYjPcZmM8BZtsMPflvU7QRO1ylK4p8WIXjUsE4Ns0itfk3x3SujHl+FXBoCOHC1D25ZwJl8rsFeAa2jnU9FreQ3nM4X84PairrZetktQk1YvV7tNXn0u/VtO5eDayK36/F9qdW0dNezxwK025Bv7VFz2P0ItVVTfI0qutFefRqt1XVcTbWu+ispufSbX9e0LIPrxdei40ln8DWUC7AXmr83Xj9w1jc01VYXHY/L2rsIoQQsPlC41jvUL1vtu54sxjjc/L2HNyNhr6LijiAKubb2mltZHJbcoN0a8zYx0II/9ZPYpnnrgO+GEI4LufaXpihviS09OYgZ+EhO+X+xSGERwzg2cdhbzf/YdvPTqVxNLB3CCFXoUtaj5XvtLzrjjNIXSnp+cB+IYR/bfO5juPMbyQ9AnhVCOG5w87LQkXSV4C/hBAavwmtjzSPpsTm6PPZp2JO+T+3/exUGmuBy0IIbyu4HoB9QgjnDyoPzmCQ9EgsyGKvEMJUwT0DlzFnBklHAC8dxByrIt33AruEECrfDlfjWW8DrgkhfKbyZmfk8fZevFTZB30++1zgsVWBLo7jLCx8buP0g89tHMcpYi7WG535SVksRJ/PXYod0nDfUHFImOM4Cwv3Vyw8JHWwwwEPCyH8bwvPcxlZYLiMjAaSLgBeNpfxfZJWYcHx+xRstG3yLLcvB4ykV2Aven/UHKa5GpuP7D6AZ/va3DxD0n8Bl5f4nXfHfBMHzG3OnGHjusBxnLbxvQWDweP1Fh+DWj9YqIz6vkFn7mlzr4bLyPxD0unASUU61PdDjTbef5028FgNx5lbfP1x4eFr1E5bDGpfhNv8s/EziUaXQfq9hsEg93qOGq6rHGdx4vE5o03La6ePxV4isQw4qGxuNV71sBDC8n4z5DijRgjhxcPOg+MMkxBCk7dHO46zQAgh/IzZb6Fw+kDSQ7A3FF2EvWnoEODYoWaqRUIITxh2HpzRRNIS4HXAcUWHI4HL2FwiaRvsLTqfnIO07om9zeoP2FseXwS0MgcLIbT9hl5nHuPt7QyCEML9h50Hx3HmHrc7nV7xuY3jOGX4eqPTNvFt7vcadj4cx5l73F+xMJD0ROAX2Jvt3wQI+Hkbz3YZWRi4jIwWkg4FAnD6HKR1MPBjTCY+gK2xre/3uW5fto+kOwF3Bc4G9gHeCHx8qJlqEV+bm19I2gt4BvCAontCCJcBvrHEaRXXBY6zOPG9Be3j8XqOM1x8HW9hMMi9Gi4j84vY1g/E2jgX3w81Wnj/dUYJ96U7Tj6+/rgw8DVqZ5Rwm99xnFHAdZXjLE48Pme0GPDa6Y+BHerc22kjwfmMpMMkbcr5d1HB9+cNKB+fLkiv8feDyN+wKSjrJkkHDjtvo46kOxfU7VT8l3ftzgPIR9O+OKd9dNhI+kFBeY8adt4WEiX1HBZC/Us6r6Achw07b8NgvtgAmTz5eDcEhmxv7QKsAzYBHwNeEUL4bQ9lOLBIflrM66KmpI4n57LuJR3VcKwq+v4Hg8hfG0i6F7ARuBPwkSFnZ6D0YHsMxSaRLdReA1wFnJT6flC6Z1vgG8DNwCnAB4Fv9/nMBc0w7bwSm2pBzs3mA4vJrncbZ26YL3bOoHA9NZsSPVI0Hx6ofimxceetzTrKzJc+73ObhY/mydrDoHA7ZTaaZ/51twGGR1Hf0AL0c7uczQ0l9bwg1ovdHp5NiR4pslkHql+0yOJzhoGaz1OHMn9N5XdQMnEAcAFwLXAw8PQQwua+M7wAcBmZxmWkARrivE3SOuBTwKvSL4PR4OK/DgEuj//2AZ4TQgh9PnPBMmT7cinwGeAm7GDgb9PjYV4lNtOCm3sNm5JxaN6uzUl6J/BH4P0hhIuGnZ+5ZrHNs0ZRRkeRHmzSkap/H1e6KdEjQ1mvUvGayyaN0NrKKDJAG74qXY/Xm+cs9PF3GPaUj0XtohHbp6rBrbm1sldjMTGKfVHS8cBpwOtDCDcNOz9zjfdfJ2EU+2+vDFDunBQl9eyxGvOEYc1ZFwsl8z5fo/Y16kK0yGKLh22LLhZGrZ41z/3Zw7ABFpKtPmp6rmQ8XxB+3PlEma4aJR1WhNve3ZTogqHtR/b+PhyGMa5m0l/Qa6fyGFDHcRzHcRzHcRzHcRzHcRzHcRzHcRzHcRzHcRzHWRxIehLwUWAMOC6EcOyQs+Q4juM4juM4juM4juM4juM4juM4juM4juM4juM4juM4jrOg8cNfHcdxHMdxHMdxHMdxHMdxHMdxHMdxHMdxHMdxHGcRIGkM+D/g8cBlwC+B54YQ/jTUjDmO4ziO4ziO4ziO4ziO4ziO4ziO4ziO4ziO4ziO4ziO4yxgOsPOgOM4juM4juM4juM4juM4juM4juM4juM4juM4juM4c8L+wPkhhAtDCFuALwOHDDlPjuM4juM4juM4juM4juM4juM4juM4juM4juM4juM4juM4C5rxYWfAcRzHcRzHcRzHcRzHcRzHcRzHcRzHcRzHcRzHcZw5YTfg0tTny4CHFt28zYrlYfvttx14phzHcRYSV1517bUhhNsPOx+O4ziO4ziO4ziO4ziO4ziO4ziO4ziO4ziO4ziO48wf/PBXx3Ecx3Ecx3Ecx3Ecx3Ecx3Ecx3Ecx3Ecx3Ecx1kcKOe70HWD9FLgpQDbbbuKFx1+6Fzky3EcZ8FwzAc+c/Gw8+A4juM4juM4juM4juM4juM4juM4juM4juM4juM4zvzCD391HMdxHMdxHMdxHMdxHMdxHMdxHMdxHMdxHMdxnMXBZcAeqc+7A5enbwghfBb4LMCddrl9AFi+XCxZIiYnppicBAKMj4uxTgeAiYlJBCxduhSNBWCKqRAQQvGeEI+YlTpIAjqEAJ1OhyVLlrLlti2sXLmKyckJQgBJTE5OMT4ubtuyhRACUyEwOTXJ2PgYU1NTBGDLrRNsvmULADtuvwPLli1jcmqKqakpxsbGCFNTSKIT8zE1NcXk1JSdgishKf4NHXUIITA5OQlAZ2yM8bExJiYmLO8dIWRph4A6sqNz45G6kxOTdDodpqamYlkVywobrr+OqakpliwZY+mKccbHO9P3JGUL8Z89f+ZU3qnJ9PM6CJiasqtjY2N0OqIjKw/AxNYJ+23yjGDlnppK0mA6X8n/AGEqTKe1ctVyJBgbH2fJ+Dhbt06A7Dmd2IaTk5PctmULK1eunK6j8fFxJiYmWbJknMn4rLFOhyVLljAxMUEIXWcNW55j/sbGxxgfH6cjsXnzragjxjpjsd6tLBMTE9x0wyYmJiZYunQJO+68HVNWICbj8yUxFabYsmWLtWXSzvHf+Pg4S8aWMD42lpJHSFIJ1g9MBjod+y7VPumsQ9LGUwTCtAxt3bKVa6++AYDtt9ue5cuW0el0mJicpCPrF1NRDsfGxqJ8dZianIrtPzWd161bJ5CY7ksk+ZAIU7Gvyepqampy+lljnQ5bJybitRn5D0BHJsc3brqJW2+9FUms3G5FUjKrs6TOY58khJmTokMg+aTp3yR1GIUuVlIn1Q8Idn9s9mnFYLpC8dH25KmpwFSYAsRtN99mcrnNNixbtmxasKemplCnM91mSn6fPFfWZ5N+FrC66qiDOmLLli10OmMzfSAEk/uxMdNrUXdMTk4wFu8LsWMlspZU1G1bbmPzrbfiOI7jOI7jOI7jOI7jOI7jOI7jOI7jOI7jOI7jOI6Thx/+6jiO4ziO4ziO4ziO4ziO4ziO4ziO4ziO4ziO4ziLg18C+0i6C/B34DnA86p+tHRphxUrxOQETE3a4ZbjYzA+NkZHHSYnxghhiqVLxtH4FEEQwhSdzhhjY+PxMMbk8M0xO3y0M4YQY2PjLFu6nFs238r2223L5KQdTmkHWU4hTbL5ttuYnJpkamqKrZOTjC8ZZyIe0LpJt7L5li0Isd1227HNihVMTEwwOTllB45OTtDpdBgfGwfsYNfJycnpAzDt8EY7oNJIHe4aD9+cmLSDTcfGxuhIdqBmPKwyTIXpwyAnJicYHxvrOqwzOVz2+o3XMwWMLemwYuUSxpd06HTGpg+ltANrJ5maCkwmB4ACBJicspMyO7KDXkOYOWh22bJljI2JTjw4c3Jyiq1bkwNo7bupyWAHWU5NMTk5haYPf03axM7gnGIKrFpZtmIJS5cuYcmSJSwZX8JtW7bQ6XTYunWr1ZJkh45uFitXreC227YQCCxdupQwFRgbH2MyHp5pB8guYWJi6/Ths51OJx56agembp2YYMmSJSxdupSOOtx8y81RzsatzLF1JiYmuOXmzUxMTDC2ZIwddtrODv6MbZscvDs5NcUtt9zMli12MHBnrEOn06EzNsaypUtZvmQ5S8eX0okynBxEGmC6TSUxPjYW82yHrCaHniYHBs8c8DtpB5t2rDJvvXXL9OGvq1auZNWqbacPEp4KUybf0zJmaYyNjXUd0pukv3Ui1nk8lNUOozXhSO7vdDp04oG8Vs6O1evWrXYQ7Fg8hDl1oGoIgdu23GaHv3bEipXLYxfoTB9sG4CtW7cyFaa6ZD2QHLAauvKFhEJyhC7Th9Im8mmyN3PQcoh1mhyyOt0fQmBiaoqpyUnSh78uX7acVatWdh3G2xnrMBUPTR7r2IHPk5OTM4e8JmWJ9ySyp06HzZs3T/9tIhCmD+RN+vnYWGf6d0lfSR+6mz5w1g9/dRzHcRzHcRzHcRzHcRzHcRzHcRzHcRzHcRzHcRynCD/81XEcx3Ecx3Ecx3Ecx3Ecx3Ecx3Ecx3Ecx3Ecx/n/7NzNq2zZ1uf17xhzroi9z8m896rlYxW+1b9g247gH2BLe6IgVMuGYMPCv6Bagt0CBQUbCgraKBARbNixoQgi1RU7D+rz1H3JzL13xJpzDBtjrhWxz71569Hmrd8nOZn7xI5Ya675Eq3kK/8IyMxhZv828N8CDfiPM/N//4d+0Kwima1x2S7EmGfY89I3Ll839jG43+7MMcBihU/rDxyhVQeMfQ66d1rrFbzMpPfG2/s727ZVjNHg+nLlp59+qEioGWaBtUYAXpfC1/UBtt4rhplZ3dPVo8xI5qqaZibmTs7A3M6gp7XGft/pvbFdLsScfNxujDHoWydmhSVZccrL5VKxUSpQecQh87iHOYYR6z75zXyOfXC5tsdLT//21s7AZGbWfTGa+/m6WYVzv7x+AQsy6737PmgrWFpxVyfmWJFSx40zbPrN7lh/HuO5Xq/03plj0tzZLhuZyf1+X3Nw5eV6ZYzBGPsZLX19/XJGV5s7cwz29XczJzPYtguXy4V933l5fcVutxXXdJLk69ev/PTTGxhn2POI8dqaJzKJzIr8jp3r5UKS7PuOu7NtFe7NqEBpRYDbuZ+OQGmeEdXfD6/OmGcUtuKmK8J6vLKin80NrPaaGWzb9s301jV67/z09ka0XPHbCtrGDGYLWnOae0VkqZhr7xtz1nuO/eFeUV8Ad6O1xv12I0la75gZ930/g8VzxhlY9YT9vq/7H3P5tG/PrVGR2dYbNo20eAq2GmmPwCtUcPdYE2r7rTBqkGHn3ner58s1pjgirivQamdhNZ8Px7lWmXlGbM9nWPd09/OMHvuJTMaoCHRkQiTu6xw9nbzzs1Dx2BWsTZK+bSsMa0BUIDcrpPwcsRURERERERERERERERERERERERER+TmKv4qIiIiIiIiIiIiIiIiIiIiIiIj8IyIz/x7w9/6/fCYymVTIc8yJWeLdyQhu+wcf9/eKa664JFbx0ff3O5cLjwgjE6Oipft+x91p7YK7s+8JFrgb7jDn4He//h3NndY723YBM2YGM4Kf3t7IDOacj2cDxvq72wqvrjFFBJBnDPJy2Ziz7nfEJiOC1q/n9XrvXFeg9P3jnTFHxW8jGGNnH+OMR7q3FYQdXK8XzCtKO/ZRAdHFzXF3brcPtsvl0zwfjcvmTnqeMVL3ildOqyCom7NtG9t2offO2/uP7Pv9DLxmVnx0zor0uhuZjq1YZ8aZMj32xPrzGMu2bdzvN+73WqcxBi+vr+z7G+7O5XKh940ffvyBl+sLX7/7DsOYc5AR9Na4Xq/s+86cwdev37Hv+3lX98YYg9/+7nefIrMfH+9r73zQmjPGirb2zhiDt/c35hzn+GNObNtqXs3Itb/cjBlX5pyMMci1J3rz2gcr/Rox13WCyDjnxswIN3Ky3m+Y24oYWwVNOaKf9Y7aY+BPPx/np6Knxu1+5+uXL4w5aF7h4zEm3339ysftVhHYnEQmBnz/i+95++mtosgvnYza/z/++CNb72RWBNXMuVyvjH0nI4i0irge4do1BjMwvPbntwHgBHPOPV0R11gxWn/qsX6OnBqPkG6sYPHzlTOSWOHcI5Bsax7d/RFPXcOs75BjvEc0+nEtEvrWH5/hKQq7zvE+Br01evczshsR9NZpzWv/zcHr6ysz5nmtrXdwr30b84wGzznZto33t/cV+62Q8KMwvcYtIiIiIiIiIiIiIiIiIiIiIiIiIvIzFH8VERERERERERERERERERERERERkZ8VmexjsK/oYWtOM8Oa0VqrGGZE/cmKk768XNm2Cm+2tlVMc072Mdg2Z9sujDGIeOPL1698/e6VmMHt/oEZtBVuTAxvreKfMXl//+BX/9iviBV63G8BvAHw8vLC/VYRVAzmnLTW2Hrnvu+wQo5j33l7u7NdNiwNvEKvWyS32+0MfZoZ7x8fXK9Xvn75eoY2c8Ul67lX1NKMj493ZgRfv34lIiq82pzL9fIU1BxE3LleXjEavbUzGhkxz6itkTQ3zNoK3AaJ1z0N9piM2wcf9xvXy8a2XVf4cmJW14qcYBXA7WbsY3C9bmTCfh/c94FbhTEzK4oKFS19/fod+9jJTHrrmDfeP24r3Okrdppcthdau5BpKw5aa7+PHfeK1MLg/f0NW9FYNyMzK6Z72fj1r39d67RtFTlt7QztZsb5XGPu/OqXv+TH3/7Evo8zJBwR9K0zxyBIWluB321jXi/Y2gu21onMFRWFGVEB2KwwsPkjWxoRZ9TUzPA00ny9tgKo6zqZ0LytCGl8ir++XK8rcLyfweL7fedysTpP7ry/v9NXzNVs7T+M28eNbdsqOHz7OH//9euXOj8zaN4r1nu7Mcag9w5mFey9XkmS1io0u+8DyIrtznHUXE+PuGuVXo+Y6vG2mh4/u7F2fq6+DyaTMOM5EHuEVY2aqIwg3VcUesWX1/cMT580g1xn+dBao615qj1Qb3QM90bMSfPG9XI5o873fT+DtEfs+Qjj7vsdzNa5qe+H+/sb23bBs6LLewS9d2IOevNzDVjXqmBv/RERERERERERERERERERERERERER+TmKv4qIiIiIiIiIiIiIiIiIiIiIiIjIzzJ3fAU14YhirpDmCsF6dzJgDoiEGckYk4gKKB4RydY6+77z8tKA+t3b20+YVchzjIF5hUi9OXPCPnZGDCIqRvn+/sGYA/fGWaEEbh833J05670VAaXCrwm57peAuRFRYVQPJyNxNzhiq5GYNwy43+q65oalYb2Cj+ZG636OIbORwNjHioAmRBJz/v6kVjOWmBU3rdIlZ7DSzGrOI4mwp3skSUDW3w3ndrvRVzy1tbaeC5o7ucKyYx+01sAgoyK2HGPEzmDus94rqDrmYOud1jruTmbtgff3D77/xff89je/43K50HuntcbtdmPMAYCvvZNZ8xBzsq8walvxz1iB17nmKYExBlvfzriqZYWGZ8yzDupuXLbtDLS23vG1z8YYYHDp2xn+POKex/vr2WsOMsGcM9Jba1Jzdahhx4qVPuKvtZBgbcWAsU/7sp6rgqsW9Z6X65XIZEbg7mfM+Nifboa503vjfr8/grDmrG4pZg5Wz7vve+3H1rA1r5fLdo6No+2b9fRntPXzloSs0Gv9vPaHP85+fTYBr/N/sFxRX8fyccW6VpyR1+NPZuLeKnS8/n7Emo/14hjD86a0Y8prLX3Nf4WH13mLqO8sq7Cz+WP/Hc+Qxy6wmrN69No3but5s/Zvcz/DvMCa33o/bud6uTkiIiIiIiIiIiIiIiIiIiIiIiIiIj9H8VcRERERERERERERERERERERERER+XlHMNKMJD7FGS0T5xG8rNCnsa+IJQZRZUagQp9HnLT3TkQw52TMUXFMDCO477ECrc7lcqk4ZE7M4Xa/MSPqz3iEVSMDSyNW3LR7xwwisq57xCdXLdLdV1y0ApLuDWJW7JIV28wVHF1x1iTXPCTNG/YUnjQ3urUzHMpxb6/cJDwCpDHzjM8ewdHII5K5YpUZmK0QrBlPScy6RwIWjFGRTjtClusaR+byEZV9hF/NreZ/HgHYfO6VriBqjbkin0ZmcLlciBnc9x0zo7dO6+1TOLbmyGtteo3JN+PjY1Y4eI09CLa+PcU3kxmTjW2NHzLjnDfD2Pe99hNnn7PGOh9znFkRz9ac1hpb9gp1UjHPM/+ZKwFqdizXOf5P83ywo4Ga5wu2Pp8kEXn+6rmjm2ve07Pix/NekdMVww2veXR3ImLFlRMyiPAzDmzr3pF5Bl5tLVrMWa+5P54jYc6o/mvU7jnnOh9n4nmgse5xPHcC/QiwPoVYbdWL7bzbCrqakUc8FVuRVTv3fZ01O2O8c+axS4mIFYRlvWeFdZ/X4Ii8sqLA7rjb2jsBVlHntiK/lscz1hzONbeZNQ/+HKQ9q7qswqxh65nPNVgx5ZqrxFdQ91gPEREREREREREREREREREREREREZGfo/iriIiIiIiIiIiIiIiIiIiIiIiIiPysyKx4pttZ3LTqo4LBzMBXZLH1RqRxv93o2wZBhVabY+b1eq//dbH3RmYj7jcyk32/0/uGhTHnTkSAda4vVzKj/gD7fsfd2cdgH/s5ziOeCRV29RVBdcsVpvQzfhkZ9NbOqOURcMyA1voZjDwCtm7OzElG4K1hGK05M4LIICPPgOwZf133eWqJPkKTERWPXF3KJBlj1LjdKzg7H/HRRyTWnkKcWV3MTGIGO4MZwWXbKlJ5hFatop/7PmqcCc0b3hv3+84YEzKo+mXJ9VxGI6FmAAAgAElEQVS1Tp05J/s++e7rRqy3bZeNfd/58vrKnHEGaLdtg4T7fq8QZ2u03sFqnd39jHW+vLyQWeHPfYxaBzN6bysOWvPnrRLDY4ynIGsyj8gwFY5lxXnH2DHb6NtGb53s9Xt3A57Csma1rdeCPcdeK/J7LGVC2nMW9hE/Xc3XOWNd3z71St0rSDpj8nJ9OWOnFUo15pxcLlfaCosegdy65sTbMd48o8B97SM3I73myebEj/09J2NO3Crye8x7W3t+rHjvszz3VH6aB9zPM3I8a3rNx6fS7IpCH9HWY10Mx/wp/vo0z7nmlVzfM/kIGR97/tsYb8QKFa9j5t7OKHWYndeorZ8rIh24GSOCCOiNczyZce47tzp7qwfNzGTOSWaybVvNdyZxzpOda6n4q4iIiIiIiIiIiIiIiIiIiIiIiIj8MYq/ioiIiIiIiIiIiIiIiIiIiIiIiMjPslVCzMgzonhED+es2Grvna21iqEG9MvGft9XRLESjm7QeuO777/n7e0nPm4fHPXI3hoft48VRHWSii6aJ7/57a+BykgGFZs1c7btcoZkgTU2p7V6bUbQVvixWpPxCGr6IyY69gqKXq4XYgbt0ipqOwMD9n3n9eWVzGRa4q3RzRhzEjPIIzbrzu12q8BmVAyzArHzzFeOMfh4T3p/4fXlZUVBA1aM1tzY93E+U0Uyn0KjtSIrvFuvxMyzzTlncGc/r9W9V4h17rTWCAsiVjSWFdE8RvfUrvz4+OC7774Cxv1+Y85JZPLT2xtzTuactNYZObhcrkQE5sb1egWrGK5PJ2Jy+5hnsLb3XvOWQXNnjMk+di5rLSOC2+3GGIOYUdFgYI654psV9X3anWTO2qOZjDU2sDXGxrZt9K3z/v4OQGtOplfIdP1hZV7dV5w31z4xO+d5rUi938DyETh1ewqefhtPXVfPFRLtrRFz0nuvKO/Y2fed25y03mnNad5o3vjp7Y3V4H2aw405Ru19o8K/+07vnUtrNQdRQVPvncvlQltnc+wVVfbmRHw7xmMffR7/7wWMn//kEXBdkWKeosm5zr7XXj3LsU8BWDNfc1nh1YrbJu3Y43y69edtun6Yc5zfTbniv8/zfkRrL9cLrHhrW+d1zAo6Q0VkW2sw6hzN9btjb+33+3qfr/UMjPXzEVoWEREREREREREREREREREREREREfkZir+KiIiIiIiIiIiIiIiIiIiIiIiIyM/qrXO9dMiskOmKJR6hRiNXoNK5vlzITN7f32ndyQxaa3z/3Xd8//U7fvOb37BtFeQcYzAjyAj2UTHRGZOZc0UjfcUbowKcbmy98+Vy5Xe/+4G39zfut0codYzB1jvmXuOLxFqFILfLhpkRc2LA2Afb1nGzM6K5bRvZKma77+OMvvbeud1vABWojODj44PX11dshUHdnOZ+BiANAzda79iKyEKFI3uvsfzwww/03ulbBT/3MTGc1iqKmlFR2cyASJIA7AyO2gqhGk5EcN93DLh+95XWG3NO7mNgBpfLxpwVfp1jMsYAg5eXF9zvtRYjzrl8f3/nsm20XiHbbdvIXHO0Iqsxg5eX1wq1ZsCAu9+JGFwul4p/mtN743K9VpQ1ky9fvgAVdP369Qvv7x8kFe+Eiq6+vrzy8fHBvu80d7Zto3mD9hz3rD3iCR+3j4p1ZtR8AeaN2+3G/X6nb51f/vKX3G63c33MvfZKUvv6iJUeodJ1H4NHANbg6T9rJc726fqlnZ+FirO6GdY6sWK+ZrbGm7XOzdkul7OROsbkY9wqEnu94OZ1zTwip7CPHaP22EtrZ5TXzHB39jnr/lHnJ1Z09zny+m1a9fHEuRKuxhx1TTPDjz/uZ6w1o2Kx5n6uTa7vhZoOO89jrOBwYljGCvHWPdv6PiGzxnkEXZ8m9/zOyWO/POa5Iq3Qt62+o9aaHWO73++rPVsB2Nv9fn5neKvvjDHGigtnhWBbO+8w1/zNCNyNbbtwuWyQVLR6xYVFRERERERERERERERERERERERERP4QxV9FRERERERERERERERERERERERE5GdlxhlTbN6w1lczMs/4Y2Ryu915/7hVCJSgt07vnfvtzm9+8xve396Yc/L2/rbCpg3DiKww5PV6rbjinIwVsZwxVkzTsRVefHt/J6ko7WwJ7ECFVceYYBM3o7XOPnYiAp8rLBoV3Oy90Xpf4cYgZlRotDXIiq5eL9eKaI6d5m1FM7OCkdvGvu+4O2Sy73ciOpftwpwTXyHM+/3O1jeOSGVmZTVZAdUZFZS8XC5cL1dmBPt+x5tjbowVb3X3xzWACMgIJhCzIp29b0Dy8XFfU2Y0d1przFmxTDeH3sCOEG1nzsGYfIps/uL778kM9nutQ0acgdOIWiM3577faa3x5bWCrpEBWXNpK6zbWmOMiunWGtTeaL1xv9+53W9s24abMwlutxvX65WX15fzXvs+zgDp876873cyoqKd7rg1ZhgRk4ia59Ycw9nvO9t2WWtVkV/mI3h7XP8MnR77iUdidOVEn8aQkEba59CpPUVJK+5b+8fdMYx97IxRIeLeK0Jce6LCor7Cvm1FdEfUe91rX3RrZ3R1RjD2nW3b+Ljd6L1hVuvuVgnWjCAyz9Dq8zyez4+BHSHb2tfn21YL19Y/ZDBjPs0dzKw9YRyd2iRiwooY2zorGbnGxiPUC7TmsIKvcxoRSeTncR5nsM5AQk58PSdmEBXaHTxnYal5WDHY4/XWGu4VbbZv5qm5g9v6fqsxHuHjx/fFfY27MSPOeLGIiIiIiIiIiIiIiIiIiIiIiIiIyB+i+KuIiIiIiIiIiIiIiIiIiIiIiIiI/LzMFbmsoCgrYGpJRSZ7xUHnnPW6VYx0xsDDMK/3jzkwrKKvDq33Cn6uAGcC3bb6vVXsMy2ZWaHOSIBYcVn7XHeEMyqZmRXI7J3b/UZvDXMjo54hV3j1iHyuHiY5E1rFTSuEahWEdQdWHBRbkcsV0EzOoGZm1vXyCFQmc84Kyj4FQ40VkozA3FbYdc3xEQg1I6j5tqw5PNKVmUnaI4T5WKbHNSpsCrGu1VrD3DFz/BjfCtlmVjDTmzFHXe+ybbVmY5CZFbsdg32/M2eFYNulERHcb/cVN4V935lz5+XlpSKZERgQK6h7PNvRUB1jMMakecNbhTi3ywV3X7FaA/faXxE0b8/bkpgTW9c99tBxfTcHrzgnZtzud75uFeKtNam1jiNOusKlx1I9x2bt/NenHz7N/RlUzd/79frUiidbRX3XTfDWzvHmunqFU4Puj9ewmkcy6xw1Z4xBzEnfNqAipzEDszoDkQlzEmbrWWtOzz36PNY87/Rp1LnOW0YSXj9bHs/MU0i2orvHtTKjvg84IrnB44bHPj0WrebHrfb2Oqq/N99mdoZej/OTmQSJpZ1n4mjBGo+Qr5kRGRXNBdqa24gVt85cgWtfEeP1+RWtjXXdZhWtnnt955n7+awiIiIiIiIiIiIiIiIiIiIiIiIiIj9H8VcRERERERERERERERERERERERER+ePOaOMRjozVbDSwiqt6Gm4V0Yys8OkR/QQjsuKUW+8VD/VOc8cscHPu+x13A3OchgHdGzkqvHgMo3tjzBVxfK5XGrRW9zY4Q6yt9Qo/WmDGGYGdc3KGJVf1M1fksUKQ9Z7LttU1V5DyuGfzxoy5grZecc5Y9zginStS+TkLWe9vvZ0R0jljzZWdIVWPqEBlJHY856qAukGuEG+FOR/R2tZahTozKuw6nNbaWhs7I5WZyZw7kYE1o2VjUlHSbdsq+pnJjDgDmkcs1uwRxI2o6C9ZYxijIr8Rscb6iHf23is+CmeM1Kppu/YSbL3X/jniryvgmRGwIq9rtYhMuldQOGKufVI7s7X2CPxGEpHErHBqX0HYOQZkPEKvT2Fcd1+h1AqJfnMgPv91veGMt35zdL7Ngj4HSW2FWbdLrXuueYljL5IVprXH3jOvUG1EvefaO/sY+AqaHpvl2BPr0erzfjzMp1E+nbGnc/UUFA4MO7vLj3l+/k9GrFjs07R4zUjGY+zHfT7FZuvQnlHlx4vPT2QrYvwIGz9iy3W/irSukK/ZY+2MMxBLJrjjwFjzDRWENXdyXxFbX2cNVlTXaG5ntPn8rlD3VURERERERERERERERERERERERET+IRR/FREREREREREREREREREREREREZGfZxU7rB8fgchYcdDMSWtO64alr+gp9Oul4pTA2Af72OnegcYcg2uHbI2Yk0GCJWlGZBA5KgJpdgY4ydWHdCMAIp+itHDZLiRHvBPu+73GRwU/K7RZsdm+9YqfjnHGTZs35py4VWDyqEbOOTF3ZgQxK6a59U6SK17ruFeE8jYGrfUzurn1bd3/mMr66Xa70XujeeM+7ox94M24XC60FZJNa7CuO+d4BDlXILMCpjD2CoVmHmvkWDNyQkU9K8jat63WY43tiN26rwApyX2N83q58PHxAVQI9vbxwXa5cNm2mocI5qxn/fL1a80Rxmtz3t5s3XPy8tK5XC7sY/D+/s7WO75dyEz2uJMJL9cXLpcLEcF9vzPnrPH2Tqy4ZwVg4VMsdMnIFbStUGhExT/7tpGRjDGIDF6uV/bx2Fd2BmL9ERDNx/6Zc+LensKvjwDy+dLz7+zpXflNDXRddx/jvE5rvvbXYIzJ68sLjMGMSUTWvl9z3fqxd6H3jd4b7+/vFc8FxqxYaWRyvV5wd/Z9Z84j/lpjdqtQbnMn08/9eJzpOj+fn/VomxorQnz0kg3svLbVHoyo7wWq+XpEgo8rnpHdc4qO01lzWUuzYrGfxvGYbzvWwI7vA1/nvJ4vjujyGk/9HDBZIepj38T5/WIrJOvuRMSKOde4MpOYcc7RGAPM2LbOGPMPbUkRERERERERERERERERERERERERkd+j+KuIiIiIiIiIiIiIiIiIiIiIiIiI/FFGBWDPOOYZNF3BzTkJwBIMr1jqGMxMwGm9s22Xug7Oy/WFX/7il/TW+M2vf40Z3PcbkIwIxhy03irK6I4TZK6YpDm9G6115v0Rh4ys0GVrDcMYc3B9eWGOAe3xv0tufaOtcKq70+aEFX99/3hn2zaaGWSeMUgDmnuFWTH2MWitrfkY50xULHTNVRgRk9Y/3/vL6xd+89sfgI2xD9Jyvb+ilZFBdXVrnt0b2ON+Zsa2XbjfdmZM5gzAaL2REWRWDBagtYqvHs8x56w4rxtGw5uz74Ozvrn8+OOP7GOvgK3B9XplRvBxu+HubNuGe6v45RjsY9T43ZhzctkuvL6+0FoFdfd957uv3zHGTnLH3dfna533fQeD3ju9de77zpyD+/1Ob43X1y/cbh8VIl3P5uZcLhX8vd1va39U0NXdmWOuSHGFRMcMmjtBMvcb7kbv/fHeOK7bwCHmERd+zMsjlvqp9HrGkb9Jlda+nJNYodGMqOjoukQmZzD1vu/MCOYMYk68tVrD3tm2jpkxx2SOwb7vNfdrLXvvZMaKuia32519v9N7P6qrdY7cz/lp5Kf467FnHt3afCRgnx73eJ+t+fb1zpjrdXOMRyTasgKtzR/R3ePqx/QeAdjn3/J0jWc15bFiuBWBjVnfQZOKFRvUfo8Akn6c/6eAcmTgVCT4iLxWCBrmp7B0nsHj3hutr7WYk613mlfEuTf9L9kiIiIiIiIiIiIiIiIiIiIiIiIi8vP0fxqKiIiIiIiIiIiIiIiIiIiIiIiIyM9yM7w5Zk7EPKOoUFHII5wIiaVhWZFYA16vLyvhaEQm99vOmMkwY7/fyUzGvvP68sKXL195+3jHgOvlQhorTFpZSHfDvDFmEDGZMdnHPMe5rZBnQoVnx6goY98wN2IFHPex8/XrV97e3lZstLGPCrgeccwjtDnmYNs2yCRixVhXKDYzad6YMRn7TmsdLM/75ApU3m/3syM55uB2v/Hd16/sYycyIMHcVih1rHis42YkNW6rbiaZFbUc+86YO2C0tTbuTrqfgdGk3nvf91pDr/eZ27pWEJH01mp+ntKlP/z4I2bQWqNnxS7dndeXF8YYzDnpfWPMGxe/8OX1lTEGP7290bxxu9+5Xi7cb3fGimRiFTKt4ikrJhzEDO5rL5gfcxv01rFL7YEffvgdv/zlL9fnau/linLuo+Zh2zqtVZw3M7jdd3qv0GlG8vHxwcvLSwVi/ZiPlSP2hlmsdbK1FypszNq/FRo9EqUrXkpCWpVQqdDpeTCO89NaRVgNIhLcVsQ2VrzV2frGfq+5Auhb53q5EhmMUfHcYw2AMxR8BIHf3994ub6csdMjp3rEcj2TXFHh2pvJnPEprPoIweanAOwRtn3+XWadA0hidVpzxWRthYTt+H5Ye/MYO8esHv86ArDniytOnI/Y9Pm5yAoYr+8cP8dmZyw3zjmo80yuz1gFg4/nzISZj11f5yFq5Os99d3XuV4bcwzGnJ/OlhmM28BbW/cVEREREREREREREREREREREREREfnDFH8VERERERERERERERERERERERERkZ81owKUzZOIeUYXj8gjK/RqVsHGCqUGMxNvjcRWLDFXPJYKe7rT3Sv0msF9vwNJaxXsnDExq2BkrFCpJYwVak2O6CbrPckjU1mhzgo0Gr5ilK03VrMSNz+jrsd72wpIHsHJMx4ZK9J6PDNUpJQjZLrGuQKQGevzzXD8+Ai55gbmGeGMDAigNxzn+nKht1YR25jYNHrvuDmTYEZUaJMVUH2KfB73yHqBBMaYFaztVOh1hS3NnGSendLnyOblsp3RzzM+C4x5jDl5f3vD3dnHXvFWOGO65sa+70QE7k7v/fw5M5kxyVnzPud8CqvW/S7bZUV0V9Q2gn/wD/4BhjHX+q9lrkBt62uOa6DVVa3rH3Pc+8b9vvPy8lLhV5KxD5K6hq09Elk10rbGuiYLN1vh3CMemuefYK598ZjDhzx/te/7OR8ZMG0SkVxaY+yD5hXndXPmnGss6xIr9jrGOEqp672NtgLGR2R3jsn0OOOwdoz/sdi/N1bDzoBrRV7r748dXz8dr9V5q08dc59H2NcMvObriA5/OyWPwuwRm83zThW6NTLt3J/P4pwbX0HXY3hHmHeNM2tsZiuKbI9n+fRfo6611vfYk0dxeb/fz7Mda3zbtn3+zviDay8iIiIiIiIiIiIiIiIiIiIiIiIiUhR/FREREREREREREREREREREREREZE/6gx2rhDoc+cwSdwq8ugrurj6mWQEccRJyTP+GZk0jsijs++jAqskeH2O9fsKbFYA1qJ+Z+4rSPooQ2YkQdR9Scx8feaISFZI0swqqup2Ptdz/LXCrUmSZ4T1CFrWeKLG3xsxa8wVE30Ka1YNtz7D53qlrX/OeOx8xG0hHmHP448dAc2K69oRel3PcpQvk8BwkjgGfK5dmq01s2MQNG8Vnl0h0Of4K+uerLjpvoKrEfNc+hkTIsCMsQ/cncv1irszxljRUcfNKhQ6J82dmUlGYl5zPucRFK7QK1bR3cgK9/bWcHP2MRhzfBqnwRl+jVgx1qjN597ItPW61X6IAHy1R9eeXs/fWltrtiK6Fo/Yr30b9nzsp0w792v+gf6rrffWPQOy5nbm8x6v8XhrZ6D3eNYzNgtrjxxnLNc4ar3O8PA6e635U+iXdS4qnGpH2PbTmj+P3UirkOuZZH36fX779jq2xAoO+9NzH+HX51vlUyr1CL8+T9sZkz4G/iTz8ennaPD5OXfIeArKUntwnaFj4Ee4Oc+ILUc7eJ231X59GvOxnu4VB37Egj9/F4mIiIiIiIiIiIiIiIiIiIiIiIiIfEvxVxERERERERERERERERERERERERH5WUfkMmacccRDHgFLr6BlWzHG5om5c58TMgkDw/HmTCr4aVbhzXsEEYG3lU9MCIzW26NkuV4/4q2+yoxP3Ucig5zBUXc0NzIqFJmRZyRzzolFYBhBroBphUENI/2RofQVaE1P3CtEuY/JnLOqkFnX9KqAYjjYI2R5xGKf59Ldab3jGSt6aiusm0QE930/w6c1x0/FzeeCJiuSa+1YjPPez+HMiMDN4QyQ1py21ipku+b/+cq1PmvujYq5whnJtBXS/PHHn7heryvQWzHRyOCnt5/4+vVr3X9Oxr7Teq/wb6yoa+987DuZMFd4d3Nna73WMlZU132N17nd7rz9+AHMNaHUnporfBrJnJPeN7x15gyOtOeciXsnc813zrOwO3Oe9/MVgD3itY+I7tG6raDpEfZ1N2bWhWyFST93dNesGbQVsrWn37k7MeexlfDWcDPu93vt8WN/RxBRz3bshTxfD9yMMefab7W+EXFGf1fStuZ6zdXzmmfm59DpEX5d8eBH7HXNx9FRPbbnEUrNFcFd7/28j58jw/bpfkczeW2wT8Hl5zGyws7urIDysfd5DOjTWbHzjB7PkGdsGcg4dvXx5LTmj+qrQesdBisa7bh5xaxbY9zvdf5FRERERERERERERERERERERERERP4IxV9FRERERERERERERERERERERERE/kSY2T8L/KfAXwcC+LuZ+R+a2T8O/OfA3wT+D+Bfy8xf/1WuWcHOiiu6Vexy5RwfEUsMN2g45gYr5okZM5MRwZwV/fTm9F4RzDkm7x8fbNtGzqS501ujtcbtfmPEI57ZWz/jnMEjNno44q0QFXv0CjT21lkZS6DioBlJ3xqOVwQzg97aCmO2FW1NxhyPYGur4CcrQAsVCz3CpxUaXdHQFQXFHW/t9+Z0jMG+72QG29br+bPGFnMSXtHLyFzPX8HKR9gVIh5h1/p7YseanGM8VirZ952Y84yZsq7JUwD28Pr6yn2/se93eu/82Z/9Gb/97W/XPWzNd3K5XM4oaWYyxsDC+Pr1K5ftwu1+Z8zJ9XLl9eWFj9uNXKHZewS9b+z7TnOHTO63G+/v73z//fdrX7ECp5N9DK7XyyO0ue43Z8WEazvUfoiM9dRH8nT92xp8WqParxE173NO3Kz2YO/nGM7q8ToLxlwBUq+07Aq6Pkd/D/vYud/vuDvbdqG583G70Vtj6xtJnatYEdKx4r9jDC7X61NsOYmo4K+5QdrT3mzr92sfRhArvDoj2NZZhKS3jTHHp32wpvPTfB17+Ygs57fl5+N5j3lZc29Pey+T2sPr9YhHfBjLp/uyorFrfz2d6+dhmhvNWwWB1z0jai2a17kdYyeiosrHusSc6/tgfZ+t69f3WXtarzrT91uFd9uKD+9jP4PFcwb7GDR3Zuz03uvMPkWeRURERERERERERERERERERERERES+pfiriIiIiIiIiIiIiIiIiIiIiIiIyJ+OAfy7mfm/mNn3wP9sZv8d8G8C/31m/h0z+9vA3wb+vb/KBTOSiKjIqVfQ0Y8O5IrBHlFVAnIE7x8fYEa/XoiEmUGs5mPvG3MGEYMkef36yj/3z/zz/OVf/j+8v71xv+9k3EgS863CkUfENAJfMVRvjdGOR4bmTuv9jMKaOyMHEbOu4BWlbK1VNHWFW8MSViSy7mSPiud6fm9+hlevlwu9dz7ePwDw5njzis+arQgtZxy0eXsKpkbFTvsFdyOiIqqMyYy5GqMrTrrCnkeYMiPB8oxnHn3MJNbPSRJ4MwxnFTvJrEBp8wqaVoQzmGPSmuOt4y2pduUdgPePd9zr/hHBb3/zW7w19v22Yrew3+/8E3/tr/EXf/GXa7wV4hz3ya9+9asznNtb4/3jfY076X3jer1wuVx4e3un986+7ysM3HA37vcbYx+8vLzgGDMmL9eXitUe80HFa1truHUwmHNyv+/M+YgWVyy3NmzmZMwdcp4B2CNWevY/V3s0ImnmnBHZ1Rr2FUGt5mkSGesMcEaD3fzcP6+vr/RtY4ydS78yV2R27DveKgjrrfH68lqh2zkZY9B6w824rziuueMOrTdsGhFJRjDzCJ3WwM0ca3Uejr34sObuqK0+cTdmHJsqz/Uyc6r9nGdU+IgNc4RcMchYsdg6p5hxzEIFfB/vP4LJjz38iDxn5uds79MwzQzzOqszc8WMj3MaK1TruD89x/rMEXw9rlNns87oYz8lMYNtRY0zK6Tbt+2MzV62Cvbu+87lsjFGhWWP64iIiIiIiIiIiIiIiIiIiIiIiIiI/CGKv4qIiIiIiIiIiIiIiIiIiIiIiIj8icjMPwf+fP38g5n9feCfBv4V4F9ab/tPgP+Bv2r89Q/8JaGCh63inl73q5CmO713Eth6rzhlNjAjqGhi79sZ5dx653c//JaIIDIruAhnhPUINa7aJpnJnIO0ICIeYztjpzVIp64/RgUiPSrSama4Vcx1Rl2jt8ack94bM2KFVo9nrTHFSAbQWz3LjElrDajo6IxJ87bilUAEc84Vb60xxaz4K1aR09bqf+OMrMjl8dpxjzyKo2csM9df67l9xXjT1p+s6KdZO2Ol5k5GBV/PluYK8la0dsU2nxZ6H4PrZePl5YXL5cK+D97f33B35pxnIPPj44Otd777+pVMuN1ufPn6wv1+Zx87MSuy+/13352f7b3j3iqk6sacNU+RAfdHUHXsg4+Pj3p2YI5BAmPfnzc8cw7GGE97wYiYzIgzAtyq/EtmsI/gum00rwhwkmvOzsRwxXHnhKd9CobbI6VqRyjYjCOBWtvQzhgswNvbG68vK0a872DG9Xplv9/XegYzHvFYqDXzbOf52LaNzOTjdmOMD15fXmjuTGovrO5pRZHd8XVmIhNv7TwTAGPOMwz72fE8nM+T6zw9ZVN5fCPUs9vxchzPXO+PzFqD47nyEXQ99tvzuHi6cj7dw57mMmYwx1iRV6P3vr4zKszq1Pms8G99n1hmBZ8/3WudxyMge14j2O8V5e19q7Cwe30nJfg6kxlZAdox1xnM33sWEREREREREREREREREREREREREZFnir+KiIiIiIiIiIiIiIiIiIiIiIiI/Akys78J/AvA/wT8UysMS2b+uZn92V/1OiZUq+kAACAASURBVBVbBUi82Yq8OkkSkewRtObVU6zqY4U8zbjfd3IFYc1aBRMjaCRuFXTdx+B+v2N5xFjrXmZHkHNFYFkxyggsK/AZ8xGwzEgmk1zBSTevAKZNbP18vDaZZ2nyjHuuYGZmkr4imLGikFYxyYwKPx5RyNYahjFz1rXcsLAzXmlA88YjDfqI184JrXk9pxutdyInSUUz3R1zJ1YM95GWzLUGhlmruc7KdcacpLX1nhV/5RGnjAwsK655jG3G/L145dZ7xXrX67033j8SZ4V413rsK2aa6/6t9zNIC5zzdL/vZAavr1+AZB87Y+zc953e+rrmY44YVEA485y5n+47Y47HOFfgs8LDcb5eDeAEogZpSdpxnZrLMYywR5g0rebzOXJqZkTEGR8+oqqPaGk9s5utq3LGU41HsHSuPXoEV1uvPdN6rz21xl3rwAq3GmS9f8bEplegNOIxL8e+TXvEew0sIYCMuc6Bfd475BkttjNma0/nALxmb03zSrYe3dcVWX5M1RGAtU9t2CPAetzHnj6Sa/2ePc9pEBxn5jHGdb7cOcrGFTx+fI7jvetZ/Jtn4HHVT/dmnf+WRm55fl8835sVmD3Gfj7Dtw1dEREREREREREREREREREREREREZE/QPFXERERERERERERERERERERERERkT8xZvYd8F8C/05m/u5TxPCPf+5vAX8L4BfffwdArOjhpzimHSHWJGJCtkcUcgVT3Z0xBuaOH1VKqzpkRpArIrrfd+aYbL1VpHEFX705xgqZRkUrzYyxD3pvkI7lU/w1A8tGZEJCZNC8VQSyVfjVvEKeEVEhVAzzx3Plilu6VzxyxFi/eMxRRFSs1dv6zCOc6uaEx9miPFqZTzO8gp2skGmjNaO7496IGWRUotQssVVwNcBtRT2z/lWxTl8NzTgWsMKnuSK6awAVGeWMmdaYHmM5+7FL37aKd85gH5PrZTtjvL130pMZNc9mxj4Gbn5GgG1FYps3zJ2Pjw9iTq4vLxUnXYHgiOCyXWit0da45py4OckKoa59F5G8v7+z2+DIu2YEufZL87UnyfX3ChRX5zNr/wHGiu/iK+DrZ6j0iJQewdc5B4Zjxxrbo256/PsI6T42in2Khra2IsHuZ5h4nlFZqzX3usacE9xp1sj1vkwq6rvOYesV7D3vY0dsN8mj0Pp8Zo/1XjHgOgeO801Y9fi7Pf5+7O9nR+j3WHuO4O0K0R5zUl3UJGec5+k5jJsc732auzx/Wtv58/fWEW+uuZhr38aaizoXM+b5ucf8PGKyx8PZH/i7Ab7CuEc9Ode4zv32NA/mds6ziIiIiIiIiIiIiIiIiIiIiIiIiMgfo/iriIiIiIiIiIiIiIiIiIiIiIiIyJ8QM9uo8Ot/lpn/1Xr5/zKzv5GZf25mfwP4v//QZzPz7wJ/F+Bv/PV/MuEILtqKnIL5U/CRFUs0r1CnV2DVWmPbOhHJXJ+rZmnSWzt/hrqeN6e1jlEFTzejtUYMI2Iy5yAiaK1x+9jZvnZeLlfGcODjeG761rFh5/srFMmKNwYxOcOwc0xab7hV5JOEfey4+yNculUwFTMaviKkFY1NS+63+/r9ep5LBUsjK1g7YjDHOBOXZhWN7ZcN9hVBncmEFbjteHN684qUjoF5hV8xq7DuipuSxpw1NrcOBq1tZ8jUfc17BsFcsdqkGpzOnJM5E9LIMI7OLUBGzX/FUJ0xgHTce613gq0g6RHTrfvCtjXe3t/OSCeZfHl9JSL46aefeLleaa3jGP1yOcOh27YB8OOPP/Hd16/nfB1+9atfYW7c3u/MGSvdeURIwczXvNe6e3v8PbOinea+Ep8No8Kv7l7PfBQ+vYKzWO39zGTOWc/YOs39DPpmBjHzEQytFz/FgrftUnOx9m/MYIyxwqIrHjwG18sFz5rHfQzG2GneeH15ATP2fSf3ndvtfu7R40bnXKy5rGlfwdoMeusryQq99/OMPSdLzaxiw09nmzVnn78k1l2PPXlMhh3zkuc+zRVPzcgzdvsIxq5Q7jH3nJP6+PkbeRRs8wiy1lk4zuVYcd2t9zMe3Huvc2+24q21580rGBtR44MjqMxjf62wMOd3lT/u/xyY5fOai4iIiIiIiIiIiIiIiIiIiIiIiIh8S/FXERERERERERERERERERERERERkT8RViXC/wj4+5n5Hzz96r8B/g3g76z//td/1Ws+WocVNTWcyGo3mlUoM+rezKzwI8CIqBBlxOo5Vihyaxv3sRO5orLAdrkQkbStV1MS47Jt9JeNv/iLv2DbNr5+uVaAcwa3253bx42P+6O4aG7krLqrYcwx8BWRHGNfsVnDLxVRbc2xhMhZcUo3mjUwKtC5D8YcXLYLY+x1D+wRtMzE3eh9W1HRClBGVgy0rT9zTI7M5hGXHGNfwVQjSWbMs3lplow9aN3pvTNjrK7kEdBsFagcwYyJe/t0bY7YbT4Fdtfc7/u+ArydrW81xu1CzAkBH7wDFQhtrVWY14yPjw/2/U5kBUx771wuF3744Ucul63WdlV2f/nLXwDw9v5Wgc1Mfnp74+vXr5gZY05a67y8vPDxcaO3fkZeW2v84hff116bsfbfipg6zDmfGpuGm9NbJ2ISZGVdva04aoOYxNq3JFgmQQV3wYj0NW9Gc68YsPsKqAZ47d+YsdY8YOuYrZ1lR5DUz7muVmico5xznPN+PM9l2xjjESgec7Kv2Otxz4rZBmNFdjOD6/WCWQVIj/OYsKLLFWk9YrYRkzEGcyZhFQl+xE3rmpF/pFi6ftXOOO7aVysMazyFXAEs1v4z8IrOZqw9uD6caeRZlbXzJrbOwRGVNR7XzacxHmsFsG1bfR/Z430x5/na8XxzTmJOvLW1hlQu9ikye/ZrqYhwdXVXnHeFjXm6zzH/56T84VatiIiIiIiIiIiIiIiIiIiIiIiIiMhJ8VcRERERERERERERERERERERERGRPx3/IvCvA/+bmf2v67V/n4q+/hdm9m8B/yfwr/6Vr2hWcVMzYg4qmplnntHcV6yyQpHmRkQwoqKnGXlGGyOCkQM3x1c40tyJzDNWaYBbBTEbA2+NiOS+71y2C71vvFxfK7TKjZ9uH0DFIDMS5gSOIKbxenmp9x4RR+ByuTDmYOyjYpyXC2bG7XY7P2dPQdPm7XztCGeaGa01cgUmzQyjIqIV6IQx1j14jmxW6NLcsKh4aM4g7IhWVqAzwojmYMHleqm5G7OeI5KIpPf2CGyyoplmK6DJGec0qzjp9Xqlt1bBWpx93wmb6z2PEY4xKiIayb5itl++fGGuuR374P39nevlipnxcbuREbTe+Yu//EuMmsutb1wuV1pr598jJvcVkp3jMZfHvM452bZtrffGZdvw1tj3ncvlsvZNxU3f3z54fX2tsa8Q8RkDjVxz82hzRiRzDtz6Ged193MMR8w1VpCXY16b4VS49D7utc5HBHfbGLf5iJTm52ApCZfrBXfn/e2d3it2u23bGRK+Xq/cbjfuc8fN8Ob01phznvPi7my9s49BrAhuxHrA3mmZzIjzd8d6ZOzMCFqrIO6cExL2FSB+7MqnAa99f/z98Wh27rOKzNojaks+7SPD8IrArnOXRxja6p72eYrWFXKd3bWPk09n57jOuV7nvl/r3xxbIWePx3OZV8z37POufeLuWOZ5f6jw7hF+PQOwQFufyfXa+fNT9FdERERERERERERERERERERERERE5Oco/ioiIiIiIiIiIiIiIiIiIiIiIiLyJyIz/0d+PkP4L///v7KvOKZXAPJRUSSpP5iRR3jUnJzx/7Jz9zyyLNl635+1IjKrunufc2aGM3c4AAWNQwH6DHIIyJMIyZIgQwANAXQFyNDLBxAgUzY9AXIkT/Qp3A8g2ZJDQKBA3ssZznnZe3d3VUbEWjJWRGRWde8zM9SVLjl4fge9d1dVVmZEZOS2Dv4ABJoESRM0JaAUtB6prGYRadSEag05JbgYkiYsywJx4MPjVyjlKYKYEpHZslVspQIeAdShlAJxmWFI7QHWvi77D+JvFUXO+S5euYchAe/RWwV6mLWnVJFSijalO6xFWFZV+9x7AFMAcUHK6TasCYdKBGBNAFgfl8W6AQJVgblAzGFuyLkHLzHCmIpmBcc0pnsPnvb59pblTQw1orKG6/UKgfYAagbcUQ/111hDIGKYDbU2pBR7oJ821kAVl8sFogpNqd8fw7IucQ9FYG5YlmUOMucMTQkqgoaIzJrva78sC1prMGswS6itAT2AGgHfOFVrhs+fX1BKxbouSDn2zbJmuEQcNmK8CUCCedwjN5+BX/TjNKXDHTLUanH/e2DU3fqe6rFfa2jeYN4AcSRdbiKn5ntUFYI+nx7xbTbjutIDp816PNh7uFQU5hZ7pDXkJUNFUWqJp7GvtagCiOhyXhb4ts1Ar6rCWos93PeDAFjWEy6vrxDRm38opMdzXQSARaK4d2B9bN0ReNURQt33y/GfhTHvGSMe+xMOs9l1Pbh9BmOv76HZ474cz+vYM24W3+rXGRHmUace/xbUWvvwBTYGdLhnI/Y6xj7/GT38WyeqmIuyH7HPlYiIiIiIiIiIiIiIiIiIiIiIiIjoCxh/JSIiIiIiIiIiIiIiIiIiIiIiIqLfb0ZR0WOvET/0HlQEBK0HSmf00T0ikypQ1QhSmkFmhLXHREUAFQgSNOceZQXyuqA2Q84ZAsHzp8+orcdINd0EF2upyHnpgdIeiOxxxxg/gB5IHYFM74FPVcV126BJ0axBXXvgVWYsdojvREey9qinHNYGvgdZ4Xt8dbweYcsZupw/EpFRS3DZj7VmN3FU7XFLKejrOyKcPTrqhzGMEyFimYo4ttUGEY859s/c9mBp3CcHJL7brCHltC+iADlluEX4No+Ya2to1rDKOscVod24z80MIznqDuS8REy1tQj85oSkCSkleB/HDKr2wO5cZnOUrcLN0FpDzhmtRRw2pYin3kQ5XSLG20PEmhMUgmb7XjA3iAPm7bC3Yq+OaumIsro7anNIlQjozvjobX1ZRHqU17GuK1qtM5YqLjBrc65y2DjeA7IztIrYC5piTUbUdXx3ho77XTqu3UiVjs8cQO7x3nnPReHRL4Yh1mrfpccJjcCx9nGOq461GmveI8iqcGuxn/uNd5/LdTjvMWQce+9NUHU8yj3CKtIjsLPPKvO8+79VMZ6IOI+uq2B/MsYj4zN6LB7n2R+fWbmdP/vT2xeFiIiIiIiIiIiIiIiIiIiIiIiIiOhHMP5KRERERERERERERERERERERERERD9qBiBF43fZ3494q8J7SNNhPcwKeGtIGvFPkR6zFMGSF1i0YWFwLMuCUgqSZkCAZnHF18sFHz99wvl0hkDwu2+/gwDImrEsK7YGAJcYiwOqsgdeR9TTvYc1BYYIhY4orJkhpYR1XbFtV3z14St8fn6GyB6cNTO4xTnQQ54NEQBttc0Qakop5m89wtoXSHQPQ+4hTYObIQ7TCFU6YOZwMcBTrI15xC0tzuMSQU7cxDPjF7M9GBqxWBn93Xn1Ean1hAiyuqO2FhFX3+OvOWdYX7+Uco/OKqCO1nqqVnVGV+c1ZV+vCOxGWLeZRTDTDBUV0mIcDw8PeH19RTOD9PV2d3z48AEppXn/zAylFKzr2qOjmGFXa47rZcMmBXq54rJcsa4LUk5Y1gXHkKpJBGRTisis9DUY84+4bI/pCuDW4r4DaK3BBbDWsCwRJzY31FZRvUJ1BEYFmvaoqojEHvCI6LYRsUX/fq2ACHLKMIl92cz6flYsyxJ7to09FftuWZaIMHt8p9YCGwHfvjlyXtBajXvS13LbNqjsceOxg0Qk4sAYsdQ36dV+6r5fD2FUx76f9uPGbep7rpeiXfqTcBerPb6K2K6/CemOE6e+p5JoT/OO6HR87m4zHOs9kDz26byO7+fT/pyMdnJcuAdi40bB3WDQeG4PQWkZV2L/lYiIiIiIiIiIiIiIiIiIiIiIiIh+BOOvRERERERERERERERERERERERERPRFogrVFIFH1Yip9ipj9Bwjrmgj7NgDmBFxHcHK2qOrEQjVPGKYhtIaNGVctw2nVSBN4FbgDry8XAAHrmXDkhb8jZ//HG2rEcL0Y9gUWPKCWipUNeKaGjnIWvf3Zui1bHD3CEIKUErB+XzG+XyGu6OUglJrxFPNAQFSSlCNsGRrDaqCvOxh1JQTvO7hV3fvYVE/diYBRCjVPZKV0iOaEec01OpwB6S1iFqKw8wjvooRnvQ5JzPp6+x9rDIjrxHqjHuWUoKZo9U4NuUVKWUsOUNFkDTh+YdnAOihzIivxrwV27ZhXRc0u2K7Fqyr4PHxES8vL3HeVlFKwbIu+PjpEx4ezjPmas2Ql7yHeAGYGZ6fn5FzxtPTE9Z1hbvj0+dP+PjpI77+6mu01rBtG1prOJ1OEUqd1VCZe2Cu+dZwvRTkrMhLnDeivcC6Lti2gmVVbNct9m+P1UIAFY2Mp8bYWo/iqkbMVTXCn3nJqLXC3Of9fN1eIyibE1JKh8hvXCOpAojzjKhwSgrtn3t/Tpa8oHeA0WqNwKt7jKvvxYjxRlw2L3HvXl8vWJYFqgD6fBzA5XLBw8MZpRRYM7hEaFnE5roC+96DOACDwCHJoS4wF4hHeHgGhQFYM5jHGkGAJBnNWg/DRk017suI4tq+Lj6egXF16b1V7RFaIHLSx5XE/Dfn+Hy9V171EUfu4dYRJY4Q8P5dGfd9HCyAuM8YbsSLHTZjsbfXm8fJ7fWJiIiIiIiIiIiIiIiIiIiIiIiIiO4x/kpEREREREREREREREREREREREREXyQiEJUesRQ0a9AeF4XbDD46eng0ipbImqAnYE0LkkgPhDZABMt6QmkVBmBNCVvZkJcFtTUIBLosKNsGMyCnhFobXl8uuLy84uH0iJ9981O8PD+jlDLH2VpDSjpDtK1VpJTifD1aW2sESjUpzAxb2SAieHp6Airw6fMn1FIBROjWELFMtwhZWo1o5bLkCEq2FnFXjZik9YiniET4VB2a9CZYaW4QP/QiewQzMpfxZjObgd3WGp6fX3A6r8g59xhrXGOsp/RjIXsoVERmIBYQLMuKVitqbRE2dYdZw/XakFTRWp1reb1ecD6fAURAtJSCp6cnXK8bVBTr6YTXlxd8+vQJeck4nU44LxHPHeHUWAuJQDAcry8vOJ8fYpaqOK8n5Jzx/Pw8fyAC1YiFfvfdd4eIrcwQrB+Lvz7iqmmuuyZFrRWX5w21xF5NOeHDhyfU2pAkwcUgCdCUkDXPe1da2cOgqj24CwgUOUUo+OkpgrellvhOLTinDHODV4OZReT4wNwB7yFZEbRm6Onf8ZTB3VBKixCtxnVra7BmSDlh0YzaGlQTzCIMW2vFtRTknNHaiBxH6LSWgnVdYWbxHPQAatk2qCrWdUVOae66GWg9xFEdPX6MCDrfJ05jr8UdbtbDxCKQm/Bxj0Ufoqrej4mm6oj5ol/bZrhZcHtNQfw7U2vtz3mMF+43mdg5DkiEW3tgN64/zrPvFyDGY4jwrwNQt3n9OQoR6KFAO9ZI9geYiIiIiIiIiIiIiIiIiIiIiIiIiOhdjL8SERERERERERERERERERERERER0Re5AdIUy7rgFz//Ob7/4Xu02nrs1eGtwq2HRtGgMIgLbKvQpGjWUBGhxfV8Anr8EiJIqqjNkDUBLihe4zNUNHOkDIg6RIFTSnh4+BrXywXFXiCpIuW9uKi9pioSgU3VpY8/YpEjaAkRoAcxkya4e0RkRbBtG3LKERs1i1ArInjbrPUQJpBTBEMjVhuxTrcIf6pqj0tGGBeydyHdHdZsRjDne+6AC1IPUUYMtEdIkQCM9+P41hyiAoVCXAE41AzeI5vuEeQ8BlhrKRBRpJRm7FRVUUpBFYFV29eyv9+swcyxnk64bmVGRN0dfn7A6+UVS16wXTdc/YqUE3LOUIkAa04ZeV2RUsKSF1y3a1+vBGuGbbvGei4ZrcX6Jc0opcDdANsjtimleR+P99xjUSJUOgO8jpwj/OvmqKXi5fmCUjZcXi94/HDGIhFTBVqspaYeqjW4OFQU7tbfF9TSYN7QaoMIoKLQFLHVrHkGb1srsLqPcVkWpJRinfv4zQ1omPFTgSDnFcsic74iEmuYcwRl3SEiuG5X5JSxbRsAzHVZ1/Um2jr2sLthWdYeDdYZLQYOvVLpf3g8LzfxVwdEvB99F4A9hFQxg6uIZ2zcJ+8zFMHt5Xqk2CPo6rP+2tdF9nPO7/Wga7M252uwQzzZISNeix6XHc+9O6A956oAvIeJHXCPyG6zCPTCHAaF9ktb/358TfaAbH92RQ4RWyIiIiIiIiIiIiIiIiIiIiIiIiKidzD+SkRERERERERERERERERERERERERf1gOKrTa8PL+gVY+OoiaICqwhIo6iSCJQtIhmSupxyz2MOAKdx9etNYho/GAPeKaUkFKPNgqgKlhSwnZ11LYBCojuYUhNKSKZZjdhVVWFue3RUHeIKFQU0IhdttZ6aFX2KGUPTaKHKUUEojFm8wilppTmdax/P6fc18UiLnrThBzjwvsxTOy9yxlZncfI/H4EXsev8YuqxtjM764Z8c3oVx7WYZz3puY53pM5fwGQNKHVDYa476qKx8cHuFvM1Q21VmzbhlobliXHVfUwXgA5pR4KBZq1HoqVHqIVJM2H+aQ+z30/HNfjOD/EFpn7agSA3eK7DqBgi/tsjsvLFdu1xHWS4HQ6YVkXiAgMMR+4QCX1wG4/t0eQdcRZVQ/rij2a2rzN0ZlZRIMdsMPoR4RUof17EXjV/p1mBrgjJUFrUYrNyzLDrcf9syzLzQ1VlT5+QTNEmLiPbVkWNN/HOpZw7PMxj7ER3SMgrOI9Atsjy2MuIvO5fRN+Pd6jwx0aZ4i/HOL7XFz2cOubcwkgqkg9tmrezxbFV4jEHkkpzTCwIOY/9t3MxI5LjD3V10169HfMyRGRYeuv4T4DsHPOeOchIiIiIiIiIiIiIiIiIiIiIiIiIiI6YPyViIiIiIiIiIiIiIiIiIiIiIiIiL4oIpeKnDKeX17gDqzrgpwyIIC1BtGooor22KIDKWkELHvI0SGwHsqMwKLPuKJZQ9LboGXKCZAWMVd3uPbziaC1Pc44qCia14iw9nipW4QgBQJRiWCkWbwe1+oRx9YDo4DPAKuK9sAkkHrws5nB+zhySvAeMnXzGQQVkR6IfC8KuQc1R9hyjLdZrEXEcCPgiRGlHT/ez2HWY67x/gieWs/tHkOzo456jNyOsY2QKewQJhVByinG1A4hU3fAGkQzTsuKeqoR713iXNfLBddSkPPTvLaZzXudU56BVhVBzhlujlorcs5IKaGUgiVnWF9jM0NrbUZ9D5nQm/sf04n1UYm/Y41i+lZ7FNiA62WLdRBgWTIUCVl6tLfvH02K07qiWVwbiEipiEbMtS+ZmKOkuo9FRqg3bNs2I8HY7yJEBUkTVAW1NrQW12g9+rttG9Z1Bcxg1npkNZ7FETUe11yWBaWUGSOV/iCmlObaWQ/AHoPF+0ruodMRRR1R13gYfB4p2NvCx3zxaLWOMPGb/uu8WMSIRQ4HHB4Tcenx1/05PA5UEGHguZdVMZ4l6bFa1XQYO3qYuV97TGCGqcezLhCN/626YZzL5zVUDs/SODf6v1lj7xERERERERERERERERERERERERERfQHjr0RERERERERERERERERERERERET0RSqCp8cn/OrP/iaqN3z73bf45qtvoCp4ubyg1oLT6YTL9YrodSpyj3cmTSi1oNYGEeC0nmGI6GetFWKKdVkA9JBm/9vhcDe0WvooBNYisJpzRisV1gy11TnOUgqqNeSUZpgWPSirojN4upUtvieI4xDx1qSpj2NERT0ik7VGIDJFDNVqjTipO2prEeQUhXnERS+XS0RSe7jScYhsusNG91WOkcxRo/Q9NCrSI7AK1Qy3CJi6AinFXGo1OHQ/dx+3I8KnMQiLoKaOeUmMy2/jqTf3XAVJ47xmEcZ1dyw5Ryi3Nlxlg6pCVVFrxYIFAuDT58/4/PwMN8PpdMZpXeGIEOnL6wtEBA8PD3h6+oCX1xckTXFPzVBrRUoJ5/MZP3z8GEHOHh9urb2N6fa454jnYgSFe/hVk0Lvopxu3kOfPQZcDZ++/4Tn9BxB35zw4cMHfPX1V/j6w1d4fnnGy+UVrcaeWda8h2hHnNbKIeaqEe3ttm3DkjNyznGb+7oCPTqqCSIRuF3XeBZqbVBRJE0RM+3B1tbqDC3XWpEOwVx3n6HeiJVGvLTUgtN6wrIs8L7Xx5oe19Pc516Vnngdn8+Q6nhxrLuOhnLvErv5jLeOD0Zod99uHmt0jL5C9r5xD9HC7SYia2bxzPVzqeqM0Tow519rhWoMKO6V9sir9J8+Ft/jwGMsmhLGAQ5A3GGtIeUMlT2WPILP+/iJiIiIiIiIiIiIiIiIiIiIiIiIiL6M8VciIiIiIiIiIiIiIiIiIiIiIiIi+qJlWaBJ8fHlE5IqvvnmG6SUIrAoil/8/Bd4ubziBPQoa8W2GVJKEVVNK1JaIQKYR7C0tg21VjQzqEQMtlwvvaAoMDe8lorTeUWrEWZdckbKGdfLBSklpJxRigCI4KMmxeP5EdYaamtwN5zWE0otUNEZbXw4P6DUgrIVePYe6wS2smFdVlhrEBUseYGowFxRSkGrFSllnE8ntGZorcYxImitopSKb37yDV5eXqDuEbI1Q7O2L+ZsYsrsZ94EMRHdSTPvYckoyKoq3A0QhyqwLBl5SRjJyYjKRjB3v84eQgUEyXsIVyN8CosxQgUqAjuEQMd3BBHurKXg4eGxny/Cp0kVz6+vyEueMdlSK87nc8RIJdbNzfDVV19DVFBKwbquAIBPnz/1SK/0GGuEPFUVWyk97Coz2KmqeH5+vgnWio417OslgGhEoCS/vQAAIABJREFUc6tViAICn0FfVY24qFkP5aKvbcRI3Q3XS0PZvsP33/8Ah0FUkZeE02nFh68+4OXlBTnniMeO9VgEUgFTR1LFuA0A8Pj4iIeHR5g1tBZRV0kCsxbzLLE/P3z4gForLpdX1Nrw4cMHXK/XWC8BWm3YytYjxTEXN0Pr96P1fasiM156ucazAonoq5n1KHPEdK3te9P6XCK8jBl5VRWIePz0vRb7a1SMx19y2Dx9bUX38/W9/SaTOq4lIzoLADpDtMf77T2OPOY4ArdxrYj5ppRg5lBRQCMom1JG6XvqmGudwdnD+cu2zT2UUoLkDLMWkd2toI3wb18zAd5GiYmIiIiIiIiIiIiIiIiIiIiIiIiI7jD+SkRERERERERERERERERERERERERftG0bPn36hJeXF9RacTqdcDqtACK++OHxAz59+g1++pOfwBaHuODhdMZf/vaf4xe/+CU+f/6E2ipUI3hpFiHKCIgmtBYR2BF+FRXk/r83bqVgzQu8/15rhUCgOcPNDiHHEaWMuKOKQPOKbdtgbnCNMCgMeH19nUHbEZNc1gXZIhC5LD3oag11azidTxGFNdtDk0mxygLVBOulz3VdI/wq2sOgBjNHzmmOUTQitBHhlEOM0nsEs8c7FRAoIILW4jzRl3S4AUkduiac1jNKqxH+FIzmZm9/7m+ISEQzVW/Wy+E9rqoQ3Yulox86oqsigm3bkHOaoVkAyDlDRVBqhZthWTJU0lyP1loc2xub67LM6GhKCbLEGlgfi/bgJgCsp1N8ZoZSClQV5/MZn/UZEfwVeCxUH/S+F8wNKfXw6Fx7zPVw2aOf1u/LCOeOdfQe+URzNGt43V7x+vkCd0NOGTkn5Lwg5wTxBE2KJAliglrqHEspBVe9AgIseUGpBTkl1Nrg8Ii7OlBbRa0FKWesa8SSl2VBa7X3UQWnNfYhoH0uDohCVFFrw7IuaH2fjnsH7HNJqshp7MceAR77weZugfRga9yTHkkdexQRfo1HYbwxtq/O97SHhs0FLocA8rwg9rvjgpsOq4wMbH9o59sxB1Wd9zXmO46ROa5Ypx5olTZjrTCb51LVeN6AGanNyzKf9dZan3mPyfYRiQhySjf/Jtw3bYmIiIiIiIiIiIiIiIiIiIiIiIiIjhh/JSIiIiIiIiIiIiIiIiIiIiIiIqIvenh8wMPjGZ8+fQIQMVgzQ84ZKSX85W/+Eu4eYctW0dwhKeMnP/kp1uWMp0fHZbuilA3NKgCJUOWSISKozeCoo1g6Q6cpKZpZBBsBRIJRIpA5ApaH4KK7o9YIZcIdrVWs64qtbBEaFYlQq2COf4Qbl7zg9fUVp9MpYrEjnpl0hkrzkiGQGSN1OFLyHrlMqK0iqaK1ipQyRBUibY9DAjN4W6tB3HAstsbsvIcvZUx5RiijWdkjsALkJSOpzIilwyDeQ5YOiPhcoBGzFZeIvtpY5x6ElWNGF6g14qVmHvHZHs1sracwfY/D+gjuqkJFYRbR0loram2AO2qJe9Z6gDapQlNCzhnbdUNtEfXNOcMBtFpn+LW11sdieGOf4s1bc2/cTEvuDn+/1nlc+3GBEQaNyKijeu1jM9SSUF4bnp4e8fCQYz0P1x17CQBK2eaaRUgXsGYwazeTac1QW8OS85v9L6pwm8lgiDvcHZo0wqQzmyo9GAzMTTN/0Md0WA1Bj7DGwkUAduzRw+r6+MHN3m4OpATMt0bMeXxnRFb9dq/t540o793Vbm6hSMxfVKNWC/T17vdW4nkQaASF3WMb9LDy3BJ9z84VF0Bc+r87aX5ufQ+OeLL0KrIAqK3Bx558s9eIiIiIiIiIiIiIiIiIiIiIiIiIiG4x/kpEREREREREREREREREREREREREX2TNUbeK7VKgqqho2LQgpwxNiteXV5zOJ3z87hO2UmHN+7GC7VJgbtjKhuv1EnFWj3hqWyKKed0qtEdMIyQawcYIqhpaD5NGzNJRS4XXDSKKUkYQ1PH55fM8DojI5Ol8QikxbiACohFs7KHRHpDMecHr6wvO54c5RhHt0U9HSimikAK02rCVAgARMVWFiKCUgpwzaq1IKUFV0VrEX0fw0g2oxdFqn9OIrsrNXxihT3gfc3NARkgUcHOISw+3xtFmBrO4lo0wp/cVEUerBleHyR6ztD52VYW1Pa76+dNLBGX7eaxHW+UwUBHFyHO2FlHUiMwaBILrtqG1BgFgFmvVRjRYFSKKVhquI/4qgpwyylZmxNcPcxqpTrM9hmpzjm/Xb/+zf+Z4897Ru+8L7mKk4z7GvqzVIFJRWoW4wlvESEc8FwBeL68zXFtrRc7xv+7G+o6wr0FTQtK+5/qcl2WZ8dthfK+nYGdYdsZJ0e99jykDmO8ff3d3lFrm79u1YOZWezH1TfzVMZ+JQ5N2D6X25yzGKRCxuX+OgVS/vTP7Gt9eqo9hP3YrG15eXqAqM4orPc4b3eT9BGZ7xHmet4/7uHbzO/2vvOWb4LC5QXsoN46PZR3njz0i2LYNRERERERERERERERERERERERERERfwvgrEREREREREREREREREREREREREX3Rt//i+997zMunK7777cc/8szX3/N5+eInr7jcvHYAv/kXv/0jr///v1IaSmm/56j3MqS377Wt4fry+lc2rnu/++3vv+d/jMvLX30Y0x1o1X7/gf/vr/QHvf/5hxd8/uHlzVG/+/bb/w/G9FfL3fH54+e/7mH8Xp8+f8anz//qj5OIiIiIiIiIiIiIiIiIiIiIiIiI6J7+dQ+AiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIjoT1H+6x4AEREREREREREREREREREREREREf2r6yfffIMPHz7M1yICEQFEIAIIBADgcMABd4/f3+PHX/vx/ZVAICqH8wHwL5yn+/z5M777/nsIBP/2v/W3kVQBkX4Bh7vHOCHAfNshIjCzGGt/PT4bc1QR9K9DROP7DrhbP06gKgCkz8X7+YD9crFG/+c//seoteLD1x/ws1/8FKoKt1gltQS4xjjQh+8O0Ti/iKCWDaoJInGtsSw+V0v6RQVqsf7zfcGc383a9PmOOV8ur/hnf/nPAADL4xr3YtxrHNbguE54e243AwCoKkR1fGV+R1X7usV6mvV168eNGWnS/R4dZvr68RmtNjw8Kv6NX58P577bfz72zxhBv6+q8dPnNseHfc+ZW/yYHcY39ob3vdDvvQvcBGaC1hzWgFIcv/ttAQD88pd/A6eHE+COWiuenp7w6dMnpJRwOq04nU4wc/zw8QfkvGDJGeaOjx8/4fVywddffYWHhweIKK7XK5ZlQc4Z1+sVpVSYGVQF7g5Vxfl8RkoJpRS8vL5ARdBaQ20NZoakGnuqVlxfN5TSkDThV3/2y8O9vn0exirq4bsQQdLYt7FOhmVZ9u8JoBJrXUqZ3zV3bNuGJWcsy4Ja+xxE+pr7zT1yAP/kn/7fcABPX51wflqRU0JKsR/dHCINOQmeHp9wvWxwc1hzbNeCl5cLnh6f8NXT17huBaUUtGb9/Arpa9esoZQS9+jxCd7vV6kV7sDj4yNaa2gW313XBc+fn3HdLgCAWg1bbSAiIiIiIiIiIiIiIiIiIiIiIiIieg/jr0RERERERERERERERERERERERET0RdJDjPEi4pwRf91DnfFRvHcMio7v7L/c1F/3SOc4txzjrw43zGu915Od4VEAKaUZmAT2cUgcuB/bi67aQ5QAoD1m6zYSoILDqfdJiMM9zcGIKERGo/YQf8WIxsZ89sCo7+vTx6CigEUMVrSPBSOsGt9STfMeCCS6o34XdO2fapLbtRK8mY/36OlN1HTc437OYwjX3KFySM2O8O9cV7k5N+CQHv68uR9m2A/v74vFfTjsA4ig1gZz20O4SW/ut8iYq++d1/7Tl21eY0Rej2PS454YY/eemXWB2Ajqxj2d91WPdzTir0gRf1UFLN2cEs0alpxwOp3w+voKEcdPfvI1aq1oreH18goAWNcFS16gKcHN8PBwwtPTEz4/f4aIIKUEs4bLpeHx6RHruvawakWzhvPDGa1WqEY09/XyCjeD9ljsCYCZ4XK5RER4RoxjCy3LAuvh3ntuBu/fH/tw7tMe1D0+8zPeegi/jvVVEZxPJ0iP0o5rigiSZix533uHhwsAkJIipQSHo9SCvGRoUqgAqoZtu8DckDQjpwzVhDi94PXyCpUU70vsKfQ5jb0MOJZ1QWsNuf97oiLI/b0Rvm2toZQNpRaklCCIiDERERERERERERERERERERERERER0Zcw/kpERERERERERERERERERERERET0J0ZEEoD/DcA/dfe/KyI/A/A/Afg1gP8LwH/s7t/9cSfdA68AIt4qtzHXL391j2XOw8UhLvMct5nUN4f/IcObkc/7Ie15UoHBIX43XNmDtu8PII7eO5SHnGuPjI4Q6k34FrfnNDOUWqAaEUqRkZq9nWvvUPagpB8ipXsYFvJ2Td9yuAtEHH5/f2Zk9p3vH6Kw7nu0VmZI9hiBvY2/Rq/zNjY7wpouEmcdgxnR1xECjiEDDrRW51om0XkP95jsfg9nnPUuPDz3xIy/Cm5He29UhuXNO/va4HDD9nmqAOj9XD0EYHVGRhtEgForcs4zmmpmSKqo7nA31Box1IeHB7RmyCnB3VFrRSkFoorr5Trjqsu6QKrAzVBbw6nXb93sJnCac0ZKCbXGui7LirIZUPfg630M9/j+e3HXN2vV46gpKdyl75n4vLU2j1lyBgQw269p4yaqwlqLOLLqm+dZ+vVbc3gzIMncl+6ASupbSKCasK4rrDmsB5rhEfCNtWhzfyQV5JTjGhrHKBRqCaoCEYVZxGtNAGsGAZBTQmvtx/75IyIiIiIiIiIiIiIiIiIiIiIiIiIa/5spEREREREREREREREREREREREREf0J+c8B/B+H1/81gH/k7n8bwD/qr/8gezRT9gDs4ID34Obxv+OX342L3px/P/d7n73TjR190LuDZY+izrDp7es+YLjbrIfenP5mDG8HNE51DL1GFHNkKSMSOYOjdyc1M2xlQ6kFzVsEL+EQ6WHVsZYzuGowM4jofv7xn9xfa4+yxkxnvnW/R4efmM+Y0I+EPwHoIfI6Dtujr/ta34/jfn3Gd90d5gbzGONc05uo7mGchzkfvTevY6T0Jv477sdhP/jhoOOx47e3KxLz8Pf2hjpEAVWH6j6GZVngcFy3KwBHbXX+npMi54TT6RSf1YpaClprWHJGqxWn0wnLErFYc4eb4XK94vXyitYacs5Y1wVbKbGuFns7pQTt+6O1htYaVASn0wkpKU6nFalXah2xN8d9Pa7zCL2O98friL/uEeB4HfvO+n0ws/n+zf1CPH4iEWFV1dj7Fvu99vHC/fae9+c1aUJOKT7Hvo9VE1LO/R45IBKvBUg9omv9+RrxWtW0h3SXBUkVKSdoUqSkyEuCqCDnDO3h2tO6Yl0ylpyRtK/zmx1BRERERERERERERERERERERERERLTLf90DICIiIiIiIiIiIiIiIiIiIiIiIqK/OiLytwD8+wD+WwD/RX/7PwTwd/rv/wOAPwfwX/2BJ7wNMB4rh73rOSKjX85lvqMHTm+issfLuMDFb47/UTMUipsA6Ai+Wr+eisJ7VHKfVgQhcfjebWdUcHPKMeMRL3VApM1jbwOa+xfNDKUUmDtS6uNQgUKhCpg5zPrY5nAEKilimDPoKhA5Rmdv/5rZ12Pd9D7u6ofy7X1Nt49PpEc+9Rhu3U91s34QyF3kdT/dMa3qM7oa7wtED+HXfuiyLP0+YUZM3exwrlirY8zX9wu+jeK+F7gde7eHSF0ccLlbjJvDAX8vVhzzUHUYIgI7RLgVqLVhXReoG5a8IKeEZg2lbMg598hvxFBFFK+vr30dY8+eTivW04rvv/8e63qCQFBbBa4XLMuKVit+9rOf4fn5GdsW57xcLng4nwEA1ho2AI+PDxFYLQXmdjO/1tpd1Hh3v56ttXmciGBdF5RSseTl5rszPKva5yaotcZ8D/d9BGZTzj167GhmPZCMeYyq9s8bco4IrKpDtOeO3SPeigRrhq1VlFKw5BNUFa3Fd1vTvh8ctTa4x/qfz2fUVg9h2hiztRivuiBJxrquqCVCvo+PD4AoLtvnd/cNERERERERERERERERERERERERERHjr0RERERERERERERERERERERERER/Wv57AP8lgK8O7/3S3f8CANz9L0Tkz/7QkwneiWb2Pqb3OOVoZc6Y6+Dj3cPLw/FAnEPfxDQxg7Dud8d/aZx9jOYRCHXzw/tjwJjBy3H8/dzezGGe/34B+nd9hDH3z95EZccrdzQ3wBqqNSg8wrEKJMmAAA6LRZkBWemdVsW7CyF+83pv2B6Ovb9/czz7L8dg54yy9t+Tppv463EdRAB3Obw+xm9j/nG+Q4TWEQHP/r5CIXIbGI37HmFRVYWKoNl+v9wBtxH8vL0zcY6Ie4pixnTnUnjc5RkslhH3HeFXuVnLETn1EbeNq2BuLXFIn6sqoLoP6HK5YD0tM2Jba8W2bXAzLDnj8fERH3/4AV99/TUul8u8uc8vz/jJNz9BM8P1eoVZwbKs+PW/+Wt8++23AICtFFwuF6SU8PDwABVB6hHV1hoeHh7iWu49ZKr4/PkZ18sFT09PyOmKa5+Cqvb1kRlpLaXMeeSc5305PjPj/pj5vM/jHo5zjuPcvUeM4zlLkub5cs7wHkcWEahEOLbWum91EeQlY8kZ23bFui44nc5wryjlEs+3NagABqCZofXQbM6p3x9Da+PfCIOkhJwTRHLfg3GfrtfrHJuZ4+nxCdIabP5b1eO7cLRa0ayBiIiIiIiIiIiIiIiIiIiIiIiIiOhLGH8lIiIiIiIiIiIiIiIiIiIiIiIi+hMhIn8XwG/c/X8Xkb/zL/H9vw/g7wPA1199ADACmCPciWNdFCOE2Xue933PN/HXcQqMuGc/Zs9t3o8HUE1xjhEova2PHk56iHS6w9x7l1P2QKqMpOmc79tz+bsj/lI/dQYj387gMObDqUQjHmlugDkaADEAOaKTM4I6IqMuMDOo7AHWmzGK71cWwMz7feo3a4RP5e3Sjdt5XMN9+Idor/seU5UxN+xjvVmc+7XzuRboMV8/nFvuw78yvtXnMa6hAoXiyA4T6jnW/VhVCCIiKjKCvvfjfHtTD9uy/+03+2rGhGc8eN8bIrGZ22GY0oOsEPRYKHA+nWBmM4j64cMHtFojdquKlBI+PD3iw4cn/PDDR5zWFeaOshVcLq8QAa7XDafTCeu64uPHj3h8eMDzywuu1ytqLQAEOqO2434JHk4nnNcTnp8/o5Z6M04zQ2tthltnCBa42ceXy+UQfTWYGc7nM1R1HufuMx47zm0W4eXT6YTW2s0aXC4X5JxRa0VShaYUwdq+f0eb18yw1RLj1BO27Qr3iLDmlAHv13FDa36zZwXj35Q+HjeIj7lGkLiUCpWENS9zLrokbNcrRGK+qoKcEpacIXBoUqTDWhIRERERERERERERERERERERERER3WP8lYiIiIiIiIiIiIiIiIiIiIiIiOhPx78D4D8QkX8PwBnA1yLyPwL45yLyK3f/CxH5FYDfvPdld/8HAP4BAPzqb/5i1h5HqlNuc6Hx3gySRmT19tPD697a9Pli//6xHTrisLef3UY6/b5iOoOd+3+zToo96CmQm0DlzQj3GinG148fHE4XZ3o3+NrPOE7p8fs8tew/7g0uCeaG5g3SAEkLRPVw2TjYzeHiPeh6HKwfIq3jWqNEOmZ8u55j7iO6+R4RjWhsH+wIXs7w6RyD3MRfzTziszhENz0irRFOPS5ZfE/v47F9n4z7FOFRg1usw3vrPScs45w6zzuCn/eHv5d+PYZLMWPD+2eje+w9UBvn95s1Ro/NDtfrFeYVgCClCKoeo7VmhpQz3ByqGgHgfqLXl1fUWud4VQW1RPhUx+LC8fj4iCUlfPr8DIVgyQtqbShbwbIsaM1gzeBmSOfzjJyOGOsYh6oi5wwzg7sj54zW2jxG9Ta+OwKwY91aazG2fpyZIeeMUsrNvjtGYd09IrAAkio2N5gL0uH8NzdPIrxqraLWCneDwJAUEbtV2fehO6Tv29hLAtVRihYgxVq7GQyxz8wMDiCliPACAu+R2loLVCNKKz3kvK4rSi1oh7UkIiIiIiIiIiIiIiIiIiIiIiIiIrqnv/8QIiIiIiIiIiIiIiIiIiIiIiIiIvrXgbv/N+7+t9z91wD+EwD/q7v/pwD+IYC/1w/7ewD+lz/uzPeZzF7xvI+hyiEP+6VOp7//mRxioyOsOS5w3ygdxx2HNUOdfjgGeBs4FdwES2Uv0u6v96ItIqq6/3083W24th/Tx/t+WHVc1yOIOv8zVGswb/uyyiG6KzHGd5e0XysCq3a81LvrdDta7It7N6+Ip+r86u105DCX/T6J7EHP8WM97hnrZzDb13Ac/84yQfp/4+L+Tq11TxLvEdr9R9/Ofc5hnPv+QwciA4qblPAI7DrgsP7jezi4h25n//UwJ0dEUJs1AILWDNtWUFuDmfVIKdBqfO7wGRK9XC/9nD1kKhIxVneoCqwZWq348PQId0fq8dYlL8gp3YRTzQy1RjBVIDifzj1uGve2lAIRIOcRN5U5nxGDPQZcbxZU+vlbBGVHBPZ4bXefe/K4P5pFcHXcitbi+9ba+8/Q4baZxXVGxHY8ezGn2HuCPVqrGjHZnBI0xd/90Zrh1/jp96aPw8xmDHjsWbO4D3nJ95uLiIiIiIiIiIiIiIiIiIiIiIiIiOiN/PsPISIiIiIiIiIiIiIiIiIiIiIiIqJ/zf13AP5nEfnPAPwTAP/RH/rFQ9qz9w33oKYc/oygpsNH/lUAeLyH+PWuCjvCnrhpcMr8o3/PR9DxUAztUcejEZcc4dD5HtBH1cd9EzmV+Zkf6qoyrnM8hx/jnn2+cvv5PqHjNe6apdLXyA2Axms3uBnME5I47qf7pnraA7Jz7dzvv3Ds8sb85nH7evm+uHvItBsB0NoaVPVmrmPtZsjW9ihozopaj2eyHs3UCIKOsGsPxxps7qN9qgJzO8whFjFJ2u8txj0RROdVerD2UGF1OURa5XCdQ1gWjnGUyAjoRpAXbnFvjnsYBQ6FQ/v90xi0y3Go08P5jGVNMHecT2f87ttv4e7IKWHNGSqKZobXywWndQVaxFFTznB3nNYTAKC2hm3bIDDknNFq7ZFSxbos+P67H/D4+IhWK1prOK0n5Jzw8vKKJS8RQzVDuRY8fvOIrz98hVIaLtcNDsd125BSQil1HrttBlWFqs79MkKqooJa90Crm6O1hrxkuO2h2FLKIb6qSCn16xTUWudxZnFsO8ZWcU/gZrheY+45pxhX3zOt2RyTWYM1QCXGn1T7HtEIA2OP0sbXI4RbawFcYTCUFuNZ1xPMbcZi93HHPHNOSIfQLhERERERERERERERERERERERERHRPcZfiYiIiIiIiIiIiIiIiIiIiIiIiP4EufufA/jz/vvvAPy7/9In2zuZXwi/HoOlhzBrjzI6AOl/+IzI3p0bt6HTPapq78RQvzTM+4rsW621HgyNAKiKRrvTHS6HAKxI76IKRO4HPMKv4/WXJnQ3ph6LjO6poFnr7/Xgp2VkeL92hFmtr9fou464aIRr7eYD1WMYNWK44vf12X4b3aE9lOr9fPfHjHXQHs4EjvfFewB2j/NGs1NhZnt/1f3mPMeAbF/dMeK+NxxuFp9prLWbo9QNDsDc3lnrtzd7rvPd5/ctXXlz/8bs36ZHR2837s1+1I9sSVy3DY4MiOC5vSBpgiZFuW64NIOo4oePHyOIWhuWZZlx1KQJ122b508aAd1vPnzAy+vrfO/777/HeT3herkip4Scl4ioNsfPfvoz1FogolhyRs4ZtTZcr1vEePsaLEv8L8XNGlqNAGvOGddtg4pgXVeICLZtw+l0wrZt8cxg9Id9X7qDEX41sxlbba3B3GYMNueI+tbW8PT4CDvskTHGMbbaauxzAZoZ8pIhPUDs1uL5hsJavKeqEAjMHVYbkibkfAhW93153BGndY3zpITcI7xJE1qrEN+fhWVd8Pr6Eqngm31JRERERERERERERERERERERERERHSL8VciIiIiIiIiIiIiIiIiIiIiIiIi+nF3QUc5fHCMYY4U5ruB1mNjs0dRR0QxIqK3X9qjov2rUZiE+/sBWOlByONYb87ZP7uPVEZydKRsBdBx3D6OPUjbv+N+iKDuJzter7dX34zVe6xVXCM6aY5mBgHQvKHWApUElQRJCgFgLQK4I1gbPVjb59Un1yyCmrctWrmN0PaFHXFZkds8LQBoSlBVaI/kHuOvuDt13I8Rfm0wc5iNEGbcrxGKPSz6oRs8wsEjABsfn04nmDW0ViPs6bfrPtfzcLr4u+/FHtCNcO/xgjJ//7Fo633+9bjF3QFzh/h+rXmNY6kYwLqsWJYIiC7LgtPpjOv1CsuxRmbA+fyI1hpUFbVWAMD5/ICkiu++/x5JFaf1hPPphGaG3/72t/j5z3+OnBO264bL5QLt+/h6uUJUcD6fkTQBPVzq5qi1RWS1lHj+DiXnJS8zzCoiWJZ4/fjwMGPEI946wq/rus73VRXbtqGUgpwzUkrzs9bafA8Atm2L6GpSmBtK8fn+iK2OPXq8371VDHeHSuxJM4N4zD0lRc4JCkG0WA2iCVYrXl9eewA3grSqCQ/nFVspaLXC3JBSwoenD7BW0Swi1qoS53BHSmuMQxV5yTBreHx6xOvl9c2+JCIiIiIiIiIiIiIiIiIiIiIiIiI6YvyViIiIiIiIiIiIiIiIiIiIiIiIiL7oGGCUXmF1uTlgRlln9PIYCvU3v3zpQjc1zv2ae6jz/gxy+EVF+1X8nQP2gOwMqHo/tv8tI3TOhjfGAAAgAElEQVQqCnOHe8N7IdsRb/U38xoh27fTOlLZz2mtAT5CuAp3Q7WKpHGirBF/9R5UjfBrn6dZzFulxzkjSKo99vp2DPu45z2dzdL78G4PzPZorLsB0LtIr8/Q620M93Z9ju+LSIy3r+tNUHZEYPufZoZSKlprAICc8ruR4PkVOcxV4k05rP+7QeKxAHNzHUdwv354E341B3QEhXsA9j4rO9ammUFqA0Tw+PgEO59RS0UpBdYa8rL0WyFIKSGnhFIK/uwXv8DL8wu27drXwnE6rbheLrj0uOppXZHTKUKreUFOCeeHOP+4lyYON0OtFbU25B5iHaNV1b5OEVQ1M+Sc0VqL2KrqvJcppRn4PcZfR9w157hXI2i7LEuMzfp+7/dxXCOCxY6UdI7DzODWIIeboaJzHD7HEbFadYWZI6cEa45mDjeHpjg+LwsAR61lRmatGbZS4r6NPW8OtzqD1uaOU84oNd4Tjb3bWkWpJfZpKzDGX4mIiIiIiIiIiIiIiIiIiIiIiIjoRzD+SkREREREREREREREREREREREREQ/ykdd0wGIQ/wYt+w/PZkpcOx12LdBxPcanHuIVN68P2KQIx46gq3vnWNEJf0QYhTEd2aiVQ7h1/75mzHehEmPc9nDpiIj7BmHyJcmd3NemfOBWx+z9gtGaNJrRRND0obWImzZqkEAiChMIp5qbjEGKKRHYsf1x5x8zPwQqj2GYHvd9U2hVvU29DrX6tCVNQfcDWath0DH3GJBZARY+zlUBJoU8D46uQvrCnroM940az06O2K00ud5u/fGvI+/z3kegqyzzzqvcPNins9vftmXzg8/EQUFxBx2eB761rrZniklqCZYD8CmlCCiUAVEWg+KpoiamsPd0Frc+1IqllznGVurgAPn82nujSVnnM4nwBIAicgsImJ6fBZUBJIi5po0IaV8CCbvkV5VnUHfpCOEfIj8wmeQdzxzMceIF4vsz+vRiKk6fEZU4Xs89lDtvX3m90Zt35MKYDwPfV8gos2tGcx8BmtFE/KSsTTrsdcGg8M8IriqilI2iAqSJkCA1gxwQ6/UwmHYyhbjdIdCAY2x1VZRa70NThMRERERERERERERERERERERERERvYPxVyIiIiIiIiIiIiIiIiIiIiIiIiL6vSKj2UOXcowdHnKXo9941351HBubIzh6CET21zcxULz33R42lbvcou+h2PHJiF8exxGXlpvw6zFyehOF7RFLkRG47eft41TVGcGc5zmO8525yHH8LnNgI2Jpbj0A6v2cCoHC3ZFTjtf9OnOpXaGuM9h6nG6M9/1Y7ljVub6HY2Sca85pD7XuhznM9p9+OMz2cG78vcdeVdNNWHXcjf3m7GdvNsKih3kdg6KHfq3Db+4rXGacdzSFBbHmIsda71sROB1B1MOEx/XGJcxhcIhYxEf1/bVUTUiqaKY9SKqorcFbQ2s246n7vG2GVs0MP3z8AeuyYllWtFbhPbSbkmBdVqzrAlFFK7FWaECtDfV6Rc4RexUIcs5IKffnJCGnFAHWPt4I+OJmLKIKvYu/woHaKrTvRVVFzhkiglorRIBa67z/83v9tUpEblUUEJ/XHRXpm2MPe3puEYk2q6YeGvb92H0/xj1JKSHnDJziWXJ3pAyIys0aKxQu4/m2Pf78/7Bz9z62LWme13/PE7H2S+Y59/btqmromUZCODhISAgbIc0fgAO4vEnjjTBp8ReMO+4ICWFggHDwcJBwx0DCQINGQnRD93RPV1fdW/eeczL3XivieTCeiFixdp5TVT0Iuqv4faryZubea68VKyJWWkffFs99vb0gL0vsc4uIsbYwLrQ9+/qFDUVEREREREREREREREREREREREREBMZfiYiIiIiIiIiIiIiIiIiIiIiIiOhX6HFTNwMELbX52QPHNwdGObUHREdzU/bw6Wev1sOd7fPH1GsPih4/HxFXROlzXO5hlFNJ9jH8uodD9/MdK7Y9aNpecbQY6zH0OvdJHwOw3g9whwogmttB7Z6BFoZ1VKtwB5Iocl5QbBuhy/jS6JHWiN4mTchLRnJrgdg2Qy1o218bNdQRwP3MCvTwq8h0jB/iqz5FNyPS2efDoLrP3SHc2uKh7tM559mR/eQqAowQacQ6a6mHMZg71ON+DrtBHvaG98WITGy89lgbnvZZH2t7pfdqx8sADA5Yr8MaHAJta2jTGF9vr1hLlGEv1yeUrSDnOFnOGafTCS8vL0gpofZoKgSvL694fn7G5fmM03KCiozY8LauOJ/POC0LzAw//9nP8dX738W2bYf1VlGYGC7nC2o13G43wB2n8xmq6RBW7fHkMbdmLeYq2Lbt8N5pOY2xmFXUWpFzgtUan9s2QATn8xkqEsHbUpBUsSwLzqcTSq3xt0EVgoje1hrrG+eOvzJLnv6ps/c4b3zusQUsKlAI3BMEESTetg1AVIlVBSnlsZ9KKcinpY0jArnmhpz3uanVkJYcf/fEsa4rIILr0xWigvfP71FKQdkcwB1ERERERERERERERERERERERERERJ/D+CsRERERERERERERERERERERERER/VIRvrTxs3j0QwVzJNV73RTVLKKPolN0sxGBirRz+h5Ebb9DZG93tmP3MmqMowdA58Snww8xyC8xtzfh136yQ4rUfcRd2wyMwGn/wOHe0YOo+zmOAdk9Wzvu1Q3VHLWFbqXPlTnMLL5UkSSNMKaIQDRBxWHmqDXWJaWEBYacz0jSQ7u9VIs9/Nr0NRjrNr1nLfI7n8Pd2/UxDu7BUJH9/Gb7HM3z22OhKtPxeAjn9nkBUEqJiKrH4EQVosd76G+bAyp7krhHb8fOa/vnMcY776ARyvUp+Or9tekL++sGg3rsu5Q0ngkVuE0bsTqSCtwdtw8fAAiqAEs+QUWxmkGKwbbYl8tpwfl0xvLVgqfrE9Ztg7vDqqFsLcq6OU5LxrYKSnVcz19hySecT4pt22Ku4+Fs445gqibF0/UJt9sNRcqYaxEg54xt23A6nca69ddyzjCzsd6lFOSUoKot2lpQtg0pJZwvF9Scx351OJacIx7thq0FbpMqSq2wbYO0/Vtrxbt371BrARDPvplN6x0LkFowtu/ECO7u48s5wyTiri+vL1jygpQSzBw5JaSUsd7vOJ/P2LYNKWWklAA4TqeMUtcRu5UkuC4XmHnEhpNCRHG9XlBrhYgg5QRNexyXiIiIiIiIiIiIiIiIiIiIiIiIiOgR469ERERERERERERERERERERERERE9EVznPVQ3nwgiCDsiLS2/86RxnFOn7KbPsU6Bb2gGhHY4yBagvV4/s7MIeiB2ha1hByCruN6LRTq2IOh83v9IyIR9jTbI5k9IBqvTTf8eJ1xK/Pre3TWakW1CrRY5T4ewNUhNUK3ZhWlbFPwNuK4Vi0isR6RVUfEKd0MLhFKlR7NnYY4QqCi0+QfibbYqsgItUaEc47jYoRg+3f3/f1+nz0kqv2+zQDz42fbukfAN74irKnt3uJ+87L/s1efxhH3KLH/EHFiyNS0dYe38+x52Ie97D6d08e+OQaGp0ehBZBhgMAh4hGnteOOe7o+QRW4vd5g5jidIkTaA7GXyxlLfofX11ecz+cxj7VU3Nc7ylZQbQ8eCwTv33815goQbNuGrWwwi4CsqiLlhHVdkVLC/b7C3KCiKLUg54xq9bPrVUoZEdWtBV3XNWKoPYgKRMz3MK62Z7ZthZtDU8JpWfDy+goggq2x9AZAkHM+rIKq4nw+436/x3vu2FpcdV4AEWnzZ4DOcWVv99TizioR5DVFXlI8X24wr/DqcBhu91fklFDqhlI3JE3YyobzdYnIKwRmjm3b4BL3nJd4r9SK1ObRrEaomIiIiIiIiIiIiIiIiIiIiIiIiIjoCxh/JSIiIiIiIiIiIiIiIiIiIiIiIqIvikbnHlgUCNr/jwf5IV86Kpkucjx2BFanvOYcNp2v299HD3Ji/9yhINtefwgw+vRZtIhpnFuOY+nX7Pc5Lr7fN+BtmNJ+/lzs8fE1xxebkII9bNpjqH2cEjFNVUWtFea1jTqubW5w6wHWFmrVCL5WM4gaxFt4VSIWe0iZ+j434y7fDD3usQdgIxW7r0qPt+6/RMpzD4Q+3Lu0OKxPa9Lzu3083gK2LWo6x2Ohb9e7VkdKMvq2fSn7ms5pXtlrtdN+Po5P2pj7/vjSCu/B2T5ua+8qkgpGhRZA0oScFX6JAG5ETx1WI8a65KVdXqGaIgQsglotYqReWvRUR5C1lBLr3e5xWRbknHG/3SNs7BJx2V5XFcDNUaxAVsGyLCiljKixO1BKGfvtcW/3NRCJ9TUzpJQgba3dDFspLTbs47VS63ROQ60GqxUOIKcU85MTtEV+SylIqiMAPKddY5z9dUF1R5pKvCO03PaZANAEJCg0CaxG+FVcAFRsZcVpOcFh0PbsqAAnzYDskVpHRH1rNUCAtCSklFCrxXttbj7/94CIiIiIiIiIiIiIiIiIiIiIiIiIKDD+SkRERERERERERERERERERERERERfNodeZc+nHr618mZkGf3QZZUeoOwn6uFMAG/KqHOgE/vPPr3vx1feiBhnH67sUcYphPnwgXHs4+e/eIU37z9EZ/34uj8cGVFVhQhgvsdp90FGgFRV4IgwpvXiqEuLv3oLviaoACoOEYfZhmoOUYcgj1jvcdA+T++be5B+EyNOaw/3tR84HwtgBED3Jd4/FFHOPicP64IvxGVFIjwrcgjWOhCh2xYkjT03517bx33/+e3iyzyS/SXZ35uPO3SNfbR6Y+TiUPE2zp25QXXB+aRYWti11BKR1hZ0NfMIkIogacRFU2rhXRUotD17LQhsFYqIyUIi5trnUSWCrFvZoCkCsTYFbWupyPntPx+utWJZljfrZWZT0Bcj/trnXUVgqhGkFQCiLczsqLXG+y0o62Yj4GrtZ00JonFv7t7uz8bkVrN9PHC4+SEi3McJiYCyqsS526qp9lhzRb+NeP4cmmJONO3R4iSKInW/DgSaE9xqPG9TINpa9JfZVyIiIiIiIiIiIiIiIiIiIiIiIiL6VRh/JSIiIiIiIiIiIiIiIiIiIiIiIqJfYq+/9pCozO8Be/g12qSA+2PLdMQ8XX5VXHU/934d35uxe3HzeHSPj2KPhLr7HnOVeK/fQ399jjnGrcTn3ccVP3stkT2I6d4Dk/39/ec5mOoAqkdMdVmWiHJ6u6a32CdaPNUdgoRTzkhJ8Xq7wd0AkRFjPaWEGEaFWwXcYclhvgF+QqRjEwCFVYO2eG+MySIOKu132QeqohDdJ3kr5bPz8GZORiR0bIQp7Brnt4dw53SGFi+N+mo1O4ZYD2HguAmrhgqF9LELWvR2Oifax8ZnP7er3o7nEDluGyjCxtICpsDYWgaYOEwd4t72QyhbheU216ojKJqSAhCYOS7nS0RWRUe49LQsWLcNKWW4OmqpWMuKp6cnAIJt3WBwJIkg6cePH3E6n7CcFlg13F5vePf8DhDg9XZD0oTz+YxSCtwc5/MZOaf9ftt6p5RGNLnWGkHalMZs9PfMrIVt4/gep5UosI416vHWlNKIzlYziCrqtsHcoTX2jqaEUuvI7lo13O/3YzzZHdbGtf99aYshEXJ1AF4N1v4OVYu/A6fTKULKZjH/HvsinleDSByLLDD017StVZy7WkW12mcDxcrYB0REREREREREREREREREREREREREX8L4KxERERERERERERERERERERERERF9WQtd9gbnTg4/C3zqffZ848Ox0kKnIwD7cNzh/BHRlH7IHA39Qju0feph/PGauBxbnv3YHoBtx7n18CsA2Bjj3iuNSKuKTk1Sf+iZSguSyqFVG9FQQ85L+3mKpM4DBlpINX6uZhF+dUD6+9IitxZB2B437WFOrQUqCRBBaoHOCNbG+JNqhFZlv6fOzNp097Ec13oeq48AZ7+PVmw9dlrju8R9Hc4wT1wbj4giqR7G1O9/PmcpFmsrDkDhGjtPBVCV6b4+UwueHbZgHO8iba7lYZv2333c7bw9H9u2fd4FCre2d6ARVPUI65rHfFczmDkgFQKBVUcpBYKIpy7LgrIV5GXB6XSKAKsZ3B2aFDkl3G431FqRU8Z9vSOlFMdWw7qucf2kqLWOiLAIcD5FGHbbNqjG+GqtWJYF9/u93YdASoGI4HQ6Ydu2CKlqXLuaoZQCFYGmBG17zFRh7nAzuBmqtRBxi8SaO2xdIapYliUCraWg1orz+TzmWEWhLaCbcx5rIqoQdZRtw7bFM+a2P9sKIC9LhFrNR0Rak8JqhaYc4V03iAjWbUNt9yUCfHp9QdIUaybxTJvFfC7LglLKmEsiIiIiIiIiIiIiIiIiIiIiIiIios9h/JWIiIiIiIiIiIiIiIiIiIiIiIiIfoUeTOy/CyB+bKn6HlWMWuNDaXUKcMbbLRjbcpuYQ5v9NOIwn869j2TEWqchwnuEtdc3Zbp6j6O24Gv/foyURjhVRKAtTIlxOm/vR2zUVVtgFCPkOi47lXLlzfkdOUdIs9a6j6PPgO+fiXNWVKtwbyHTHuFs4+qfV43jRR2Ao9YCgSKdMswq0OKW6NFZaIvP9ql6CK3O4VWRw+rtb+0THEPr99znpd9VC/nCoS2oOQKpx2puO6VDVNDzqz0y64d90O7fev823lGJcKv3k+0zO8YSr0z3JA+H9E/K9MI4dtpUbVzW1swMUPXDR5YWalWJoKoIsPqGWm2Eb19f7yO4KhLr8nq7IacUMVtNMHestzuenq6oZnh5fQE8oqanZQGwQERxWk6oWiPuWg1WDZA2jiWCsa+314iqjmcCKKXsewwx1+fzeQRga60jutpDsH1+zOPL3XG9XqGqMDNs24aUEpIqvMdRU4KaIbXz1FpRWug1q4z9sVyvUBHc7vdp7tsz6MAiGaXWmDM44BWC1JYowds6iAokJRQzSBK4RLjV4FB3aEoo7nCrwHjGMlTbfRkAJBRzmNfD3k45o1pta7f/vSAiIiIiIiIiIiIiIiIiIiIiIiIiesT4KxERERERERERERERERERERERERH9ai00undN5fjeHFTtL05ZVzhayrMFTN0jKjqCnjK3X+NzI1S6B2ZHCBT7e7PenRVEoFJ7qfSxRduDq+6H9/eoZfzco64eL0AlIo9mFaX0gKdAVJBSivdbmXUOws5KKTidln3MU0hzLodGJFVaCFcjZBnd3XnqI6LrEbV0VUSQ02BeoSqomyGnBKve2ryyz63MMdf9nNoWY55/ORw4r1cv1h7P1SOvgj7oyP26zeHe/pnDysPMP3ejR4ctGNc/BIr7jPZ474jJ9iWeF6dHgT8n1sb7Pn/4EgBiDpMWC7X9k0kT4IJSC2q1iLkmhUJbXNSQkmBdVwAV7gVuEcnNeUEpBaIKtYi4msUgT6czrNaIrJYCgWMr2wiz5iXiqqUUnJbTHhtu69lDs/MtWrUWX439sW5bi89Or60rAOB6ucBbKDklRU4Jt/sdpQVfIYKk8bq7o7Tr9vOUUiISWyO6mnP8k+Z1XaEisByvLUse8y8QaFJIDxe35bZWAe5/Z2Jvx+9u0vaAQ6Bv1vgxvgwHitXxt0NEYAKoKKoZkiggglpLC9tmVLPPPudERERERERERERERERERERERERERB3jr0RERERERERERERERERERERERET0RSOoiCne+qUjfXzi8PkIvQItAzqMpOMIcR4LrT3auJ/Lp7jjMazaw6TeIpHzRfrv/XM9DOvzWA9FSIcB0MNIelA2YpPVDLVUuEcAU5FaUBMjHrvP2T5GEUE1g5kfUq/SK6Ie8Vr4PhvSP9vuxOUxXxlHmvczWovGtt/Fx7WhLf46rtvHu8+Zux9X8THOKp+f3x5Inee/J20Pa4B97fp8zSv/NiT8dgyCPc4J0RaYlYfjRn12mq32a7tHwfF9fG5PHJq88uaYMWaP+OvD8sDbXhExmDven9+jWoXVAiDiqjnl/Z5lj6SKKlQUroKUoiqbcwZKiTBrO6bWDUlTW1tvPV6Bqrbgbuz9iKcKrNp4tgQRqTWJ+OsIA7tjOZ1Qa21rFfO9bRtKreN3b/eQtIVRWxRW2z1oSpBaR0B4XMNs3H8/j5kBIjAzlG1rz/UeaI65WlBKjXs1QzytNgLV7g7rwd/+zMeDG0sygs59Z7Yocbu+m0FzRGfdAU1pRHfj7xna8ykoNY7/XIiaiIiIiIiIiIiIiIiIiIiIiIiIiKhj/JWIiIiIiIiIiIiIiIiIiIiIiIiIvqyHINGipM3bBKxEFfHQQGwl07mXKT2/GWcQ6SHQ4xm9X/sQAW3RRrcRpxxXn4KkI8Q4vk3RR3OIyoipHm/V9/CpO3w6JuKiLfRpEa40tz3WOY1b2v3oFILtYxRVeKnYStkDtu57MLadMyKv/a0eOZ1uWfb7Gtd2h7vBrCLStYZqFZA0IrUiMuqy41wP3cq3HcvjTM2Z3sPr7sel/twxYy727z1u2+f9cTz7KKZzCpBSgmqLwGqEeUUeV/Uh1trvux031tqnfXLMAo/26z40eXuMR1tUH6LEIzTazl+rQXNC3QxmBqsGFcX5fMa2bTDp8eI4tu9VSARa3R3LsmArBaKKJSWoKj59WpGWBIfDqqGUiqSKlBPWdYVAkHIEiiHAuq1tnwRVjfewPz8pJVzOZ9zud5RSoKo4nU4opaCWgrwsgDtqrRGQbWMppUTYNSWUUnBZlhahjev0uGtf9zGGtiYpJZh7XKcFYvtaqsQ4122LdXCHwCCI57rHoUe2uT3PaYo99/hwdW/7Z1+reF4UIhGorbXinBeUssb1zMfaO4D7/Q4RiTgsEREREREREREREREREREREREREdEXMP5KRERERERERERERERERERERERE9FtERH4HwH8B4F9D9An/YwD/BMB/A+BfBvDHAP59d//ur3LeiK0aoAKBAhD4IWzaM5uyx1fjkwAizDlVSgEoRipUEOcGRhxW3GAwiERmsUdfzXwEUn18BiP8+Gbc6DHN6T6wB1V7XNZaUHbEZqXdh+zH9rGLAJoSssg4V9IE7QHXKVg7xy0BgWrCsgjKViBTeBIie4TUrVVf3yzCPp/jJ4z4bL96tQpt93a/33A5P2EtK7IuLWoZwdExVshh6lQEqUc63WB+DJ3CfVx7jEba9ym82QOr+9wBULR1x/7fHoLdp+lNmPeRiCDnBaIYAc82ZIhGVDiuvYd1xxhkDrS2/dXWbA7iTgnR/b7G545rHXFYh/txH6omnM5nLMuC19cbVBQff/gATSnWQIFa64j8eq3YSoWq4nd/9yv87Oc/x2lZoJqwtQDrtm1YcoZZ7NmYi4yX1xfkvABwlLJhuVwhIlBVmBlKKeN3mR5I94iYXi4XrOsKd4eqQlVxu99Ra0XOGTlnpJTw/PQ0ArB9H5RpNjXpvrotBgu0OKxIfM4dKSWUWiME254zOOK+xvzpmMuUFBDgdntFSgkvL68RrVVBvNWeZwEUEZttJWaIKmo1jKdGEH9Lao3Is+gI+6ac9/hsMaRUYu4l7U+KCLZ1Q9L8kAEmIiIiIiIiIiIiIiIiIiIiIiIiInqL8VciIiIiIiIiIiIiIiIiIiIiIiKi3y7/AMD/4O7/roicADwB+M8B/I/u/vdF5A8B/CGA/+zXOdkInwogaNHIKYQ6fZs+hEMAc8RgfQ9xOmz+dXwgWo1+/Kz3sGY7h/dzHo+TuSI6X3/6RZOOGGkf1wjEKiAe39EjtnMktN17yhmLKtzs4d59+oz3zuhhjGaGpAmnc0KttUVbpd2fQV1gri0E6yOK6SPAuq9HjD9+1jY20QjtOgzVCgyOVDJgCpMEaQ1fGU1NacHZfZwGh7UX3Q0p57F+8/KMbi3aPoG0dW3hVe9Bz31B+nyMIKzIuHgPyYoIzGwf0ByDlf3zOecRe1Xpy+MtNNwvZJApANzHL2NX+Pjy/n1fwvE1mrAec+PjCy0eHNc3OU7m7X4be3VZTqiloJpF+FcTcs5Y1xWq0uKuCU/PZ+SU8U//7M9wvV7hLYi69HUQgdU6rvHy+oqXl494fn7uy4Tr9YqvvvoKry8vAICccgu6xl6yEUKNOe1R2afrFQ6glILSIq3n8xmqCnfHtm0RPgZwX1eoKk7LMtbT3JFTggPY2vtLzli3bURg+3OwzSHmNhBNEaqtLQo7x19rqailIKUEd8ey5PbZKdO795EPz7kjAs9ARGQFCrOCUmsEcSVitClnQBS1bEiasFxPWO8rcl5apFbH82gOlFrgZm0+iYiIiIiIiIiIiIiIiIiIiIiIiIg+j/FXIiIiIiIiIiIiIiIiIiIiIiIiot8SIvIVgH8LwH8IAO6+AlhF5N8B8G+3w/4rAP8Tfs346wiKukBGyXSPefr00gh0eu99PsRZRUbwVeBxXuyhTe8BTo9Qo7cAaI9n9uAiWnRznN4BN99rpPMQR8jTWyRV93O2MQtk/Oyylz730+/hWQGgKSGpwiBwt0MQtF8ax9wogAh4lq3AM/D+3Tt8evkU0Ug3mBnc54Ckj/sT0YiYugDiI5bp7nDpYVPpbdoIaFZHtYolZZRScD5doaoQ11ibft/Yx90teQGkx2f1sI49zruPbczgft8i0B4NBgDb5yfitPF6hD2lXWufa6sGaRtFVCNs2/fQtMgijqSCOI23/ekjAtuP2RO/PtZ6j8Dua+Quxz318D9zwOJ2YA64SbzQYrIiAhvji7WsLdKqmiKcqjripaVWqCrO5zO2rSCpopSKbduQl4yn61MEW5OO4PFyWvDy8mnEXAEgJ8XXX32Nbdtgbi3C6/jww4f4vceDt7jhshVo0sN+zTnDzHC731skVpFzwv2+4n6/I6UEEYlgsQiWnMd5S60j+OuIELGmBE0JpRRUVdRax1ykvqYiSKojNivtvZQSckqoZscqcd9OZshLxFg1aYuv1vYM9Xjv/vB7+0zSFBMKElsAACAASURBVHsKAmvP7P60Ia4HA8zhIliWBTnH8xPhVxnhWnOPkG+tOJ/PqAsA3EFERERERERERERERERERERERERE9DmMvxIRERERERERERERERERERERERH99vhXAPwlgP9SRP51AP8zgP8UwL/g7n8OAO7+5yLye7/uCQXYI5578xWjxCjHICf68R4BRTyERaWHR1stVKL9CYtTtairt8Brj3Luv8fPv3zA0uueEhHI0XN1AIo3n5eHuKi3+5R2f/2j8MiHjjG2e5nqtX3CPpN+3Vk13O/3CNb2RmULrbofY6x7jDRCs3BAFJCkcYU5zArFtpU4ByJICngEQLXN+RjkNDj5zPqNdZI2tjG5MYZpS/RzRbj3OF/zTahoi27aHuwFxu/9c9UqckqQx53lxx/NDCoCh0CnW+lfjx9tqdsp+jq/vv/+uGZj7wBjffZ9GrenANxa9HiimpBSAgTY1g3PT08RHfX4QDFDTgnmBkWElpMokkZguNYaW6oFYHUEUyPuG/tBkDSCpm4Ob3Fl8wie9nvuhd6UEjTp/lxDDpHTHlEFgGVZYo3aa9KivtVa5raFiKWFaOERRkWtACIIW2sF3Nta7fOrbW+hhVZLi6mKxt5WPYaHa6koZUNKGWXb0MPFPQ5tYz9jxJrbhcbmmAOuMSd7ttjMI+YsDlWFmcXYRVC2FSlFINdqhH3zkkcU9/HvHBERERERERERERERERERERERERHRjPFXIiIiIiIiIiIiIiIiIiIiIiIiot8eGcC/AeDvufs/EpF/AOAPf90Pi8jfBfB3AeCr9+/6i5Hg7L1QwUNwVOYT7KVMEcgIwB6ucgx0jk7rQ/S0f+89UX/oK8oUpe3jPPy+n8jhx/emsY/Q6WO7cdxyBCvHvSDOZxZB1NFE9VaxbcnSfrl5zCIK1QR3x/1+P86eA5oUbg7DHqZ0N+wDFDi8nVMgohHfbRczd3gtUI2wp7TjAWtRSwNaJrWPGx5HzevYryltjkdwd9zvHI/1tnb7zfbG7MjAepxHVSIi2kKifR7N7bAe5gZoipm2vTR7COO6RyhUNGq42u5M9rk6hG73uxv//fw7+9hHqNSP38e9Tr+P71MYF4g11aRj3KIKL+UQTi21jjBqUoW2r1orajVABFkFmmLvpJxQq7WAqUOhKG4QaRFlOFQ01ktlRI/FY36Tpjbn+0B7AvUQPQVwOp3avNthL5vZiLRCZIRcHQKrFdZe05T2Y1uU2M3GXPf3cs6opaDUitTG0eekq7WilBJ7xKzFYW08E44Iyrb0bYxXgCTarnVY1bFFvO2t8WK731K2COwiYrEiFVZ9RIeXvMDNUGoZe5iIiIiIiIiIiIiIiIiIiIiIiIiI6HMYfyUiIiIiIiIiIiIiIiIiIiIiIiL67fGnAP7U3f9R+/2/Q8Rf/0JEft/d/1xEfh/ATz/3YXf/hwD+IQD8/r/4k8cc6jG++vgeANjbA45d1T0oCkS0UbwXGL2FSseRgGgLkT6cs53j0HN9rG5OA5A3mc953A7xHvD0lm7dL7RHQgVzirLHJ8dYFIDroSr6OBuqgpzyiJjuUc0+dolzzuP11OZFWtDVAQFqqRAVpJRGeHNbV6SEdp4EgUJU4NVQrcTr/b+HTq4c5q7U2u5JkPQ4x8f5aBPc6rzu3tZ7XhsZ79VaxxqbGapZhELdodLuJSUkRID0cf3m/eHuKKW2MK0DSQAVKOL7tIRjJXqaN9Z5Hh8+dwVMBdvp8z6O20Owe0A0IrGPIV1HSorr9YJStrb/BUvOOJ/P+P6HH/Du+RnbtrVIrmIrJWKntcC8wj0jJx/hU7i3LRPrtK4rzqczgAIAyDljKxu2dUNe8pjzlBMEgvvtjlrLuLN+vZwzVCNWa2YjtiqiyDnu636/43w+Q9o5e+y1j8vR4q3tXNIixlZjv4sq0NYf7hFQLWXMvoogtc+VUsZcSgtJl1JxOi1xLqTj35gW1O1Pq0gEdwFgu90jntv2mUjss/43JmlCyvG8lVqx2QapEctdloxaDaJA1jTuad3WvtAgIiIiIiIiIiIiIiIiIiIiIiIiIvoSxl+JiIiIiIiIiIiIiIiIiIiIiIiIfku4+z8TkT8RkX/V3f8JgL8D4B+3r/8AwN9v3//7v8JJ49tDyvSxddhjpkCPu2Iqv87RzhbbHIFUb6FJh7n1Duw413xshEDj/CqyXwcRoezx1nFt4PD7iIjKdE/T9UQE0UVtmVf3EbOUNpAIUPYx1/FaH0m/3ZEbne+jBVwjONnjr/GOasuypgQgjftW1SmA2UqjbR7MLOYNNq4QwUtt0U2FOFCtYttWeAayRhu11A1AvB/zV8c4VWTvl4pARtR0j6iqTAsjAoUCigiBmsFdDoHeWivM6hgpJOKnWBagR3fbXFa3iLjuE3dcSwDmjnUtSEnglpCyIqWIhmoSaOvZ+tS17dtR2gT69Frsi+Pe6cbelzYK8cPn9vWWdt/7Z/taq8aafPr0CefzGWaGbdtQzfDhwweoCC6XC0QE27bh48cPeH56xlfv3+N2v2FdV9z9jsvlAjPD9XIdcdR1veO0nHA6n6CbotSCUkrsgRSDySlDFsHtdoO743K+IOf+z4hlBF9jmeN7zhkppRGC7ffx9ddfj/OIKnJKSCnBah1BX+9rXjaklGG1otSI9V4vC0wjvNojr9UqluWEsm2xr1tVt5Z9X/YwrrS5NDfUWlqc9YR1W+NZEeB0PkNEcL/fUbaCrRbklNG3cS11/zvj+1oBQPUydlsEduM5Vo3rK7T9vQByTrBqh79FRERERERERERERERERERERERERESPGH8lIiIiIiIiIiIiIiIiIiIiIiIi+u3y9wD81yJyAvB/APiPACiA/1ZE/hMA/xeAf++vckLf65bx+2fCr4+/RyQ1Pn18fY6h7oeYG6xanPsQGY1Qp4zv+5em/Zqiuh871TtHZNX2MO38BQAG2993aUFaQJNCgUOsVfq1IG1e4tzmEWL1kQHtY57HArjtgdoIXApUYyx7DNbH8RqV1Xaa+Fy85rCH+0opA1IBaERI2zUMjuoVySscCo/C7TFsO9EW/HyzUD1y2+7r8XM9mlvN4G4j6KrarqcK8RavFYWmNO67X6cHOffYsLSh+iHUGQHPuH93RzaFJYUlR3JFUoGoRqh1b9Tuy+GHpRmvYew/wUPitZ3jYfPPH/f9q7tczlAV3O4tunq9YL3fcblcseQFAPAv/cEf4Ha7HfbZ9XqFefyec8bpdML1esX9fodVw+1+g4ogpdTeP+N2uyGnhGVZUGvF/X7HkheUWtrYZYRjSy3TGjtKKRFhbYHWfvztdmt7Kx62dV2hLVBba41lbWPwdvPxfPRTx7EpRSTW0fa9O3S6nqgiqaL2vSUCEYVPz3h/PpIoaq04nc/YthXVDLVuIyKdckIpBW6OUmpEoduYgf7ct7hr3xjt/GWrqIhwroqO0LS1fZD6fm77JbW/BfFMEhERERERERERERERERERERERERF9HuOvRERERERERERERERERERERERERL9F3P1/AfBvfuatv/P//OyCx9Ar0CKn3muaU8BUBPBjQPP48TjWzEbEc2p+RkpUMAKeIoBoj3i+DcnG+SMc2tOkPv3v0PHsQdD+Pz0GYTGfr4dHgQiCmsNgh3it9zG/ieT6fPcAgKRpvOotNCqQEXON+Gy8r+ojeikiEI2zmFnEJ1Ma8VirFao5BuK9Zert/VE2BcQgSO33t9HKcc9weG3zHQuCPZ7ZO6n+5jP9uD4njgjp9ivO62DewrvtGhGLTYdZO5jirbF3ANR+p7Z/KiWoO0TbPhG0IOkU0nXAxQ8zMM3SiONOmeI3QxlbtkdrDbDphKoJKWeYO2oLrKaUYFZRSuy7ciu4r3dcLhckifBuRsbHjx/HXnF33G93rOuKvGQk1bhjd2hK+PTyAlVBNYO0PXRaTjAziAhOywk5Z9zuN7y8viBNgV93oNbapi1BVccai8gedgVwOp3iGiI4LcuYJ1WFmx1nSQTLsoyorWiEU1V1RF+tnTcnhbm18LAB3oPKdZrv9pyYIWnCuq77Pmpj6qFoN28RYh+vieiIN8d5vDWJdYSLrT0bIv1qsc5JNZ7B9jfQaoyx34NV+/x+JSIiIiIiIiIiIiIiIiIiIiIiIiIC469ERERERERERERERERERERERERE9Gubyqz9p1bAdJERwxxR1sfSZ3sxeo82oqZmDjfby7AiLfAqI/qKHoBtMc/H+Gu0PPeArMNHDDLelvHaHHbsVPQwyn5fNqKmGOdzxHjHPQOHsR+maq7dOiJ0mtr1FHH+lqttlUpM/dR2SgX62EeQMkq4SRWadH9P0QKy+zVH2FZjHt29pS7fhl9jyD4N31pxt8VOZb8578FTtGitWxuDQg5rGWMde2Wf9Naf7WHdNscPoV5/+Dq87gDqYcJbNDiuo+1nFcC0J2/f7ov5kj1q+3itrgdB+wx6G1ifjzZJAIAPHz/gdr+h1opaK/LtFuFeAAKFqqCUCrOK8+0OVR1X+/TpE15utzZUibhrrViW5RAkVlW83m5Y8tK3z4ia1lrhAJa8IOeMdb23YzPWbTus+Rx8FYnIqbZgaxnhWsW6bkgpjWN8iqD214AIpkbMV0ecVVVb/NbGtfr3WusecR1zOU08JObYovqr2vYasN/3dP2+CklT24O2B55dpmdg+psggEia/8KNKPHYH2YRy+37f1oLIiIiIiIiIiIiIiIiIiIiIiIiIqLPYfyViIiIiIiIiIiIiIiIiIiIiIiIiH653mB0b9FR4BAOFUDmQCoegqjzqdzhMIjFUeYGM4ugY2ufiiDCjhLxyR4HFbEWcIygZztJG4Ls4Vdv5xrZTIFLjF1bkLLXO0fis//ew5GyhyZHIlIEKtpirWNqDvO0pzenyZnu3cwAB3LOEdB0RzVroc2Iuc6JXdU0rhnjauNQiVBmC7uOz7qjesVIpcoe4ezhWqCiTTcE+jDeGKcmhfsezJ3XdHyf4r7eo756DOn2eetRzh7T7XOpqjCRcX+O/Zg+qV/sarZ9aQBgPZ/rqC34Co9rinqMy1vuc7rdtlX24OuIB6Od7QtrLcfvPUQ7zwkA/LOf/uUXBv83T84ZZvE8qgjMYy/3tYj962Ovuht6OLXHbXuYNkKxCeu6Apj+LkznEpG23yMebNWwriuW0xJ7SNBiuMH72FLEaC/XywjFwh21VogIzGJ8ogp1R06phWl1hJO9/w3zFi6W/dk6hqH33HLfi1YdVut4T/ofLiIiIiIiIiIiIiIiIiIiIiIiIiKiL2D8lYiIiIiIiIiIiIiIiIiIiIiIiIh+DS1qOjdfe/iyFTVlhFQV4g70qKfv54h4pI3QZg+izlHT/iXiLfjaQ689/GrtvSncij0wOeux2vG9h0ixX78fF3FSi5yjagQp3eL0qtA2Pp+Lny0IGeezNhfeziFQmUOSEZOtqEgpIYlCU4K6o5QCEUVKEWOVKU4pKc5hbnC3CL2mjFoLqtWYPwjSkuHVYC2KG/PRQ50+wrsRPBUk0YjHQg+RTTNDyqkFWw2aUou9tjBri9X2a/SQK3QPe3oPBes+39bDsa3wOwdXxxZpgVptUdCocsbei7HOO3IK/gIwAcQi/CrVATcoABWHWcypt6jvvFfGONpe7nvWva/t5/aTj2jsvhdaTPY3tAM6ngtzGGIf5JwhIsg5j2NUFdu2Rby43euIGbfoq+pxT/X57nHZWitySrEPzFGsIC9xLU3xObeI9nZmsR+WfMJ9u+F2u+F8ubRQbCyAOcZ1xpOtClSD6pRr7THkEXiOhVZRVCstEq0jBrttBbXUsUdqNeSUkZcFSRO21QHc/l9bGyIiIiIiIiIiIiIiIiIiIiIiIiL6zcb4KxERERERERERERERERERERERERF90WPcsjdgZ3vsUtrvIwOL0TBFjyxaRExrD8DGd1WBQqECJAVE98grYBF/7eFXzEHYfWw9MNm/96ToCKkCqLWiVzt78LEHTMettsApfM5+tlCktxBpC6t6D7VaC1D2ACwA8YifjtlRxbIsI4zpDiw5fr/5bYQlpZ0Xbii1thiuosdzzQpqjeuq6oiQ3m53nJYFPR47Li1t7t0ijhk3AqhC1N5Ec5OmiJxCIBLhTHPbI5lAhGtboLWfu1+rB0LbauwB4LEOkU41bzFhbXHZvpiisJiIWJseVq32sB4t0toinmb9DHGcukLhSABSEkRJVMZazvvY2rrFnuxxYBy++g32+Z7DxnMktu+N3xQiguv1ivv9HuHWFkYtJSLFNsV+a63xzAJQbWvpDhWBAdi27fA89X0L7KHfbdtgZigtyhx7NfacA1jvawSOc1y7c48xlU8vyOc0xmMt5Cwq8GLIS0bZNlQz5JRg5lBRWAslOzyeTcSe8bZvVATQBIUALocwcS0Gq7EnzA2lVFh11Bqh4rKV/w9WioiIiIiIiIiIiIiIiIiIiIiIiIh+UzH+SkRERERERERERERERERERERERERf9MMPP+DTp09/pc/0pubb/KW3iKYf4qvAHpCVFp7s+dY90OmH8wBArT326fjf/+iPPnO1ue95DMK+HbP8knenY+QLb07305Kw7T4EpVYAQLmv+FgKepw17lcBwSFyuY/XWwwWD9fd70z2Q+O6InupVOYzHT7R7maPdPZwKgC8/vAJkD1yGpf8zMz0m/hl7x0naLq3x3uabu2XrIK1AKxXoLy8bRGL9OBvBVBjGCMyur0J3U4Xfbh8i7/OgdcYwR6dnT7qDlSgBU1/c8KvAFCt4k/+7J+2gK8clnXeTruYGx2R5T146+PgHmLGWKTDefrJJ/0JfBtYDvd7wbbWEQUe38cgIjArsodb5xCtP+6tz23bnl4+xKD3e+4v7KHfFcDx+SEiIiIiIiIiIiIiIiIiIiIiIiIiesT4KxERERERERERERERERERERERERF9USkFpZS/7mH8Sp9eX/+6h/ArmdlnIq9/89RS/7qH8Cs5IgDbf3777q/z2j/vlf953/2byd1xu9/+uofxK5k57DdyhomIiIiIiIiIiIiIiIiIiIiIiIjo/+8YfyUiIiIiIiIiIiIiIiIiIiIiIiKiLzotC1JKcHeoKBwO9wgwigjcHSICOOAPYcb+evsFAsDcIBA4AGnHmBkc7TyI4yDYrxOvxPm9fcYNtVaUGgXQlBQAkHOGiKCUAjODiEBVx9dWtjGm+T0zg7ujtvOpxvlqrRARpJTGa/PxMeYY41YLkuqYFyDuYVsLHB7XauN0t3FnY9bcgXY+TPf6mLvc579NFPzwUXeMOdznbv/vdPpprgGrEabNS9o/5w43h7XxHta3zYWIjLXrZ5W2fn1cIjLWfR5HHDOtvchhCsa12j7ZygZre3FZ8pu5kcMYx+bDtOjTW9Nr/nj8fo7+1uGjD/MwX9HdsW0bAOByuSKpjnvs380MaPvPzKDTOksbkwCHWLC5H861z/u+T937eGO/eV+ANs/955QS7vc7trJBAJyWNOa/fRzuFsFVN/i46XnHyviWVHE6nQ4rMO8v4DOLOk3am5mfDv/0+gIAWJYFOWeoKKpVCKTtBRnP1ZtwcbtfAHGM7xHmlGOf93natg0ppfH3RSX2dq0VkPY3wXF4tlNKqLViK9v420FERERERERERERERERERERERERE9IjxVyIiIiIiIiIiIiIiIiIiIiIiIiL6om++/h18/f49Sik4n88R4Ny2EUStZlhyRq3WIpEOuENUkVOaAqwJIsD9foemFMeIIuWIUJoZcgsvAhFxXbcN2gKXDsBqjeOWBWXb8P2HD/juh+8BAM/vLgAcX3/9OzidFnz73Xd4fXnBcjrhfDrh6ekJl8sF3377bQRjHTidT7herrhczvj46ROsGj5++gQR4HK+wMzw6eUFSROen59xvV6RkuJyvuD19noIwwLA999/j6fnpxGTdHeUUvAXf/YzVHMs5wXXd1cAQCnbCKe6+5uYbA9M5pwPscl+LIAR/+zR2ghXAmYtdqmCpAkQgVkdMdYwB2MFVgyvH28AgK++fgcVBdxh5rjf71jXFXvYU9r5FafljNMpopxJE8zquC8za3MEnE+XQ5y2W9cV1Sq07YUlZ0iLDO9BVkHOGbf7DT/92c+wbhuWZcFPfvLjca4+d6oyxjcCuyMk3N/f5xIQJNV972KKz2KOoFqLIPcxdTLmsM9pKRv+4qc/BQD8wd/6A1yvTyMmWmtBSgnrukJEcbmccbvfcT6dUWuJMSaFikJVcLvdYn3cULaC69MVVis0xVzlHP8U+OPHT1iWjFIqai1wBy6XM0qtECCeT6sQUdRa8e7dO/zJn/6f+NnPfwZVxU++fofUwsmxXxz3dcXtvuJ2W1GtzaUKolsrI6yqqrheL/jbf+tvI6nu849jIHjM3BRQ3deizWYLBfe5dTf8r//bP4bD8c3X3+B3v/kRzucTPn76NObx1J5vd8f3338/Is39GelR1ufnZ7g7Xl9f8fr6iq+//ho5Z5xOJ2zbhu++/Q7P756RU8J9XbEsC86nMz58+AGaEi7nM0opqNWgKii14v27d/jF99/ju+++xfcfvgcRERERERERERERERERERERERER0ecw/kpEREREREREREREREREREREREREX9QjmaKKUivc4mcAI9jq7lhOC8wM1kKLKWfUUiEj/OhYtwhfmjuWnKGqWNcVKaUIcJrB3CHt3FEn3UOqEfeMa6eURnS1/+7u+PDhA5bTgq/ef4X77QYBsG0bfvGL75HSR/ze7/0efv7tz5E04Xq9QkTws5/9HA6P8Yrg3bt3ePf8jD/64z/G9XJFqQXbtuF8PuF6vcLcx/UibKn4xS++wzfffINaK+7rCgB4fn7Cz34e557n0tGilBYR2vm+etg1TSHcOQ4LwbjvONceiY0YbA+6RlCztvMBeyw26psC6BQu3Q+LCKkmCOL4ZVmAdq5Yl3Ztc9zvN9Ra8fR0xfV8QamC0+mEWiM2uyxLzBEiQLrfT+wNh+O0LEgpQqY5Z3x6+QRpwVMRQU4JtVbklKcwaIxbNWK3cwi3X2MPvbatJJEjnWOjqhEWnoO0x2vsx/bwqztGnFYEY+1GGHb6vFmEQpMsqLUg54z7/Q5AkJKOE8e96ljHj58+xh5rcy6iOJ9P+O677/D+3Xvc768opwVP12ubt4Tb/Y6cEnJeYBah5HiuHKfTgpQuMHOs64rX2ytKKW0WgWWJ6C5E4A6YVby+3lBHvFlgDrh5b7seGrgqOu3LfRpEtH1Nn2mB1xHgFYG0k8Xc7/M3r0ufz/t9xcunT7g+P+N0OkFVcbvdIiRc69hz1WrEplXh5rjdYq/2kPXr7Ybz6bTHp5eM19dXiAhKKVjvd6ynFaKK0+mE73/4AaUUqAhO5zMulwtutxuWvGA5nUBERERERERERERERERERERERERE9CWMvxIRERERERERERERERERERERERHRF/U44yln3Ne1RVDPAIBaSoQbRVBuN6gqNCUIgLJtEFVYrb33CDeDLieUbUVtMdPSYo3AHnCtZnsUtgUyrRU8a63Y1jUimSqHseac8fz8jOvlAgdwPp9HGLRawXbb8NO//CmsVnz1ox9jWSJY+/zuGbfXW4s+VtxvN1itOJ/O+Prrr/Dtt9/h5eUFr7dXfPvdd/jJj38Cs4qcM9wd23bHN998gw8fPiDlhNYFxcvLK96/e4fvv/0IoLZ7q3s0VHTuXI456BFXB7Ct2xRtndYFLXgKmc7hAHRET62FQ72FRc1alRMAWti1x2DN9/qragvPukBUsGisj68b3BwGO4zHrKLWCmsxXG8RYDOLEakipwTziJFCBOIKbeOPQHBEZ7dtBRzQpEgthrosS+y9+zbirl2ERe0Qz90jsHNxtIdf9wjvPn4b55rnzqe46x4rnT/fzynH8xyXNKK3YlCJwPHlcoVZ2w+14nQ6t886trIB7hBI7OMWPe7H/vhHP4KZ4d27J9Rasa4bIoKb8HR9gruh1BprLTb22n0tcHecT2fc73eISNsPaDe5YKsF67piKxE73rbS3lckzUhtze/3FZAI56LdO9paOiLe3P8uzPPW93Wfof5e7L1+Hoziq8gUyAVQSuyP8/mMd+/f43q9AgDWdcV9vWNZlogzW+yH5PEsqirO5zPO5zNut1d8+vSC9+/f4+X1BWaG8/mMJWfUavjw4QNOpwXn0wmisf/ePT8jJcW2bXHelGC1Yr3foSmhlA21Ra+JiIiIiIiIiIiIiIiIiIiIiIiIiD6H8VciIiIiIiIiIiIiIiIiIiIiIiIi+iJV3YOd7bVSSgQ9c0ZelhGT7IFKEQFEUEtByjmirWZYlgWlbHGOLaKmPcDqLe6qKeHUXpMWywRaOFIVDuyhxakDauaodYW74367ASK4XK5IKeF+v8f527+afP/+K9RakZIipYzL+YyyFZRbGfe6jXtcsCwLqlWoKN6/e4/vv/8eooIf/+hHSCnh9fUV9/sdeVmgGlFNt4p1vY/IbdfjoeIOURmty37+lNK4nz4vPQjbf+8/i8iInrob3PYo7JgzwYiTxut7mnSOccr0urvBERFfOGKcI+LZyrYadVr3GOe6rnh9fcH5coZXj8uIQNq6ujvcHC5+GLe2OehxX7MI5EZkM8MRcU+r1uZrD7r28fSv/b7next3ewjWxpL0z83z0QOxfYNJ++z45HSOfT4fmrSHOQbivhwRJe0xXpGIoprH67F3DOaO5bRg2wrcDTkvMS5g7KX7uo6fay0QkQjntr0DOM6nE1QVWylIHnPtDjw/PwNw5Jza2CPCfLuvWNc1Qr4tmmy+x1xVFQIZgdw2g4BH+LZaHXvpoVU8rVl/b4/zRsB4Xz+Hf3Y+U85IOcczZYbb7Yac85jn++0OuUjEqd2xlQJzR06KUmIue9D206dPqGZ49/wMM8P9foe543RaUGvFZYrw8wAAIABJREFU9ekJKoJSK7777jtcn64Ru04ZZobX11cA+L/Zu3teWZY9z+vff0RkVtV62Puc0/epe0aaGQMPEwNhIQ0+FggDaYRAYyJhAda8AV7BeJg8aCQwRxoJF4cBYWDRwzR097333HP2w1qrqjIzIv4YEZmVtc85t7vRSCN6fp/b++y1qiozIyMiy9r6Nl+9f0/J5ac3gIiIiIiIiIiIiIiIiIiIiIiIiIgIir+KiIiIiIiIiIiIiIiIiIiIiIiIyF9CLaUHKgO1B17XgCfuLczqDrVCD4XuC5BrQBKMGKwFJt1J0MOg9S7OGWLs0dB+iX6OFgWNdyFMaAHMFqBsIVKAh9MDMUTcfRv7+sd7aDSEW1B1GIYt7blGV9dzBQtYaPf8+vbGOAxcLheOxyMpJXLJnI5HSi3knKnVCCEyLwv7YOiXEdWtMepr9NLb3z3+ugZJ1zGv57A1Zmo9t2mBSr3FZbcQasDsFtDd9HO1ZfJ9R7ddNxjQYrv06OztD1gf+xpLzTlz2cU4tyhtP18IkTWCaqGN2b1iIbSV9Vs/0zCqt5io1VvM9D6wuYZt1/u4j2/uQ7e32+6x3d3n7rdp32/botxe34623TjNv4ic/rB42tYuYl57UDX0WGuLva5B1hb9bYMxM2KMLEum1tLP06KxBSPE0EKkGBZaqHjo876tEevat3u2Hped57kHjdMWGgZYloVlnnsk1fu+C9tzGUPoz+Q6lr4efd/WUltQOcT1Yf/BXOxmuW+eL9dz3TP1x492xzBSjBRuMeQQAimmFnDOmZRiH5qTYiQv7buh1ro9L2vAen2+1u+N0/HUviN6bLeUwjTPLTgL5P4949UJsUexw31YWERERERERERERERERERERERERETkS4q/ioiIiIiIiIiIiIiIiIiIiIiIiMhPcndyKZRSOIwjsVYKLe3o7szz3EKftyImmJGXhYeHB5ZlaTHJEMg5MwwJesw0l8KyLC1sSgtgurcQZUoJB1JKW7ix1EqMkWEYtvOuWvQxbZHRUgqfX18Y0gD4Fo0FeH194f37r9oYcmGeZ2qtnE6nW/wyBHB4eX3Ba4th1lr5/PkzJTslFn777bc8Pj7wzdff8HB64HA4cLlcKFZJCWI8YGa88MaarzXYwprV69YYXUOUaxR2/9qXYcl9eNer9yhtC3MWr9u6WY9wruHY9TxrHHQfgPV+HPT4KwGjn8uMUlrwcs3ErgHPECJmLeo6z/O2ni342q5XSunrYC3o6i0mmnMhpdiDnH3vVEgpUmplmZe78O0axm2TcAui3vbBej+2RU+3/6zT2uuvLRx7m9c1MGu7cOltvuiRUduObZ9ZA7Rsx65N1G2tgvV9F/s9VEqpmFWcSEqJISXMWpjV+5xixjAklgVyLkDe9naMYfvZHUoupBg5HA7knFlyxkp7Jlpo1sAqvjjTPBFzZhyf7/bDNE3kUlpg1Yxg7ZkMFogpktJACIFSKsGM4hXHcBxzKLW090Lsu/zefl43fov27ve49fOuY1u1AKtzOB4pOd/leVNKDOOI18rr6xspJcZx5HA48P3332/7J6XE4XDgcDhs318ptRDu+uw/PDwwTdP2HfP48MDHT594enq6vfb0iNfKdJ3afO1CuiIiIiIiIiIiIiIiIiIiIiIiIiIiX1L8VURERERERERERERERERERERERER+ktkt9FpK5TCO5FJajLWU9qEe+0wpESyQS+bp6YlSKyFGSs49/Dpsx1R3DIgpbdHFXFrEchzHLSKaS6GWgrsTY2LJmRgjaRiIqQUXDXh+fsc4DlvI1B3O5zPH44G385lpmlg/PI4jZtYCs+6UkskFXl5eCCFwOBwYxxGvzvPzM9frlXM/R66ZP/qjX/Lx08c2viXz7e++5Ve//BXX65VSK8fDAQuBeZ44HMa1fIl7pdbcQ7K36KWZYcFa9HIXbV1jsL2nu8VrHSfGSPW6rcO2Fu1C/ZpGCIDbLpTp1Mq2Xu33fUazhTzBCIR1F1BrhR6t7afp61i3fRLMyDlzOp6w0OKlMcYejq3tfmqro9Yego0eemy2xVxDMJaceTidqO4tOOvOkhceHx/4/uNHYOnbzsiZHsLtcV1j+9nxW4i0beJdmNW2eYU1iNtCpmZhFyv1LdrqHrdI7Lp267re1vJ2ToB5nrnGKyEExnHk9fXM8XQkmG3h1tKfJ6/O4TAyjgdKyRwOAwCXy0TOhRAC8zzz+vbGOIwMQ2IYBh4eHnCv5NwCsYex7Q2vzrK0uUrDQIq32Ow0LS322u99mmfCGtrtr1WcECIpxhactRYjjilS51ss2IFa2vWHlHDzHsldI7rrXN4OWKOuW8zXbx/ZIr9+H3/9+qv3fPPN15zPFy6XC8MwkFJinucWXS6Fh8cHlpwZxxGA3/72txyPR4Zh4Hg8bqFXd+ft7Y1a6/bdcDgcmJeZ8+/etu8I7+t6Oh7BnUN/fT3OgafHR4ZhQERERERERERERERERERERERERETkpyj+KiIiIiIiIiIiIiIiIiIiIiIiIiK/h2EhkGIkBGOeZ0IIDCkRQqDUSi2VFGPva7aQZ62VZVmopWBmLdTY46XTPBNjbAHTWhnGsQVBe4TU3RmGkSUvBG4RyVpbHNZCaIHTXbP0eDxyuVyAFkkNIZBS4unpmVqdyYyUIn/0R3+EmXG5XDifz1tcckgDl/MFzJiXhVIKQxr4zW9+0wKa1iKjMUS+/fZbQmwhTu9R1P/zj/+YcRyJMZDSwDiOHA6HdqyvsVBu8VS7D6621mX/n9+Cuy3+2qKi1dtcV28h1RgiwUI/Zv3cGixta3CLx9pduDTGsIumOmEdF7SQZaWFWrEWrS0t9hl6EHNrdfqW78Rp81prZRxHSsk96NrDocGIxC0MGkOkulNKaSHgCCGOHPre8FKwAGaRJS/t3my7GKXUXcTWtvn1Pj/7+WvzsV+H29S3edjt+N2xbS4rtToh3F5r67iPv96uH8JtbQ3bgqO1Vr7++msA5mUGd4Y4sCwz49Bjo165Xi9rXpaU4hYHxuDdu+e+b9c1LXx+OVNyYRjSFixtsd3A8XjsMeXMNF2356uU3PZuv98hpf4e255IIRJTIsV23hACKQRyzm0f9uPbs1vIObegL4CFXbjVuHtY26zewrwOmOPb6W47ah9/fX07k+InSil8+PCBx6cnghkxRh4fH0kp8f2H7/n5z37O5XLhOk08Pj5u0dx5njkcDgzDwOfPnxnGgafHJ86XC9P1uvvOeOI6TRwPBx5OJ379m9+QYiSXsoWqx3Hk+fm5RatzIffIroiIiIiIiIiIiIiIiIiIiIiIiIjIj1H8VURERERERERERERERERERERERET+QtWdZZoI1mKwt4woW1zUewjUzFrQs38WWtCxupNzJvZQbK2VYEYuhZQS1TOllBZeHQZqKcRh2I7FnaH/XkqhrrVI4Hq9bpFYaJHS4/FIrZXD4UCtlWm68ud//mt+/vOfMQwDZoFaC2BcpyuHw6EdG1qwdJpnjscWiwwh9NhmZckLp9OJeZpYegzSzJinmZACpVSWZebl5YXxMHLLo9p2ji22ai0Quo1938jcBUp9F7s1Wohzjdy6V0ouYNYzm/exzbWfeYuhtkDuLQh7fy3DqN4jtNbWqZRyO+N6SJ+TLdBp7VqlFMZx2N4bx4G8tBBsDGHbJzG2n9c4bEyRGCI5LyxLj71ilFoAyLncXavNQaDWNRLaAqwhxL5HeqiVFk9dA6a11q1eu0Zh92HYFry93Whbe+9jNdzb/N6Oua1fC8Xe9mWIoY899xgu2x5YA7+1Vsz6HG/BWVrY1yulVLw6bs71OrX9E0IfZ1vtEKztZ2/3FmPEgWXJ5FzaPITQ1rbWu2cFIKYW5V3XZt0Soe/NGNfQcBtXX5rb3u3h2rve65f7ynYv7Pby7SX/shF7Zw0tHw5H3r97B2bbnmn7tPD89My1h1xP/fl/fHzkcrkwTROllG3NDuOB19dXUko8Pz1R3bler8zzzDgMzHN7hnPOLQr78MDlemVZFmKMTD0mG9MPA8IiIiIiIiIiIiIiIiIiIiIiIiIiInuKv4qIiIiIiIiIiIiIiIiIiIiIiIj8NWJm/xnwn9Ayiv878B8BD8B/A/xt4P8C/n13//CXOV+LSbbo6hp09VpxM7BALaUHSG/RyDXWGiwQzNrrPXKZUtrCr6UUlh6iLKVQa91Cqrmfdx9FNetR0lp7nNTXt5imaQuiGkb2wrIsLexZCiEYh8PYI5wtsplLwTDGMeEX5927d9Rat3EsS2YcD4Cz5AwODw8nLpcecI2R1M8zDgO11G3Oam7BT+8R1b42/X4cs1ss8i7EubUw15hom7d9z9XMtnjsdn5rJdNbdnQf27xFX9ffjTXWuQt27tZvDXqCk3Pp69miqOv7huHs7+8WAW73GoC6xXrNbuvp3gKm1tczBCP0fVBK7ZHRtne8Vmw/AXdj5RaE3e+/NcDq4D1Suk3wOgdfBFB3Z2ANsN4+Yrs5pb93i7/eKqd+N54YIiEY1SFZolZvIdlaeyi54E57Lsyotd1/KZmcF3KG0CO/0CKva9y2zWFkHA8sy7w9o7WWbV5CsB4FDusWIZfM0OO/92ve1sf6s7UGcK2vxRoCxtaa8Lru9sO5dG579os53H4z7vee//4ArLtTcgZ3Qowsy8I4jkCL3MYYGYaBy+XCOI4t0DpNTNOE9Rj0uj9zyeSSqbXevhP69xPe7rP2UOzj4yPLPPfvk7rdyTzPGMY0T1yn6ccHLSIiIiIiIiIiIiIiIiIiIiIiIiIC6P/NvIiIiIiIiIiIiIiIiIiIiIiIiMhfE2b2N4D/FPg33P1fByLwHwD/BfBP3P1fA/5J//0vZY26xh6gXOOJtccnSylYCNRecVx7j96DpfswpNdKinEraLq3MOsaf22xykCIkVJKCzHSY6f99RafbKFQ28Ukl2VhWZYW3jRYcuZyvTJNV67XK2A8Pj6RhtSDkC3mWEoB2vkfHx95fHzkeDwSYyTGyOl0YhjGFp6shXEcGceR0uO0aUgMw8DhcCANqc2TtYJrCIFcMmvN0ljjqHdrdr+G7EOi9Liq4/UWFV2PWQO6LfbZ1mQfr4U2T7fYabgLldbqt8/uxnSLt7axbiFVs7uQ5xrqbNe6neAWgG0/L0um1rZfWsV33SRtjtbYbQvuLu1zDqUHONdz3TVB/T7yuqVXd3NgZliwW8B1Cwbvxopt97rGcX13T+63P7f7Y3fM/tgfYbdY7zAMPYTb4sW1R3HdfQuXppSwYNu651xa7DQYMQZSGogxbmMDGMeREGLfs+EWka2FECIpJmJan992zyHcx19rqdv+XOfReyB3PW7dh23tbvP4Zfx1H4G+jfN+Dm+T88VRX4aIdy9Ud0qtLcRM25drFLf0UOs6jmBG7ON+fXvd5niN7JZcmKa5PaM5cz6fOZ/PpJQIocWnvc/t48MDmHGdJnLO25zUUrheL5zPZ5Z5/okNICIiIiIiIiIiIiIiIiIiIiIiIiIC6V/2AERERERERERERERERERERERERETkX6gEnMxsAR6APwP+S+Df7u//18D/BPznf6mTxUQw43I+Q496xhhxd6Zpah/qsVAAenQx58wQAl5bVJIQKDnz+vbGkBKYMaSB56dnai1cLlcwJ4RIiAHcSamFWlu0MbDkjNfK4XhsY0v3/wzSzDiMB8Zx5O185v379yzzQrW6hR9LLvz2t9/yy1/+kjGNuFfmeeJ0OnG5XBiHEYCcMzFGfv4HP+NP//zPCBYIKXC5XDmdjgzjQMmZEALjOBJj5OX1lWEYWlC1FmJqQc7lemGNnq7hyDbgXdzyyy5mFyz0t2+BVt9FQ9fYbbCw/f5lUPbLSGetpcdFaw/R+l1kE4xafRdLvZvlfh+3X2MMrNnaUjIewl1EtNbCMA5b5DUYEAN5WYgxbWPKpV1zGIY2N9UxWvQ0l0Je477rXd3dq9/HYPfR4d0U23pPvV3q+F1EeA2V1upb1LXFYCstDPvD0OttSM6X05WXzLws4JCzseSFWuoWCnZ3lrwwTVfWAC7AkAaOx8MWsq21EmOilEwpmZTaPss5t1isO9M8kZdMqWW7pyUvu8BtC6gOQ6LW0tZ4v7KhhYG9z0MIoUWNY6J6bUFn/C6mexd97UFor4FqLczaWs2Ou4E55mtU+P7at+DuNpPbGq3WZ+10POLujMNAipGCMQxD+15xb2FoM2KMHI8nrteJ0/HIt99+Sy6FwzhyOBzwUvAQGFL7jpvmmblHXNcxLsvC6+sb7969Y57n9szHyPF4pLpzOZ95enoCnPP1jIiIiIiIiIiIiIiIiIiIiIiIiIjIj1H8VUREREREREREREREREREREREROSvCXf/UzP7r4A/AS7AP3b3f2xmv3T3P++f+XMz+8Vf9pwxxi1oejwe+fzyQkqJ2P/kZaH0wGt1x6DFO3vE0+saGXXS8cgpBKZpopRCKYV5nhiGEQuGWYu+lpxJKVFrpZSyxVJLKeAwzzO+/t4dDgfmed6CldUrx8ORZcm8nd+4Xq+cL2+YGaUUUkqcTu39j58+cTrRYrYPsCwL1+uVw+HAP/3f/ld+9atf8c03XxNCi3XmZSGXwul0opTCNM/8/A/+gIfTicPhwHWeuF6veK3U3RjXiOgaJt0HUp013ArsYqT7z7p7j3C2yOkakl2jm2Zhm6s1BFt7DHP/eouMtuv03ide7q9Zi/cA7BrCZAtxtrBoD4XWim2xV8dCC3GGEIgxEkJoEd/rxDi2mOkaUg0h9kBoC7bGEBiGRM65hz/b/dZa2lXXaO42Tr4IvNa7160P2bbX+g/e92r9sViu79Yp9KN9F9o1rM9d/78v3Gd013mgrwW0yKpXx4MzpAGA2p+Tdk7DAuRcGMehBV7NGMeBUgovL6+cTm3+zFpgdv3bvTIOI6fTiRACy7K058UrtbZn5nQ88vZ2ptSyjbiUQiwtVryGU8ehxVSdejeHtRRSigD9Oa4MaSANQ1tzC3f7tnpb8zVCG0IghPsw75eMFovdv5+Xpd3ryfj46RNADzpncn+m8zxTauXl5QXv74/jSK2VlBKH45Hj4cCHjx/5O3/7b/G7333H9Xql1so4DFwvV46nY4tO97378vICBuMwUHvY+vXtjZIzp9OJ3K8vIiIiIiIiIiIiIiIiIiIiIiIiIvJTFH8VERERERERERERERERERERERER+WvCzL4G/l3g7wAfgf/OzP7Dv8Lxfx/4+wDvnp+AFkKdemx1mqYWlMwZ61HWmBJmxtI/U80o1yvjMHC5XAgWej/TCTGSl6WFLIc1elkpJRNiJJi1c/TQpoXAOI6UWvGcOYxjD1n6Fo9dXa9XzAIfP33i5eUFM+MyXLaI7DAMmCVeXl85no5cLpctLPtwOm1R1mmacFrA9nqdeH5+5tOnT7y9vTGMAykmHh4e8Kmy5EwthVor12mi1srb+UwI7f7mZeHd8zuub7+jrDHW6j3E+hPVyy9yolt0dPd7rXVLjK5BzRZTDdscrkFYWCOcYTuP2S1u2l7x+2SpW4+u1rv4Zu/G3mKpPYbafwHYgq7LsvRoKQzDSK2+C9i2IG2MgRjXKG0bT4yJeZ63e1pPn1IibJHZ21yt87NGRdfXaq2EEGFLwLKdr83ZVrK9ze9dzHUN3O6uZuu62Rcr5btjuCua5pzb/fR7qLWSYgKjR3ltF8A1Qg/49kbt7j6ceZ4ZhpHD8YBZIKWIWeTl5Y2YIu6VnAtLzszzhFkL8bqvEWGo3u7rdDq2cezsg73r3gHf7sfMCP08a5zXzIh97lOMPUhru325xoLvp7QFdvfPwG6P/8SzMR4OYPDt737Hu+dnhmFg6s+d1cqHDx8YhoGhz3N1J8YWbH59e6O6k/qVUkx8//0HSintHlJq0Woz8pIpOUNKJDOet2vNW6A5hMDzV1/z4eOHL/aCiIiIiIiIiIiIiIiIiIiIiIiIiMgPKf4qIiIiIiIiIiIiIiIiIiIiIiIi8tfHvwP8M3f/FsDM/hHwbwG/MbM/dPc/N7M/BH77Ywe7+z8E/iHAH/7q595fw2ttrUe4i20a4NYij2sS0/rvrDHOXgzdwp+1EmKktvoj3qOwtZQtMum10rKuPQDaI5TeY45s793knBlSopRKLS1CmnPegqEpRVJKPBwfwZzT8QR9TCklSi09HtrEGFly5jAcGErC+r1cLmdqLTw8PJBSYppnlvOZ8/lMTJGyLOTc4qwhBK7TdRez9O3cOeft93VOHQfnLnC6ztv63vqaYS3Z6t5DomF3hdvn+g/bdda5WyOW++tv+6D/5/Z6n38cc/u9pcsQAiml3fWsB2CHbUzBAsECpbbgawiBUiqlFJYeB2YNiIZADC0K2wKpP7r8d9fafvc+8+5QW2DWPbT72IVJfdvd/RXbr9ctXHofnt1fe5s1fpAutVuUN8bEOLQ9XEru4eO6hXFbOLddo1an1kLuz4eZ4bUHhEthmReWJWxxU6MFTEOM233XUvuY2+9mxvFwJMZwP5f9/kLo4VnAve+RPpdrPNZo0dp9MHh95lNK7T2z2/Js03cfgt32Luv23Ed6d1O/m/IYI8MwUHpwOcRIjJFU233GEBiGkePxSEpX5mVpMWSHcRgYh6GFo3PmeDzg7hyOR/x6pZRCjJH3795xvV4ZD2Nbn1y2+YoptqhsKUzTTK2fW8A3xjbvIiIiIiIiIiIiIiIiIiIiIiIiIiI/IfzFHxERERERERERERERERERERERERGR/5/4E+DfNLMHa9XHvwv8H8D/CPy9/pm/B/wPf5WTrgFNd7aY6hrorLWCe4uPmoG3OKTXSghhi3DaLqy6RmBLrdQelnR3av8DLShZa6VfpsVI10hmD4auoUxo8dMYYot51haszcvCMi/b3/O8tJakt1BmjJEQWkCzurNezPprh8OhxSWHROz3HULgcrls4w49CJpLIaWBcRjBWngToOSC39VAvUdI717cJnof1AzBbsHR3cf34dL932sgdx95XaOd7bgvLtfXhi+GEux23S3Quatwuu9yqbv7WMOgaTe3LSbaXmvR1R4PtRb5rV63+Kd7C8DCusa2jcUMaq23y30x5nVPtc/0PdXno+2rusVT1xPc5mWtjNou8nqLlK73/xPt1z7v+xzqTYyBISVSGgghMIzDNi/r81NqodY2o7U6pRRKyS0M2+/L+33N89zvt5JzYV6WPub2DKQYSWkgxbRbw9s6xdhCuzkvuNfdvd0itSHYXQjZ7/bIbd+32PMt/truiduutF2+2W5/frh+tluH/at2t++g7Z1hGMg5k3Nup+nHxZS2sY/j2GKv0J7jlAghtuAzEHo01794jodhbNfpsedSS9u7WwDXejS6MvdQ8e9pIYuIiIiIiIiIiIiIiIiIiIiIiIiIAJD+ZQ9ARERERERERERERERERERERERERP7FcPf/2cz+e+B/ATLwT4F/CDwB/62Z/ce0QOy/91c5r/VgYvXKMAyUnPvroUUkQySmSM6ZWgsxBnIpxBgpPQIbe+DVadHPfTS0RV7tLv44pMSyZIIFireoZ4yxBWhjIOKY3QKV4ziQ0oAvC7mWLfLZArSVaZ7x6wQGx+OR6ToxjAMxRmKMzNN0F3iMMXI6nTif35imGXcnpcTT0xMfPnzg8+fPPD4+YkCMkXEYqO6M4wDAuZyppXJ6OGF26eMx3GGeZ6wHbHdr138AN98Ct2vMdB3b/vNbcHN7DWytavag6hpW7b+BtXOFEFpQtC3k3blDiITgLaTbm7hr2Pf+Yvvs5S2cmlLcjWv9XI+v9mNbyDdscVYzI8Qe7/XaI8NQq7MsmVoruZTdvmlR1C/ncD8vWwh3nfvbJ7fTuDsxBmrtr/k6XesHbnP45Tqs0eLbwu2mvosxklICWug1hkDOuYVWafdXS6FSthjrFtw1YxzGFlimhVunaWEcD6Q0UGuh9MiwmVFK3tbcvT1XpawxXDD3LZq6LHk7Flo4ts8MeF/rbZLWz/XIagjEGAglUOoXNd5t/n7Q5/3B/v3yPe9zaG3af6CUQi6lR4Od6XoFM0ouLHlpn+nfOeMwEEKklInn5yc+ff7MNE3EGBmGgWVuz/Tlcm2x4pSopXC5XrhcLts+Df174O18ZlmWFrK2wOF4JJgxLwslZ2opPxywiIiIiIiIiIiIiIiIiIiIiIiIiEin+KuIiIiIiIiIiIiIiIiIiIiIiIjIXyPu/g+Af/DFyxPwd/+/nG8YBsZxZJomhpRalDOlLYQ5jCO4k5eMhUDs79XSAqzj0GKoOecWG/0i0Glm1B5Z7OPHHaZpxsxYemg2hLB1JVus8z62GEPk5eWNYDAMiRQj87KQ89LisyFAtB4ZDXz4+IGnpyeen58JITAMA2ZGXjLOGoGF6Tq1Y8woOfPd999xOp64XK98/dVXHA4H5nkG4HK9UIoTY+RwODBdpx8WMLvqFc+3N82MYUi7aGehlMLhcGif7wHQ1li1LTy6D4XuQ6+r9nbdWq37wKlzC6Z63Q20h1hDrNCjli3cuQZO27WDGRZsu/Yazq3VKWXZThdC3fqhIYTWFvXKYRy3OGkIRgwDwQLX67WdKxjUQs4Zs9Tjsb7dV62VUgsxxB/Eg+8YWDCC04O67fotPFtJdtt7+3rprW9rPUR7i6Wu12v3W++vtSuX1lK5XK4t+BoDKUbcnWVZtqBwCIEQY38Pao8Xu8P5fAYgpYHDIfYAchtnjImUjOv1su2ZdT+4tz2Whv5Phfu9j+PI5fqREEOb322NWiy35LJ2fNtzue6xUNt99XBwSolcKs5uf2z7se/Fn9j7d0vzI2t26yDfnyCY4bVyuV75w1/9itfXV87nMyFGHk4n3J3j6dTirX1u3z0/U0ql5EzpezmEQOlrllKkeiVUYxhHfv3rX/O3/9bfat9HfZ2++/57zIzpeu2B55HcfYlZAAAgAElEQVR3x2deXl6Yl4WnxydS/54TEREREREREREREREREREREREREfkxir+KiIiIiIiIiIiIiIiIiIiIiIiIyE+qteC1Mg4D1+uVw/FIKaUFL80Yh4GUBsxmoMUfS61bTNVCwGttOU0zQuixxf4eQJlnDFhyxsxIKRFDIITI9XrtsdgWeD0cj+ScyesYuvPlzPEwkktp0ddSeHx4aNFNC1Sv5B7HnKcJB77//nteXl/55ptveP/+PSEEPr+8sMwLMUZOpyPX68TlfO6xULaA7TTN/D9/+qc8PDzw+PDAvCyEYByPR86XCzi8f/+ep6cnPn7/ma3dagAtRrvGS73eYrjrnzXwWXbxVXff2qRrNHONfbafwewWL23rcft7jZXuP/Fj8pLbOMzoqdke8zR8H/W0Wzw2mBFSIPV1X5YMZgwxMgwDXp1pmhjHoQWC+4TU2mKi1Ss1F4gt7uvuGC2IO44jKUVeX1+xPvJ1n+znyt2pdT8ftc9TC7SaGTkv22fWKPAtCmptjbdA8S2QS4+pxhD7uCu1VhwnWLitR72tGfTobAjEGBnHgZwLKSUsBAwjxtgCr2aEYeznhDQMTNeJYRxJMW6h5NPpgRACyzJTasWrczqdtvV1Wmh5nme+ev9Viwz39XGHT58/MaShz+9NiO1ZrG0CaLPmuNfW/K1AYAshJzNS7pFajHEctz3x5eZqn7Av9qr38d7eW/93d+zumNKfvSElfv3rX3M6nTidTsSUMODl5YXz+czT0xPTPLMsbwCMw8CSM7EHpkspvHt+ZppnDOPt/EZ2eP/+xGEc+e677/jmm29wd67TxFdffcWyLCzLwpgSh7F9z5gFfvaznxFj5Dpff/xhEhERERERERERERERERERERERERFB8VcRERERERERERERERERERERERER+T1a/LL9NI4jeWlhVDPbApilZCwYtbQ4YwyBXEoLc67x0n4+C0bwW+QUb/FPC4GU9v+s0ai1MI7jFlzFYJqnFnQNLYi5OhwO1NquHfrY5mXGq+OhhUBrP0/rgQbcYVkWPn78SK21hSRDwMaB6s7b+Y13z8/UUliWpQVLY+R6ndaKK9frdQvUYjBeLi1say3u+nZ+2wKWxhpgZQvXhhAgQLBwdz/rHOSSiSFu4dbqlep1TaBu0dG1yOpubC/RSq1rP7P09QGofY7cbxHWm9KCryEQY2jrWlsAdeu+hhYaddgiqbXeQp5DanPIGvZ0J8ZErU6dZ0opHI9HzKCUvF0595+nedruG2A8jJiFH4RF13vw+2YoZmAWt7lprWIDAma1j9y32OsWb+132PaIbZdzA/M1RupbrPS+pLvOyH4ca6TW+hz7ts7e3x/HgRhjD7XWFrh15/n5ibe3Mza0vbHkNjfVA7X69ly4ez9/ZckZr23+L9cLQ0qkNPQ5aM9TDKHFedeBG1tctgV/16BvALzPZX/PrO0F1r3cxnY8HLEewTWsBYp3wdct4rqPB/dJ+DL4+lNCD0JbqLx7/x68hXavlytLXjAzHh8fyf0753A4kFLi9fV1C/B6re2Y65UQApfLmSENjOPAPM88PT1xuV6ZpomUEikl5nnmMI489Jh0rc5xHLj4mQ8fPvD0+EjdBX9FRERERERERERERERERERERERERL6k+KuIiIiIiIiIiIiIiIiIiIiIiIiI/CSvjnslpoS7U2vd4pVrkNRbQXP7PYRAqT1QasZdmXP9XEtE4mYtfGqGxbh9BlojMlj/j69vOWYtSrqPpcYYqbUFIEMMBA/0AmULv+7G4O6s6VKvzjRNvLx8JoTA4TAyDAOlFPKygDuHw2ELyq6h2qVHcN29x2gDy7zg1YkxEmMEnOrpizBpv28qwUKbB7v9aQFQ3+KZ1Pt5vgU118ir7adsC79+Oe3rfa/R2TXeu8U59wHOWxO0RVHt9nobu90u1N9w6+/310OMUGsbhPffe0y1FO/Xbkdv4VmDWioh2Bb2XMOjOWdyyfcR0e2ebmNf79udW2S1x4vXc7nbdu0fxEl3c2Hu7V77q2A9+Op9z6+R2X5Uj8Pu5/IWHDbc6xY4tjUsuwv11lKptVC9PXPDMLSAcq0UbyOJMbSIL+2+ay2EAKU6wYwYAt5jrk6bw3W/bPVes7vlM2yLD9/ir5Vg1tfACGENDdtdbNf6tcZxuD3Xuxvbvh9uk7vNt93todtY9oHf/Vz2Hi+GMaSB8/lt+8wa2a2lcr1eSf0ZbHMWCf17yfuzFGNsz3gppD7PuRQOxyPzsjAvS//+MfKyMA7t/tbzhtAWPqVELmWLFouIiIiIiIiIiIiIiIiIiIiIiIiI/BjFX0VERERERERERERERERERERERETkJ63xyhgCpZQe1GyBx9Djp/SQ6BoLdSCGsIVgcaf0EOgaMMWc6rQYbLDepLQe7+zn28UnzWyLiJrVLbi5ap9p14whtHNWZxgGpmmilkKwFsR0c1JM1FoptcUxL5crh8OF4+HQw60tGplL4XQ6MQwDOWcMGA8jl8t1m5vQ7zWXgkMLleZM9YFT+pF/qtmDt2v80nYhU+8h0zUKu557+2wPdf7wlD3uyX3Ycz9Ht1f2Edk1DLo713o+u6VP1/n/4afXY24B23VOcG8hU5wUYh/KLRJc/RaiXeOpbd0jMSVKLn0vRbw6ecl3IdF9wHY/R/sQ6zavWwDVdvP9YxHSHnf9Yv7aNrdtD69BWQjbp7br7MaYlxatjaHFVdf7uu3pHq+1sp271koFrteJEMMWcF2jwkvun+U2jloqw2EkxtTjrO3z0zyT5xnrcdc1/lu3tW/WfRZj6OPoz2J/Du/nl22OWog5MgwjFtYS7m1ft46x9bH+cC/u531913Y7bP/zOu9mkHMLtKaUSDGSUiKGwOV6Zbpe4XAgxEitlSGl9v0DpBgJ40hKienlZduva6x6jbuuey2lhAPzvFBKIcW0vTYMA8fjkWWe/4J7ExEREREREREREREREREREREREZF/1Sn+KiIiIiIiIiIiIiIiIiIiIiIiIiI/aY0jzvNMSgOlzGtiFPfKkjOn06kFK2vFa6W6czoewQyvFcyIIVJp0clga+i0HUOPvKaUMAu4V6ZpYhxHSi4Mw0AIkVrLFqDMuVBKj4dCi0Cm1IOe63nhb/6Nv8mf/tmf8fL6AkBMkWEY+Oqrrzhfzry9vVFr5Xqd+e6773l+eiYNiWmacHe++fprAEqtTNcrnz594nAY+eUvfsGHjx+Z57kHcSHEwLIszFOmlkqILYz5Y7HU2MO5bd58m+v9vO9jqmyhTwihBTZvUdP2Wu9bbp/zHhbdx1FDCNvvbdy+nWtV3Qnud93YH2tbbuddx0yL+K6B0RaQBa/OkhdqadFeBywEvFZCCIQQ+31W3CsxRsZxYGICYBxHaq3EFG9z5L5FUb+M5H4ZfXV3qleCB8z2N/LlTfnuGLbKrW8TsIvu2vaf7fNrdHU/V/Myc1gW4uHIOI6cz2cAhnHEDJal7e95mTmMYwsqV2eaJnLJhNrntLRnota6BZFTSozDSCmZcRz7OtYt9DoMIzkXxmEg58KyLGBwna4Eu1/zMaU2n7WtUevxettXreDa1pL2DNVcwGAYB46nB9IwtDVdg7rbztrt/vVFuFunNRK7rZv5dtwaCN7muUdiP7+88Pz0RC6lj7Ot//FwJC8L7k5eFswCtRbmZeHh9MDhYWQYBt7OZ67XK4fDoQ2rVmIPPJdSery5Esw4Hg58+vyZcRxZlplcMqfjkXfPz1yniYeHB67TFRERERERERERERERERERERERERGRn6L4q4iIiIiIiIiIiIiIiIiIiIiIiIj8NKOXIKHWQuyRSKMFPFNKeK0MKVFqi18GM3LOxJT6cbcwrNPCp1t8skcsc87knKG/fzqdWuwxOqW0IGOMLVzagqGBmOJtmGbUWnl4eMTM+P7770hp4J//339CLYXD4bBFWqdp4vvvv+MXv/glP/uDP+Cf/8mfcDyOlFq4XC6YGUNqAdjL5cL1et3CosM4cnp4YJpnDocDx8MBM+NyuXA6nfj06ROnhwM4nC8Xjj2CC617ucZKay27mGvY/pRStsBnrfUukrly6x1NX8Out3ime2Ufhr0Lse6OCeGL+OYuhOrVqVTqGuR0YIum2u2/fU5W1Su1FDzYFigNFsgl48vtXi20iug0TS1UGnu4lbYXQoi3+aqVZVnuwr/re/u13173St9W/d77Pfby6G2edvdLu8db+LX2NbO1eYqbUWoh9DKq7Y5tbd5+bu6dTqcWMa6F8/lMrZUQIyVnPLYQ8TxPjMNAjKmve+Hh4cTleiXFuC5QjxRfeH5+xiyQ80LOC8fjicvl3PbkOBJCYJomzudzD5YupDRwPB5ZlpkYEyEEvv/w3TZ/wzCsMwS0eKvFgFmglIqFtj44VNozOI4jMQ0cxpEUI973ne3XxG5zj9vdPtttp7t1vIsg++3n0mPBz09PfPj4kcv1yjxNjP05/PT5M8fDga+++oplWcg5t9gxkZQSMUbe3t6YerB5Xha+/vprSilM88yyLDw/P/PNN9/gtXI+n3k7nxmWhRgjD6dTfx7bys/zzPVy4ePHj7yd3xARERERERERERERERERERERERER+SmKv4qIiIiIiIiIiIiIiIiIiIiIiIjIT1uDmGYtTpozMcQt2hhjxN2Zp6kFWWPscVMn0aKZoUdAW8i1YFhPTDYlZ4wWDwUj0kKcMUaWJRN7ZDbGyDzPbVg4tdT+M3x++UywyPU6rQPnm2++4fPnz8QQCTFs8ddxHHl7e+M3v/0NKSYO44HrdAWHDx++53w+8/DwQAjGNM88PDwwz3OPRhpvb2eOxyPX6xV3ZxiGFrQNgXEcKKUSU+RX797x+Ph4H7Psf4cQthAp/X5rj+eu71swvK6BVtsipbXUNlfOFqWF++P351zPt87LOpLeMe0/h+249eftXLYfuWGhfcZ8jdluW2Vbt1pr2wvBqEtlGEdwCMH6WNaCbYuDeq2UXk8NsbLkFqF1d5a84NUZxuEWCL3bor77u0VYQ1jvL9wFdG+BVwdjixX7tqvWmGsLwPraLV3nMrTzsR7jvpvRvh7hNrpggRAioX9qnmemaWIcxxZwrcv2LFyvly2gvCyZYRjIubS9YC1sOwwjKQ2cL2eWeaZ6e6aOxxPLkre1budv4xgPB7y2WGn1ivuC9+Nua06P8voWJb7trdr24W4fhNCivcNwYBhHLIRtr94tzu0KgN89C3efW/fCLij8g1Dsunb9+tP1CmYsy4LXyrvnZ3IpW/h1DUWnlJjmmZjafgwhcDgcAEjDsAVrqzvTPJP799HleuV6vcLxyDgMXK9XQohUr8w9/ny5Xnl4eKB64e38+mM3LiIiIiIiIiIiIiIiIiIiIiIiIiKi+KuIiIiIiIiIiIiIiIiIiIiIiIiI/D4tCFlyIcV46z96izPmZSHEiPXw6xr+NOMHMVJoMcxaCxYCuFNLIaUBMxjSQK2VUgtevYc7e3jTK5HIMCTmZdmGtooh4sCScwuPhsDnT5+4XK+YGTFGhmHgdDrx8vJCGlKPi1ZiHFqgNgRKqUzTFTP4+uuvt3Bo7ZHQw+HAy8trC9aaUUphnmeGYeihVdsCoCEGLpcL7ObAdz9ssdLdGy0s2oKo+/Zli3b2aGmPZNKP9lq34CkYvv8s7CKvu8XDt7mln2Ov1tt5+2i2QCrewqprPLW9a9v4Q4i41215nBasda/U2uY5hNCjqz3CWlvM18y2oGpK7Z+5llJwc4aUdvd9219rMNTWQdH2jvttPdYw7W1ObDev3L3vXnHA1rDrLhjrQOgTus2Je9vPfQxhFzhd97P1+7n28Ost6Nru3eI+atv3TzCWpbS9HyMxJkqZW5C0R3attr2Zc8aCtUhySpScSWlgmiZyaTHT9szBMA4sOe8eoBaCXffNfp9uUWLWkK219bZATMMWZV6PWUPEju/28C4Ku9u79/zueb4bRGchUHLh06dPxBCwEDBaCDamBGY8nE6cz5ftGtM0bd8H6xqu78UQeX193e45pUQMgaXW9n0W2nfG8XCguhNTalHZWjkeDpRSeHh44HA4cL1efuSeREREREREREREREREREREREREREQaxV9FRERERERERERERERERERERERE5C/k+H08s79e3Ym0IKaZbVHOEGP7bI+nbpHOnoW8BVGtx0lboBWDnEsPTrbA5Xp8rRXb4pO3iKQBj4+PXC7XW0AU+PzygrsTLFBiO2dKiev1yuFw6LFUqLVQd6FUry2mWUu73jRNmBnDOLbgay1bBLKUQimZGCPzMvcALOCQl0y749ssVnesrmHUFhO9hVV7qHX3nrfKbg+n9vm3FuJsH/Pt9RBij+5+GX61u+DmFlD1/XV2a+3eYqx9DWybmFsY1H+k1bmeu81rCwV7j+Y6vsVxa3VC9BbsdSesEVS8RT0tAE5KcYvh1lJ/5Gq3e/vyHrdFANx7kNQr1WuP1bLdQK1+29+1bnvB17nwite2l0Ot1F38dZ3kNTtr96Vdaq3UUu7GOKREsLAFZ9t8tWBt77NiZlt01WjPV0qJJS/kvGyh5RAcd8h5uT1TPVJbSibn9ifEwBAC3gZJinHb/+vxt1BzC7d6aOtQ1whwaAFWsxZeTTGSdveyhl3d1zH43eZen9svttP9cn2xhPt4dAwtPjsveZtr7xHccRi2/dCue4vzTvPM4XDAau0b18ilkIbEPM8EC8QYtu+veVk4Hg6kIQHOMIxcp+ttz4XAOI68vL5yPBy240REREREREREREREREREREREREREforiryIiIiIiIiIiIiIiIiIiIiIiIiLyk9b44pASpVZyzsSUsBAIQOxB1FwKpRS8FEouHI+HHrYMuDulVoIZ87IwDEM7r8MwpBbY3F0rxh5jBNIwtiBn/5OXTAyxRWC3yKbx9ddfM8+/wT0RQsAMrtcWbbXQIpHTNFFKIZdMfsuM40hKkZwLOS/UWltUM0WCBT58/EBKiRgj79+/Zzwc+PTpE7Xf67wszPNMKYUYJ87nc4thhtAitiXz/O55a4FWd8oWAt3HMA2sB3K9h23XBGyfp1r9LlLru9An3EKY6zzZLlC6D6O2a1qPxFYgAlDcWMhAi+/iLYLr9NBsr3V6v6ZTt0jpWvhcz+3ujMNAqZWaM2kYMKD0OWjnrhBjj7HGHrQ1YkzbvfScKsGM4s48zy3C2u8jpXSLCtsa8q1bgNe9trXgtn/cnXY7YdvjpZQe2b0PHK/z7N6ive1M6xrt5nb3vBjg+/irtzhrC60aX73/ipwzLara1vRwODLPcw/n9ueltPHGEPoeTIRgHMZDv481UmukFJmmKzkXrtcrwzAQY+T19RWz9n4Isc+ac7lcOB2Pu+enxY7d63bvIYQWXl5jwn3dI22MISVSatcxC9u6/MBf7eVtzvdzvwohcDydeHx64rvf/a7vJYc0EGKLDb++vkJPTIcQeHx44OX1lXmeGceRGFqoNi+Z4+nY7rEHf3MplFp5eXlhSEP7HoiRUgvuzvV6ZRxGhiG175Gcmc0IIVJy/j13JCIiIiIiIiIiIiIiIiIiIiIiIiL/qlP8VURERERERERERERERERERERERER+0hqBNAvkvJCGgXEc8eosy0xZli2ESWjB1hgDZsY8z9CDlrFHLUMI5Jx7oLVFY4MF8jJTe7BxSAOnhxPff/eB0ymwLAu1Fk7HE+7exhOsRUlXZjw8PHCdJkouABwOYwtXujOMI4+Pj3z91Vf8s3/2x9TqhGCUUpmniRBbZDPFSC6Vy+WNmIynpydiSiw97mhmvHv3nk+fPvHu+ZlhHMk5cz6feX5+5nw5M88zh8OBd8/v7uOVFkipRThLyXeR17WG6esPtqZPDQK01C7gdRvHFhptZc678OkaEu11WcysRUNxrJ9rHds+ngqwLJlgoV/DsL5WFaD6XbgzWOiRTnBr58y5cDqdqMuCu3MYR0opgBG8tihsaX/ysmzXcaxHSNsVSinbPqm1kkum9vtvndnduJ1+b9ZDp96ipLuA6JY67fFU6Olbg1LqNvfuhepQ6u36ZkAt4Nbjru1v8905LdytAUC0wGE8EGNkmuctgIy3MZRSKf15OB6P7T5rIaVAinGLIi/LzDQVUhp6uLfFeWstzMsMDilFnp4eSTFyneb2PFyv296yHnJd5pl5mpimeRtnrZllyVucOA2JYRgJu31BDwqnYSClsb2/fjf09XXfR425D+lyC/d+WX9t+eDbGvqP5GFzzlyvV4IZIUaGvr+rV15fXlqMGON4PDD0Pff29sYvf/ELzpcLeVlYlrxFgedpYsmZcRgYUmLpezGlhONbdPpyufD+3Xuu05VaC9Pc1jeEwB/+0a/49PEzn19/MFwREZH/l517h5Uty/O8/vv/19o7Is65j6zqKaga6J52wJhuYaGxR8LBGISBQIOBgVoaB2lMptvCaqmlwURIjDEaMHiMjTOCkRAOOJhgIBAItbqmszIrM+95Rey91v+P8V9r7R1xz8lJEKirun+f1L33nHjsvV4RVupLRERERERERERERERERERERDQw/kpEREREREREREREREREREREREREb4roZoWIIacEEYmQZ4uw5pxRq0E1Ap3VDNYCoCklTNMMCGA1fs/tmkDEHs0MKSeoCtZa0GOO33zzLebDjMtyQdIIs57PZxyPRyzrGuHWEdl0fPr0CW6OH33xBUQEX3/9S+Q84+n5CR8/fMThcECtFX/y8z/B6XSH8/kFZo6kivv7e5zPL3AzlBYRTUmQNGFZVzw9R9D1/u4O0xyhyJQU5o7n52c8Pj7C3fHu3bsIfZ4S5nlGrQVtqcY4o1AZkVtBi4puWdIteekOA2DVInAavdEWzvQtuAqPp6RHXhWqMqKl/XU9lOotFOveXo8eUN1FalWRNI0wrZm9Gop1863a2azrirvTCefzBYBDNWEtBcuytLhuxjxHfPbl5QV5mqCiSHmLvKaUsK4FIoKUFKopwsM5X0Vq+3jGyrX16Otdrca4vWVFo6Ta5tJe7w6Ho1ptcVzAWhx0XNsd5obsr0RJd5FTg0Oln+yQkqLU0sKhjuPxCBVByhMEW2C2tDUCAE2Kd/fv8PgYRVFza3vY56xwW0dMub/fzHG5LCgpwR24O50iZpoylnXB5XJBSgnv3r0H3PHNt99sx7IvWovqajtHHjeMcHGakPOEeT5AUx5n2Fv5V7Sdr3ZO3X2cwX7WbvXz7+1zsS1rnPkIGO+0z8XpeETOGU/PzxGEzhlTzi2UG2vTw9O/+MUvMB8OsFohqsg6tb044PLpE17O51hHUczzhN/48Y9xWRaYOw6HAy7nM9wd8zThsixIKeFHX3yBL3/xC/yTf/JlnCn7PFZLRERERERERERERERERERERERERNQx/kpEREREREREREREREREREREREREb+rhxpwS0OKcUitEtMUeHe4GRwIQ0UZVjQinGUpZo/DYQpClFGhKEdo0G48JgJwyos9pSCmij4d5BgDUajA3nC8XmBsSdAtWQnA6nVBLhXvEMg+HGbUajocj1nWFuUFEsa4RET0cDiiloJSIft7d3aGUMu7TI7drMeSsOJ/PWNYVh3nGhw8fcHd3jylnLC3AaWZ4fIoI7CwzzAxmhvlwwFWvVFqMFT1aGn9vKdYt6ur7KGd/cevH9qhp625CW8RVBFfR0v37t3CqjztHS/bmdVC0gucY1W4CV7FXsx5X7ecFI/qpogAc1Vo4GIg1r1t0dpqmEQt2OHLKKLXGmRDATCFSYGaYpnmbg8c5QR9rX5seeH1l/n34+3G6R7B4LbWd4xbWbe8X7QFch4/z7m1VBA6FABF+hcF7yLRZS8ERwDzPuFwueHl5GXPuL8zThFprrMc8IaWEx6dHVIvPmVkEapPoOGs9QmvmWMsKWARQVRRujsuy4HCIz87lchmRWdX47NVaRoS5i9Bu/JmmCZoSajVABCnliPfmjJynVm0VWF8r+NjvzxOvN+TzX0Suz1UPyO5jv2aO0mrKnhLWdY1xtsDsZVkgIljXtZ2f2Iucp/gOaPHX2mK5vvucuzvyHN9h8X3U9r099/j0iLvTCUkVVg3ffvcdaq0Rtc7837GJiIiIiIiIiIiIiIiIiIiIiIiI6Pvx/zYkIiIiIiIiIiIiIiIiIiIiIiIiojdpUuSUIgRZaot67gqa6OHG/nOLNqqiukcsVuJ3M4O3x/rrzT3ije29ce2ElDJqqbuReIs5GqTdcx9VnecZz+sTSnUkTTgdTzhfLphaWNPNUb1ARVFLhU4T7k53cHc8Pz/h7u4Oj49PEbsERmQzaURoI+bqMKvIOeHu7h7mDlHF8XiEu+Ph4QEpR+S0B0JTSuiBS/cWSwW2AKbHjw6ByBbSjLhrW9t4AXxfOPUtHNtDrftQZo+efh5/3UdlX4/E7sd29V7/rM85IrRx69ifWiuSKjwp4LF2otqGHnvRz0RKCV5rjMscSFs8NqUE1QiMppSQUtqFaB1mDtUtZLtbvbFn/ecx8B4rNoe5tTPZ/uDG7nztmrNxTe8r398V4VdzvYrh7nYIKSXUuo44rQAQjYhxzlOsCSJkmlogGfB2hmI+PWqac459s1j7ZVmhKhAVmDlqLePzs6wLACDnjJTi/Pfg6dV0RVoANkGTjrVOmpByRp6mMc4RB/YWdm5re3u9vpc/SDvn+6Xfvze183Q+n3E8HmFmUFVUtKhwKbvPTPxRjT+ltN1q3z85pRGL3R/3y7JEADfpdr5boPqyLCPqjDW+I5JqnO0fOkciIiIiIiIiIiIiIiIiIiIiIiIi+guJ8VciIiIiIiIiIiIiIiIiIiIiIiIielNOCTlniAhWNyRNI1jpLeqpI1SJiCC2eGUPLfZgbI+Aeos2ighKrVCNYKabAyoRm1WF1YpS6giL9vcAgGq6CkOKCNZSkFLCPE2Y8nVHNMUAACAASURBVARzg4iO5y6XC6Z5xrJcUGvB8f17TDnjcrngeDzi+fkFKSnEIvqoOSHnCeflEnNQRakFj09PEBHM8wEpJRwPB6gq1nWNQGULtvY12MdJzSyeQ8JVPlRaDrTFVHuYU/taoz++j77GercU5+Dtdf01b0U4Y6vaa/eR2B6FvXptG+dNTDbGPv6Cu2NpUc3sES2tpSDlDBWFiCJCvoCKor9TRJFSexwCyQnTNENEUGuBiUJVxkS93aufr5uhjaDtWLv2gn5ue/i1n9s+D5EWb23XlBb/3S7er4kRPY1ka4RJVewqqhr7Z6jVkJJinqeICksERlXi3JyOpxF3dTju7k5Y1wIAmPIESERPL5cLDodD+0zGsGaZWwhXRxRZROOztdv7vk4x9+1cbivag7tp7I07kPOEqYVfc57a8rSZ7/bexhm7DjP34PDut7bv7UV9W13Gc7stuFpLVcG6rjgcDhBVlFJRyopSCqZ5RikFx8NxXLs1i6FJx/6LCI7HI7779Ak5Z2hKI268LAvu7+7GZ8bawFP7PoqgcHy2p2lCTgm1rTMRERERERERERERERERERERERER0VsYfyUiIiIiIiIiIiIiIiIiIiIiIiL6NSMifx/A3wDwpbv/bnvsxwD+KwC/DeD/BPBvufs37bk/APB7ACqAv+3u/+iH3svMUWuFqCK1wKmZIbUobCkF0zSN0KaZoZYKTRH+1Fao7JFOqxWpxWJHMNYd0zThfLmglhWraMRfzSAAUpqgKigFI6zZ79f1KGbSiFdWM6xrgbvjw4cPuDudsByPeHp+wt3piMfHJ3z19dewWlFrxbquuDudMM8fcb6c8d2nTxGnLQU55wiGmkEQj/3yl9/gpz/9KVQVLy8vyCnhZz/7Gc7nFzw9PQPuOB6PeHx8HOFLAa4CtgLF1r8U9Cxmy8DCHRGbNIe7YddzjTUYv2yBTzPbhV63COd+rSKIu61fvHQfr5TrIKxE7FPa7R0ewVPVFu3cYp7uwGVZAAdsyrGP7vB1xTzPSO1c9CjrsiwR2lWFakZKilorlnVFrTGXanFmRKariGhcx+C+hU23lY5Ap8Fa8HWLtt5cIs6ix95KC/eqChwSwVmgxVJ7mzfGHqtgsZPugCjc5apCu5YVB49zuZaCD+/f47vvPkFTQkoJpRSUUgARLMsSAVUAv/zlNzBzHI8HLGuL6eaMdV2xLAuWdcE8xXo+Pz/jeDyOsaWU8P7dOyzrAoji7u4Obo5SC56fn9se7IKs0s/EFn+N+Gk8nXLGNM3IeeqHZZzR29Cr3P4uiDUR3xZ+d9/+++2evGZZFpyOJ/zoRz/Guq6YpxiPJsU0z3j//j2WyyXW8nLBWgoEwOnuDvM04eXlBWhzPF8uUFW8e/cOpRRYrcg5Y5om1FoB+PheKLXiw/v3+PjxI/KUAXcsa8HXX3+NdVkg7buKiIiIiIiIiIiIiIiIiIiIiIiIiOgtjL8SERERERERERERERERERERERER/fr5BwD+IwD/2e6x3wfwj939j0Tk99vvf0dE/iqAvwngdwD8ZQD/rYj8i+5ef8iNelRzbZFOd0dSBYCIVgIo6woRBeBQEaR5RllXTPMcEVA3eIu/akoRuGw/wx2lBVirWYQzJV6bVZFSBuCopWBdVyTVrSHZg5xw/PxPfo48TXAz1BZp/Su/9Vs4Ho94eHjAuq4RbgTw9PyEUguOpyOmKYKaf/qLLzFNE6ZpihgoDFOaRuDW4MiaIuj69IQ8ZXz69lMLRma8XC54eHjAF198xJQVKSfc3R3w8Pgd9mlL94iF5jRFUFWAlnqFmcNh2GdMa60RefXW3dQWKN1FSOO6fhXEFZERmjWzuE5f97Z/1WJfIDLWctv3GFdPnI7H298x9gidej8nIlARWC1YZYVqhDYP86HFNSdAMIK7PVALoI3RsK5AzgnaAsCiguwZIkCtNtay92rdZcx/C8A6RBy1GswrzBxW64i8RgzWIkrrBhWFuY2z2kOrqa+fOwDDWG3ZZ3ABuKNC4G4Q6NX+TfOEw2FGShl3qng5v+BwmEfcuNYKc8dXX32F0+mInKcIHlvGu/sjnp6fI6AMwNzxxRdfYF1XHOYZ1SoulwvcHVOesJYyAsyAY10LckojsqqiOB6PqNXaWm5SUrj1vY7wq8ORNGPK8TnQlFpg9qYVfHU2tizsPjDbV6yfzfbs1dnqr+iP7883gNiTlGEWodYecHWPUOtXX30V51jQYsKKlBKSKr76+mvUWjFNEzBNWJYF7z98wOPjI46HA1LOeHx6gqrii48f4e5Y1nVc+3y5AN99B29n1arhdDpFUPaHlGuJiIiIiIiIiIiIiIiIiIiIiIiI6C80xl+JiIiIiIiIiIiIiIiIiIiIiIiIfs24+38vIr998/C/DuCvt5//UwD/HYC/0x7/L939AuD/EJH/DcBfA/A//JB79VhmyhnLsiClBHeHAhFvRcQQRRAhxxYAFclAC1H2yKi5b6lH0Yh3ikBaTVLQfm9xyH2w1B1IqshTxDHdfURMAeB4PGJdVwBAShEPPZ/P+NMvvwTccTge8C7d4zd+/GN89+kTvvj4EQ+PD/j06RPMDO/evUMpcb/j8YgPHz7gyy+/BCSuB0RM9OV8hoiglIKcJ9RaATi++OIjHh4f8fT8hJwzjknxcj5HfLMnU1Uj7ikYwVGr3mKXaGFNi2Bm66L2uCWkr5Fg38vsv0vbh229IiarihFZTUm38GbfC9mSnVdXFYGIR1x13+eUnuvcB2jH4IGUYBbBzFIrsjuSpl2c1UdQUzVhmmJ9ai2oVlv0s509qxAXiCi8R4T9doz91j16esPRArUtjNtjpCKIXHEEatsrxnqqKjRpnGV3wBXVK0T7qku/NMxi7gZAsR9j7GcpMbdYM0exgklmTFOEYWOujmVdWtRWMU0THMDd6RRRZDhUFOuy4nCI8Ku7j7NpLWjrAMwjrptSgqYUEdwWVtaUWrR5v+MS1/aCUiu0jSGpIKUMTTnmWS1WaER795HXiOGODbk6NOM2r4RS96+VtiOvvBcRm16WS6xXO78CtADzhFIKyrpCVTHNM1Qk1iFnCICPHz4gTxOs1rG2IwK8rsg54/7uHt999x0OxyO0fd/UWrcItDvKuuKyLJgPc4SMW8SXiIiIiIiIiIiIiIiIiIiIiIiIiOgtjL8SERERERERERERERERERERERER/fnwz7r7zwHA3X8uIv9Me/yfA/A/7l73x+2xH0Qkgq5WK5KmXTA0AqNuhlIrppz3b4KqwNwj/NrCnz08KgBEW8gUHsHXdi9BvFdE4Yhw7JaYBNCvGfMc1zvd3WFaC6YpI6WEWivWsuLd/f2Iwp7PZ6ylYJ6nFo9NmKYZ67pCRJBzhDF7VPN4POJwOMDMkJLC2lznacKlrq2bGiHTp+dnTFPGZbnA3VFqxePDw3VoswUyRRTW4p0jfdlDptYKmT2SudVyr0Kv3p/rl26X369zRDnf3tuW6/w8tTl6r4LR+XTgtgMbudQ+Nd/+lR5FNVit7V9D0QIRgVnEQs2tBWq3c9F/HtHb3b32udFYsi1ku/+DFiJ2b9FhM3i1Fkf1m/eg7Qm2CbaQrADwpNsiOQAVaAu/ClqEtMVl4dL+3caYUkKeMkSAWg3z8YDL5dImEmdhXdd2zmWcqT7G0s5rUkU1w7qWsde1WlxzPuD5+TnulTMmESTVFnpdMeUJ1Wrcp1bklGC+PycRe+0Hop8j1YSU84gsW98PEai0zisAN4e77U7TVZ14O2yvku2f/Tq3x8S3a/WQNDzW7XR3wlpiPXJKmKcJj2Zt7Dr2p9aK4+mEnHN8PlRxOh6xLAtqrRDV+GMWAWJVWK1YlzXWb5pwPB7x+PAQR6B9NyyXBaoJd3d3qLXgu4fv3pokEREREREREREREREREREREREREf0Fx/grERERERERERERERERERERERER0Z9vn7U98UaKUUT+FoC/BQAf3r8DAKhoC3YaNKWIJ7ZgZo+Xmhl6KLRHWVUVMOvXhe7jr+PnVgndDzUqsBABVCIgu0VAJaKX7brmNh6/uzvBaoQfkyocwOPjIz7+6CM+PTzgcjljLRGBfXd/j4tcIAIcDvOYi7VQbSkVZV1xOBzGWHOe4lbLAhXBPG0ra1bx9PiIL370BVS1hScFaylY1/U6YtqCo30OAonmqPvVpvTfZPd3j5qOLfT9vxHj3Ac9t7hsi+zubuAe73vtcLSr9q247tCO4Cpa8BMjStvnqS3+G2vT4qtuKGtBSgrAI7YpArMa78V2LswNSVPEW8ccvYWI93PYj7avmgMGQHwLv3pEX7dArfW86qtrEUFTg8G3I+kRLEYfZw/AukMBWLVxnSviEI01Mjc4DJq0RYwrHI5SC0qJgLK7jHHWGsHWec4QFVjZQrk9XisANCleXs5IqvG5aTFTIM70/ty4OzQlqOi41phT25OI0EZANWlqIV6MvRjnQOTq3PbxQPabhFf4CMy2AzTOUFvUPirsPxWiChVBdUdSQc4Zy7pGnFkV8/EEeX6OO7RAtJlhuVyQW5y6thjxNE0jhjunmKOZYV0WHOYZ5g4rBaXWWIeURvw2t9c/v7zgdDrhcDhgmqbXJkpEREREREREREREREREREREREREBIDxVyIiIiIiIiIiIiIiIiIiIiIiIqI/L/5URH7m7j8XkZ8B+LI9/scAfnP3un8ewJ+8dgF3/3sA/h4A/OynP3EgAqs9irouC06nE6oZzCKEmFJqYdgIWroZqkfc092hEpFMv75P6zvGtatFtLXWCqDFQ1MCEIHIHpQVOMzjtVYr3Hr1FDgejliWBZ8+fUKtFR8/fkStFefzGY+PD7hcLtCkOB6P+Orrr/GTn/ykxTIVOWWIKp6fnyAiKGXF41PFNM345Te/xP3dPY7HA5LGa5dlwfF0xOWyYF0XmBlEFbVWuMeazIcZcGBZlqt5R6BWx9h7lLT/iTn3d8gIjrYX7+Knsaq+lTfR3yzY4qBRLZUR7ox7bJnT7f37DerxWe+pz15n3bVXW3y0hXr3YVnpAdwW743IKVBLgSONmCYAlFKgI8rq8GqoViFzFGHNDW5xr5R0jNPhMKtXYd2+DmYW0WCrcDPAHYoYS6xFG7sqRHZrL4C4jOu4AQ6Dt/doTu2MytXqaMpwK3Cv8bnYjen5+XmEVJdlwbffFrx//w4qCW4x1vlwQM4JpRbUFpGdcsZaCtwd5/MCYEGtFff393B3LMsFSRNyTnh4eEDOExzX580sYrGPj0/w9rlJKWFZFxwPx6tQsLlDRBGlWhlNYW/XcUcLMe9iwG3jt+8Ia9d07E/K1fZcxYrlJmh8/Xw/E11q56aHgp+fn3G+XEa4eZ5nmMUeWA9E14rHdUVKCYfDAbVWLJcLXkRwf38f5yEGM/ZoPhyg436Kr7/+JfI0jQBxqRXlcsHz8zMO84xPDw94btFZIiIiIiIiIiIiIiIiIiIiIiIiIqLXyGf/0ysRERERERERERERERERERERERER/coTkd8G8F+7+++23/8ugK/d/Y9E5PcB/Njd/30R+R0A/zmAvwbgLwP4xwD+BXev33f9n/30J/57/86/8f/nFIiI/tz5w//wP/mf3P1f/rMeBxERERERERERERERERERERERERH96sh/1gMgIiIiIiIiIiIiIiIiIiIiIiIiov9nROS/APDXAfwlEfljAP8BgD8C8A9F5PcA/F8A/k0AcPf/WUT+IYD/BUAB8O/908KvRERERERERERERERERERERERERERERPT/DcZfiYiIiIiIiIiIiIiIiIiIiIiIiH7NuPu//cZT/8obr/9DAH/4/+Zep/cHzHdzv874A3dAANUE83LzLoEIAJf+W/tPkTQha0YthlorxAUqCTklCAQugLvBzCCica9tJnAHUlIAgpeXZ3x6fAAAzKcjAEBVISJwd4gIar3u3IoAIrKbT1xX4gm0B2J6MtZvN6/+3hhjexhJ02f3U1UAwPJygbvjeDji/u7dbiw6rnGYZ0AEpRSUUtr4gZQyzAzrukJVkXOGADA3rGuBqrY/MsYX4/V2D8GyLG1dtteZGXJOY15rWfDtd98AAH7rN38TOSXsZg2HA7utGL9LPN8Xra8PxggcPv4O5oZSCswM5gazCmvnqu9Pzhn9ytrOwbqu+O7bB5RScJhn/KUf/8bV/lydFDNA2shkjPBzY732/LO17C8RlTHfPqfYDx+PV6v48he/AADcf5ih7f/WzTlBoBBVWI19V01tLRxlXeGIszTNM9wtxtDuFXMCxHXM0eFIKcU4pY2hrWE/f/C2B2OaMc7nhzOW8wpVwYef5Jh3LNhn69X3tZ2e8brPlvOVnyBx6W2Vt/VEm8vn678N+Os/XQEAP/r4AfenE9wdpVZM07SdOQGsGtwdmnSczX52+l72P6ISY9qd2f3PZgZRQdIEa+s8zrsItH12ReKcPDw+4ZtPn16ZCxERERERERERERERERERERERERER469ERERERERERERERERERERERERE9D3SpJhOaQRAR2iz/ZtSRnWBu/UebAsiRtRRfAu/woEpzZjzjLoaaqkQV0xpiuu3EKvDYWZIKV0FWQGg1BqhWFVUq0CLv6YWMhVVaAtmikhEHvtVHVCNcGOfwxZ1FKgIrIVtHRjXiUCrj9BjvFcgpvE4Wmiz3W9EU6VVL5ucJtyd3sX8akXOGbUFK+d5hqrgsiwjeps0YZoyzB2qF+SUkPMEEWBdV+Q8jzGJCJJqi4cqaq2oZkiqUEkQ0RHN7VFR1S2MuWu24sP7DxHWHHHT6/hrbFNbuxb6lf6E9Ne3Vfe+o1sKtlrFWtaInrqh1vjX+wFCBFCBmFNKGXBHWTIeH55QSjz//t27cf0R7W1zcPM2Jxn/Xudh0Qc7Ip49aOpucWZvgqF9bUc4tM8fEbTt4dVSthhyngXTIUG0RZBFWzhUWuR2wroqaqnIk7ZzpzgcDyiljPPb10dVYAVX+zVNOWLEbmMTVGWLru6ir2PEIri8LO2cAod32ldktzQ3KdcW0R251l1U18d7t3V8ze33B1wBVzgc4vu3tYCxA4KI4h4PB7x/dw93Ry0FeZrG+VXRFhK2LXrbqOr2/WUWn/FtQONu+3nurwtE0FdFxzkRCMwtnhdgWddX50tEREREREREREREREREREREREREBDD+SkRERERERERERERERERERERERETfw9xRa70Kn4rIFgS9yib6FoEc8cj44+5wc5hGoBESAU+BIqeEWg1lLYA4JOm4cm5BU7QYY601Ipj4PC/pANwM3kOo7hE4BQAzOAxwgUf78ipu2Qum4ojnxxxaaNO317Y+7FVk0twh7hCVdt02311oMoKrAnPAzEeg1t2wLAtEBesaUdQelDWL4GfOecRk3eN+U87j3m4GqEZUNiW4O0op8JSgKY37mxnWdcU0zai1otQKbev6qrYeu7rnWCMY2p6P7OfNG/vzu/0ZMdXt9z62Ht00q6ilAg6klDBNEdiVm6hnv6k42hh8G4PKNqp9oXT/xj6mHkzdPbbNooVrJYKy7g5x6VOLYyMS5wrx3J6ZtzCvYFnWuI9oi/EmoEV+TQyHwwG2i5OaG9TTiC5HkDTBbEVKCSkpVBU5Z5hVeN1G7u6o1VrcNNZWWrw0Pie+bypf7e9+ya60OO+4pPt+xbfPzc0afNbd3bqu4+fbF92u47g/Yr1Tyu2sGFQESIKU0rZH4yxFRNq9jVQVaobSznt/XTylEQJG31Ogenye4ICkXfzZrK3ZzToSEREREREREREREREREREREREREb2C8VciIiIiIiIiIiIiIiIiIiIiIiIielPOGVOesKzLiCumKUVEdCkAHKJAyglJIzIaocUeuewx1AhQmhmKV2TN0KxABT49PODD+w+w5IA4NKcRdXSPgGqPN+acUc1QzWC2qy6KIKsCEvfNU0YtBQ7Aqu0CpN6ilb0lGdeOvud19bL/3oOPvQgrcGjSeH+7lvaoZg9UAhBVpN1a1lpxuSwRvk0J67oiaUJKCaVULOcFqhF97enSUgqOxwOmPGFdV1zWBTknzNMEiGCephHFXdZ1XBcAprZWh3mO9Wrh3B4LnaZpjPc6YNnW5KrQ2YKcvYbbwpdjriIR4dytXn+fYmuLVt8CsFvMUyOwKxj3FRWUtWBd14gPQzBP826EV0Pb7U3QfkFs84uIbS+X7p+VLeLariKQEXVVibBorbWVgPtJ2t36DT3uayaYpox1LRCNfVONa2o7Az3828PCCo0wrzlqMZSyopSKJIKUNOK/Ary8PLeosEUkGIK1lPjsqUJUx2cRUJhbxHX3sdXd0mwT2x8KGeu4vXB7akRfX1uMq/DrriTcC8C7C423S7xmP4QegXZEGDenPKLUou27RqVFliMUbNVi39xbAFe2z6tvezTi1g6I7oKw7TtI2tmMzxBa5Bkwi5+JiIiIiIiIiIiIiIiIiIiIiIiIiL4P469ERERERERERERERERERERERERE9KZSCkpNyDljWRZMecLlskAEER5VgVlBLQaDRbhUIoyYNEFFYeZwc0x5wpQmZM2w6qhrhZnheDzCHTAzQAB1h7ago4pAd+PpLciUIpjZCYBqBrijSoQw4d7ilwKFjjd7i5qOCOnu2vuMo+8f6f/ILhgKh4v0TiXEAevR1L4GuzGqKqZpgiaNIK1bBCdbUDRPGbm9XkShqqhWUavFeDz+zTmjlIJpmnBZlli3FnWtNdbTzEYE9vHxEcfjEeu6QkQwzzNKKVBNyDmitPt12JVyt8brVd9yy572aKpgC2aO9YW3vqeP9/c1d7cW1ZTdmnqLd2bAEP+XqztEFGVdsS4L3LbBmVmLfMq4HrCFeCMU6vvhtvXezaKdNXdH9doashEo7dHPMTcBkiocDqs27i+a21lrEVHbFiul1ObnmKcZIoLYLkcpEbcVCHKecDweUUpBrRUpJZgYRBRJAeQ4F4fDAW4FIsBaVqgqPn78gMvlgrXFYUUiNBs/a0RK3QFzmMVnrtbreLK3jY5Gal+/7eg7fMRxYykc3vYfvu++vh1C3Y7YFoCVV15/dZ1d/bVHXhURdzWLPRAA1oLJ1WoL7voW3u3nrJ0/EYG0kHWf1z7wLCJwa/upGu9pMdn+ndRDsdY+w8y/EhEREREREREREREREREREREREdH3YfyViIiIiIiIiIiIiIiIiIiIiIiIiN6kqlCNmOL79+/x/PSEnCKIWGrBpBNUEuqIIAqSpIhl+i6SWAzVKqBAFYvoowtUEw7TDDPHNE8jcAoAbgZroUXRFop0jzBmCz/u9fintLCmirR4aFxDJaFHPd090pMtBtrHbm4jCmnwiFz6rh4KjCimpjSikbVWAMCUp56FbZHNOsZnbi20arhcFkxT7gOHqGC9LCOGqQlIkjBPE55fXiKCmxJEDC8vL7i7uxvR19TClA+Pj/ji40eYe9wHWyhWVfHu/fsRyU0pQVWQ0hSh2mW3kLL9Ky0Ger3Qu0VoAc8ege1L5ej738u48Xy1CrNdPDXp2LsewxUVmNexRzHOCAlfVTZbVFWwC9D24KzZ1Rj7SF0iBtvzoz1Su5+a7GKmPXzq5i002ubar9oDwtfV4G3PqyGOqWNdF6gmuFVULxBNmHJEWlNKcLMRK4VjhJQdCQ5AkyPljHVZI24MwKzi6emp/exIKWK4Zi18HB+BOIvjMyNX4/WxX9t898fAgS2oOh7bor1XU/feMpbP1rZfbOzKru/aUrLbtcRxc+ri+8Ds6jxenc3+OZbdldoCqO7OWQ+7yi5I6z7mCWAL+e5Ctb777ujX0hadxe1nhIiIiIiIiIiIiIiIiIiIiIiIiIhoh/FXIiIiIiIiIiIiIiIiIiIiIiIiIvoeDhFARVFrhSaNYGJ7zMygPQDa840u8Oowq3BxuAFeHdUMkgTSIp7iQIQqDbUaVBXmimp1i032wKJv8UX0wOO++yiRadSokMJqXMN6EFakRWy3SOxndUlB3Gcf97xZi/g74qUOjyApsIVoDSN4uw9FjjGKYC0F7h6BTok4bVLFuhZM0xx3sFi/lOa4tig0KTTlFgQFSq0xTlWoCO7v77Gua0RW+/ha9LLWipwzNEWY97IsOB6PWxD0qtHZw5hjk7Zgp+9fs0Uwb/unMV8A0LFPPczanzR31HVtEVFve9X3u12vtTd7pPdmlFfnob/W3NrPPQD62RbC9hPez/2Nhqe7w9wgLi1CG+cszpNtAdo+lkaTIicFJOKxVkusQYuPwts1LK7fA6sOh0Kvzw8EqtrixFv42MyQcx4BXgCx/+5w0fFZgsd5NXeI6D612vZlq+JGSHfbxx7i9RFKvlms3efGr87S9RrvZzP+Fo9z1Tb9rYyqA59/ntoApb0xqV793t401qD/Ue/zb4/1/Wrr179HfBd+7ffcJuHjXPirkyYiIiIiIiIiIiIiIiIiIiIiIiIiCoy/EhEREREREREREREREREREREREdGbeixRVLAslxafNIhGiLLWCnNpMUkABjgMXg3FHQKLCKcLoBEqjQtHQ1EkwqRX7cQW9IQ7fBfSdETocgtsbs/1EKS0aOM+wPm5/tx2U/d+X0BH+HLkIXe/YYRda60wsS2uiZiL7OKT+3FEgFYhVUaUNda3RT3hbW4Rx43nDNojlB4x0ZQUpZQRuFUArgl3dyc8PDzsQp4CN4OZj8BuxHYd67pinmfUUuBmvdTaxtnXqG2S9qW6XQlp0dY3gp090HsV3jSgzRNtDUWlrYWNO2RJcV76nXZrfL2H+9+2MYu+URF1jLV0+FUA9fXrAftz0n8U9EDqFrQd8ePdJVUTUkpwVFjdIscRVJbWJjXUWgDR3RphFxWNCyZNLU7qn8VGRaSt436ttwH314sKkrf48lUUd4v8RpPWt9l7Dy07euHVIS3Yim0Vt6d3V7qJwfrVXbbVVALF2AAAIABJREFUbvcb+9Hvv3vvCOyO39skdkHa/ffFbXB2m4+377A0AsL93KmmiPmqxt70z0afa5tMxGEV+6AsEREREREREREREREREREREREREdFbGH8lIiIiIiIiIiIiIiIiIiIiIiIiou9lZiilQFWxrityzhEr7eHD6kia4A7UGuFXQIEa4VcVRUoZSRKyZlh1mBtEFGmOoKWIwFqUEWihRo2grKhG/NNs3LPHUruIaDpqe78DEPcRih0hyR7q7IHTFgF1N5gDSbXXL1tXUj4LhDqAPOUIPrYoZEoJ7hFZjesLNOlVvDKmpDiejlguC1S1RVkrRIDj4Qh3x+EwQzXBrGItBfN8wLqucLTgrFWsa4EmbWOLkObT0zNOpzs8PD5ARZFTivCrG0QyIIBZRSkV0zTjclmQc8RJe4wWwC4a6q39GnFOd7l6/DaRertGcB//msc4rMVo+1pkyS3Y63CPM6VJoVfXFli1sbav3cz7uHYh1pvRxN9xq9tt6W/C6N7uw8JRBIZCr6PCu85rj7h6i+tut3aUWiLuCh/nxM2jh6wKs4paFfOcUQCUtWCeHaVWqCgMhpwSDqfjWLce1RVsIeHY376+gjwlJE0opYy1sWo4nU4jHPzqWu7W6KaxjKvwbIuijsvcXO8qiOq7T+suShshYN+Fm3cn62Z4ItKiq9fB1j5W79do9xrBW+mf87FM21kQiWB1+yzH99A2ZvMtggtHrKU78jS9EiQmIiIiIiIiIiIiIiIiIiIiIiIiInod469ERERERERERERERERERERERERE9KYeN+zRypzziEb2f5MmpJRRS4VXRy2GqQVi4YBKwpxm3J3u4OZYa4FLRCuTJlSrLYAZQcqUUoQte1zWDLWNJwKRMZ6kaRunWbtf1ChVFbXGu8xshDbjGoDILuTpaGHSCEq67TKRNwFK94h8AtquF7HJWmu8TyIa6+2xfVS11orz5Yzj4YCcM1JOcNuCqOfLGfM0Y10XTPOM0/EEeMVa1/baWI95PmCaJpRaI/DqjlIKcsp4Ob9gnma4G9ayopaKw+GAshaU8oKcM+Z5Rs4ZDw8PyDnioOu63EwUrxdS94+JjzWSfV0Tu8BmW3CBXy2liiDlDPUe6zWYO+DWQr8O3e9Ri37uB+LwFnn1tnf9pdJCsd7bvABknJ2+R4LreKeMudxUXdtzKaW4m28BVNEW4N2FbrG75rIsSG0MogpNilIqzBwptXOcMg6HQ5u/AwKs64LD4Yi1FKSUkPMEVR0RZqAHdeNeZtaizAlJY66XZYFVQyl1jFXbWD93tWNjyXtG9zaAvO3LtkxXS9b/8tvnb+4jY4G3C7xWE27vin02wIGU03hi7MfuHn2MqhoB5PYzWrha+iQVUG/fDSoQbyHq3dr22HVShagip7ydlddTwkREREREREREREREREREREREREREA+OvRERERERERERERERERERERERERPQmbSFVAbCUFTln1Goj0ppzhlSFigIKIDnEBUkSsmbAJQKJBpyfz1CJAKZqhqiMQKu743A4AACs2hZzFNlimyLQFnQstaLWMsbZX9cuBqt1ZBkj2LmLOJpDksDMR7TTrLbALa6jsOY3sVhvcdf2AvTopECSxDoAIyLb59dfE88L1rLA3ZDzhJQUpVwgEMzzhFoNVg3n87mFQFckVdRaxtpP8wR34HJZIALkacK6rjgdjzhfLnD3iOvOivP5jJy3/2VU2jXjegmqev18e9EW8/Qt5rlf1KskaARee6B195JxU2kBVhFpz0fxM64v7SeBmwHmMEXESttNVfU6AOuIM9eGF0FPgej1Na/e4NdBX7n+5bo76mP2AACFxr76FpWVNi/vc9vPGREVTt7G7UAtETgW3c5YSoo8Zbw8v4zAsqpiLQVTzm1uhloqlmUB3Ns6tvG5x/lu8dj+Majtc6RJxzxFFC/nczxvtk3V/bqt+9qCjF+3x6/W76qB6leN2atLy/7UbJ8hv33dZ29srdb2GdrdqcV+AbQwbrx225PSwtL9+8wsYsPb8Wzfc+09ZhGY7T+rKKrVcY6rxedaRVtM+I1iLRERERERERERERERERERERERERERGH8lIiIiIiIiIiIiIiIiIiIiIiIiou/Ro5qOHkBVABVmtgVGPWqoKgKkDFgdJUdBRC/dHSmnFgBtgVQzuACnuxOeX56xlnXrqYogpzSirmY2nrJaIwS6T49eBSX737fhzxiHuUEsApY9oimSkDShtnkJABe/SkwCEXtMU0IpZYQv/bp6uXuHX8UxNSmmaYrwZDVcSoW5t7Brxf39PTQpzCMc6+6YpxlWDbVGuFY1wd3w8vyC1NYnJcWUpxHGPcwzzLYg5rv7+xaJjbmWUlFqwel0h1JW1FqxrltId7Q9x5pugVsg+qn7GfbVjqBpj5r66MW6bIHS8U737U/fWRFoD+vK7hq7Pd4nNrcoLUZYtrdit1dex11304nRvxXt9Ovrx7z34dctgDr22QFrMdZtngazLS5ae9y1fQYiDixYlwXVDKIRCHZ3wA2llvF5EamopUDVR3QWiKgxRvx4+7wAQM4ZOSVYe6yflwgR35Rd22xuH5XdHsfiXp+Hq/3AFlt+PefqV+98Nfi6e/y6J7ut/xZr9tEkfjXC6tsd3D2+c9oj1q43gsTuLTxtMcJY9rYf1uKwGAHY/Trv95yIiIiIiIiIiIiIiIiIiIiIiIiI6Jb+WQ+AiIiIiIiIiIiIiIiIiIiIiIiIiH51uccfgWCeZ8AB1Yi4WjWYRbyzByhzzsjTNKKKmjRCrVFYHZFKd4tQZo+qqowYqMgWpuxhxoi9AoBDVEfIdK+/Fj0C2iOTLdYou2uO1+sW0ezR137d/p4eeuyBR1X9LHzZhtZm1EOn1zHKHgytLV5braKUglorRID5MEMl4p/7MR4O8zYfQax5G4tozDcilHIVfU0pjbVX7WORUdXMOe/iuvV2MVscFxg/tD9XTVjfx07bcz2Qebs/u7+v4q8tuDuW0bcoa2RhfX+BmzXf1kFVY+36G3c3lhaE7dPZB20/v6yP8KvvzugWGpXtrLWg8KtjA5BThqiO+fVrbCHiiP+uawH62W8FXE2KUkrESCUir+afx0ZfC5DGz/G7tc9b32dVbedmt0RvRXDfmtibj48t+Z7HRu63/XYTed09fvv7iFH3L6b+zNgPvzpbfe49HOzo64HP9nCs7+7sbvsWZ2wEiCVmYR7vYfyViIiIiIiIiIiIiIiIiIiIiIiIiL5P/rMeABERERERERERERERERERERERERH9CnNAXKCacJgOeLw8YpomiCrMVigiLlrNoJJacDShrAWaE5IkwAGrDvMKEW3Rxi2ser68tNc64BE/VRGUWgFrYUoB0MKMU87wFsG8Hqtvwci4xTCu0X4WRCxURFBrhZtj9RUpRdi2Jz9FpIVAd6FPvwlT7n+/6YDuo5pmhrIWmBnmeY6wpzlcHTlPIzLbo7RwRykFx+MBZoa1vVekhXgBwOK6l3qBAEg54/xyxjRPOMwHAI6np2dM8wRv780pwd1Ra0XOuV1TcW2b4RZM7XONjKbvXhdb2vOu/fldAHas/c1+eQ8Ho0V6Yz6qKa7cQ7CvxEm39boOefbgZw/dxlX7GWoJUBHIa5HSq599O0fS5+7QERnGiKqOGLFf52QPxwMghstliTVygblD3KCeoAJM04S1lBE97teepwnLsrR10y0y2vZqdGR3MVnoFuLte7yuC/rnzeGYdILtgrux9NKu/XbU9e2VaveDf76muzDwZx+afvP9S7ft+ew221Fqn11t3yVX0dfrfRORFthNgCBireNzkEe42sxiHTS+e6Ita/H5xE2MuIVn3Rh8JSIiIiIiIiIiIiIiIiIiIiIiIqIfhvFXIiIiIiIiIiIiIiIiIiIiIiIiInqTSsRdS60oz88tQrpCVTHPMw7zAS8vzwCAahVwQRLF4XBAUkUtFTBBUkVOGXCgWIWbReRRBaIpopcpo1aD1QpJCWkEHgE3gwPQFpm0FnvsrEUae5x1BD7bH9+9XpNGsFO35zUp0Hqy/Tot/zrCnu4Rj1zW9bN1umqcysiNxvhb0dLMUGrB4XAY11dRaEotyGp4fnnBlCdMU4ZqAgB8+913LeQao0sp4+npCcfT8SpimzSh1oK7uzuIAGYVZob7+zvUatA8AXCsa8HL+QV3pzu4G1QVOaUxl22t5Gpum1Ybbc+OTqcZoDqe661VwbYHfS0jcKtAtdhL89FnLbVAs8BawDVpxE5v9xwS5zP2Jq7Rx37T/t3irfsorLZX9CDsZ3sqiJqptCCw3VwsorTaw6ZtXqpbSNesIk8pAq/ripxSC40KVByiivlwQDVDKXXMcZ5m1FpxOh0jaGu1nSvZnbH4L8K+EXq1WsfenU6nCAy3s540bcle95u5ohVX/Tr2259/5UG//e17IshbLHh3vz6OXfB19F8/20CMzzMAJI3Q9HZ5H5/PERNGi9qaj/H3YPD47nEZcVfV+F4otY73phzfQ+YOqzZm4uYwt/jeap8/IiIiIiIiIiIiIiIiIiIiIiIiIqK3MP5KRERERERERERERERERERERERERG+qLdSac0YpBSnlFhsF4MD5fI7YpQO1VrgAeT5ivSzQKUKXCoWqRoBUFSoC9GuIwB1Y14JaC+AR9CwjYhlRUevh1qwRd7xpdbrb7iHfP9FCkhGZdI8Iq1WDu0NbQDIlRUoJtdSIjsqWNfUWplQROBDxTlFsyVD5PJYJtDnKiFtqUszTDBXFZblEQBKGspaI5AKYpxk5Z4gIaotQujlyTlAVLItjWRYcjwdcLpcW542x3t2d4I62T4qUM+Z5xuPjE96/fwe0sQOCnDLMDCkpaq2oZmPs7i2+2dexVznb2nprv8b2CUYZtwVtpQV6++tcAIw4b6yOSESCgRTR4B4HlX7uLGKyLajqbqhtz7Y17uveg6hbpLSflwjPxk9bfrSVRfel0tf0ei3auenncZRe+5zbVayvz3a9dS0Rf80Tzi9nTHkC3MeSusWc+n70bHAPLOdpAiAopWItC6Z5gmrsY22fEVWNyGsbV84TppxxvpwhEKSU4O6oVsfPehsslS3i27dcdj/vQ8DbjHfv2J+X639wfWVcR2J3xdf+Me3nQPxmZ3yL+4oISinjDFzFZB27eDOQUmp7137XCFpbreNeKhHsjRhzfCf1CHStdYvDwgEDrIeAd0FaIiIiIiIiIiIiIiIiIiIiIiIiIqK3MP5KRERERERERERERERERERERERE9GtGRP4+gL8B4Et3/9322N8F8K8BWAD87wD+XXf/tj33BwB+D0AF8Lfd/R/90HullJDzhDxFSHRdV5RaUWvED3NKcDhqqUiaME0ZOScsApSyQhBx0lojPCkt9hqBTNlikrbFQqvbiDomVXhKUO/BTWBdV+R2rd2iIPKNgnZLAIjoo0eQVLQFW93hGnHIiKHGjUUiEKqiEI0Ip1mFWQtKShtD0wOpDuyCn5E+bcXMCJjuQqQOx/PzMw7HQwR1a4GbI6VYu5Qynl+eUWsdUc+UEh4eHpFSgqaYZa0Vx8MB58sF4oJpnvDy8hJ7kjOqGeqyoGoa4d7z+QJ3xzRPePfuHdZ1Ra0FIoKct/+lVFWgKi3S6XCzq4hthG3lai360o8I61Um1Eck0+Ewt3HdUssIeo51bJFeTQmqipQUgCAlg6he39N3Ic5tGFtwdBcu3T1we4nryujtS+Tmmn1mPW67D9LKPo4a7ylrgQM4nU5Y1hUicRYVCkjC09MZU87IOsX6VANqrHktK0QFmoBJBeYrUNtJV4mm8QjwtrApIhDcg8MiCpGI19a6SyTv5iy7COtni3nz4z6yLLdr90pH19136djX9fDr9Uvk6nqiEZF29xFilv1re6B5F+XtoVtrceMIFscXxHhMZBcs9t3lpMWiHZAWzO3fLy0KrBIRXQZgiYiIiIiIiIiIiIiIiIiIiIiIiOj76D/9JURERERERERERERERERERERERET0K+YfAPhXbx77bwD8rrv/SwD+VwB/AAAi8lcB/E0Av9Pe8x+LSPqhN0qqyDkinLVWlFIiBooIKZpFqNXcoKrQlFDNoElRaoUmhSaNsCIwao0RYZQIW7b4okqLK/ouoNnCihF+bJFGM5j7dXRzvDYCkKoasdcWxtyHRSMSqSPYKBCY2YhB9vBjvHXLmPr+nu7bnFrccnRG+5hFrsa4BSUtgpht3iJASoqUMswqaqmotUYUVlOLn0aUNWnEdiEC1diXEWaF4P9u5/5CfVv3+65/vs8zxpxz7X12JJJa0yRokXghXlQpuSnUgKhVhOiF0lxIRCEKKehdrV60N4Ui2lsh0kCFNjGgxVxpKwi9qk1bgm0SqsEGPSYmaeJJztprzvkb4/l+vXj+jGf85pzr7PR0n3n22u/XYe0552/+fmM8/8a8Orw9WtC23baUeq29FFlfFx3jSilpXVfdrKtOA+16YXNUXY97HfnXkXhtAd+2MjZdr73Zko3Q6O5Fxf0IAbe1S1bPUY+/9pBu34tjaG0/Qqd/PcrbB3Xs1BH2PE/wPcZ0bezXOB/TvI7rXu256jMSEbq7u2tR4WP8pZTxfndXFG/B4Ha5OMZdPxvTWtRrebjMpGXJWtZVuQWZ+/mrkeNQeI2m1mufY6Uml1nI1P5ZtBrrMbdoz5LF8U/RF+Clf/N6T5tkY4KnfxHHlMf3fQhW/1b08GtfHo8aFPZxlnScmVoSno7iVeS1XaT/vXEvKn7sSWp/o0bctf9NaOMg/AoAAAAAAAAAAAAAAAAAAD4L4q8AAAAAAAAAAAAAAAAAAHzBRMRflfRbV6/95YjY249/TdL3tu9/SNJPRcRjRPw9Sb8k6Qc+881a7DPC9Xh51F72FlGtUcTiPkKTSpIiVMqunLM0oqZJluwcZmzRxJyyzJJMqQZZ0xxdtaMAGTXPaCZZSi0OOUc27UnHcwRm6wIpwo/PjTikjkjm9M/DFd6ipHP8MY7Q6XmNjiBkSkkpJeWUnqRFzUzLuqrsZcRmzZLMalx32/axnmamZanrsyyLcl5OsclQaMktDhuh3GKpxzLX9xUv8uJalqx1XWXJtG0XRUQdZwutHnqEs6/5Eak9Vq2/8/Sf9tk4IqxzL1YaayO12Kn7FIVNY/1yzso9bNvHEnFaz5iinde90SlHO6q05/jwnK09zeb5Hmx/rYVf+7xSi9XOZ+Q6/jrem0y3Nzen+e/73vYsRqTXexh4Chgfe3DEcEPRYr/1/Tkv7Qy0KHCytsYx4saWknpZ9pwsDUmuEWad9/PqXfbS/+Lpa/3dMtOpFTstao/OHvXgKfwa12HVeoHjPMT5fJyC0HWS3v9eTfszx5dDUnico9LRA9DnyOvo/Frfi2fOCgAAAAAAAAAAAAAAAAAAwJXltQcAAAAAAAAAAAAAAAAAAAD+ofv3JP237fvvUY3Bdl9tr30ml+2i/GBa8qKI0O3trbZtk7srpVo+dK9hUffQJTateZGZdPfmbsQVU06KEkfYdYqkRmmxVYUsTEo1Auo9Whk9EmlKy6qbdVXtOU7lRWsBR0kWMaKZ7YO10djuGx4y1axlKJQsjWjkHJCs0dU84pzhIVcNyFqtxvZbn+Kv1uaVzLSXMobYr/3m7o3evn077p1Skrvr7adv9fHHH+v29nYELUvZR8x133fJpHVZ9PDwqJxatLW918x0d3snD1cpRV6KUsq6vbnVvu/ycOWUlFJW799u26Z933XZLk/GqWkdNNb6KgoaRx40Tb9tlVDNP0bU+eacVbwomUktEnz9IXsmqjnHN9tAx7rbXJiNGiueXxh92qvoqY0xx/h6dZe2DNP17IgGy0zW1yAkl58DpMmU87G/3/Ed/4jevv20xVjLWL9SyvhcMpMti5a8yK3GWNtOKCUpSmhr8eAIKecaCK4/H8+Kl/r7Od9a7xtKdo66Xq/GtYgWvI1TB/f09qefPEKup9+eN1Fx/cGp5zuvZV+zkOTFlZfcIrnHBecz0s9cKWW83qPG/b19yv2ZySmP6ypU49Y9kpxSjcO6t2ee9isAAAAAAAAAAAAAAAAAAPhsiL8CAAAAAAAAAAAAAAAAAPABMbP/TNIu6S/0l55527OFRzP7UUk/Kknf8clXJEk366q7u7sakwxXSknruraAoili07ZvullXedmlnHV797G2x023Nze6PF5UNpfJdLveKqWk4ru8+IhVunsNxJrVHGuELGdlOwKvofa+cEk11jiHIVPOUtL4fP1X7zuHWmXSuq7j3j1ymnOWIo7QbPvcuEfElAetcVnFEbI1M7m7Lvv+JOo6Ft1De9nHOJZcI5PR4pN3t3fat73FPOv9c160LIseHx9H4DVCWm9W3dys2rZd27apeNHd3Z3WddXj5bGOvwVwHx8fR9ByL0XlclFOWaHQ3e2tLpdNl8sRf+2HJp4rsF6doFPX8yq8ebxnCsa29U5mWpa1hk0jVLzFTFV/pxYN7mOx9trZOe5q05iO90cNl54Ko/MonwuehhRT2dPUgrBzKnb6Tzs3yaydGztdyyyUUo0Zf/rpW33yySe6f3jQ5fGikFT2vX6uf6KNtZ/F6LeyGuKNfs1sSpa0rosiahzYPWTJlHJWKaG8pBEvlamGUHM6PTtP1jSufu5fWvh1Xufr766X8cXfjffUZ37Kt04fP4dhk9V5mZmKFW3bppxzCxofgeIefZ1DzhHHKexh14jjviml9szYiMH2i/Vn+2HflSyN2Gw/DfYNpggAAAAAAAAAAAAAAAAAAED8FQAAAAAAAAAAAAAAAACAD4SZ/Yikf13SvxhH3fGrkr5vetv3SvqV5z4fET8u6ccl6bv/8d8TkrSXosvlUZJpWbL2sqvsZURYc1700e0bXS6bXK4USY+Xi7bLRWV3rcuqvGb57rqUi27sVjIp5aScknJetO+79n1XkWrgMpkiQvu+y8xGmDF6nLW9llKaB3+sg2q7s/5HLVp5RCDbWp0jnREKM5n7eL2GVo+ApKmNxSTv3dD+cU3XnQKg50Bt0pIXXbaLlrwo50XuLjPp9vZG9w8PSkrtNVPOSaXsevvpg27WGy3ropySJNPlctHj40WlFIVCy7IoPHS5PMpLUXGXQsrZdHNzU8Og4VqWrLvbO23bRWbpFNSdztFVwHT+pY5mqkwW0dZaI06r1k2NOEc3R5yzvX7es+OedY1T3ZMXA6J1L0YgNLzvQK/FytquhI5wb7oOyFqNd853GNM712fbnNpVpw9EhMJd3s7pfC4jiiJ62jXkXvTu/p3WdVWyO93f3+tyuWhZljqOti7Wz2Ku0dawdsasRoQtmZK1EKq7wqM9H5JKXZNlrf834VLKscpmWnKeXvsszkHYsaPPbMs5e9vuefXGiB7THdnep5c6msvHtdszX6Otprvb2xH6NbO6LlYjuDKrMd4pwNx/7s+1Fx/h2R5gTlHjriPFO00opfo3q18zIup5ek8jGQAAAAAAAAAAAAAAAAAAQCL+CgAAAAAAAAAAAAAAAADAB8HM/oikPy7pX4iId9OvfkbSXzSzPyvp90n6fkl//bNeNyLkHrIkeYSSJSlL7jZin73PmFtYcdsu8gh5uLZ9U7KktGRZSMX3FlRt12jxzpSSihdZSFINOYaHlCR3V7IaXuwx0TnKKqmO8ZkIY0z/7fOpd7iKNra4Z7JU398u1iOPUotHWpIsjbDoiETG2IfT15zz6d4RoZyyck5KOWnbN22XTXvZteRF7kWWamxz33e5h9ZlHdFPl4+4aJyLnHIviqjhVLO6N+u6at933d7eqpRdvd66LItSytr3Te7ntYy4Xjcb/w31qGrLmVoPg8aLa2v9P2b1LCSTdtVAbQ+ativ22G+NmZ4Wdh7KiARbSN7OUL9PMquR4P7pPiHT+RpxOgCaz8npAz1ia09/1VcmWlB0zL9xD4VcUqpxUcvat/pM5Jx1d3ur+/uHevZSqhFZHeHhPqp67kMRpnVZT9MJ1TDqUSVWOyNtdH0927nuMdSTHrXVvNu/e+cm8nPR3mv25G0xfROnLWlhXGkK/x6VWHevc5XGuVCMk9pen/9++HEvs/r3pf0utb9lalHYGvVtzz8AAAAAAAAAAAAAAAAAAMDvEvFXAAAAAAAAAAAAAAAAAAC+YMzsJyX9oKTvMrOvSvqTkv6EpFtJf6WFR/9aRPyHEfHzZvbTkn5B0i7pxyKi/O5uWL+4u8xMlkypxSxDMWKS1oKJxYskU8i1u2tJi3LKCkleiixqgDJUI6CStbDq8a9e7/i+xi9b1DPq72ZXKdaRKO3fj45nC7Ca2SnSaarzGtexc/izflvvb+7n90zrZO+LZkYdZ0qmvCzat32s3XbZlO7SuG6P7ko6QpSKFmqVIryFUk3u095Yklog1tSv47q7u5VM8uIq7goP3dzcaNs2mdVw73mgU3XTPlsKdE7FxlXQs65LC2h6DZVGCwTbsWnHmGMaQwvz1jLncQ+T1SDrtJ/HnsxpXJMsxhjO86rx4ra8x6dG1La9FsfehkIWprAjdVrH7W2IVxHZiFojrSdeHq7iRSklLeuiW79RuLQsWeFJpdS9LOHny7QzmvOi4uUIuqrFhsPGuajPYY2W1nVqMeU23/eUkq8Crp815Rqn5+HIyJ6v9uRacf5+fDuarsdq9nNhZiOG3N8cLfibQ6dxuHsNMIcdt2h/A2L6rKlHcv3p4e1HokeXp7PZzwIAAAAAAAAAAAAAAAAAAMD7EH8FAAAAAAAAAAAAAAAAAOALJiJ++JmX/9x73v+nJf3pf5B7mdUwqzQHRmsktYdUUytnWmtrmtXYpLfwpff/tWjqHCYt4Qp3LXkdkdP6rwU+LcndazCzlDGGrHyOr/YO5BQqtVPns49ZLfgYI/wpqQZZI8tbcDNFehJy7RHQGpRcavhxDoK2SmqPxXr4iLu2QYx555Ry20t1AAAgAElEQVT19v6t1nXVmzdv9PD4oG3bdHNz0wuVYx1KKfX1tgelFJXiWpalBivbfcxMecnaLt72xPTw+DD6o8msRjK96OHhUXd3d3IvyjmP66suj3rasidPjxxmaMpetjdH/2l6xxFFPS9jPU8pJSUzudeg58iSJlMojbDn/NFzCLStcw/uTue0lPIkDtzf86w52tvmblbXtU7e5OFK6pHV4yxMH2sziCNKKo1nQqqBXUtSihbyDZeF6eOPP9bbr7/VsqwtZFvbzL5PZ9Q01i3aOXD32pU1KaXjNTNTylmlFKWUx9p1qUVMT7HWETk+7/d57+tP57htm147Cv2SR/b1hTWfQrOt4HsEX6ci7NxhjXkeccRmx73aH41kdX7u/qRYG9Ge0zHBdm6uwrV9Hcd42j1DatHdeVzx5D4AAAAAAAAAAAAAAAAAAAAz4q8AAAAAAAAAAAAAAAAAAOBF7q69lBGMTC0sKYVKMUULUB5hxvbPJFmNrHq4ShSlnBSlxSOTZFHDi0UmJdV/0oi0RoQsSdbCrJZqYTKlpMfLRdu+j3GOduMUCDXrgcs5ytlCoyG5vMUlQ1JWsmhBzRq17ZHbEaTVEb3tccj++3rDfl8bkcklL3ps49n3XQ8PD/rKVz7Wu3fvtCyL8lLX0iQt66rL5dKmURf19vZWKdXPpmRKKSvnrPv7e23bptvbW93crJLdaLtsKvteA7Feapg3Je37pvv7e+Wca+Q2Z7356M24xrquysvxfyk9Wph97SSLI/l6tC59xHT7vNWXcyrwjmRo9LWVsiUty6qI0Fa2GvaNkCxklnR3czvWYeyJxyliKtUQp0fIIlRsSo2e4qJXJdH+vrZPpz2chj6OxnTPI33aJtmLp6cQ7TS+CHkpMov23FSXy0XL4lrffKSvf/13lJSUkin8uFPxUruobUMs1TXb911mSTknRYT2fVeEyywppThHUiXt+1aDsKkGkz/66CNt23YVf402hSPjW8/7dby1B1GndbL6PF2/1Z78d44KHx+OVrftz93pnc9EVXsAeV3X09WO57S+1v9mHcFYjWe271X/TI86p5TGmetrkFJd/9JDzjEuNq59HcQFAAAAAAAAAAAAAAAAAACYEX8FAAAAAAAAAAAAAAAAAAAvMpNSaoHElr7sMc4aSOzVxxp5NdWXLLVIpEmuot2lnHINklpIUWOqalctUeR7Uc6L1mVVeGiLotj3FpcNmZv2FjdNKZ3ilYoeYJxCndG7medga0pT3HJEL9XGlhR2HQO1EfXswcg5VDkCktL5q0leRs1T67rqo4/e6PHxomVZVEoZ45SZvLjubm9lluTh8lLH+/j4qJyzLNVQ7Lt397q7u1WElHKSZHXcChV3rTerFl/aOpnubu9GPFbWgr0tEPvmzRu5u+4f7k/rNtc9z03PWvq0qMnaZJKSjVjveP9oo8651Lq+SpK7KackX3INA6c6/ofHR5Vyke9Fy7KMGGdx17Lk01h6ytem6Gvd31RDslHTpWFPZjAm2t8X6TreGSMkbFI7b/3TcRwzO77a1Ur18fQz0YPC7qXGXNszta6r5NK2XeQebd+y7m7vVNzlVuO/jw/3urm5bdHTkHso3GUylVK0LPWZ8OJ63B9H/HRdb0YQVQq9fftWkkbgdN7z0PFcHtOxsaehqEFaTUsQLQB7vcLzl9Py9r8lx8/9OTxizNO4nllLk9Xxx3GllNJpTmb1jJXiumryqt8sQvV5l8nSEXlWOvbLUmrHIa5GDQAAAAAAAAAAAAAAAAAA8NkQfwUAAAAAAAAAAAAAAAAAAC+qwcVUQ57eg69HTDHnRe6lvmeoUUWXt2BibS26F+W0KOWk8B7XjFqPVMglqeyKUqOL4SHLSSnVuGlesnLONWRqSTlN97QecD0il6dfTnNJPcbZUpdRm6iSWkz1dA3TVTu0BShtxE77daQWQLUWnrSsnLIeWiy2BiZTnUPZa7RzrwHYm3XVvhfdPzzUz+b62RoELSM8mSwp5aS9lBHALFZkqQU03bVdtjEms6Rtu7Ro7tKCqlnbvmvJi9Z1VSllrMlJqO3NUc60qOsZLQCrFkQ1haJFWHuec3ws7FijqZ1az1I7X23Fl7bHSaZlWUZo18y05OUq+Fsv1GO+p/1xn8Y2bjuCrscmX0dfr85MveApMFundORU5/c/uYqlGkIOKZnJ21xqmDX08PDQ9nlXTrmd66x1vVFx116KLtvW9ihNgdMWf+2B2xEjbtdu6zbHUCWNaHJMVdW+DOHHc1A/r1GFDdk498dcn3nG5spqu3D0F/ra92BrP0tt7OHnuOrTe/ShmfKSj7PRLlXDun58zEKW6vpfj8t7Kjp87I3ZOR7bn4kamX06sjHrHowFAAAAAAAAAAAAAAAAAAB4AfFXAAAAAAAAAAAAAAAAAADwDYQU9uRnS6ack4qXFlaVJBtRRW+1xBpGdEVI2VQLotbTqqpxxhZ7dQ8pilJKCrUgpIWUpBQ19prsaZA1WWohWZNNocYeC7Ue8LQ0Ypm9TprauDW9Vq9h9XdXrUuzWot191Ossgc1e2jySWSzxVlr+DLqjaex7mVXKUU5ZVmua7vvvUxb10I5tOSsS3HJQinlFreUvN3Lw+sapSNe2eO80WKedQ5qUVh/Nrn5bM5yNE+tl2D7oshiLNCTz7Q87LGG7S7W1tNbALTGSZOsRUyv9+/JoNrr0ec2IqgaAdB+JkdseIr79vjvs/q9+2ff0/d8+Vc1ohq1ftzir21eIRVv+91+DrmKS6kUFS8joNujwXUvj9RoD8n2+GmXJGkKvUYL5Y5gcVzt+JjcFHgd8de+nNHu/Q1Cp3F8M1Z/au32IPSIw0Zbo/6mHho2KeZF789XPws6njFrUd0+g/ljY73s/LxdD3n8XYh23dGsjfPfhn6tGe1XAAAAAAAAAAAAAAAAAADwHsRfAQAAAAAAAAAAAAAAAADAi2JEOU01KelHtHVEGKegZf2UvIcm7YhSRkgul0ePjVqNuqrGPhXeooo9PulyueRSuLdw5NNQqaax1HvaKcrak5A9AtlDoP13NdZqT66b2mtjVj1KWW84gp3P6YHMmGKToRq3Da/r1YqdNdzqoX3blZesnHMNerYI5ZKXGrhsa5NSGmHXZclKOUsR2kup35eilLJSqoFa99CyLmM8xV05ZUWEHh8f69yvY6Dv07qvTz/xTJz1qHxKPc6rGuvte5LM5C38W2OmVs+EpdHYPEKw5xvYfKN2Vr2t1bHPMb6fU6b9/m2hx5kY51s6gqERY7/Od38umzv91GOn7iqSwkzJYowlVGO9Oec6BXd5KYq41D3PuQZ+Tco56/FyqeehR2Et1bPiLWQbMXqtOaVxjjzqOYjwGpB9plbao7vzNobOz8D5h/5AxHUf+bQyMW1/n3PvH5/ecGoJ97jrVWC4fZsstRCuxrM7/nKkdOoS13DvEYW+/ttwDGN+UiWLKeLcrtP/VgAAAAAAAAAAAAAAAAAAAPxuEH8FAAAAAAAAAAAAAAAAAAAvqjHOpJRyjZcWSeE1IlqKpKmdqTiHUVOLsk6RyFJ21TJsff2ITdZwZTKrYVKvEcuUjtCit/umlGo89JkI4xGNfC4S2l6LaIHIqRDZwo6hI8y5LIu2y0Wy1CqR8SQUmVJ6cv8jitvn37uhppxruDU8tO/biHd2b968kUna9l33D/cKD33yyVfkEdoum/Z9V0o3SpZG6DO8Ji2XnHV3e6fHx4e2P67LZdO2b1qWGpB1uZKSbtYblbK3qGmc4q9H+LTNVX2/puU6zbqHVJ9sx7S8Paxa35tzUs5ZHi5zG7+zKQorHSHTGqjVVAxte2xjkON9PUzcX+4B435QezS1n7s+1XlOphpqrV/7+GtAtN63f+DY575OM7OknOq1enTXzNqzU8/648Ojbm9ujzPdY6qWVEqp18hJSvXruq5ydxWvIdeQVEo5xt/O6bbtWpZlnMF2hOtTl9IxdklSUrrawDmU2mOoMR8Mm65gLes6BXRP14pjXGMfe0D42ZBw39pjTPO+Su35Sel4blNSqEZv53Woa9j/DsU4E3N8ub8/979z7gqFkmzElUspx982HWFnu3p+AAAAAAAAAAAAAAAAAAAArhF/BQAAAAAAAAAAAAAAAAAALzpiplLZS40c9ihm1Ehi/d5bhFSylLQsWVILSHp9X7tgDU+2VmTxouJFy7Io5SQV6XK5jHvdvblTzlkyyd2177vMTOuy6vlk5JVWl6xfpjDlHGu8CkDWzGeVctaRmzS5lxFyleao6TPXNOlmvRkvubsu29bCtiEPV87H1T/55BPlnLXvmyRpXdcWhjVFuJZ1UU5JOS+6v7+XpLo2ktxD27brcrmod04jpGVddHt7q9vbGz08PGrfdu3aZTLlnLWuqyJCe9lPY5/XxCNqXvMY6pOVrx/pb5je2H42a9FNrwHNlLJyyvLdR2A4S8pLHqHO6GdGmrKd0wstELuXGgU2k1LKspSO2GsfzTyn6etpAm0Pn0kK17nF8Tz0C/cA6KlkOvHi2raQ+14bqT0krBo2zjkf0eOclZYaA16XG6Wc9Ttv3yovi2RJ275pXW8UXsO+pez1mcv5iKu2ZzIialy3rWEN4PZoc/3qLd4s9WDqEcxtFxxh1SPSXEO2dfpzPLmtx3MnoIde4/i5Pyojwnpc4kV1bvXNHkXrurbqdIsgRz1LfV7T6atzzFPYNWL83TGz6W9ZKNzPr7W/V6mtp/txZsf6vK98DAAAAAAAAAAAAAAAAAAAvvSIvwIAAAAAAAAAAAAAAAAAgBeZTBHS5bIpp9RCoJrCh9JeXDllSVHDpi65kiK8XcGUlBRWPxdzPFMhJWnTLoWUs2lZklIkyU2X7aLYJIukJa/KttbeYwlFmUOboWh10tYE7a+2kOUR8HySmez9SZvyomZydyWr86/Rz5DHC5HHFt48/Sxpt/0UocwpyxbT5fFS3+ahsBqYvL9/p5vb2xoyVY3oJqvrWPYWtEyh0uKW67rWeG4pkkl3d7dKyXS57LJU7xUKpWQqxWXJtCyLIkKXy6XGRpOdx91Wxvo35yWevlynNccyt1NhIxh6vC/q3reXU0otxNmXvO1fMpk/DczO4xz39NC2bYpwJUvK7f8Z26PEPfRqU8w2xrWixljn69n1pKfRm87HpodW+5qZnX4v1WfjZklab1Ylq8+PlxYp9dDmm27WG7mHFh2B48eHR3lIn97f681HH2lpkd6bm1X3nz7UqGvUM5JzVm7rWbzUOKy73HflJSv18K0lJZNSC9BueT9mZ3ms78i9msZOtqWc1irGO/t62Xz8rb0nTl+uwq/Xa9yve3xmXs56jRhx4NIirE8dcdqQ2hnvfwvON4723Pa57/uuJS/1PKUa4i2ljLNa48DHPcc1AQAAAAAAAAAAAAAAAAAA3oP4KwAAAAAAAAAAAAAAAAAAeJmZkpncpkho1NCqJZPctS7LiCMWeY0pev1qtYrZL6VRSpyajTZVRmvg0WUpy8wUW8hDsghFuMxqdNbLLi8+rjEHSWus9fjFKSJpksXTSGd9axwBUpnC64XqPKytRQ1nuvsxj5jCn3N0Vqph1rZuxcuIrpqZ1mUd90pmynmp43WXzJRTqgHXHuVMppTb/MOPyUljfO41WmmpjieK67IXmW01mtmCsnvZFQotbQx76SHQ04JM+3Z+bd6568UOa6HXJ1HMY32jfayueb1WyOv4czo2a/rM6Uot4hkRyjlLqmuazOr69XtEKKyFSc1O1+ox0tPZkF3N+0h9pmmP+56klBRtrvV+V+P09t6oKVL3Osd6Bup78pIVJbTtez1zksySPLzGenVEZkvxcX7Co927/kttb5XreQhJS86nGvI85zliOqdxa/i1PePXE5oW6xw+bevc73IVCo44vXw+R8/2lPsnX4gt69iDcQbNzu+eno2+TuOW01kY12nPurfwa05JllLb7/68Pzce6q8AAAAAAAAAAAAAAAAAAOD9iL8CAAAAAAAAAAAAAAAAAIAX9bCitbBoDyRaHDHJGogMyULJYgRc20fV44gj8hrXocaov2sveISSTFJq934mAWn2QjSyX3H6rhYv+12OyOc34O5KlkZccwQjR9D2PG6TKazer19/RGLHaGpccsmLcs4qXlooN2tZaqgzXJKHXPX+KdV/beha10U5tahnTGsbde36/PreRbQQb0rKLVSbzOo1ZDJrYdMX1JRr/yFUp3hcf26/Xi1++zkU0y/CWuBWPcBpSsnlpa9Xj75qes9T0eZaA6fjVvWcqu+RjiPXx9vH07+OOGqPnU6h4x4/NU3h2qMO2yOqLcN67EWzLGudmxf1YOoxnxoT9lLH2/epvl7nsaw1CFxKkaWkfd+ULctyVpjLvZ7NUkqN/rYz2s+MJWvnd0xjhGGv1Rivtf3tPz9Z9WMNrkLAilBMz+p4zxx+beHob8iuvr73vec3TQ3mMeI5/Np3rK9Xf1Nft9OzLinlpFKiPiMx7T8AAAAAAAAAAAAAAAAAAMBnRPwVAAAAAAAAAAAAAAAAAAC8yCNaqLMGFFNKtbA5FT+37VHJpvBkrgHTaAHPI56aFB4tmmntGj0aKSVLkoeKS0pJ2UKWJIXJwmSp3tOS1Xjqkq9Ge2Qfe2g2etAzalzzuPcU6byuRXYjWlnHP8dNbXywXcL6K/XaPXzZo62StORFd7d3kkI5L/JwlVJU9qJ1lSwlLSnLrWgru7Z9k7vro4/eKKWkbd8U4bq7e6O7u1uFpN13xVzYlOTFpSQtS9a6LGNv3P0IheasdV30+HhRSlajsedpHzO0ln9t0dcegO1b2NcxnlnLHt2sX1v4tJ8HtT03KZRknqQo851Pa/ukBGqq56JHWdt1I3ycgB4unmOedSTtvQqZkubE7Zj/GKfJWhRUOuKfNo9j1GfPcdA3b+5kadfj5V4RrpxzC7Iec3t3f681Z92sN1Kq0dfirsvlotu7uxoINtNii/atyNZU1y0lJQu5uzxCpfipg2op1WuVfQRNU85KZlcx1GMiJrWAqx255Ks5vfDRc+S1fyJivBbHwtYa77SIZtcXetJ0HeHaPohkNva3r/2TB3l+fvsM6ySVUp2vt4uPZ7e911vkOuU8zk//O/D8+gEAAAAAAAAAAAAAAAAAADyP+CsAAAAAAAAAAAAAAAAAAHhRtBClVMOLJkktaOruCg8tS1YrItavXn9nZsppkdTDo15/L5MptbhjtMiijnqoSSGvEcoWaKyRT7Ugp9empB8BRrMpJtsDkP0z9Q1HsHTEStv7/Ii1jkio1XCrmSkp1d+7xrzVb9WDmS2ueS3lpFbAbfHN1GKvq0rZVVKWFmlZVu37pkt5lHtoyYuWu0Vmpm3bdblc6j2WrH3fte9FHq6Ukta8KOfc4p+mnGvMtMcrPVwf3X00xl5K/ezlssnDJa/7M+262k5MwdQp+toDmu1dNezpci91jpb6p9vnTa3bW8dsSTkvuuyXelzcZTItKUsRujw86Ga5HaNxPwKscwA2WlE0plfNTCnlI/R7FX2tB2cK+V4HZadX+kmtc7IWi53e1C/TXuyhXyvHNT/99Gu6e3Oj25s77dum8NDlsmlZlnoWSmlzMO3tmVEylbJrvVn06aefaslZtzc3urG6jvcP97pZb7Suq3JeVDy0RhrnNtqejwhxqmc/JBUv2tse+lUo1ewIvkZM62DHekUPwY4jYOM5PtrI/W/B1EueisLzXcdjdL0DT1889lOSm8laOLjrz/C5yhvnUKsd7+1/B3rU1d0VCuVcn7FkSbk9b0vO4xl57jkHAAAAAAAAAAAAAAAAAAB4H+KvAAAAAAAAAAAAAAAAAADgZT22GKFkNRJqKY1YYg2zqgVAj8hiROhIbh6Rxf7VUg9q9nxou12SFKlfpfYbR7wyFF4jk2uLZ56GOn3Xx2Ij0GqKHn6MI+QaVwHM4911jD0IG1EjkpZqILMGTtuYRkbyGTF/G2PdvvbbX5O7a11WpZR0f3+v29sbbduum5sbyaTtsulyuejjjz+usVgvUkj7vo+fUwtiukcNiqakfTdt+ybfami1r8XlcpG7a1mybtcbPcZFpezyOO+d9fm0mGjbhhGAnec1PjfVQuM86TnHO3apx3LXddXuRR5FcmmxRSmSvIVs+ydcR5xzvtIcY53H7SP8O0Vbe1y1Vm2PmPHTrZJa8LV/38ccCpml3v09xWefi4Kua5ZZyEvR3d2d3r17p9vbW7m79n1XSEqW5OEyt3quU9K+7YoILTkpwvXu/l7v3j3ozZsbffzRV7TvRY8Pj3XZU1JOuZ5Jq4Fdk2m0luMqYttmneYnpp1xtZCrWd/bKeqsHnTdT3t5Wr9o5yTsHF297q/O0dbzMh9vfuGhqn8/2rmez+HYi5F1PX1m/r6HXPvfrf5c5pSPZ16hUkrdH/caU34mTHv9tw8AAAAAAAAAAAAAAAAAAOAa8VcAAAAAAAAAAAAAAAAAAPBeMX31COUeVpVqqLLsp1BnDWvWOGptLIbcj2CqehxyVBSTpFCE1c8mtchrTJFOU5LJVfuj7j4Cju8dedRY4whTtoDnKUbZ7tFroj0w2qOjZiZ5fT1blttx3yfZ1xFLrdfrgdFQHfO+7Spe9ObujbZ9G/db11U3N7fa913bvilZUkpJy7po2zYt66KckmSm9WZV2YvWdVWEqxRXKeWIwpYik9UgaItkPj4+yr1IkoqbsmoMNucsyVR8H1OI+bu2J3Vq0fZNR/G3v89MSWlak+v85rHWshrbTGbKOat4qfHNcHl42yevZ6etYUpJKecnEc+UeoRXI/6pdu3TfOLIxh6jm+d7PhPj9R54DbX45zGm620f52tuno6fQ9u+a1lXbdt2nLmoodV6D9e21+hrj46mlGrINUU9G9umh+13pKjPWM5ZJtNWdpl2WUpKyZSTKYorwhXuNYpqkls9Q+7xNFg6B1lPv5qDv8f3YTWGevR/43h+4vzRp3rx9YU3vFhTPgdb5wFHr/BGD8oez3H/ab5sMjuCrqp/y1Iyefh4bmrwWSregrp2dU6uxwEAAAAAAAAAAAAAAAAAAPAM4q8AAAAAAAAAAAAAAAAAAOBF28Peoo418Bnush7cbJFN93LEMM2m2GIoWRnxSzPrl2lx1FFbHWoctL4vWRoh1Zp+NYW3hGMLmnaXh8djDCP0GSPCOm4TfWTtfmPMptbi7NMYkckauKwBTU97jc5ej71VQZ80K81GHHLfN71993WFh/ayqZSiaAFbS0nbftHj40Ndo2QjThkeyktWv8Pl8lDjoCm3SGoNwLoXLcvSorh1PmY11lrXra6dJdOSFz08PCgvWSZpL0f89Td/8zdrFHbsk64insf6Pfmm11GfdEVt+n0LhSrkEdp9l3upQdL+P1c7c23/U42llr0GbPey6//77a+N6/bg6BHuneOvx+9GlPdqp+J6wNemaydL4xpxfQYitJcyPvb4ENo3r+FcFVlK2rcyPUNSMq9js5C0K6LuV0qu8OO5cZf2zbWXImth2JTq9z0ym1IN4tZ9j/HsRnv++vzdY6xlROjt7zye1yD6E1T3KaZ9Ds3R5auM7tOG7pN1lEZP+Pz4jG+OK8xX//Tdu/EsPYm/XrHpBvO8eozZo6/rKNcqVAOw7jX+qqjnM6csD38S/B1TitC7+4f3zRoAAAAAAAAAAAAAAAAAAHzJEX8FAAAAAAAAAAAAAAAAAAAvurzbdHm3vfYwvqHHd/evPYRv6LJddNku9Yd3rzuW9/nVX/t/X3sI39C2bfr13/iN1x7GN/T4rkZfn/qsr73E279vnnvoa7/1bXwgm9/++lv99tffvvYwAAAAAAAAAAAAAAAAAAAAftfSaw8AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAD5EFhGvPQYAAAAAAAAAAAAAAAAAAPBtxsx+Q9Knkv7+a4/lW+y7xJy/DJjzl8e3et7/RET8nm/h/QAAAAAAAAAAAAAAAAAAwLc54q8AAAAAAAAAAAAAAAAAAOBZZvY3IuIPvvY4vpWY85cDc/7y+LLOGwAAAAAAAAAAAAAAAAAAfPtIrz0AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAPgQEX8FAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgM8B8VcAAAAAAAAAAAAAAAAAAPCSH3/tAbwC5vzlwJy/PL6s8wYAAAAAAAAAAAAAAAAAAN8mLCJeewwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA8MFJrz0AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAPgQEX8FAAAAAAAAAAAAAAAAAAAnZvZHzOzvmtkvmdl/8trj+TyZ2S+b2d82s58zs7/RXvtHzeyvmNn/0b5+52uP85thZj9hZr9uZn9neu3FOZrZn2h7/3fN7F95nVF/c16Y858ys/+n7fXPmdm/Nv3uQ5jz95nZ/2Jmv2hmP29m/1F7/YPd6/fM+YPeawAAAAAAAAAAAAAAAAAA8MViEfHaYwAAAAAAAAAAAAAAAAAAAN8mzCxL+t8l/UuSvirpZyX9cET8wqsO7HNiZr8s6Q9GxN+fXvvPJf1WRPyZFr/9zoj44681xm+Wmf1hSW8l/TcR8c+2156do5n9M5J+UtIPSPp9kv5nSf90RJRXGv4/kBfm/KckvY2I/+LqvR/KnL9b0ndHxN8ys08k/U1J/4akf1cf6F6/Z87/tj7gvQYAAAAAAAAAAAAAAAAAAF8s6bUHAAAAAAAAAAAAAAAAAAAAvq38gKRfioj/MyIukn5K0g+98pi+1X5I0p9v3/951ZjkF1ZE/FVJv3X18ktz/CFJPxURjxHx9yT9kuqZ+EJ5Yc4v+VDm/KsR8bfa91+X9IuSvkcf8F6/Z84v+cLPGQAAAAAAAAAAALx5/VwAAAPhSURBVAAAAAAAfPEQfwUAAAAAAAAAAAAAAAAAALPvkfR/Tz9/Ve+PKX7RhaS/bGZ/08x+tL32eyPiV6Ual5T0j73a6D4/L83xQ9//P2Zm/5uZ/YSZfWd77YObs5n9k5L+OUn/q74ke301Z+lLstcAAAAAAAAAAAAAAAAAAODbH/FXAAAAAAAAAAAAAAAAAAAws2dei2/5KL51/lBE/POS/lVJP2Zmf/i1B/TKPuT9/68k/VOS/oCkX5X0X7bXP6g5m9lXJP13kv7jiPid9731mde+kPN+Zs5fir0GAAAAAAAAAAAAAAAAAABfDMRfAQAAAAAAAAAAAAAAAADA7KuSvm/6+Xsl/corjeVzFxG/0r7+uqS/JOkHJP2amX23JLWvv/56I/zcvDTHD3b/I+LXIqJEhEv6r1X3WvqA5mxmq2oE9S9ExH/fXv6g9/q5OX8Z9hoAAAAAAAAAAAAAAAAAAHxxEH8FAAAAAAAAAAAAAAAAAACzn5X0/Wb2+83sRtIflfQzrzymz4WZfWxmn/TvJf3Lkv6O6nx/pL3tRyT9D68zws/VS3P8GUl/1Mxuzez3S/p+SX/9Fcb3D10PoDb/pupeSx/InM3MJP05Sb8YEX92+tUHu9cvzflD32sAAAAAAAAAAAAAAAAAAPDFsrz2AAAAAAAAAAAAAAAAAAAAwLePiNjN7I9J+p8kZUk/ERE//8rD+rz8Xkl/qfYjtUj6ixHxP5rZz0r6aTP79yX9X5L+rVcc4zfNzH5S0g9K+i4z+6qkPynpz+iZOUbEz5vZT0v6BUm7pB+LiPIqA/8mvDDnHzSzPyApJP2ypP9A+nDmLOkPSfp3JP1tM/u59tp/qg97r1+a8w9/4HsNAAAAAAAAAAAAAAAAAAC+QCwiXnsMAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAPDBSa89AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAD4EBF/BQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIDPAfFXAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAPgcEH8FAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgM8B8VcAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA+BwQfwUAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACAzwHxVwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAD4HBB/BQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIDPwf8PWrCJZVEVxnEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_size = 32\n",
    "learning_rate = 1e-3\n",
    "\n",
    "train_transform = transforms.Compose(\n",
    "[\n",
    "    transforms.RandomCrop(32,padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "valid_transform = transforms.Compose(\n",
    "[\n",
    "    transforms.CenterCrop(256),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "train_dataset = datasets.ImageFolder(root='PlantVillage_Training_Set', transform=train_transform)\n",
    "#test_dataset = datasets.ImageFolder(root='test', transform=transform)\n",
    "#test_dataset = datasets.ImageFolder(root='use_test_plantvillage_model', transform=valid_transform)\n",
    "test_dataset = datasets.ImageFolder(root='PlantVillage_Testing_Set', transform=train_transform)\n",
    "valid_dataset = datasets.ImageFolder(root='PlantVillage_Validation_Set', transform=train_transform)\n",
    "\n",
    "#train_dataset,valid_dataset = torch.utils.data.dataset.random_split(tr_dataset, [round(0.9*len(tr_dataset)), round(0.1*len(tr_dataset))])\n",
    "\n",
    "#pdb.set_trace()\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "validation_dataloader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=True)\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "def imshow(inp, title=None):\n",
    "    \n",
    "    inp = inp.cpu() if device else inp\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    \n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    \n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.pause(0.001)\n",
    "    \n",
    "images, labels = next(iter(test_dataloader)) \n",
    "print(\"images-size:\", images.shape)\n",
    "\n",
    "out = torchvision.utils.make_grid(images)\n",
    "print(\"out-size:\", out.shape)\n",
    "\n",
    "imshow(out, title=[test_dataset.classes[x] for x in labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = models.resnet18(pretrained=False)\n",
    "net = net.cuda() if device else net\n",
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.0001, momentum=0.9)\n",
    "\n",
    "def accuracy(out, labels):\n",
    "    _,pred = torch.max(out, dim=1)\n",
    "    return torch.sum(pred==labels).item()\n",
    "\n",
    "num_ftrs = net.fc.in_features\n",
    "net.fc = nn.Linear(num_ftrs, 15)\n",
    "net.fc = net.fc.cuda() if device else net.fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=512, out_features=15, bias=True)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device\n",
    "net.fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "\n",
      "Epoch [1/400], Step [0/439], Loss: 1.1631\n",
      "Epoch [1/400], Step [20/439], Loss: 1.1206\n",
      "Epoch [1/400], Step [40/439], Loss: 1.5420\n",
      "Epoch [1/400], Step [60/439], Loss: 1.4577\n",
      "Epoch [1/400], Step [80/439], Loss: 1.5894\n",
      "Epoch [1/400], Step [100/439], Loss: 1.2954\n",
      "Epoch [1/400], Step [120/439], Loss: 1.3931\n",
      "Epoch [1/400], Step [140/439], Loss: 1.2980\n",
      "Epoch [1/400], Step [160/439], Loss: 1.1746\n",
      "Epoch [1/400], Step [180/439], Loss: 1.3409\n",
      "Epoch [1/400], Step [200/439], Loss: 1.4937\n",
      "Epoch [1/400], Step [220/439], Loss: 1.4144\n",
      "Epoch [1/400], Step [240/439], Loss: 1.4132\n",
      "Epoch [1/400], Step [260/439], Loss: 1.2441\n",
      "Epoch [1/400], Step [280/439], Loss: 1.6853\n",
      "Epoch [1/400], Step [300/439], Loss: 1.1191\n",
      "Epoch [1/400], Step [320/439], Loss: 1.3907\n",
      "Epoch [1/400], Step [340/439], Loss: 1.6610\n",
      "Epoch [1/400], Step [360/439], Loss: 1.3553\n",
      "Epoch [1/400], Step [380/439], Loss: 1.7937\n",
      "Epoch [1/400], Step [400/439], Loss: 1.3232\n",
      "Epoch [1/400], Step [420/439], Loss: 1.5848\n",
      "\n",
      "train-loss: 1.5737, train-acc: 51.4471\n",
      "validation loss: 1.5057, validation acc: 53.7715\n",
      "\n",
      "Improvement-Detected, save-model\n",
      "Epoch 2\n",
      "\n",
      "Epoch [2/400], Step [0/439], Loss: 1.4873\n",
      "Epoch [2/400], Step [20/439], Loss: 1.8280\n",
      "Epoch [2/400], Step [40/439], Loss: 1.5348\n",
      "Epoch [2/400], Step [60/439], Loss: 1.5753\n",
      "Epoch [2/400], Step [80/439], Loss: 1.7174\n",
      "Epoch [2/400], Step [100/439], Loss: 1.3498\n",
      "Epoch [2/400], Step [120/439], Loss: 1.3003\n",
      "Epoch [2/400], Step [140/439], Loss: 1.6983\n",
      "Epoch [2/400], Step [160/439], Loss: 1.4953\n",
      "Epoch [2/400], Step [180/439], Loss: 1.5921\n",
      "Epoch [2/400], Step [200/439], Loss: 1.2985\n",
      "Epoch [2/400], Step [220/439], Loss: 1.2857\n",
      "Epoch [2/400], Step [240/439], Loss: 1.7073\n",
      "Epoch [2/400], Step [260/439], Loss: 1.3548\n",
      "Epoch [2/400], Step [280/439], Loss: 1.5417\n",
      "Epoch [2/400], Step [300/439], Loss: 1.4380\n",
      "Epoch [2/400], Step [320/439], Loss: 1.1783\n",
      "Epoch [2/400], Step [340/439], Loss: 1.3140\n",
      "Epoch [2/400], Step [360/439], Loss: 1.6790\n",
      "Epoch [2/400], Step [380/439], Loss: 1.3136\n",
      "Epoch [2/400], Step [400/439], Loss: 1.8002\n",
      "Epoch [2/400], Step [420/439], Loss: 1.4318\n",
      "\n",
      "train-loss: 1.5712, train-acc: 51.2618\n",
      "validation loss: 1.5022, validation acc: 56.0873\n",
      "\n",
      "Improvement-Detected, save-model\n",
      "Epoch 3\n",
      "\n",
      "Epoch [3/400], Step [0/439], Loss: 1.4489\n",
      "Epoch [3/400], Step [20/439], Loss: 1.2602\n",
      "Epoch [3/400], Step [40/439], Loss: 1.3114\n",
      "Epoch [3/400], Step [60/439], Loss: 1.3452\n",
      "Epoch [3/400], Step [80/439], Loss: 1.6393\n",
      "Epoch [3/400], Step [100/439], Loss: 1.1545\n",
      "Epoch [3/400], Step [120/439], Loss: 0.9672\n",
      "Epoch [3/400], Step [140/439], Loss: 1.5492\n",
      "Epoch [3/400], Step [160/439], Loss: 1.6223\n",
      "Epoch [3/400], Step [180/439], Loss: 1.4967\n",
      "Epoch [3/400], Step [200/439], Loss: 1.4893\n",
      "Epoch [3/400], Step [220/439], Loss: 1.2021\n",
      "Epoch [3/400], Step [240/439], Loss: 1.6463\n",
      "Epoch [3/400], Step [260/439], Loss: 1.6703\n",
      "Epoch [3/400], Step [280/439], Loss: 1.4067\n",
      "Epoch [3/400], Step [300/439], Loss: 1.7510\n",
      "Epoch [3/400], Step [320/439], Loss: 1.4418\n",
      "Epoch [3/400], Step [340/439], Loss: 1.5413\n",
      "Epoch [3/400], Step [360/439], Loss: 1.3028\n",
      "Epoch [3/400], Step [380/439], Loss: 1.3342\n",
      "Epoch [3/400], Step [400/439], Loss: 1.4924\n",
      "Epoch [3/400], Step [420/439], Loss: 1.6070\n",
      "\n",
      "train-loss: 1.5690, train-acc: 50.9552\n",
      "validation loss: 1.4996, validation acc: 54.0582\n",
      "\n",
      "Epoch 4\n",
      "\n",
      "Epoch [4/400], Step [0/439], Loss: 1.6258\n",
      "Epoch [4/400], Step [20/439], Loss: 1.3349\n",
      "Epoch [4/400], Step [40/439], Loss: 1.1688\n",
      "Epoch [4/400], Step [60/439], Loss: 1.5303\n",
      "Epoch [4/400], Step [80/439], Loss: 1.5614\n",
      "Epoch [4/400], Step [100/439], Loss: 1.6300\n",
      "Epoch [4/400], Step [120/439], Loss: 1.1457\n",
      "Epoch [4/400], Step [140/439], Loss: 1.3340\n",
      "Epoch [4/400], Step [160/439], Loss: 1.5250\n",
      "Epoch [4/400], Step [180/439], Loss: 1.5772\n",
      "Epoch [4/400], Step [200/439], Loss: 1.5373\n",
      "Epoch [4/400], Step [220/439], Loss: 1.2181\n",
      "Epoch [4/400], Step [240/439], Loss: 0.9761\n",
      "Epoch [4/400], Step [260/439], Loss: 1.4341\n",
      "Epoch [4/400], Step [280/439], Loss: 1.4377\n",
      "Epoch [4/400], Step [300/439], Loss: 1.2377\n",
      "Epoch [4/400], Step [320/439], Loss: 1.4064\n",
      "Epoch [4/400], Step [340/439], Loss: 1.5920\n",
      "Epoch [4/400], Step [360/439], Loss: 1.4620\n",
      "Epoch [4/400], Step [380/439], Loss: 1.3398\n",
      "Epoch [4/400], Step [400/439], Loss: 1.9369\n",
      "Epoch [4/400], Step [420/439], Loss: 1.3827\n",
      "\n",
      "train-loss: 1.5666, train-acc: 51.3402\n",
      "validation loss: 1.4992, validation acc: 49.4707\n",
      "\n",
      "Epoch 5\n",
      "\n",
      "Epoch [5/400], Step [0/439], Loss: 1.5547\n",
      "Epoch [5/400], Step [20/439], Loss: 1.4137\n",
      "Epoch [5/400], Step [40/439], Loss: 1.3194\n",
      "Epoch [5/400], Step [60/439], Loss: 1.6042\n",
      "Epoch [5/400], Step [80/439], Loss: 1.2823\n",
      "Epoch [5/400], Step [100/439], Loss: 1.5835\n",
      "Epoch [5/400], Step [120/439], Loss: 1.3256\n",
      "Epoch [5/400], Step [140/439], Loss: 2.1173\n",
      "Epoch [5/400], Step [160/439], Loss: 1.1967\n",
      "Epoch [5/400], Step [180/439], Loss: 1.6975\n",
      "Epoch [5/400], Step [200/439], Loss: 1.6500\n",
      "Epoch [5/400], Step [220/439], Loss: 1.3947\n",
      "Epoch [5/400], Step [240/439], Loss: 1.4320\n",
      "Epoch [5/400], Step [260/439], Loss: 1.4021\n",
      "Epoch [5/400], Step [280/439], Loss: 1.2407\n",
      "Epoch [5/400], Step [300/439], Loss: 1.5053\n",
      "Epoch [5/400], Step [320/439], Loss: 1.6612\n",
      "Epoch [5/400], Step [340/439], Loss: 1.6748\n",
      "Epoch [5/400], Step [360/439], Loss: 1.4466\n",
      "Epoch [5/400], Step [380/439], Loss: 1.2988\n",
      "Epoch [5/400], Step [400/439], Loss: 1.0661\n",
      "Epoch [5/400], Step [420/439], Loss: 1.2501\n",
      "\n",
      "train-loss: 1.5644, train-acc: 51.3473\n",
      "validation loss: 1.4975, validation acc: 52.1614\n",
      "\n",
      "Epoch 6\n",
      "\n",
      "Epoch [6/400], Step [0/439], Loss: 1.3661\n",
      "Epoch [6/400], Step [20/439], Loss: 1.1531\n",
      "Epoch [6/400], Step [40/439], Loss: 1.3585\n",
      "Epoch [6/400], Step [60/439], Loss: 1.5701\n",
      "Epoch [6/400], Step [80/439], Loss: 1.6723\n",
      "Epoch [6/400], Step [100/439], Loss: 1.3204\n",
      "Epoch [6/400], Step [120/439], Loss: 1.6926\n",
      "Epoch [6/400], Step [140/439], Loss: 1.2869\n",
      "Epoch [6/400], Step [160/439], Loss: 1.7380\n",
      "Epoch [6/400], Step [180/439], Loss: 1.2080\n",
      "Epoch [6/400], Step [200/439], Loss: 1.5723\n",
      "Epoch [6/400], Step [220/439], Loss: 1.4639\n",
      "Epoch [6/400], Step [240/439], Loss: 1.4735\n",
      "Epoch [6/400], Step [260/439], Loss: 1.1239\n",
      "Epoch [6/400], Step [280/439], Loss: 1.1576\n",
      "Epoch [6/400], Step [300/439], Loss: 1.5050\n",
      "Epoch [6/400], Step [320/439], Loss: 1.2529\n",
      "Epoch [6/400], Step [340/439], Loss: 1.3747\n",
      "Epoch [6/400], Step [360/439], Loss: 1.7166\n",
      "Epoch [6/400], Step [380/439], Loss: 1.5859\n",
      "Epoch [6/400], Step [400/439], Loss: 1.4055\n",
      "Epoch [6/400], Step [420/439], Loss: 1.3360\n",
      "\n",
      "train-loss: 1.5620, train-acc: 51.6752\n",
      "validation loss: 1.4970, validation acc: 50.2426\n",
      "\n",
      "Epoch 7\n",
      "\n",
      "Epoch [7/400], Step [0/439], Loss: 1.5349\n",
      "Epoch [7/400], Step [20/439], Loss: 1.5746\n",
      "Epoch [7/400], Step [40/439], Loss: 1.5297\n",
      "Epoch [7/400], Step [60/439], Loss: 1.3044\n",
      "Epoch [7/400], Step [80/439], Loss: 1.5037\n",
      "Epoch [7/400], Step [100/439], Loss: 1.7217\n",
      "Epoch [7/400], Step [120/439], Loss: 1.5648\n",
      "Epoch [7/400], Step [140/439], Loss: 1.3921\n",
      "Epoch [7/400], Step [160/439], Loss: 1.3652\n",
      "Epoch [7/400], Step [180/439], Loss: 1.2709\n",
      "Epoch [7/400], Step [200/439], Loss: 1.2443\n",
      "Epoch [7/400], Step [220/439], Loss: 1.2155\n",
      "Epoch [7/400], Step [240/439], Loss: 1.3483\n",
      "Epoch [7/400], Step [260/439], Loss: 1.2787\n",
      "Epoch [7/400], Step [280/439], Loss: 1.2736\n",
      "Epoch [7/400], Step [300/439], Loss: 1.9645\n",
      "Epoch [7/400], Step [320/439], Loss: 1.3915\n",
      "Epoch [7/400], Step [340/439], Loss: 1.3751\n",
      "Epoch [7/400], Step [360/439], Loss: 1.1591\n",
      "Epoch [7/400], Step [380/439], Loss: 1.6815\n",
      "Epoch [7/400], Step [400/439], Loss: 1.5788\n",
      "Epoch [7/400], Step [420/439], Loss: 1.4514\n",
      "\n",
      "train-loss: 1.5600, train-acc: 50.5560\n",
      "validation loss: 1.4940, validation acc: 54.9184\n",
      "\n",
      "Epoch 8\n",
      "\n",
      "Epoch [8/400], Step [0/439], Loss: 1.6149\n",
      "Epoch [8/400], Step [20/439], Loss: 1.4587\n",
      "Epoch [8/400], Step [40/439], Loss: 1.3744\n",
      "Epoch [8/400], Step [60/439], Loss: 1.0987\n",
      "Epoch [8/400], Step [80/439], Loss: 1.3265\n",
      "Epoch [8/400], Step [100/439], Loss: 1.3752\n",
      "Epoch [8/400], Step [120/439], Loss: 1.2076\n",
      "Epoch [8/400], Step [140/439], Loss: 1.7580\n",
      "Epoch [8/400], Step [160/439], Loss: 1.8820\n",
      "Epoch [8/400], Step [180/439], Loss: 1.1260\n",
      "Epoch [8/400], Step [200/439], Loss: 1.3465\n",
      "Epoch [8/400], Step [220/439], Loss: 1.5761\n",
      "Epoch [8/400], Step [240/439], Loss: 0.9008\n",
      "Epoch [8/400], Step [260/439], Loss: 1.5009\n",
      "Epoch [8/400], Step [280/439], Loss: 1.3181\n",
      "Epoch [8/400], Step [300/439], Loss: 1.6584\n",
      "Epoch [8/400], Step [320/439], Loss: 1.5031\n",
      "Epoch [8/400], Step [340/439], Loss: 1.6583\n",
      "Epoch [8/400], Step [360/439], Loss: 1.3165\n",
      "Epoch [8/400], Step [380/439], Loss: 1.1559\n",
      "Epoch [8/400], Step [400/439], Loss: 1.3309\n",
      "Epoch [8/400], Step [420/439], Loss: 1.5633\n",
      "\n",
      "train-loss: 1.5580, train-acc: 50.8911\n",
      "validation loss: 1.4933, validation acc: 51.5659\n",
      "\n",
      "Epoch 9\n",
      "\n",
      "Epoch [9/400], Step [0/439], Loss: 1.5232\n",
      "Epoch [9/400], Step [20/439], Loss: 1.3526\n",
      "Epoch [9/400], Step [40/439], Loss: 1.2695\n",
      "Epoch [9/400], Step [60/439], Loss: 1.3006\n",
      "Epoch [9/400], Step [80/439], Loss: 1.3933\n",
      "Epoch [9/400], Step [100/439], Loss: 1.5966\n",
      "Epoch [9/400], Step [120/439], Loss: 1.1237\n",
      "Epoch [9/400], Step [140/439], Loss: 1.5217\n",
      "Epoch [9/400], Step [160/439], Loss: 1.4897\n",
      "Epoch [9/400], Step [180/439], Loss: 1.5867\n",
      "Epoch [9/400], Step [200/439], Loss: 1.4624\n",
      "Epoch [9/400], Step [220/439], Loss: 1.5745\n",
      "Epoch [9/400], Step [240/439], Loss: 1.9447\n",
      "Epoch [9/400], Step [260/439], Loss: 1.3754\n",
      "Epoch [9/400], Step [280/439], Loss: 1.5013\n",
      "Epoch [9/400], Step [300/439], Loss: 1.1339\n",
      "Epoch [9/400], Step [320/439], Loss: 1.2587\n",
      "Epoch [9/400], Step [340/439], Loss: 1.3325\n",
      "Epoch [9/400], Step [360/439], Loss: 1.0637\n",
      "Epoch [9/400], Step [380/439], Loss: 1.5394\n",
      "Epoch [9/400], Step [400/439], Loss: 1.2842\n",
      "Epoch [9/400], Step [420/439], Loss: 1.5582\n",
      "\n",
      "train-loss: 1.5558, train-acc: 51.6895\n",
      "validation loss: 1.4905, validation acc: 55.3595\n",
      "\n",
      "Epoch 10\n",
      "\n",
      "Epoch [10/400], Step [0/439], Loss: 1.3538\n",
      "Epoch [10/400], Step [20/439], Loss: 1.2784\n",
      "Epoch [10/400], Step [40/439], Loss: 1.2779\n",
      "Epoch [10/400], Step [60/439], Loss: 1.6206\n",
      "Epoch [10/400], Step [80/439], Loss: 1.2877\n",
      "Epoch [10/400], Step [100/439], Loss: 2.0144\n",
      "Epoch [10/400], Step [120/439], Loss: 1.2272\n",
      "Epoch [10/400], Step [140/439], Loss: 1.2047\n",
      "Epoch [10/400], Step [160/439], Loss: 1.4341\n",
      "Epoch [10/400], Step [180/439], Loss: 1.1135\n",
      "Epoch [10/400], Step [200/439], Loss: 1.1567\n",
      "Epoch [10/400], Step [220/439], Loss: 1.5543\n",
      "Epoch [10/400], Step [240/439], Loss: 1.2383\n",
      "Epoch [10/400], Step [260/439], Loss: 1.2648\n",
      "Epoch [10/400], Step [280/439], Loss: 1.6647\n",
      "Epoch [10/400], Step [300/439], Loss: 1.4321\n",
      "Epoch [10/400], Step [320/439], Loss: 1.2816\n",
      "Epoch [10/400], Step [340/439], Loss: 1.5308\n",
      "Epoch [10/400], Step [360/439], Loss: 0.9330\n",
      "Epoch [10/400], Step [380/439], Loss: 1.5150\n",
      "Epoch [10/400], Step [400/439], Loss: 1.5708\n",
      "Epoch [10/400], Step [420/439], Loss: 1.5264\n",
      "\n",
      "train-loss: 1.5535, train-acc: 51.8748\n",
      "validation loss: 1.4884, validation acc: 53.9038\n",
      "\n",
      "Epoch 11\n",
      "\n",
      "Epoch [11/400], Step [0/439], Loss: 1.7141\n",
      "Epoch [11/400], Step [20/439], Loss: 1.8408\n",
      "Epoch [11/400], Step [40/439], Loss: 1.2981\n",
      "Epoch [11/400], Step [60/439], Loss: 1.6605\n",
      "Epoch [11/400], Step [80/439], Loss: 1.3892\n",
      "Epoch [11/400], Step [100/439], Loss: 1.1127\n",
      "Epoch [11/400], Step [120/439], Loss: 1.2735\n",
      "Epoch [11/400], Step [140/439], Loss: 1.2940\n",
      "Epoch [11/400], Step [160/439], Loss: 1.4827\n",
      "Epoch [11/400], Step [180/439], Loss: 1.3295\n",
      "Epoch [11/400], Step [200/439], Loss: 1.4752\n",
      "Epoch [11/400], Step [220/439], Loss: 1.2713\n",
      "Epoch [11/400], Step [240/439], Loss: 1.5589\n",
      "Epoch [11/400], Step [260/439], Loss: 1.2143\n",
      "Epoch [11/400], Step [280/439], Loss: 1.4691\n",
      "Epoch [11/400], Step [300/439], Loss: 1.6972\n",
      "Epoch [11/400], Step [320/439], Loss: 1.6239\n",
      "Epoch [11/400], Step [340/439], Loss: 1.4112\n",
      "Epoch [11/400], Step [360/439], Loss: 1.7617\n",
      "Epoch [11/400], Step [380/439], Loss: 1.3792\n",
      "Epoch [11/400], Step [400/439], Loss: 1.8454\n",
      "Epoch [11/400], Step [420/439], Loss: 1.5557\n",
      "\n",
      "train-loss: 1.5514, train-acc: 51.7109\n",
      "validation loss: 1.4857, validation acc: 55.8006\n",
      "\n",
      "Epoch 12\n",
      "\n",
      "Epoch [12/400], Step [0/439], Loss: 1.4840\n",
      "Epoch [12/400], Step [20/439], Loss: 1.2775\n",
      "Epoch [12/400], Step [40/439], Loss: 1.5295\n",
      "Epoch [12/400], Step [60/439], Loss: 1.4567\n",
      "Epoch [12/400], Step [80/439], Loss: 1.6708\n",
      "Epoch [12/400], Step [100/439], Loss: 1.2443\n",
      "Epoch [12/400], Step [120/439], Loss: 1.4962\n",
      "Epoch [12/400], Step [140/439], Loss: 1.5160\n",
      "Epoch [12/400], Step [160/439], Loss: 1.0783\n",
      "Epoch [12/400], Step [180/439], Loss: 1.0707\n",
      "Epoch [12/400], Step [200/439], Loss: 1.7156\n",
      "Epoch [12/400], Step [220/439], Loss: 1.5782\n",
      "Epoch [12/400], Step [240/439], Loss: 1.1492\n",
      "Epoch [12/400], Step [260/439], Loss: 1.4951\n",
      "Epoch [12/400], Step [280/439], Loss: 1.3476\n",
      "Epoch [12/400], Step [300/439], Loss: 1.6190\n",
      "Epoch [12/400], Step [320/439], Loss: 1.2870\n",
      "Epoch [12/400], Step [340/439], Loss: 1.6503\n",
      "Epoch [12/400], Step [360/439], Loss: 1.0942\n",
      "Epoch [12/400], Step [380/439], Loss: 1.3848\n",
      "Epoch [12/400], Step [400/439], Loss: 1.5593\n",
      "Epoch [12/400], Step [420/439], Loss: 1.6356\n",
      "\n",
      "train-loss: 1.5494, train-acc: 51.3402\n",
      "validation loss: 1.4832, validation acc: 55.7786\n",
      "\n",
      "Epoch 13\n",
      "\n",
      "Epoch [13/400], Step [0/439], Loss: 1.3368\n",
      "Epoch [13/400], Step [20/439], Loss: 1.2783\n",
      "Epoch [13/400], Step [40/439], Loss: 1.2999\n",
      "Epoch [13/400], Step [60/439], Loss: 1.0236\n",
      "Epoch [13/400], Step [80/439], Loss: 1.4658\n",
      "Epoch [13/400], Step [100/439], Loss: 1.0905\n",
      "Epoch [13/400], Step [120/439], Loss: 1.0211\n",
      "Epoch [13/400], Step [140/439], Loss: 1.6056\n",
      "Epoch [13/400], Step [160/439], Loss: 1.3789\n",
      "Epoch [13/400], Step [180/439], Loss: 1.3194\n",
      "Epoch [13/400], Step [200/439], Loss: 1.3169\n",
      "Epoch [13/400], Step [220/439], Loss: 1.2872\n",
      "Epoch [13/400], Step [240/439], Loss: 1.4095\n",
      "Epoch [13/400], Step [260/439], Loss: 1.6738\n",
      "Epoch [13/400], Step [280/439], Loss: 1.4612\n",
      "Epoch [13/400], Step [300/439], Loss: 1.7235\n",
      "Epoch [13/400], Step [320/439], Loss: 1.0710\n",
      "Epoch [13/400], Step [340/439], Loss: 1.4960\n",
      "Epoch [13/400], Step [360/439], Loss: 1.5742\n",
      "Epoch [13/400], Step [380/439], Loss: 1.3629\n",
      "Epoch [13/400], Step [400/439], Loss: 1.4002\n",
      "Epoch [13/400], Step [420/439], Loss: 1.5350\n",
      "\n",
      "train-loss: 1.5472, train-acc: 52.0958\n",
      "validation loss: 1.4809, validation acc: 54.5214\n",
      "\n",
      "Epoch 14\n",
      "\n",
      "Epoch [14/400], Step [0/439], Loss: 1.8393\n",
      "Epoch [14/400], Step [20/439], Loss: 1.5959\n",
      "Epoch [14/400], Step [40/439], Loss: 1.6030\n",
      "Epoch [14/400], Step [60/439], Loss: 1.5595\n",
      "Epoch [14/400], Step [80/439], Loss: 1.4862\n",
      "Epoch [14/400], Step [100/439], Loss: 1.1525\n",
      "Epoch [14/400], Step [120/439], Loss: 1.2793\n",
      "Epoch [14/400], Step [140/439], Loss: 1.2791\n",
      "Epoch [14/400], Step [160/439], Loss: 1.6546\n",
      "Epoch [14/400], Step [180/439], Loss: 1.5538\n",
      "Epoch [14/400], Step [200/439], Loss: 1.2209\n",
      "Epoch [14/400], Step [220/439], Loss: 1.4379\n",
      "Epoch [14/400], Step [240/439], Loss: 1.2324\n",
      "Epoch [14/400], Step [260/439], Loss: 1.5330\n",
      "Epoch [14/400], Step [280/439], Loss: 1.6910\n",
      "Epoch [14/400], Step [300/439], Loss: 1.3014\n",
      "Epoch [14/400], Step [320/439], Loss: 1.3310\n",
      "Epoch [14/400], Step [340/439], Loss: 1.6883\n",
      "Epoch [14/400], Step [360/439], Loss: 1.5324\n",
      "Epoch [14/400], Step [380/439], Loss: 1.2528\n",
      "Epoch [14/400], Step [400/439], Loss: 1.6993\n",
      "Epoch [14/400], Step [420/439], Loss: 1.7110\n",
      "\n",
      "train-loss: 1.5454, train-acc: 51.6467\n",
      "validation loss: 1.4785, validation acc: 54.9184\n",
      "\n",
      "Epoch 15\n",
      "\n",
      "Epoch [15/400], Step [0/439], Loss: 1.5611\n",
      "Epoch [15/400], Step [20/439], Loss: 1.4993\n",
      "Epoch [15/400], Step [40/439], Loss: 1.4224\n",
      "Epoch [15/400], Step [60/439], Loss: 1.5169\n",
      "Epoch [15/400], Step [80/439], Loss: 1.4527\n",
      "Epoch [15/400], Step [100/439], Loss: 1.1489\n",
      "Epoch [15/400], Step [120/439], Loss: 1.2418\n",
      "Epoch [15/400], Step [140/439], Loss: 1.4513\n",
      "Epoch [15/400], Step [160/439], Loss: 1.5087\n",
      "Epoch [15/400], Step [180/439], Loss: 1.7078\n",
      "Epoch [15/400], Step [200/439], Loss: 1.5077\n",
      "Epoch [15/400], Step [220/439], Loss: 1.3366\n",
      "Epoch [15/400], Step [240/439], Loss: 1.3961\n",
      "Epoch [15/400], Step [260/439], Loss: 1.4089\n",
      "Epoch [15/400], Step [280/439], Loss: 1.4789\n",
      "Epoch [15/400], Step [300/439], Loss: 1.4987\n",
      "Epoch [15/400], Step [320/439], Loss: 1.2568\n",
      "Epoch [15/400], Step [340/439], Loss: 1.3954\n",
      "Epoch [15/400], Step [360/439], Loss: 1.3863\n",
      "Epoch [15/400], Step [380/439], Loss: 1.0704\n",
      "Epoch [15/400], Step [400/439], Loss: 1.9421\n",
      "Epoch [15/400], Step [420/439], Loss: 1.7316\n",
      "\n",
      "train-loss: 1.5433, train-acc: 52.4380\n",
      "validation loss: 1.4760, validation acc: 55.8006\n",
      "\n",
      "Improvement-Detected, save-model\n",
      "Epoch 16\n",
      "\n",
      "Epoch [16/400], Step [0/439], Loss: 1.3680\n",
      "Epoch [16/400], Step [20/439], Loss: 1.5157\n",
      "Epoch [16/400], Step [40/439], Loss: 1.1430\n",
      "Epoch [16/400], Step [60/439], Loss: 1.7602\n",
      "Epoch [16/400], Step [80/439], Loss: 1.4169\n",
      "Epoch [16/400], Step [100/439], Loss: 1.4009\n",
      "Epoch [16/400], Step [120/439], Loss: 1.4022\n",
      "Epoch [16/400], Step [140/439], Loss: 1.4231\n",
      "Epoch [16/400], Step [160/439], Loss: 2.0686\n",
      "Epoch [16/400], Step [180/439], Loss: 1.5432\n",
      "Epoch [16/400], Step [200/439], Loss: 1.4600\n",
      "Epoch [16/400], Step [220/439], Loss: 1.5534\n",
      "Epoch [16/400], Step [240/439], Loss: 1.7317\n",
      "Epoch [16/400], Step [260/439], Loss: 1.6086\n",
      "Epoch [16/400], Step [280/439], Loss: 1.3521\n",
      "Epoch [16/400], Step [300/439], Loss: 1.5767\n",
      "Epoch [16/400], Step [320/439], Loss: 1.5404\n",
      "Epoch [16/400], Step [340/439], Loss: 1.1831\n",
      "Epoch [16/400], Step [360/439], Loss: 1.3520\n",
      "Epoch [16/400], Step [380/439], Loss: 1.6230\n",
      "Epoch [16/400], Step [400/439], Loss: 1.4248\n",
      "Epoch [16/400], Step [420/439], Loss: 1.3321\n",
      "\n",
      "train-loss: 1.5417, train-acc: 51.0194\n",
      "validation loss: 1.4728, validation acc: 57.6974\n",
      "\n",
      "Improvement-Detected, save-model\n",
      "Epoch 17\n",
      "\n",
      "Epoch [17/400], Step [0/439], Loss: 1.3643\n",
      "Epoch [17/400], Step [20/439], Loss: 1.3688\n",
      "Epoch [17/400], Step [40/439], Loss: 1.1404\n",
      "Epoch [17/400], Step [60/439], Loss: 1.2364\n",
      "Epoch [17/400], Step [80/439], Loss: 1.2989\n",
      "Epoch [17/400], Step [100/439], Loss: 1.3595\n",
      "Epoch [17/400], Step [120/439], Loss: 1.4512\n",
      "Epoch [17/400], Step [140/439], Loss: 1.8548\n",
      "Epoch [17/400], Step [160/439], Loss: 1.5262\n",
      "Epoch [17/400], Step [180/439], Loss: 1.3831\n",
      "Epoch [17/400], Step [200/439], Loss: 1.3586\n",
      "Epoch [17/400], Step [220/439], Loss: 1.4456\n",
      "Epoch [17/400], Step [240/439], Loss: 1.5545\n",
      "Epoch [17/400], Step [260/439], Loss: 1.9315\n",
      "Epoch [17/400], Step [280/439], Loss: 1.4487\n",
      "Epoch [17/400], Step [300/439], Loss: 1.4480\n",
      "Epoch [17/400], Step [320/439], Loss: 1.4417\n",
      "Epoch [17/400], Step [340/439], Loss: 1.2043\n",
      "Epoch [17/400], Step [360/439], Loss: 1.3413\n",
      "Epoch [17/400], Step [380/439], Loss: 1.4871\n",
      "Epoch [17/400], Step [400/439], Loss: 1.3132\n",
      "Epoch [17/400], Step [420/439], Loss: 1.2610\n",
      "\n",
      "train-loss: 1.5396, train-acc: 52.2954\n",
      "validation loss: 1.4712, validation acc: 53.0657\n",
      "\n",
      "Epoch 18\n",
      "\n",
      "Epoch [18/400], Step [0/439], Loss: 0.9510\n",
      "Epoch [18/400], Step [20/439], Loss: 1.6716\n",
      "Epoch [18/400], Step [40/439], Loss: 1.4099\n",
      "Epoch [18/400], Step [60/439], Loss: 1.4804\n",
      "Epoch [18/400], Step [80/439], Loss: 1.6364\n",
      "Epoch [18/400], Step [100/439], Loss: 1.4723\n",
      "Epoch [18/400], Step [120/439], Loss: 1.4407\n",
      "Epoch [18/400], Step [140/439], Loss: 1.4218\n",
      "Epoch [18/400], Step [160/439], Loss: 1.1101\n",
      "Epoch [18/400], Step [180/439], Loss: 1.1870\n",
      "Epoch [18/400], Step [200/439], Loss: 1.2300\n",
      "Epoch [18/400], Step [220/439], Loss: 1.4738\n",
      "Epoch [18/400], Step [240/439], Loss: 1.5768\n",
      "Epoch [18/400], Step [260/439], Loss: 1.4923\n",
      "Epoch [18/400], Step [280/439], Loss: 1.9461\n",
      "Epoch [18/400], Step [300/439], Loss: 1.6042\n",
      "Epoch [18/400], Step [320/439], Loss: 1.5393\n",
      "Epoch [18/400], Step [340/439], Loss: 1.3339\n",
      "Epoch [18/400], Step [360/439], Loss: 1.4536\n",
      "Epoch [18/400], Step [380/439], Loss: 1.2833\n",
      "Epoch [18/400], Step [400/439], Loss: 1.2140\n",
      "Epoch [18/400], Step [420/439], Loss: 1.1399\n",
      "\n",
      "train-loss: 1.5377, train-acc: 52.2669\n",
      "validation loss: 1.4685, validation acc: 56.3961\n",
      "\n",
      "Epoch 19\n",
      "\n",
      "Epoch [19/400], Step [0/439], Loss: 1.7833\n",
      "Epoch [19/400], Step [20/439], Loss: 1.4188\n",
      "Epoch [19/400], Step [40/439], Loss: 1.3444\n",
      "Epoch [19/400], Step [60/439], Loss: 1.6923\n",
      "Epoch [19/400], Step [80/439], Loss: 1.2455\n",
      "Epoch [19/400], Step [100/439], Loss: 1.4796\n",
      "Epoch [19/400], Step [120/439], Loss: 1.6408\n",
      "Epoch [19/400], Step [140/439], Loss: 1.4985\n",
      "Epoch [19/400], Step [160/439], Loss: 1.6053\n",
      "Epoch [19/400], Step [180/439], Loss: 1.2483\n",
      "Epoch [19/400], Step [200/439], Loss: 1.0631\n",
      "Epoch [19/400], Step [220/439], Loss: 1.3308\n",
      "Epoch [19/400], Step [240/439], Loss: 1.2878\n",
      "Epoch [19/400], Step [260/439], Loss: 1.5911\n",
      "Epoch [19/400], Step [280/439], Loss: 1.4381\n",
      "Epoch [19/400], Step [300/439], Loss: 1.7539\n",
      "Epoch [19/400], Step [320/439], Loss: 1.5168\n",
      "Epoch [19/400], Step [340/439], Loss: 1.4657\n",
      "Epoch [19/400], Step [360/439], Loss: 1.2378\n",
      "Epoch [19/400], Step [380/439], Loss: 1.6844\n",
      "Epoch [19/400], Step [400/439], Loss: 1.4485\n",
      "Epoch [19/400], Step [420/439], Loss: 1.5373\n",
      "\n",
      "train-loss: 1.5356, train-acc: 52.7516\n",
      "validation loss: 1.4663, validation acc: 54.8963\n",
      "\n",
      "Epoch 20\n",
      "\n",
      "Epoch [20/400], Step [0/439], Loss: 1.7021\n",
      "Epoch [20/400], Step [20/439], Loss: 1.5870\n",
      "Epoch [20/400], Step [40/439], Loss: 1.2043\n",
      "Epoch [20/400], Step [60/439], Loss: 1.6745\n",
      "Epoch [20/400], Step [80/439], Loss: 1.5213\n",
      "Epoch [20/400], Step [100/439], Loss: 1.5357\n",
      "Epoch [20/400], Step [120/439], Loss: 0.9338\n",
      "Epoch [20/400], Step [140/439], Loss: 1.2162\n",
      "Epoch [20/400], Step [160/439], Loss: 1.4335\n",
      "Epoch [20/400], Step [180/439], Loss: 1.2123\n",
      "Epoch [20/400], Step [200/439], Loss: 1.2305\n",
      "Epoch [20/400], Step [220/439], Loss: 1.3841\n",
      "Epoch [20/400], Step [240/439], Loss: 1.6145\n",
      "Epoch [20/400], Step [260/439], Loss: 1.0218\n",
      "Epoch [20/400], Step [280/439], Loss: 1.4925\n",
      "Epoch [20/400], Step [300/439], Loss: 1.3603\n",
      "Epoch [20/400], Step [320/439], Loss: 1.2063\n",
      "Epoch [20/400], Step [340/439], Loss: 1.5556\n",
      "Epoch [20/400], Step [360/439], Loss: 1.3911\n",
      "Epoch [20/400], Step [380/439], Loss: 1.3823\n",
      "Epoch [20/400], Step [400/439], Loss: 1.4446\n",
      "Epoch [20/400], Step [420/439], Loss: 1.0300\n",
      "\n",
      "train-loss: 1.5337, train-acc: 52.3524\n",
      "validation loss: 1.4636, validation acc: 56.4843\n",
      "\n",
      "Epoch 21\n",
      "\n",
      "Epoch [21/400], Step [0/439], Loss: 1.2850\n",
      "Epoch [21/400], Step [20/439], Loss: 1.2371\n",
      "Epoch [21/400], Step [40/439], Loss: 1.2252\n",
      "Epoch [21/400], Step [60/439], Loss: 1.4205\n",
      "Epoch [21/400], Step [80/439], Loss: 1.2240\n",
      "Epoch [21/400], Step [100/439], Loss: 1.2280\n",
      "Epoch [21/400], Step [120/439], Loss: 1.8449\n",
      "Epoch [21/400], Step [140/439], Loss: 1.5155\n",
      "Epoch [21/400], Step [160/439], Loss: 1.3143\n",
      "Epoch [21/400], Step [180/439], Loss: 1.1874\n",
      "Epoch [21/400], Step [200/439], Loss: 1.3437\n",
      "Epoch [21/400], Step [220/439], Loss: 1.2720\n",
      "Epoch [21/400], Step [240/439], Loss: 1.5934\n",
      "Epoch [21/400], Step [260/439], Loss: 1.6913\n",
      "Epoch [21/400], Step [280/439], Loss: 1.3401\n",
      "Epoch [21/400], Step [300/439], Loss: 1.3096\n",
      "Epoch [21/400], Step [320/439], Loss: 1.1857\n",
      "Epoch [21/400], Step [340/439], Loss: 1.3776\n",
      "Epoch [21/400], Step [360/439], Loss: 1.1462\n",
      "Epoch [21/400], Step [380/439], Loss: 1.2662\n",
      "Epoch [21/400], Step [400/439], Loss: 1.4796\n",
      "Epoch [21/400], Step [420/439], Loss: 1.5203\n",
      "\n",
      "train-loss: 1.5318, train-acc: 52.5307\n",
      "validation loss: 1.4608, validation acc: 57.1460\n",
      "\n",
      "Improvement-Detected, save-model\n",
      "Epoch 22\n",
      "\n",
      "Epoch [22/400], Step [0/439], Loss: 1.1861\n",
      "Epoch [22/400], Step [20/439], Loss: 0.9107\n",
      "Epoch [22/400], Step [40/439], Loss: 1.2569\n",
      "Epoch [22/400], Step [60/439], Loss: 1.4673\n",
      "Epoch [22/400], Step [80/439], Loss: 1.1390\n",
      "Epoch [22/400], Step [100/439], Loss: 1.4417\n",
      "Epoch [22/400], Step [120/439], Loss: 0.9227\n",
      "Epoch [22/400], Step [140/439], Loss: 1.2241\n",
      "Epoch [22/400], Step [160/439], Loss: 1.4630\n",
      "Epoch [22/400], Step [180/439], Loss: 1.3106\n",
      "Epoch [22/400], Step [200/439], Loss: 1.3773\n",
      "Epoch [22/400], Step [220/439], Loss: 1.4494\n",
      "Epoch [22/400], Step [240/439], Loss: 1.5753\n",
      "Epoch [22/400], Step [260/439], Loss: 1.1713\n",
      "Epoch [22/400], Step [280/439], Loss: 1.2370\n",
      "Epoch [22/400], Step [300/439], Loss: 1.5415\n",
      "Epoch [22/400], Step [320/439], Loss: 1.3943\n",
      "Epoch [22/400], Step [340/439], Loss: 1.1168\n",
      "Epoch [22/400], Step [360/439], Loss: 2.0922\n",
      "Epoch [22/400], Step [380/439], Loss: 1.2389\n",
      "Epoch [22/400], Step [400/439], Loss: 1.4177\n",
      "Epoch [22/400], Step [420/439], Loss: 1.1930\n",
      "\n",
      "train-loss: 1.5298, train-acc: 52.9441\n",
      "validation loss: 1.4614, validation acc: 50.5955\n",
      "\n",
      "Epoch 23\n",
      "\n",
      "Epoch [23/400], Step [0/439], Loss: 1.1063\n",
      "Epoch [23/400], Step [20/439], Loss: 1.5611\n",
      "Epoch [23/400], Step [40/439], Loss: 1.3904\n",
      "Epoch [23/400], Step [60/439], Loss: 1.6850\n",
      "Epoch [23/400], Step [80/439], Loss: 1.5508\n",
      "Epoch [23/400], Step [100/439], Loss: 1.2850\n",
      "Epoch [23/400], Step [120/439], Loss: 1.5012\n",
      "Epoch [23/400], Step [140/439], Loss: 1.8021\n",
      "Epoch [23/400], Step [160/439], Loss: 1.3656\n",
      "Epoch [23/400], Step [180/439], Loss: 1.2709\n",
      "Epoch [23/400], Step [200/439], Loss: 1.2989\n",
      "Epoch [23/400], Step [220/439], Loss: 1.5297\n",
      "Epoch [23/400], Step [240/439], Loss: 1.5020\n",
      "Epoch [23/400], Step [260/439], Loss: 1.1730\n",
      "Epoch [23/400], Step [280/439], Loss: 1.3708\n",
      "Epoch [23/400], Step [300/439], Loss: 1.5160\n",
      "Epoch [23/400], Step [320/439], Loss: 1.2928\n",
      "Epoch [23/400], Step [340/439], Loss: 1.7770\n",
      "Epoch [23/400], Step [360/439], Loss: 1.5471\n",
      "Epoch [23/400], Step [380/439], Loss: 1.5474\n",
      "Epoch [23/400], Step [400/439], Loss: 1.4442\n",
      "Epoch [23/400], Step [420/439], Loss: 1.3507\n",
      "\n",
      "train-loss: 1.5280, train-acc: 52.9299\n",
      "validation loss: 1.4592, validation acc: 55.5139\n",
      "\n",
      "Epoch 24\n",
      "\n",
      "Epoch [24/400], Step [0/439], Loss: 1.3020\n",
      "Epoch [24/400], Step [20/439], Loss: 1.5559\n",
      "Epoch [24/400], Step [40/439], Loss: 1.4630\n",
      "Epoch [24/400], Step [60/439], Loss: 1.5834\n",
      "Epoch [24/400], Step [80/439], Loss: 1.2103\n",
      "Epoch [24/400], Step [100/439], Loss: 1.5048\n",
      "Epoch [24/400], Step [120/439], Loss: 1.4389\n",
      "Epoch [24/400], Step [140/439], Loss: 1.5040\n",
      "Epoch [24/400], Step [160/439], Loss: 1.5081\n",
      "Epoch [24/400], Step [180/439], Loss: 1.4479\n",
      "Epoch [24/400], Step [200/439], Loss: 1.3880\n",
      "Epoch [24/400], Step [220/439], Loss: 1.5269\n",
      "Epoch [24/400], Step [240/439], Loss: 1.2637\n",
      "Epoch [24/400], Step [260/439], Loss: 1.5010\n",
      "Epoch [24/400], Step [280/439], Loss: 1.3931\n",
      "Epoch [24/400], Step [300/439], Loss: 1.2157\n",
      "Epoch [24/400], Step [320/439], Loss: 1.2153\n",
      "Epoch [24/400], Step [340/439], Loss: 1.0608\n",
      "Epoch [24/400], Step [360/439], Loss: 1.3159\n",
      "Epoch [24/400], Step [380/439], Loss: 1.5580\n",
      "Epoch [24/400], Step [400/439], Loss: 1.2704\n",
      "Epoch [24/400], Step [420/439], Loss: 1.4647\n",
      "\n",
      "train-loss: 1.5259, train-acc: 53.7354\n",
      "validation loss: 1.4568, validation acc: 57.0357\n",
      "\n",
      "Epoch 25\n",
      "\n",
      "Epoch [25/400], Step [0/439], Loss: 1.3143\n",
      "Epoch [25/400], Step [20/439], Loss: 1.3185\n",
      "Epoch [25/400], Step [40/439], Loss: 1.6104\n",
      "Epoch [25/400], Step [60/439], Loss: 1.3409\n",
      "Epoch [25/400], Step [80/439], Loss: 1.3833\n",
      "Epoch [25/400], Step [100/439], Loss: 1.6592\n",
      "Epoch [25/400], Step [120/439], Loss: 1.4464\n",
      "Epoch [25/400], Step [140/439], Loss: 1.4949\n",
      "Epoch [25/400], Step [160/439], Loss: 1.2723\n",
      "Epoch [25/400], Step [180/439], Loss: 0.9667\n",
      "Epoch [25/400], Step [200/439], Loss: 1.2782\n",
      "Epoch [25/400], Step [220/439], Loss: 1.5700\n",
      "Epoch [25/400], Step [240/439], Loss: 1.2586\n",
      "Epoch [25/400], Step [260/439], Loss: 1.1641\n",
      "Epoch [25/400], Step [280/439], Loss: 1.8131\n",
      "Epoch [25/400], Step [300/439], Loss: 1.2678\n",
      "Epoch [25/400], Step [320/439], Loss: 1.2796\n",
      "Epoch [25/400], Step [340/439], Loss: 1.2647\n",
      "Epoch [25/400], Step [360/439], Loss: 1.5101\n",
      "Epoch [25/400], Step [380/439], Loss: 1.1260\n",
      "Epoch [25/400], Step [400/439], Loss: 1.0086\n",
      "Epoch [25/400], Step [420/439], Loss: 1.1624\n",
      "\n",
      "train-loss: 1.5239, train-acc: 53.5287\n",
      "validation loss: 1.4542, validation acc: 57.5430\n",
      "\n",
      "Improvement-Detected, save-model\n",
      "Epoch 26\n",
      "\n",
      "Epoch [26/400], Step [0/439], Loss: 1.5669\n",
      "Epoch [26/400], Step [20/439], Loss: 1.1419\n",
      "Epoch [26/400], Step [40/439], Loss: 1.5014\n",
      "Epoch [26/400], Step [60/439], Loss: 2.3163\n",
      "Epoch [26/400], Step [80/439], Loss: 1.4589\n",
      "Epoch [26/400], Step [100/439], Loss: 1.4233\n",
      "Epoch [26/400], Step [120/439], Loss: 1.3596\n",
      "Epoch [26/400], Step [140/439], Loss: 1.6763\n",
      "Epoch [26/400], Step [160/439], Loss: 1.5398\n",
      "Epoch [26/400], Step [180/439], Loss: 1.7007\n",
      "Epoch [26/400], Step [200/439], Loss: 1.5753\n",
      "Epoch [26/400], Step [220/439], Loss: 1.5321\n",
      "Epoch [26/400], Step [240/439], Loss: 1.1350\n",
      "Epoch [26/400], Step [260/439], Loss: 1.1883\n",
      "Epoch [26/400], Step [280/439], Loss: 1.5726\n",
      "Epoch [26/400], Step [300/439], Loss: 1.8300\n",
      "Epoch [26/400], Step [320/439], Loss: 0.8788\n",
      "Epoch [26/400], Step [340/439], Loss: 1.4497\n",
      "Epoch [26/400], Step [360/439], Loss: 1.5185\n",
      "Epoch [26/400], Step [380/439], Loss: 1.2472\n",
      "Epoch [26/400], Step [400/439], Loss: 1.6780\n",
      "Epoch [26/400], Step [420/439], Loss: 1.3929\n",
      "\n",
      "train-loss: 1.5219, train-acc: 53.5500\n",
      "validation loss: 1.4516, validation acc: 57.4327\n",
      "\n",
      "Improvement-Detected, save-model\n",
      "Epoch 27\n",
      "\n",
      "Epoch [27/400], Step [0/439], Loss: 1.3872\n",
      "Epoch [27/400], Step [20/439], Loss: 1.2632\n",
      "Epoch [27/400], Step [40/439], Loss: 1.2116\n",
      "Epoch [27/400], Step [60/439], Loss: 1.2058\n",
      "Epoch [27/400], Step [80/439], Loss: 1.2945\n",
      "Epoch [27/400], Step [100/439], Loss: 1.2322\n",
      "Epoch [27/400], Step [120/439], Loss: 1.1352\n",
      "Epoch [27/400], Step [140/439], Loss: 1.5534\n",
      "Epoch [27/400], Step [160/439], Loss: 1.0985\n",
      "Epoch [27/400], Step [180/439], Loss: 1.2704\n",
      "Epoch [27/400], Step [200/439], Loss: 1.2788\n",
      "Epoch [27/400], Step [220/439], Loss: 1.1936\n",
      "Epoch [27/400], Step [240/439], Loss: 1.1079\n",
      "Epoch [27/400], Step [260/439], Loss: 1.3337\n",
      "Epoch [27/400], Step [280/439], Loss: 1.1535\n",
      "Epoch [27/400], Step [300/439], Loss: 0.9525\n",
      "Epoch [27/400], Step [320/439], Loss: 1.4596\n",
      "Epoch [27/400], Step [340/439], Loss: 1.2880\n",
      "Epoch [27/400], Step [360/439], Loss: 1.3442\n",
      "Epoch [27/400], Step [380/439], Loss: 1.3566\n",
      "Epoch [27/400], Step [400/439], Loss: 1.0896\n",
      "Epoch [27/400], Step [420/439], Loss: 1.3681\n",
      "\n",
      "train-loss: 1.5200, train-acc: 53.3718\n",
      "validation loss: 1.4493, validation acc: 56.1756\n",
      "\n",
      "Epoch 28\n",
      "\n",
      "Epoch [28/400], Step [0/439], Loss: 1.6949\n",
      "Epoch [28/400], Step [20/439], Loss: 1.4706\n",
      "Epoch [28/400], Step [40/439], Loss: 1.5356\n",
      "Epoch [28/400], Step [60/439], Loss: 1.1161\n",
      "Epoch [28/400], Step [80/439], Loss: 1.4570\n",
      "Epoch [28/400], Step [100/439], Loss: 1.5426\n",
      "Epoch [28/400], Step [120/439], Loss: 1.2780\n",
      "Epoch [28/400], Step [140/439], Loss: 1.4900\n",
      "Epoch [28/400], Step [160/439], Loss: 1.1405\n",
      "Epoch [28/400], Step [180/439], Loss: 0.9791\n",
      "Epoch [28/400], Step [200/439], Loss: 1.2090\n",
      "Epoch [28/400], Step [220/439], Loss: 1.1247\n",
      "Epoch [28/400], Step [240/439], Loss: 1.1772\n",
      "Epoch [28/400], Step [260/439], Loss: 1.2284\n",
      "Epoch [28/400], Step [280/439], Loss: 1.2873\n",
      "Epoch [28/400], Step [300/439], Loss: 1.2505\n",
      "Epoch [28/400], Step [320/439], Loss: 1.3488\n",
      "Epoch [28/400], Step [340/439], Loss: 1.4641\n",
      "Epoch [28/400], Step [360/439], Loss: 1.4013\n",
      "Epoch [28/400], Step [380/439], Loss: 1.2599\n",
      "Epoch [28/400], Step [400/439], Loss: 1.6852\n",
      "Epoch [28/400], Step [420/439], Loss: 1.5200\n",
      "\n",
      "train-loss: 1.5182, train-acc: 53.1794\n",
      "validation loss: 1.4473, validation acc: 55.8447\n",
      "\n",
      "Epoch 29\n",
      "\n",
      "Epoch [29/400], Step [0/439], Loss: 1.4963\n",
      "Epoch [29/400], Step [20/439], Loss: 1.3136\n",
      "Epoch [29/400], Step [40/439], Loss: 1.2848\n",
      "Epoch [29/400], Step [60/439], Loss: 1.5115\n",
      "Epoch [29/400], Step [80/439], Loss: 1.2697\n",
      "Epoch [29/400], Step [100/439], Loss: 1.1799\n",
      "Epoch [29/400], Step [120/439], Loss: 1.2494\n",
      "Epoch [29/400], Step [140/439], Loss: 1.2677\n",
      "Epoch [29/400], Step [160/439], Loss: 1.5615\n",
      "Epoch [29/400], Step [180/439], Loss: 1.0779\n",
      "Epoch [29/400], Step [200/439], Loss: 1.4932\n",
      "Epoch [29/400], Step [220/439], Loss: 1.2571\n",
      "Epoch [29/400], Step [240/439], Loss: 1.3704\n",
      "Epoch [29/400], Step [260/439], Loss: 1.3826\n",
      "Epoch [29/400], Step [280/439], Loss: 1.2562\n",
      "Epoch [29/400], Step [300/439], Loss: 1.3778\n",
      "Epoch [29/400], Step [320/439], Loss: 1.0541\n",
      "Epoch [29/400], Step [340/439], Loss: 1.2924\n",
      "Epoch [29/400], Step [360/439], Loss: 1.4460\n",
      "Epoch [29/400], Step [380/439], Loss: 1.2299\n",
      "Epoch [29/400], Step [400/439], Loss: 0.9856\n",
      "Epoch [29/400], Step [420/439], Loss: 1.1319\n",
      "\n",
      "train-loss: 1.5163, train-acc: 53.8922\n",
      "validation loss: 1.4457, validation acc: 55.0948\n",
      "\n",
      "Epoch 30\n",
      "\n",
      "Epoch [30/400], Step [0/439], Loss: 1.6028\n",
      "Epoch [30/400], Step [20/439], Loss: 1.4907\n",
      "Epoch [30/400], Step [40/439], Loss: 1.3134\n",
      "Epoch [30/400], Step [60/439], Loss: 1.4400\n",
      "Epoch [30/400], Step [80/439], Loss: 1.0906\n",
      "Epoch [30/400], Step [100/439], Loss: 1.3140\n",
      "Epoch [30/400], Step [120/439], Loss: 0.9081\n",
      "Epoch [30/400], Step [140/439], Loss: 1.3011\n",
      "Epoch [30/400], Step [160/439], Loss: 1.4972\n",
      "Epoch [30/400], Step [180/439], Loss: 1.5277\n",
      "Epoch [30/400], Step [200/439], Loss: 1.3993\n",
      "Epoch [30/400], Step [220/439], Loss: 1.1448\n",
      "Epoch [30/400], Step [240/439], Loss: 1.4483\n",
      "Epoch [30/400], Step [260/439], Loss: 1.3637\n",
      "Epoch [30/400], Step [280/439], Loss: 1.0721\n",
      "Epoch [30/400], Step [300/439], Loss: 1.3965\n",
      "Epoch [30/400], Step [320/439], Loss: 1.4407\n",
      "Epoch [30/400], Step [340/439], Loss: 1.6615\n",
      "Epoch [30/400], Step [360/439], Loss: 1.3880\n",
      "Epoch [30/400], Step [380/439], Loss: 1.0820\n",
      "Epoch [30/400], Step [400/439], Loss: 1.3146\n",
      "Epoch [30/400], Step [420/439], Loss: 1.2507\n",
      "\n",
      "train-loss: 1.5144, train-acc: 53.2506\n",
      "validation loss: 1.4436, validation acc: 57.7195\n",
      "\n",
      "Epoch 31\n",
      "\n",
      "Epoch [31/400], Step [0/439], Loss: 1.3996\n",
      "Epoch [31/400], Step [20/439], Loss: 1.5391\n",
      "Epoch [31/400], Step [40/439], Loss: 1.2266\n",
      "Epoch [31/400], Step [60/439], Loss: 0.9069\n",
      "Epoch [31/400], Step [80/439], Loss: 1.2363\n",
      "Epoch [31/400], Step [100/439], Loss: 1.1776\n",
      "Epoch [31/400], Step [120/439], Loss: 1.1061\n",
      "Epoch [31/400], Step [140/439], Loss: 1.3319\n",
      "Epoch [31/400], Step [160/439], Loss: 1.3593\n",
      "Epoch [31/400], Step [180/439], Loss: 1.2404\n",
      "Epoch [31/400], Step [200/439], Loss: 1.5648\n",
      "Epoch [31/400], Step [220/439], Loss: 1.0044\n",
      "Epoch [31/400], Step [240/439], Loss: 1.4321\n",
      "Epoch [31/400], Step [260/439], Loss: 1.3743\n",
      "Epoch [31/400], Step [280/439], Loss: 1.4822\n",
      "Epoch [31/400], Step [300/439], Loss: 1.2968\n",
      "Epoch [31/400], Step [320/439], Loss: 1.2715\n",
      "Epoch [31/400], Step [340/439], Loss: 1.1484\n",
      "Epoch [31/400], Step [360/439], Loss: 1.6163\n",
      "Epoch [31/400], Step [380/439], Loss: 1.3381\n",
      "Epoch [31/400], Step [400/439], Loss: 1.3446\n",
      "Epoch [31/400], Step [420/439], Loss: 1.6363\n",
      "\n",
      "train-loss: 1.5125, train-acc: 53.8851\n",
      "validation loss: 1.4416, validation acc: 56.4843\n",
      "\n",
      "Epoch 32\n",
      "\n",
      "Epoch [32/400], Step [0/439], Loss: 1.2249\n",
      "Epoch [32/400], Step [20/439], Loss: 1.4788\n",
      "Epoch [32/400], Step [40/439], Loss: 1.2120\n",
      "Epoch [32/400], Step [60/439], Loss: 1.8076\n",
      "Epoch [32/400], Step [80/439], Loss: 1.1606\n",
      "Epoch [32/400], Step [100/439], Loss: 1.6837\n",
      "Epoch [32/400], Step [120/439], Loss: 1.4034\n",
      "Epoch [32/400], Step [140/439], Loss: 1.2561\n",
      "Epoch [32/400], Step [160/439], Loss: 1.5110\n",
      "Epoch [32/400], Step [180/439], Loss: 1.2469\n",
      "Epoch [32/400], Step [200/439], Loss: 1.2302\n",
      "Epoch [32/400], Step [220/439], Loss: 1.3331\n",
      "Epoch [32/400], Step [240/439], Loss: 1.4779\n",
      "Epoch [32/400], Step [260/439], Loss: 1.1110\n",
      "Epoch [32/400], Step [280/439], Loss: 1.4056\n",
      "Epoch [32/400], Step [300/439], Loss: 1.7386\n",
      "Epoch [32/400], Step [320/439], Loss: 1.7045\n",
      "Epoch [32/400], Step [340/439], Loss: 1.2000\n",
      "Epoch [32/400], Step [360/439], Loss: 1.0189\n",
      "Epoch [32/400], Step [380/439], Loss: 1.3716\n",
      "Epoch [32/400], Step [400/439], Loss: 1.1191\n",
      "Epoch [32/400], Step [420/439], Loss: 1.4123\n",
      "\n",
      "train-loss: 1.5106, train-acc: 53.8423\n",
      "validation loss: 1.4418, validation acc: 50.5955\n",
      "\n",
      "Epoch 33\n",
      "\n",
      "Epoch [33/400], Step [0/439], Loss: 1.3133\n",
      "Epoch [33/400], Step [20/439], Loss: 1.5870\n",
      "Epoch [33/400], Step [40/439], Loss: 1.1109\n",
      "Epoch [33/400], Step [60/439], Loss: 1.5848\n",
      "Epoch [33/400], Step [80/439], Loss: 1.0787\n",
      "Epoch [33/400], Step [100/439], Loss: 1.7064\n",
      "Epoch [33/400], Step [120/439], Loss: 2.1008\n",
      "Epoch [33/400], Step [140/439], Loss: 1.2218\n",
      "Epoch [33/400], Step [160/439], Loss: 1.4612\n",
      "Epoch [33/400], Step [180/439], Loss: 1.5749\n",
      "Epoch [33/400], Step [200/439], Loss: 1.0921\n",
      "Epoch [33/400], Step [220/439], Loss: 1.4791\n",
      "Epoch [33/400], Step [240/439], Loss: 2.0431\n",
      "Epoch [33/400], Step [260/439], Loss: 1.4796\n",
      "Epoch [33/400], Step [280/439], Loss: 1.1419\n",
      "Epoch [33/400], Step [300/439], Loss: 1.0547\n",
      "Epoch [33/400], Step [320/439], Loss: 1.3853\n",
      "Epoch [33/400], Step [340/439], Loss: 1.3788\n",
      "Epoch [33/400], Step [360/439], Loss: 1.1137\n",
      "Epoch [33/400], Step [380/439], Loss: 1.3215\n",
      "Epoch [33/400], Step [400/439], Loss: 1.5364\n",
      "Epoch [33/400], Step [420/439], Loss: 1.3630\n",
      "\n",
      "train-loss: 1.5088, train-acc: 54.3128\n",
      "validation loss: 1.4399, validation acc: 56.3961\n",
      "\n",
      "Epoch 34\n",
      "\n",
      "Epoch [34/400], Step [0/439], Loss: 1.1358\n",
      "Epoch [34/400], Step [20/439], Loss: 1.1275\n",
      "Epoch [34/400], Step [40/439], Loss: 1.3435\n",
      "Epoch [34/400], Step [60/439], Loss: 1.4624\n",
      "Epoch [34/400], Step [80/439], Loss: 1.3255\n",
      "Epoch [34/400], Step [100/439], Loss: 1.3736\n",
      "Epoch [34/400], Step [120/439], Loss: 1.5792\n",
      "Epoch [34/400], Step [140/439], Loss: 1.9163\n",
      "Epoch [34/400], Step [160/439], Loss: 1.1779\n",
      "Epoch [34/400], Step [180/439], Loss: 1.1240\n",
      "Epoch [34/400], Step [200/439], Loss: 1.3395\n",
      "Epoch [34/400], Step [220/439], Loss: 1.5179\n",
      "Epoch [34/400], Step [240/439], Loss: 1.2605\n",
      "Epoch [34/400], Step [260/439], Loss: 1.2239\n",
      "Epoch [34/400], Step [280/439], Loss: 1.3063\n",
      "Epoch [34/400], Step [300/439], Loss: 1.1918\n",
      "Epoch [34/400], Step [320/439], Loss: 1.2511\n",
      "Epoch [34/400], Step [340/439], Loss: 1.4165\n",
      "Epoch [34/400], Step [360/439], Loss: 1.2830\n",
      "Epoch [34/400], Step [380/439], Loss: 1.0132\n",
      "Epoch [34/400], Step [400/439], Loss: 1.7724\n",
      "Epoch [34/400], Step [420/439], Loss: 1.1985\n",
      "\n",
      "train-loss: 1.5072, train-acc: 53.2221\n",
      "validation loss: 1.4377, validation acc: 57.6533\n",
      "\n",
      "Improvement-Detected, save-model\n",
      "Epoch 35\n",
      "\n",
      "Epoch [35/400], Step [0/439], Loss: 1.6023\n",
      "Epoch [35/400], Step [20/439], Loss: 1.1222\n",
      "Epoch [35/400], Step [40/439], Loss: 1.2517\n",
      "Epoch [35/400], Step [60/439], Loss: 1.7649\n",
      "Epoch [35/400], Step [80/439], Loss: 1.3400\n",
      "Epoch [35/400], Step [100/439], Loss: 1.3831\n",
      "Epoch [35/400], Step [120/439], Loss: 1.1272\n",
      "Epoch [35/400], Step [140/439], Loss: 1.4900\n",
      "Epoch [35/400], Step [160/439], Loss: 1.2755\n",
      "Epoch [35/400], Step [180/439], Loss: 1.2346\n",
      "Epoch [35/400], Step [200/439], Loss: 1.2933\n",
      "Epoch [35/400], Step [220/439], Loss: 1.3016\n",
      "Epoch [35/400], Step [240/439], Loss: 1.3022\n",
      "Epoch [35/400], Step [260/439], Loss: 1.2734\n",
      "Epoch [35/400], Step [280/439], Loss: 1.2451\n",
      "Epoch [35/400], Step [300/439], Loss: 1.3852\n",
      "Epoch [35/400], Step [320/439], Loss: 1.1589\n",
      "Epoch [35/400], Step [340/439], Loss: 1.3644\n",
      "Epoch [35/400], Step [360/439], Loss: 1.5200\n",
      "Epoch [35/400], Step [380/439], Loss: 1.3575\n",
      "Epoch [35/400], Step [400/439], Loss: 1.2979\n",
      "Epoch [35/400], Step [420/439], Loss: 1.7064\n",
      "\n",
      "train-loss: 1.5057, train-acc: 53.3433\n",
      "validation loss: 1.4360, validation acc: 56.2417\n",
      "\n",
      "Epoch 36\n",
      "\n",
      "Epoch [36/400], Step [0/439], Loss: 1.3974\n",
      "Epoch [36/400], Step [20/439], Loss: 1.3380\n",
      "Epoch [36/400], Step [40/439], Loss: 1.3965\n",
      "Epoch [36/400], Step [60/439], Loss: 1.2221\n",
      "Epoch [36/400], Step [80/439], Loss: 1.4255\n",
      "Epoch [36/400], Step [100/439], Loss: 1.4258\n",
      "Epoch [36/400], Step [120/439], Loss: 1.0339\n",
      "Epoch [36/400], Step [140/439], Loss: 1.8337\n",
      "Epoch [36/400], Step [160/439], Loss: 1.0742\n",
      "Epoch [36/400], Step [180/439], Loss: 1.4328\n",
      "Epoch [36/400], Step [200/439], Loss: 1.4416\n",
      "Epoch [36/400], Step [220/439], Loss: 1.4689\n",
      "Epoch [36/400], Step [240/439], Loss: 1.1625\n",
      "Epoch [36/400], Step [260/439], Loss: 1.1779\n",
      "Epoch [36/400], Step [280/439], Loss: 1.2770\n",
      "Epoch [36/400], Step [300/439], Loss: 1.3063\n",
      "Epoch [36/400], Step [320/439], Loss: 1.3097\n",
      "Epoch [36/400], Step [340/439], Loss: 1.0292\n",
      "Epoch [36/400], Step [360/439], Loss: 1.2281\n",
      "Epoch [36/400], Step [380/439], Loss: 1.4986\n",
      "Epoch [36/400], Step [400/439], Loss: 1.3393\n",
      "Epoch [36/400], Step [420/439], Loss: 1.3990\n",
      "\n",
      "train-loss: 1.5039, train-acc: 53.9421\n",
      "validation loss: 1.4341, validation acc: 56.5946\n",
      "\n",
      "Epoch 37\n",
      "\n",
      "Epoch [37/400], Step [0/439], Loss: 1.1435\n",
      "Epoch [37/400], Step [20/439], Loss: 1.1727\n",
      "Epoch [37/400], Step [40/439], Loss: 1.3538\n",
      "Epoch [37/400], Step [60/439], Loss: 1.2316\n",
      "Epoch [37/400], Step [80/439], Loss: 1.7588\n",
      "Epoch [37/400], Step [100/439], Loss: 1.5460\n",
      "Epoch [37/400], Step [120/439], Loss: 1.3799\n",
      "Epoch [37/400], Step [140/439], Loss: 1.3174\n",
      "Epoch [37/400], Step [160/439], Loss: 1.2231\n",
      "Epoch [37/400], Step [180/439], Loss: 1.2632\n",
      "Epoch [37/400], Step [200/439], Loss: 1.3616\n",
      "Epoch [37/400], Step [220/439], Loss: 1.7488\n",
      "Epoch [37/400], Step [240/439], Loss: 1.1617\n",
      "Epoch [37/400], Step [260/439], Loss: 1.5743\n",
      "Epoch [37/400], Step [280/439], Loss: 1.5987\n",
      "Epoch [37/400], Step [300/439], Loss: 1.5951\n",
      "Epoch [37/400], Step [320/439], Loss: 0.9956\n",
      "Epoch [37/400], Step [340/439], Loss: 1.4610\n",
      "Epoch [37/400], Step [360/439], Loss: 1.2708\n",
      "Epoch [37/400], Step [380/439], Loss: 1.2755\n",
      "Epoch [37/400], Step [400/439], Loss: 1.4163\n",
      "Epoch [37/400], Step [420/439], Loss: 1.4431\n",
      "\n",
      "train-loss: 1.5022, train-acc: 54.0918\n",
      "validation loss: 1.4319, validation acc: 58.8663\n",
      "\n",
      "Improvement-Detected, save-model\n",
      "Epoch 38\n",
      "\n",
      "Epoch [38/400], Step [0/439], Loss: 1.2259\n",
      "Epoch [38/400], Step [20/439], Loss: 1.3572\n",
      "Epoch [38/400], Step [40/439], Loss: 1.5415\n",
      "Epoch [38/400], Step [60/439], Loss: 2.0751\n",
      "Epoch [38/400], Step [80/439], Loss: 1.6517\n",
      "Epoch [38/400], Step [100/439], Loss: 1.5614\n",
      "Epoch [38/400], Step [120/439], Loss: 1.5079\n",
      "Epoch [38/400], Step [140/439], Loss: 1.3814\n",
      "Epoch [38/400], Step [160/439], Loss: 1.2859\n",
      "Epoch [38/400], Step [180/439], Loss: 1.1103\n",
      "Epoch [38/400], Step [200/439], Loss: 1.5844\n",
      "Epoch [38/400], Step [220/439], Loss: 1.6114\n",
      "Epoch [38/400], Step [240/439], Loss: 1.5486\n",
      "Epoch [38/400], Step [260/439], Loss: 1.7247\n",
      "Epoch [38/400], Step [280/439], Loss: 1.5969\n",
      "Epoch [38/400], Step [300/439], Loss: 1.1187\n",
      "Epoch [38/400], Step [320/439], Loss: 1.6308\n",
      "Epoch [38/400], Step [340/439], Loss: 1.1630\n",
      "Epoch [38/400], Step [360/439], Loss: 1.1697\n",
      "Epoch [38/400], Step [380/439], Loss: 1.2213\n",
      "Epoch [38/400], Step [400/439], Loss: 1.2801\n",
      "Epoch [38/400], Step [420/439], Loss: 1.2456\n",
      "\n",
      "train-loss: 1.5006, train-acc: 54.2059\n",
      "validation loss: 1.4308, validation acc: 54.3229\n",
      "\n",
      "Epoch 39\n",
      "\n",
      "Epoch [39/400], Step [0/439], Loss: 1.1182\n",
      "Epoch [39/400], Step [20/439], Loss: 1.1965\n",
      "Epoch [39/400], Step [40/439], Loss: 1.0438\n",
      "Epoch [39/400], Step [60/439], Loss: 1.2240\n",
      "Epoch [39/400], Step [80/439], Loss: 1.6634\n",
      "Epoch [39/400], Step [100/439], Loss: 1.6790\n",
      "Epoch [39/400], Step [120/439], Loss: 1.1648\n",
      "Epoch [39/400], Step [140/439], Loss: 1.1676\n",
      "Epoch [39/400], Step [160/439], Loss: 1.2740\n",
      "Epoch [39/400], Step [180/439], Loss: 1.3897\n",
      "Epoch [39/400], Step [200/439], Loss: 1.6104\n",
      "Epoch [39/400], Step [220/439], Loss: 1.2831\n",
      "Epoch [39/400], Step [240/439], Loss: 1.1380\n",
      "Epoch [39/400], Step [260/439], Loss: 1.3876\n",
      "Epoch [39/400], Step [280/439], Loss: 1.3541\n",
      "Epoch [39/400], Step [300/439], Loss: 1.2420\n",
      "Epoch [39/400], Step [320/439], Loss: 1.2306\n",
      "Epoch [39/400], Step [340/439], Loss: 1.4981\n",
      "Epoch [39/400], Step [360/439], Loss: 1.2139\n",
      "Epoch [39/400], Step [380/439], Loss: 1.2433\n",
      "Epoch [39/400], Step [400/439], Loss: 1.1704\n",
      "Epoch [39/400], Step [420/439], Loss: 1.1593\n",
      "\n",
      "train-loss: 1.4989, train-acc: 54.3698\n",
      "validation loss: 1.4295, validation acc: 55.5801\n",
      "\n",
      "Epoch 40\n",
      "\n",
      "Epoch [40/400], Step [0/439], Loss: 1.1543\n",
      "Epoch [40/400], Step [20/439], Loss: 1.3894\n",
      "Epoch [40/400], Step [40/439], Loss: 1.1546\n",
      "Epoch [40/400], Step [60/439], Loss: 1.1153\n",
      "Epoch [40/400], Step [80/439], Loss: 1.0210\n",
      "Epoch [40/400], Step [100/439], Loss: 1.8855\n",
      "Epoch [40/400], Step [120/439], Loss: 1.4504\n",
      "Epoch [40/400], Step [140/439], Loss: 1.4395\n",
      "Epoch [40/400], Step [160/439], Loss: 1.7589\n",
      "Epoch [40/400], Step [180/439], Loss: 1.3996\n",
      "Epoch [40/400], Step [200/439], Loss: 1.4048\n",
      "Epoch [40/400], Step [220/439], Loss: 1.2505\n",
      "Epoch [40/400], Step [240/439], Loss: 1.3366\n",
      "Epoch [40/400], Step [260/439], Loss: 1.5422\n",
      "Epoch [40/400], Step [280/439], Loss: 1.4284\n",
      "Epoch [40/400], Step [300/439], Loss: 1.2399\n",
      "Epoch [40/400], Step [320/439], Loss: 1.4732\n",
      "Epoch [40/400], Step [340/439], Loss: 1.5826\n",
      "Epoch [40/400], Step [360/439], Loss: 1.1093\n",
      "Epoch [40/400], Step [380/439], Loss: 1.6024\n",
      "Epoch [40/400], Step [400/439], Loss: 1.2785\n",
      "Epoch [40/400], Step [420/439], Loss: 1.6030\n",
      "\n",
      "train-loss: 1.4972, train-acc: 54.6692\n",
      "validation loss: 1.4293, validation acc: 53.3745\n",
      "\n",
      "Epoch 41\n",
      "\n",
      "Epoch [41/400], Step [0/439], Loss: 1.3437\n",
      "Epoch [41/400], Step [20/439], Loss: 1.4444\n",
      "Epoch [41/400], Step [40/439], Loss: 1.1530\n",
      "Epoch [41/400], Step [60/439], Loss: 1.6050\n",
      "Epoch [41/400], Step [80/439], Loss: 1.0047\n",
      "Epoch [41/400], Step [100/439], Loss: 1.6361\n",
      "Epoch [41/400], Step [120/439], Loss: 1.0186\n",
      "Epoch [41/400], Step [140/439], Loss: 1.0974\n",
      "Epoch [41/400], Step [160/439], Loss: 1.3198\n",
      "Epoch [41/400], Step [180/439], Loss: 1.2549\n",
      "Epoch [41/400], Step [200/439], Loss: 1.5407\n",
      "Epoch [41/400], Step [220/439], Loss: 1.2710\n",
      "Epoch [41/400], Step [240/439], Loss: 1.0921\n",
      "Epoch [41/400], Step [260/439], Loss: 1.1304\n",
      "Epoch [41/400], Step [280/439], Loss: 1.3794\n",
      "Epoch [41/400], Step [300/439], Loss: 1.9013\n",
      "Epoch [41/400], Step [320/439], Loss: 1.5553\n",
      "Epoch [41/400], Step [340/439], Loss: 1.1074\n",
      "Epoch [41/400], Step [360/439], Loss: 1.3937\n",
      "Epoch [41/400], Step [380/439], Loss: 1.6267\n",
      "Epoch [41/400], Step [400/439], Loss: 1.3458\n",
      "Epoch [41/400], Step [420/439], Loss: 1.7560\n",
      "\n",
      "train-loss: 1.4955, train-acc: 54.2629\n",
      "validation loss: 1.4279, validation acc: 55.6683\n",
      "\n",
      "Epoch 42\n",
      "\n",
      "Epoch [42/400], Step [0/439], Loss: 1.5496\n",
      "Epoch [42/400], Step [20/439], Loss: 1.6000\n",
      "Epoch [42/400], Step [40/439], Loss: 1.2938\n",
      "Epoch [42/400], Step [60/439], Loss: 1.7140\n",
      "Epoch [42/400], Step [80/439], Loss: 1.7301\n",
      "Epoch [42/400], Step [100/439], Loss: 1.6328\n",
      "Epoch [42/400], Step [120/439], Loss: 1.3269\n",
      "Epoch [42/400], Step [140/439], Loss: 1.1446\n",
      "Epoch [42/400], Step [160/439], Loss: 1.5989\n",
      "Epoch [42/400], Step [180/439], Loss: 1.2666\n",
      "Epoch [42/400], Step [200/439], Loss: 1.3058\n",
      "Epoch [42/400], Step [220/439], Loss: 1.0877\n",
      "Epoch [42/400], Step [240/439], Loss: 1.5317\n",
      "Epoch [42/400], Step [260/439], Loss: 1.2604\n",
      "Epoch [42/400], Step [280/439], Loss: 1.3338\n",
      "Epoch [42/400], Step [300/439], Loss: 1.1986\n",
      "Epoch [42/400], Step [320/439], Loss: 1.5947\n",
      "Epoch [42/400], Step [340/439], Loss: 1.7716\n",
      "Epoch [42/400], Step [360/439], Loss: 1.2584\n",
      "Epoch [42/400], Step [380/439], Loss: 1.0400\n",
      "Epoch [42/400], Step [400/439], Loss: 1.2925\n",
      "Epoch [42/400], Step [420/439], Loss: 1.1716\n",
      "\n",
      "train-loss: 1.4938, train-acc: 55.0756\n",
      "validation loss: 1.4280, validation acc: 51.3013\n",
      "\n",
      "Epoch 43\n",
      "\n",
      "Epoch [43/400], Step [0/439], Loss: 1.5773\n",
      "Epoch [43/400], Step [20/439], Loss: 1.2762\n",
      "Epoch [43/400], Step [40/439], Loss: 1.5805\n",
      "Epoch [43/400], Step [60/439], Loss: 1.3860\n",
      "Epoch [43/400], Step [80/439], Loss: 1.0113\n",
      "Epoch [43/400], Step [100/439], Loss: 1.5746\n",
      "Epoch [43/400], Step [120/439], Loss: 1.2681\n",
      "Epoch [43/400], Step [140/439], Loss: 1.3200\n",
      "Epoch [43/400], Step [160/439], Loss: 1.1990\n",
      "Epoch [43/400], Step [180/439], Loss: 1.6413\n",
      "Epoch [43/400], Step [200/439], Loss: 0.9018\n",
      "Epoch [43/400], Step [220/439], Loss: 1.2152\n",
      "Epoch [43/400], Step [240/439], Loss: 0.8988\n",
      "Epoch [43/400], Step [260/439], Loss: 1.1217\n",
      "Epoch [43/400], Step [280/439], Loss: 1.5920\n",
      "Epoch [43/400], Step [300/439], Loss: 1.7381\n",
      "Epoch [43/400], Step [320/439], Loss: 1.6008\n",
      "Epoch [43/400], Step [340/439], Loss: 1.2336\n",
      "Epoch [43/400], Step [360/439], Loss: 1.4528\n",
      "Epoch [43/400], Step [380/439], Loss: 1.0011\n",
      "Epoch [43/400], Step [400/439], Loss: 1.1157\n",
      "Epoch [43/400], Step [420/439], Loss: 1.3157\n",
      "\n",
      "train-loss: 1.4922, train-acc: 54.4910\n",
      "validation loss: 1.4270, validation acc: 54.9404\n",
      "\n",
      "Epoch 44\n",
      "\n",
      "Epoch [44/400], Step [0/439], Loss: 1.2753\n",
      "Epoch [44/400], Step [20/439], Loss: 1.3150\n",
      "Epoch [44/400], Step [40/439], Loss: 1.1754\n",
      "Epoch [44/400], Step [60/439], Loss: 0.9626\n",
      "Epoch [44/400], Step [80/439], Loss: 1.2612\n",
      "Epoch [44/400], Step [100/439], Loss: 1.3823\n",
      "Epoch [44/400], Step [120/439], Loss: 1.4876\n",
      "Epoch [44/400], Step [140/439], Loss: 1.2964\n",
      "Epoch [44/400], Step [160/439], Loss: 1.1994\n",
      "Epoch [44/400], Step [180/439], Loss: 1.3901\n",
      "Epoch [44/400], Step [200/439], Loss: 1.8197\n",
      "Epoch [44/400], Step [220/439], Loss: 1.4261\n",
      "Epoch [44/400], Step [240/439], Loss: 1.2671\n",
      "Epoch [44/400], Step [260/439], Loss: 1.7589\n",
      "Epoch [44/400], Step [280/439], Loss: 1.3033\n",
      "Epoch [44/400], Step [300/439], Loss: 1.0682\n",
      "Epoch [44/400], Step [320/439], Loss: 1.4874\n",
      "Epoch [44/400], Step [340/439], Loss: 1.1486\n",
      "Epoch [44/400], Step [360/439], Loss: 1.3830\n",
      "Epoch [44/400], Step [380/439], Loss: 1.0550\n",
      "Epoch [44/400], Step [400/439], Loss: 1.6107\n",
      "Epoch [44/400], Step [420/439], Loss: 1.2781\n",
      "\n",
      "train-loss: 1.4907, train-acc: 54.6336\n",
      "validation loss: 1.4251, validation acc: 57.9180\n",
      "\n",
      "Epoch 45\n",
      "\n",
      "Epoch [45/400], Step [0/439], Loss: 1.3088\n",
      "Epoch [45/400], Step [20/439], Loss: 1.6062\n",
      "Epoch [45/400], Step [40/439], Loss: 1.1459\n",
      "Epoch [45/400], Step [60/439], Loss: 1.1305\n",
      "Epoch [45/400], Step [80/439], Loss: 1.2691\n",
      "Epoch [45/400], Step [100/439], Loss: 1.0554\n",
      "Epoch [45/400], Step [120/439], Loss: 1.5197\n",
      "Epoch [45/400], Step [140/439], Loss: 1.3285\n",
      "Epoch [45/400], Step [160/439], Loss: 1.4512\n",
      "Epoch [45/400], Step [180/439], Loss: 1.4068\n",
      "Epoch [45/400], Step [200/439], Loss: 1.3363\n",
      "Epoch [45/400], Step [220/439], Loss: 1.0372\n",
      "Epoch [45/400], Step [240/439], Loss: 1.1634\n",
      "Epoch [45/400], Step [260/439], Loss: 1.2492\n",
      "Epoch [45/400], Step [280/439], Loss: 1.3325\n",
      "Epoch [45/400], Step [300/439], Loss: 1.1998\n",
      "Epoch [45/400], Step [320/439], Loss: 1.2379\n",
      "Epoch [45/400], Step [340/439], Loss: 1.2785\n",
      "Epoch [45/400], Step [360/439], Loss: 1.4992\n",
      "Epoch [45/400], Step [380/439], Loss: 1.0958\n",
      "Epoch [45/400], Step [400/439], Loss: 1.9002\n",
      "Epoch [45/400], Step [420/439], Loss: 1.0913\n",
      "\n",
      "train-loss: 1.4891, train-acc: 54.3484\n",
      "validation loss: 1.4229, validation acc: 59.3295\n",
      "\n",
      "Improvement-Detected, save-model\n",
      "Epoch 46\n",
      "\n",
      "Epoch [46/400], Step [0/439], Loss: 1.5980\n",
      "Epoch [46/400], Step [20/439], Loss: 1.3314\n",
      "Epoch [46/400], Step [40/439], Loss: 1.4302\n",
      "Epoch [46/400], Step [60/439], Loss: 1.1020\n",
      "Epoch [46/400], Step [80/439], Loss: 1.6660\n",
      "Epoch [46/400], Step [100/439], Loss: 1.3270\n",
      "Epoch [46/400], Step [120/439], Loss: 1.3698\n",
      "Epoch [46/400], Step [140/439], Loss: 0.9936\n",
      "Epoch [46/400], Step [160/439], Loss: 2.2939\n",
      "Epoch [46/400], Step [180/439], Loss: 1.5390\n",
      "Epoch [46/400], Step [200/439], Loss: 1.5211\n",
      "Epoch [46/400], Step [220/439], Loss: 1.6010\n",
      "Epoch [46/400], Step [240/439], Loss: 1.4234\n",
      "Epoch [46/400], Step [260/439], Loss: 1.2003\n",
      "Epoch [46/400], Step [280/439], Loss: 1.7839\n",
      "Epoch [46/400], Step [300/439], Loss: 1.3403\n",
      "Epoch [46/400], Step [320/439], Loss: 1.2325\n",
      "Epoch [46/400], Step [340/439], Loss: 1.3635\n",
      "Epoch [46/400], Step [360/439], Loss: 1.3360\n",
      "Epoch [46/400], Step [380/439], Loss: 1.5679\n",
      "Epoch [46/400], Step [400/439], Loss: 1.2846\n",
      "Epoch [46/400], Step [420/439], Loss: 1.4030\n",
      "\n",
      "train-loss: 1.4877, train-acc: 53.9635\n",
      "validation loss: 1.4209, validation acc: 57.8959\n",
      "\n",
      "Epoch 47\n",
      "\n",
      "Epoch [47/400], Step [0/439], Loss: 1.0299\n",
      "Epoch [47/400], Step [20/439], Loss: 1.2362\n",
      "Epoch [47/400], Step [40/439], Loss: 1.2219\n",
      "Epoch [47/400], Step [60/439], Loss: 1.6678\n",
      "Epoch [47/400], Step [80/439], Loss: 1.2148\n",
      "Epoch [47/400], Step [100/439], Loss: 1.4439\n",
      "Epoch [47/400], Step [120/439], Loss: 1.0471\n",
      "Epoch [47/400], Step [140/439], Loss: 1.2933\n",
      "Epoch [47/400], Step [160/439], Loss: 1.3363\n",
      "Epoch [47/400], Step [180/439], Loss: 1.1853\n",
      "Epoch [47/400], Step [200/439], Loss: 1.2885\n",
      "Epoch [47/400], Step [220/439], Loss: 1.4400\n",
      "Epoch [47/400], Step [240/439], Loss: 1.4757\n",
      "Epoch [47/400], Step [260/439], Loss: 1.3159\n",
      "Epoch [47/400], Step [280/439], Loss: 1.1438\n",
      "Epoch [47/400], Step [300/439], Loss: 1.5751\n",
      "Epoch [47/400], Step [320/439], Loss: 1.1519\n",
      "Epoch [47/400], Step [340/439], Loss: 1.3949\n",
      "Epoch [47/400], Step [360/439], Loss: 1.2238\n",
      "Epoch [47/400], Step [380/439], Loss: 1.4395\n",
      "Epoch [47/400], Step [400/439], Loss: 1.2410\n",
      "Epoch [47/400], Step [420/439], Loss: 1.1516\n",
      "\n",
      "train-loss: 1.4863, train-acc: 54.5053\n",
      "validation loss: 1.4198, validation acc: 54.7640\n",
      "\n",
      "Epoch 48\n",
      "\n",
      "Epoch [48/400], Step [0/439], Loss: 1.2222\n",
      "Epoch [48/400], Step [20/439], Loss: 1.2252\n",
      "Epoch [48/400], Step [40/439], Loss: 1.3607\n",
      "Epoch [48/400], Step [60/439], Loss: 1.5253\n",
      "Epoch [48/400], Step [80/439], Loss: 1.6328\n",
      "Epoch [48/400], Step [100/439], Loss: 1.4393\n",
      "Epoch [48/400], Step [120/439], Loss: 1.8050\n",
      "Epoch [48/400], Step [140/439], Loss: 1.5655\n",
      "Epoch [48/400], Step [160/439], Loss: 1.3306\n",
      "Epoch [48/400], Step [180/439], Loss: 1.0038\n",
      "Epoch [48/400], Step [200/439], Loss: 0.9167\n",
      "Epoch [48/400], Step [220/439], Loss: 1.3839\n",
      "Epoch [48/400], Step [240/439], Loss: 1.1297\n",
      "Epoch [48/400], Step [260/439], Loss: 1.8354\n",
      "Epoch [48/400], Step [280/439], Loss: 1.1948\n",
      "Epoch [48/400], Step [300/439], Loss: 1.0655\n",
      "Epoch [48/400], Step [320/439], Loss: 1.3765\n",
      "Epoch [48/400], Step [340/439], Loss: 0.9665\n",
      "Epoch [48/400], Step [360/439], Loss: 0.9536\n",
      "Epoch [48/400], Step [380/439], Loss: 1.0605\n",
      "Epoch [48/400], Step [400/439], Loss: 1.3319\n",
      "Epoch [48/400], Step [420/439], Loss: 1.4731\n",
      "\n",
      "train-loss: 1.4848, train-acc: 54.3271\n",
      "validation loss: 1.4179, validation acc: 57.9180\n",
      "\n",
      "Epoch 49\n",
      "\n",
      "Epoch [49/400], Step [0/439], Loss: 1.6139\n",
      "Epoch [49/400], Step [20/439], Loss: 1.4278\n",
      "Epoch [49/400], Step [40/439], Loss: 1.2659\n",
      "Epoch [49/400], Step [60/439], Loss: 1.0447\n",
      "Epoch [49/400], Step [80/439], Loss: 0.9675\n",
      "Epoch [49/400], Step [100/439], Loss: 1.4991\n",
      "Epoch [49/400], Step [120/439], Loss: 1.5528\n",
      "Epoch [49/400], Step [140/439], Loss: 1.5545\n",
      "Epoch [49/400], Step [160/439], Loss: 1.2944\n",
      "Epoch [49/400], Step [180/439], Loss: 1.6902\n",
      "Epoch [49/400], Step [200/439], Loss: 1.4647\n",
      "Epoch [49/400], Step [220/439], Loss: 1.1468\n",
      "Epoch [49/400], Step [240/439], Loss: 1.5861\n",
      "Epoch [49/400], Step [260/439], Loss: 1.3987\n",
      "Epoch [49/400], Step [280/439], Loss: 1.4372\n",
      "Epoch [49/400], Step [300/439], Loss: 1.3157\n",
      "Epoch [49/400], Step [320/439], Loss: 1.3212\n",
      "Epoch [49/400], Step [340/439], Loss: 1.2206\n",
      "Epoch [49/400], Step [360/439], Loss: 1.2416\n",
      "Epoch [49/400], Step [380/439], Loss: 1.5828\n",
      "Epoch [49/400], Step [400/439], Loss: 1.0796\n",
      "Epoch [49/400], Step [420/439], Loss: 1.0959\n",
      "\n",
      "train-loss: 1.4833, train-acc: 55.2039\n",
      "validation loss: 1.4159, validation acc: 58.9546\n",
      "\n",
      "Epoch 50\n",
      "\n",
      "Epoch [50/400], Step [0/439], Loss: 1.1885\n",
      "Epoch [50/400], Step [20/439], Loss: 1.0203\n",
      "Epoch [50/400], Step [40/439], Loss: 1.7952\n",
      "Epoch [50/400], Step [60/439], Loss: 1.2259\n",
      "Epoch [50/400], Step [80/439], Loss: 1.6476\n",
      "Epoch [50/400], Step [100/439], Loss: 1.6041\n",
      "Epoch [50/400], Step [120/439], Loss: 1.3441\n",
      "Epoch [50/400], Step [140/439], Loss: 1.3540\n",
      "Epoch [50/400], Step [160/439], Loss: 1.2362\n",
      "Epoch [50/400], Step [180/439], Loss: 1.0276\n",
      "Epoch [50/400], Step [200/439], Loss: 1.2425\n",
      "Epoch [50/400], Step [220/439], Loss: 1.1135\n",
      "Epoch [50/400], Step [240/439], Loss: 1.2302\n",
      "Epoch [50/400], Step [260/439], Loss: 1.5289\n",
      "Epoch [50/400], Step [280/439], Loss: 1.1428\n",
      "Epoch [50/400], Step [300/439], Loss: 1.6409\n",
      "Epoch [50/400], Step [320/439], Loss: 1.4797\n",
      "Epoch [50/400], Step [340/439], Loss: 1.2962\n",
      "Epoch [50/400], Step [360/439], Loss: 1.2158\n",
      "Epoch [50/400], Step [380/439], Loss: 1.3376\n",
      "Epoch [50/400], Step [400/439], Loss: 1.4143\n",
      "Epoch [50/400], Step [420/439], Loss: 1.4788\n",
      "\n",
      "train-loss: 1.4818, train-acc: 54.8118\n",
      "validation loss: 1.4146, validation acc: 56.1315\n",
      "\n",
      "Epoch 51\n",
      "\n",
      "Epoch [51/400], Step [0/439], Loss: 1.0476\n",
      "Epoch [51/400], Step [20/439], Loss: 1.4919\n",
      "Epoch [51/400], Step [40/439], Loss: 1.6009\n",
      "Epoch [51/400], Step [60/439], Loss: 1.5334\n",
      "Epoch [51/400], Step [80/439], Loss: 1.3890\n",
      "Epoch [51/400], Step [100/439], Loss: 1.5463\n",
      "Epoch [51/400], Step [120/439], Loss: 1.2624\n",
      "Epoch [51/400], Step [140/439], Loss: 1.4520\n",
      "Epoch [51/400], Step [160/439], Loss: 1.3459\n",
      "Epoch [51/400], Step [180/439], Loss: 1.2760\n",
      "Epoch [51/400], Step [200/439], Loss: 1.4631\n",
      "Epoch [51/400], Step [220/439], Loss: 1.4776\n",
      "Epoch [51/400], Step [240/439], Loss: 1.3693\n",
      "Epoch [51/400], Step [260/439], Loss: 2.0124\n",
      "Epoch [51/400], Step [280/439], Loss: 1.5818\n",
      "Epoch [51/400], Step [300/439], Loss: 0.9353\n",
      "Epoch [51/400], Step [320/439], Loss: 1.6581\n",
      "Epoch [51/400], Step [340/439], Loss: 1.0473\n",
      "Epoch [51/400], Step [360/439], Loss: 1.4537\n",
      "Epoch [51/400], Step [380/439], Loss: 1.2585\n",
      "Epoch [51/400], Step [400/439], Loss: 1.3638\n",
      "Epoch [51/400], Step [420/439], Loss: 0.9795\n",
      "\n",
      "train-loss: 1.4804, train-acc: 54.0633\n",
      "validation loss: 1.4129, validation acc: 57.5651\n",
      "\n",
      "Epoch 52\n",
      "\n",
      "Epoch [52/400], Step [0/439], Loss: 1.2116\n",
      "Epoch [52/400], Step [20/439], Loss: 1.0644\n",
      "Epoch [52/400], Step [40/439], Loss: 1.6784\n",
      "Epoch [52/400], Step [60/439], Loss: 1.1428\n",
      "Epoch [52/400], Step [80/439], Loss: 1.2672\n",
      "Epoch [52/400], Step [100/439], Loss: 1.1154\n",
      "Epoch [52/400], Step [120/439], Loss: 1.0567\n",
      "Epoch [52/400], Step [140/439], Loss: 1.3866\n",
      "Epoch [52/400], Step [160/439], Loss: 1.0630\n",
      "Epoch [52/400], Step [180/439], Loss: 0.8811\n",
      "Epoch [52/400], Step [200/439], Loss: 0.9915\n",
      "Epoch [52/400], Step [220/439], Loss: 1.2365\n",
      "Epoch [52/400], Step [240/439], Loss: 1.4571\n",
      "Epoch [52/400], Step [260/439], Loss: 1.1764\n",
      "Epoch [52/400], Step [280/439], Loss: 1.4709\n",
      "Epoch [52/400], Step [300/439], Loss: 1.2140\n",
      "Epoch [52/400], Step [320/439], Loss: 1.7397\n",
      "Epoch [52/400], Step [340/439], Loss: 1.2080\n",
      "Epoch [52/400], Step [360/439], Loss: 1.5773\n",
      "Epoch [52/400], Step [380/439], Loss: 1.0890\n",
      "Epoch [52/400], Step [400/439], Loss: 1.0933\n",
      "Epoch [52/400], Step [420/439], Loss: 1.1129\n",
      "\n",
      "train-loss: 1.4789, train-acc: 54.9330\n",
      "validation loss: 1.4112, validation acc: 57.6974\n",
      "\n",
      "Epoch 53\n",
      "\n",
      "Epoch [53/400], Step [0/439], Loss: 1.1559\n",
      "Epoch [53/400], Step [20/439], Loss: 1.5769\n",
      "Epoch [53/400], Step [40/439], Loss: 1.1770\n",
      "Epoch [53/400], Step [60/439], Loss: 1.3133\n",
      "Epoch [53/400], Step [80/439], Loss: 1.5285\n",
      "Epoch [53/400], Step [100/439], Loss: 1.0380\n",
      "Epoch [53/400], Step [120/439], Loss: 1.5559\n",
      "Epoch [53/400], Step [140/439], Loss: 1.4038\n",
      "Epoch [53/400], Step [160/439], Loss: 1.3270\n",
      "Epoch [53/400], Step [180/439], Loss: 1.2916\n",
      "Epoch [53/400], Step [200/439], Loss: 1.2780\n",
      "Epoch [53/400], Step [220/439], Loss: 1.4535\n",
      "Epoch [53/400], Step [240/439], Loss: 1.2003\n",
      "Epoch [53/400], Step [260/439], Loss: 1.1099\n",
      "Epoch [53/400], Step [280/439], Loss: 1.0612\n",
      "Epoch [53/400], Step [300/439], Loss: 1.5031\n",
      "Epoch [53/400], Step [320/439], Loss: 1.8264\n",
      "Epoch [53/400], Step [340/439], Loss: 0.9896\n",
      "Epoch [53/400], Step [360/439], Loss: 1.2193\n",
      "Epoch [53/400], Step [380/439], Loss: 1.3644\n",
      "Epoch [53/400], Step [400/439], Loss: 1.3988\n",
      "Epoch [53/400], Step [420/439], Loss: 1.4266\n",
      "\n",
      "train-loss: 1.4774, train-acc: 54.8760\n",
      "validation loss: 1.4095, validation acc: 59.1751\n",
      "\n",
      "Epoch 54\n",
      "\n",
      "Epoch [54/400], Step [0/439], Loss: 1.4595\n",
      "Epoch [54/400], Step [20/439], Loss: 1.5839\n",
      "Epoch [54/400], Step [40/439], Loss: 1.6290\n",
      "Epoch [54/400], Step [60/439], Loss: 1.6865\n",
      "Epoch [54/400], Step [80/439], Loss: 1.2143\n",
      "Epoch [54/400], Step [100/439], Loss: 1.5571\n",
      "Epoch [54/400], Step [120/439], Loss: 1.3346\n",
      "Epoch [54/400], Step [140/439], Loss: 0.9966\n",
      "Epoch [54/400], Step [160/439], Loss: 1.5246\n",
      "Epoch [54/400], Step [180/439], Loss: 1.1153\n",
      "Epoch [54/400], Step [200/439], Loss: 1.4671\n",
      "Epoch [54/400], Step [220/439], Loss: 1.3559\n",
      "Epoch [54/400], Step [240/439], Loss: 1.0286\n",
      "Epoch [54/400], Step [260/439], Loss: 1.1614\n",
      "Epoch [54/400], Step [280/439], Loss: 1.3472\n",
      "Epoch [54/400], Step [300/439], Loss: 1.5454\n",
      "Epoch [54/400], Step [320/439], Loss: 1.1702\n",
      "Epoch [54/400], Step [340/439], Loss: 1.5710\n",
      "Epoch [54/400], Step [360/439], Loss: 1.3144\n",
      "Epoch [54/400], Step [380/439], Loss: 1.2241\n",
      "Epoch [54/400], Step [400/439], Loss: 1.5083\n",
      "Epoch [54/400], Step [420/439], Loss: 1.0551\n",
      "\n",
      "train-loss: 1.4759, train-acc: 55.2466\n",
      "validation loss: 1.4083, validation acc: 56.3741\n",
      "\n",
      "Epoch 55\n",
      "\n",
      "Epoch [55/400], Step [0/439], Loss: 1.5768\n",
      "Epoch [55/400], Step [20/439], Loss: 1.3764\n",
      "Epoch [55/400], Step [40/439], Loss: 1.5444\n",
      "Epoch [55/400], Step [60/439], Loss: 1.1678\n",
      "Epoch [55/400], Step [80/439], Loss: 1.2308\n",
      "Epoch [55/400], Step [100/439], Loss: 1.4547\n",
      "Epoch [55/400], Step [120/439], Loss: 1.8432\n",
      "Epoch [55/400], Step [140/439], Loss: 1.1554\n",
      "Epoch [55/400], Step [160/439], Loss: 1.3201\n",
      "Epoch [55/400], Step [180/439], Loss: 1.1356\n",
      "Epoch [55/400], Step [200/439], Loss: 1.2418\n",
      "Epoch [55/400], Step [220/439], Loss: 1.1971\n",
      "Epoch [55/400], Step [240/439], Loss: 1.1829\n",
      "Epoch [55/400], Step [260/439], Loss: 1.0986\n",
      "Epoch [55/400], Step [280/439], Loss: 1.2193\n",
      "Epoch [55/400], Step [300/439], Loss: 0.9227\n",
      "Epoch [55/400], Step [320/439], Loss: 1.3926\n",
      "Epoch [55/400], Step [340/439], Loss: 0.9357\n",
      "Epoch [55/400], Step [360/439], Loss: 1.3061\n",
      "Epoch [55/400], Step [380/439], Loss: 1.2009\n",
      "Epoch [55/400], Step [400/439], Loss: 1.5430\n",
      "Epoch [55/400], Step [420/439], Loss: 1.2084\n",
      "\n",
      "train-loss: 1.4744, train-acc: 55.3108\n",
      "validation loss: 1.4067, validation acc: 57.4548\n",
      "\n",
      "Epoch 56\n",
      "\n",
      "Epoch [56/400], Step [0/439], Loss: 1.0834\n",
      "Epoch [56/400], Step [20/439], Loss: 1.1647\n",
      "Epoch [56/400], Step [40/439], Loss: 1.3604\n",
      "Epoch [56/400], Step [60/439], Loss: 1.0228\n",
      "Epoch [56/400], Step [80/439], Loss: 1.0136\n",
      "Epoch [56/400], Step [100/439], Loss: 1.4067\n",
      "Epoch [56/400], Step [120/439], Loss: 1.3731\n",
      "Epoch [56/400], Step [140/439], Loss: 1.6027\n",
      "Epoch [56/400], Step [160/439], Loss: 1.2734\n",
      "Epoch [56/400], Step [180/439], Loss: 1.2884\n",
      "Epoch [56/400], Step [200/439], Loss: 1.2699\n",
      "Epoch [56/400], Step [220/439], Loss: 1.5149\n",
      "Epoch [56/400], Step [240/439], Loss: 1.4666\n",
      "Epoch [56/400], Step [260/439], Loss: 1.5512\n",
      "Epoch [56/400], Step [280/439], Loss: 1.4867\n",
      "Epoch [56/400], Step [300/439], Loss: 1.4039\n",
      "Epoch [56/400], Step [320/439], Loss: 1.4888\n",
      "Epoch [56/400], Step [340/439], Loss: 1.4651\n",
      "Epoch [56/400], Step [360/439], Loss: 1.1523\n",
      "Epoch [56/400], Step [380/439], Loss: 0.8940\n",
      "Epoch [56/400], Step [400/439], Loss: 1.0845\n",
      "Epoch [56/400], Step [420/439], Loss: 1.5433\n",
      "\n",
      "train-loss: 1.4729, train-acc: 55.2965\n",
      "validation loss: 1.4048, validation acc: 59.3516\n",
      "\n",
      "Improvement-Detected, save-model\n",
      "Epoch 57\n",
      "\n",
      "Epoch [57/400], Step [0/439], Loss: 1.3088\n",
      "Epoch [57/400], Step [20/439], Loss: 1.2642\n",
      "Epoch [57/400], Step [40/439], Loss: 1.6632\n",
      "Epoch [57/400], Step [60/439], Loss: 1.7943\n",
      "Epoch [57/400], Step [80/439], Loss: 1.2999\n",
      "Epoch [57/400], Step [100/439], Loss: 1.5052\n",
      "Epoch [57/400], Step [120/439], Loss: 1.4585\n",
      "Epoch [57/400], Step [140/439], Loss: 1.4106\n",
      "Epoch [57/400], Step [160/439], Loss: 1.4382\n",
      "Epoch [57/400], Step [180/439], Loss: 1.3026\n",
      "Epoch [57/400], Step [200/439], Loss: 1.1716\n",
      "Epoch [57/400], Step [220/439], Loss: 1.6719\n",
      "Epoch [57/400], Step [240/439], Loss: 1.2332\n",
      "Epoch [57/400], Step [260/439], Loss: 1.2794\n",
      "Epoch [57/400], Step [280/439], Loss: 1.2173\n",
      "Epoch [57/400], Step [300/439], Loss: 1.0916\n",
      "Epoch [57/400], Step [320/439], Loss: 1.3304\n",
      "Epoch [57/400], Step [340/439], Loss: 1.2776\n",
      "Epoch [57/400], Step [360/439], Loss: 1.3945\n",
      "Epoch [57/400], Step [380/439], Loss: 1.4168\n",
      "Epoch [57/400], Step [400/439], Loss: 1.5868\n",
      "Epoch [57/400], Step [420/439], Loss: 1.1816\n",
      "\n",
      "train-loss: 1.4713, train-acc: 56.2589\n",
      "validation loss: 1.4035, validation acc: 57.7636\n",
      "\n",
      "Epoch 58\n",
      "\n",
      "Epoch [58/400], Step [0/439], Loss: 1.3518\n",
      "Epoch [58/400], Step [20/439], Loss: 1.2401\n",
      "Epoch [58/400], Step [40/439], Loss: 1.1885\n",
      "Epoch [58/400], Step [60/439], Loss: 1.4297\n",
      "Epoch [58/400], Step [80/439], Loss: 1.2746\n",
      "Epoch [58/400], Step [100/439], Loss: 1.4417\n",
      "Epoch [58/400], Step [120/439], Loss: 1.1980\n",
      "Epoch [58/400], Step [140/439], Loss: 1.2621\n",
      "Epoch [58/400], Step [160/439], Loss: 1.3250\n",
      "Epoch [58/400], Step [180/439], Loss: 1.2738\n",
      "Epoch [58/400], Step [200/439], Loss: 1.6875\n",
      "Epoch [58/400], Step [220/439], Loss: 1.7865\n",
      "Epoch [58/400], Step [240/439], Loss: 1.0398\n",
      "Epoch [58/400], Step [260/439], Loss: 1.0732\n",
      "Epoch [58/400], Step [280/439], Loss: 1.6224\n",
      "Epoch [58/400], Step [300/439], Loss: 1.7587\n",
      "Epoch [58/400], Step [320/439], Loss: 1.0526\n",
      "Epoch [58/400], Step [340/439], Loss: 1.3325\n",
      "Epoch [58/400], Step [360/439], Loss: 1.3130\n",
      "Epoch [58/400], Step [380/439], Loss: 1.0485\n",
      "Epoch [58/400], Step [400/439], Loss: 1.4629\n",
      "Epoch [58/400], Step [420/439], Loss: 1.2614\n",
      "\n",
      "train-loss: 1.4697, train-acc: 56.0736\n",
      "validation loss: 1.4017, validation acc: 59.0428\n",
      "\n",
      "Epoch 59\n",
      "\n",
      "Epoch [59/400], Step [0/439], Loss: 0.9134\n",
      "Epoch [59/400], Step [20/439], Loss: 1.4082\n",
      "Epoch [59/400], Step [40/439], Loss: 1.1497\n",
      "Epoch [59/400], Step [60/439], Loss: 1.2053\n",
      "Epoch [59/400], Step [80/439], Loss: 1.2971\n",
      "Epoch [59/400], Step [100/439], Loss: 1.8650\n",
      "Epoch [59/400], Step [120/439], Loss: 1.0406\n",
      "Epoch [59/400], Step [140/439], Loss: 1.1377\n",
      "Epoch [59/400], Step [160/439], Loss: 1.3359\n",
      "Epoch [59/400], Step [180/439], Loss: 1.1054\n",
      "Epoch [59/400], Step [200/439], Loss: 1.0873\n",
      "Epoch [59/400], Step [220/439], Loss: 1.8392\n",
      "Epoch [59/400], Step [240/439], Loss: 1.2202\n",
      "Epoch [59/400], Step [260/439], Loss: 1.5474\n",
      "Epoch [59/400], Step [280/439], Loss: 1.1945\n",
      "Epoch [59/400], Step [300/439], Loss: 0.9191\n",
      "Epoch [59/400], Step [320/439], Loss: 0.9930\n",
      "Epoch [59/400], Step [340/439], Loss: 1.1046\n",
      "Epoch [59/400], Step [360/439], Loss: 1.1314\n",
      "Epoch [59/400], Step [380/439], Loss: 1.7209\n",
      "Epoch [59/400], Step [400/439], Loss: 1.1265\n",
      "Epoch [59/400], Step [420/439], Loss: 1.2249\n",
      "\n",
      "train-loss: 1.4685, train-acc: 54.9615\n",
      "validation loss: 1.4005, validation acc: 57.4768\n",
      "\n",
      "Epoch 60\n",
      "\n",
      "Epoch [60/400], Step [0/439], Loss: 1.1693\n",
      "Epoch [60/400], Step [20/439], Loss: 1.0980\n",
      "Epoch [60/400], Step [40/439], Loss: 1.6437\n",
      "Epoch [60/400], Step [60/439], Loss: 1.3212\n",
      "Epoch [60/400], Step [80/439], Loss: 1.1487\n",
      "Epoch [60/400], Step [100/439], Loss: 1.2138\n",
      "Epoch [60/400], Step [120/439], Loss: 0.9007\n",
      "Epoch [60/400], Step [140/439], Loss: 1.3185\n",
      "Epoch [60/400], Step [160/439], Loss: 1.3198\n",
      "Epoch [60/400], Step [180/439], Loss: 1.2303\n",
      "Epoch [60/400], Step [200/439], Loss: 1.0713\n",
      "Epoch [60/400], Step [220/439], Loss: 1.2224\n",
      "Epoch [60/400], Step [240/439], Loss: 1.2306\n",
      "Epoch [60/400], Step [260/439], Loss: 1.3295\n",
      "Epoch [60/400], Step [280/439], Loss: 1.3894\n",
      "Epoch [60/400], Step [300/439], Loss: 1.6651\n",
      "Epoch [60/400], Step [320/439], Loss: 1.2493\n",
      "Epoch [60/400], Step [340/439], Loss: 1.5740\n",
      "Epoch [60/400], Step [360/439], Loss: 1.4357\n",
      "Epoch [60/400], Step [380/439], Loss: 1.3734\n",
      "Epoch [60/400], Step [400/439], Loss: 1.0808\n",
      "Epoch [60/400], Step [420/439], Loss: 1.3978\n",
      "\n",
      "train-loss: 1.4669, train-acc: 56.1520\n",
      "validation loss: 1.3988, validation acc: 59.5501\n",
      "\n",
      "Epoch 61\n",
      "\n",
      "Epoch [61/400], Step [0/439], Loss: 2.0705\n",
      "Epoch [61/400], Step [20/439], Loss: 1.5295\n",
      "Epoch [61/400], Step [40/439], Loss: 1.4456\n",
      "Epoch [61/400], Step [60/439], Loss: 1.0466\n",
      "Epoch [61/400], Step [80/439], Loss: 1.0209\n",
      "Epoch [61/400], Step [100/439], Loss: 1.4332\n",
      "Epoch [61/400], Step [120/439], Loss: 1.0528\n",
      "Epoch [61/400], Step [140/439], Loss: 1.2184\n",
      "Epoch [61/400], Step [160/439], Loss: 0.9873\n",
      "Epoch [61/400], Step [180/439], Loss: 1.1164\n",
      "Epoch [61/400], Step [200/439], Loss: 1.3091\n",
      "Epoch [61/400], Step [220/439], Loss: 1.2368\n",
      "Epoch [61/400], Step [240/439], Loss: 1.3023\n",
      "Epoch [61/400], Step [260/439], Loss: 0.9539\n",
      "Epoch [61/400], Step [280/439], Loss: 1.1244\n",
      "Epoch [61/400], Step [300/439], Loss: 1.2656\n",
      "Epoch [61/400], Step [320/439], Loss: 1.3599\n",
      "Epoch [61/400], Step [340/439], Loss: 1.4526\n",
      "Epoch [61/400], Step [360/439], Loss: 1.4029\n",
      "Epoch [61/400], Step [380/439], Loss: 1.7228\n",
      "Epoch [61/400], Step [400/439], Loss: 1.2142\n",
      "Epoch [61/400], Step [420/439], Loss: 1.4443\n",
      "\n",
      "train-loss: 1.4654, train-acc: 56.0522\n",
      "validation loss: 1.3972, validation acc: 58.2708\n",
      "\n",
      "Epoch 62\n",
      "\n",
      "Epoch [62/400], Step [0/439], Loss: 1.4680\n",
      "Epoch [62/400], Step [20/439], Loss: 1.2022\n",
      "Epoch [62/400], Step [40/439], Loss: 0.9869\n",
      "Epoch [62/400], Step [60/439], Loss: 1.0847\n",
      "Epoch [62/400], Step [80/439], Loss: 1.0756\n",
      "Epoch [62/400], Step [100/439], Loss: 1.0944\n",
      "Epoch [62/400], Step [120/439], Loss: 1.3890\n",
      "Epoch [62/400], Step [140/439], Loss: 1.6035\n",
      "Epoch [62/400], Step [160/439], Loss: 1.3626\n",
      "Epoch [62/400], Step [180/439], Loss: 1.3360\n",
      "Epoch [62/400], Step [200/439], Loss: 1.4215\n",
      "Epoch [62/400], Step [220/439], Loss: 1.2181\n",
      "Epoch [62/400], Step [240/439], Loss: 1.4702\n",
      "Epoch [62/400], Step [260/439], Loss: 1.1943\n",
      "Epoch [62/400], Step [280/439], Loss: 1.7624\n",
      "Epoch [62/400], Step [300/439], Loss: 1.4418\n",
      "Epoch [62/400], Step [320/439], Loss: 1.4091\n",
      "Epoch [62/400], Step [340/439], Loss: 0.9832\n",
      "Epoch [62/400], Step [360/439], Loss: 1.2919\n",
      "Epoch [62/400], Step [380/439], Loss: 1.5605\n",
      "Epoch [62/400], Step [400/439], Loss: 1.3975\n",
      "Epoch [62/400], Step [420/439], Loss: 1.1278\n",
      "\n",
      "train-loss: 1.4639, train-acc: 56.1805\n",
      "validation loss: 1.3953, validation acc: 60.6970\n",
      "\n",
      "Improvement-Detected, save-model\n",
      "Epoch 63\n",
      "\n",
      "Epoch [63/400], Step [0/439], Loss: 1.2323\n",
      "Epoch [63/400], Step [20/439], Loss: 1.2756\n",
      "Epoch [63/400], Step [40/439], Loss: 1.1409\n",
      "Epoch [63/400], Step [60/439], Loss: 1.3675\n",
      "Epoch [63/400], Step [80/439], Loss: 1.3705\n",
      "Epoch [63/400], Step [100/439], Loss: 0.9946\n",
      "Epoch [63/400], Step [120/439], Loss: 1.2308\n",
      "Epoch [63/400], Step [140/439], Loss: 0.9797\n",
      "Epoch [63/400], Step [160/439], Loss: 1.2475\n",
      "Epoch [63/400], Step [180/439], Loss: 1.3874\n",
      "Epoch [63/400], Step [200/439], Loss: 1.1236\n",
      "Epoch [63/400], Step [220/439], Loss: 1.1960\n",
      "Epoch [63/400], Step [240/439], Loss: 1.2041\n",
      "Epoch [63/400], Step [260/439], Loss: 1.8421\n",
      "Epoch [63/400], Step [280/439], Loss: 1.2915\n",
      "Epoch [63/400], Step [300/439], Loss: 1.1864\n",
      "Epoch [63/400], Step [320/439], Loss: 1.0793\n",
      "Epoch [63/400], Step [340/439], Loss: 1.4593\n",
      "Epoch [63/400], Step [360/439], Loss: 1.1867\n",
      "Epoch [63/400], Step [380/439], Loss: 0.9376\n",
      "Epoch [63/400], Step [400/439], Loss: 1.0397\n",
      "Epoch [63/400], Step [420/439], Loss: 1.4449\n",
      "\n",
      "train-loss: 1.4624, train-acc: 55.8455\n",
      "validation loss: 1.3940, validation acc: 57.2342\n",
      "\n",
      "Epoch 64\n",
      "\n",
      "Epoch [64/400], Step [0/439], Loss: 1.4492\n",
      "Epoch [64/400], Step [20/439], Loss: 1.2204\n",
      "Epoch [64/400], Step [40/439], Loss: 1.4577\n",
      "Epoch [64/400], Step [60/439], Loss: 1.5111\n",
      "Epoch [64/400], Step [80/439], Loss: 1.5268\n",
      "Epoch [64/400], Step [100/439], Loss: 1.6065\n",
      "Epoch [64/400], Step [120/439], Loss: 1.3921\n",
      "Epoch [64/400], Step [140/439], Loss: 1.2785\n",
      "Epoch [64/400], Step [160/439], Loss: 1.1714\n",
      "Epoch [64/400], Step [180/439], Loss: 0.9350\n",
      "Epoch [64/400], Step [200/439], Loss: 1.0369\n",
      "Epoch [64/400], Step [220/439], Loss: 1.8921\n",
      "Epoch [64/400], Step [240/439], Loss: 1.0644\n",
      "Epoch [64/400], Step [260/439], Loss: 0.9712\n",
      "Epoch [64/400], Step [280/439], Loss: 1.5766\n",
      "Epoch [64/400], Step [300/439], Loss: 1.0587\n",
      "Epoch [64/400], Step [320/439], Loss: 1.0800\n",
      "Epoch [64/400], Step [340/439], Loss: 1.3528\n",
      "Epoch [64/400], Step [360/439], Loss: 1.1746\n",
      "Epoch [64/400], Step [380/439], Loss: 1.4236\n",
      "Epoch [64/400], Step [400/439], Loss: 1.2687\n",
      "Epoch [64/400], Step [420/439], Loss: 1.4147\n",
      "\n",
      "train-loss: 1.4610, train-acc: 56.0522\n",
      "validation loss: 1.3925, validation acc: 58.2047\n",
      "\n",
      "Epoch 65\n",
      "\n",
      "Epoch [65/400], Step [0/439], Loss: 1.2530\n",
      "Epoch [65/400], Step [20/439], Loss: 1.0763\n",
      "Epoch [65/400], Step [40/439], Loss: 1.1097\n",
      "Epoch [65/400], Step [60/439], Loss: 0.9802\n",
      "Epoch [65/400], Step [80/439], Loss: 0.9466\n",
      "Epoch [65/400], Step [100/439], Loss: 0.9617\n",
      "Epoch [65/400], Step [120/439], Loss: 1.1177\n",
      "Epoch [65/400], Step [140/439], Loss: 1.2261\n",
      "Epoch [65/400], Step [160/439], Loss: 0.9582\n",
      "Epoch [65/400], Step [180/439], Loss: 1.2357\n",
      "Epoch [65/400], Step [200/439], Loss: 1.0304\n",
      "Epoch [65/400], Step [220/439], Loss: 1.3888\n",
      "Epoch [65/400], Step [240/439], Loss: 1.1479\n",
      "Epoch [65/400], Step [260/439], Loss: 1.0863\n",
      "Epoch [65/400], Step [280/439], Loss: 1.3223\n",
      "Epoch [65/400], Step [300/439], Loss: 1.5006\n",
      "Epoch [65/400], Step [320/439], Loss: 1.5184\n",
      "Epoch [65/400], Step [340/439], Loss: 1.1352\n",
      "Epoch [65/400], Step [360/439], Loss: 1.8624\n",
      "Epoch [65/400], Step [380/439], Loss: 1.4942\n",
      "Epoch [65/400], Step [400/439], Loss: 1.7279\n",
      "Epoch [65/400], Step [420/439], Loss: 1.2802\n",
      "\n",
      "train-loss: 1.4597, train-acc: 55.7884\n",
      "validation loss: 1.3908, validation acc: 59.1310\n",
      "\n",
      "Epoch 66\n",
      "\n",
      "Epoch [66/400], Step [0/439], Loss: 1.5941\n",
      "Epoch [66/400], Step [20/439], Loss: 1.5155\n",
      "Epoch [66/400], Step [40/439], Loss: 1.5628\n",
      "Epoch [66/400], Step [60/439], Loss: 1.5045\n",
      "Epoch [66/400], Step [80/439], Loss: 1.1106\n",
      "Epoch [66/400], Step [100/439], Loss: 1.3400\n",
      "Epoch [66/400], Step [120/439], Loss: 1.4000\n",
      "Epoch [66/400], Step [140/439], Loss: 1.1977\n",
      "Epoch [66/400], Step [160/439], Loss: 1.3256\n",
      "Epoch [66/400], Step [180/439], Loss: 0.9464\n",
      "Epoch [66/400], Step [200/439], Loss: 1.1865\n",
      "Epoch [66/400], Step [220/439], Loss: 1.7652\n",
      "Epoch [66/400], Step [240/439], Loss: 1.4188\n",
      "Epoch [66/400], Step [260/439], Loss: 0.9509\n",
      "Epoch [66/400], Step [280/439], Loss: 1.4987\n",
      "Epoch [66/400], Step [300/439], Loss: 1.3500\n",
      "Epoch [66/400], Step [320/439], Loss: 1.3953\n",
      "Epoch [66/400], Step [340/439], Loss: 1.3171\n",
      "Epoch [66/400], Step [360/439], Loss: 1.2953\n",
      "Epoch [66/400], Step [380/439], Loss: 1.1000\n",
      "Epoch [66/400], Step [400/439], Loss: 1.2542\n",
      "Epoch [66/400], Step [420/439], Loss: 1.2157\n",
      "\n",
      "train-loss: 1.4584, train-acc: 55.7884\n",
      "validation loss: 1.3897, validation acc: 56.6828\n",
      "\n",
      "Epoch 67\n",
      "\n",
      "Epoch [67/400], Step [0/439], Loss: 1.2440\n",
      "Epoch [67/400], Step [20/439], Loss: 1.0389\n",
      "Epoch [67/400], Step [40/439], Loss: 1.2987\n",
      "Epoch [67/400], Step [60/439], Loss: 1.6912\n",
      "Epoch [67/400], Step [80/439], Loss: 1.2304\n",
      "Epoch [67/400], Step [100/439], Loss: 1.3047\n",
      "Epoch [67/400], Step [120/439], Loss: 1.1698\n",
      "Epoch [67/400], Step [140/439], Loss: 1.2541\n",
      "Epoch [67/400], Step [160/439], Loss: 0.9899\n",
      "Epoch [67/400], Step [180/439], Loss: 1.3798\n",
      "Epoch [67/400], Step [200/439], Loss: 0.9793\n",
      "Epoch [67/400], Step [220/439], Loss: 1.2270\n",
      "Epoch [67/400], Step [240/439], Loss: 1.1899\n",
      "Epoch [67/400], Step [260/439], Loss: 1.1244\n",
      "Epoch [67/400], Step [280/439], Loss: 1.1450\n",
      "Epoch [67/400], Step [300/439], Loss: 1.1419\n",
      "Epoch [67/400], Step [320/439], Loss: 1.7633\n",
      "Epoch [67/400], Step [340/439], Loss: 1.4266\n",
      "Epoch [67/400], Step [360/439], Loss: 1.6277\n",
      "Epoch [67/400], Step [380/439], Loss: 1.1319\n",
      "Epoch [67/400], Step [400/439], Loss: 1.3865\n",
      "Epoch [67/400], Step [420/439], Loss: 1.4624\n",
      "\n",
      "train-loss: 1.4571, train-acc: 55.3322\n",
      "validation loss: 1.3887, validation acc: 56.1535\n",
      "\n",
      "Epoch 68\n",
      "\n",
      "Epoch [68/400], Step [0/439], Loss: 1.6968\n",
      "Epoch [68/400], Step [20/439], Loss: 1.0657\n",
      "Epoch [68/400], Step [40/439], Loss: 1.3026\n",
      "Epoch [68/400], Step [60/439], Loss: 1.7425\n",
      "Epoch [68/400], Step [80/439], Loss: 1.3200\n",
      "Epoch [68/400], Step [100/439], Loss: 1.9150\n",
      "Epoch [68/400], Step [120/439], Loss: 1.4030\n",
      "Epoch [68/400], Step [140/439], Loss: 1.0717\n",
      "Epoch [68/400], Step [160/439], Loss: 1.3094\n",
      "Epoch [68/400], Step [180/439], Loss: 1.3886\n",
      "Epoch [68/400], Step [200/439], Loss: 1.7002\n",
      "Epoch [68/400], Step [220/439], Loss: 1.4265\n",
      "Epoch [68/400], Step [240/439], Loss: 1.3465\n",
      "Epoch [68/400], Step [260/439], Loss: 1.3092\n",
      "Epoch [68/400], Step [280/439], Loss: 1.3734\n",
      "Epoch [68/400], Step [300/439], Loss: 1.2705\n",
      "Epoch [68/400], Step [320/439], Loss: 1.4781\n",
      "Epoch [68/400], Step [340/439], Loss: 1.0895\n",
      "Epoch [68/400], Step [360/439], Loss: 1.3076\n",
      "Epoch [68/400], Step [380/439], Loss: 1.2012\n",
      "Epoch [68/400], Step [400/439], Loss: 1.2480\n",
      "Epoch [68/400], Step [420/439], Loss: 1.2525\n",
      "\n",
      "train-loss: 1.4559, train-acc: 55.5389\n",
      "validation loss: 1.3870, validation acc: 59.4177\n",
      "\n",
      "Epoch 69\n",
      "\n",
      "Epoch [69/400], Step [0/439], Loss: 1.3374\n",
      "Epoch [69/400], Step [20/439], Loss: 1.3478\n",
      "Epoch [69/400], Step [40/439], Loss: 1.2066\n",
      "Epoch [69/400], Step [60/439], Loss: 1.1707\n",
      "Epoch [69/400], Step [80/439], Loss: 1.2166\n",
      "Epoch [69/400], Step [100/439], Loss: 1.1581\n",
      "Epoch [69/400], Step [120/439], Loss: 1.0551\n",
      "Epoch [69/400], Step [140/439], Loss: 1.0705\n",
      "Epoch [69/400], Step [160/439], Loss: 1.3541\n",
      "Epoch [69/400], Step [180/439], Loss: 1.3504\n",
      "Epoch [69/400], Step [200/439], Loss: 1.2821\n",
      "Epoch [69/400], Step [220/439], Loss: 1.5639\n",
      "Epoch [69/400], Step [240/439], Loss: 1.1018\n",
      "Epoch [69/400], Step [260/439], Loss: 1.1305\n",
      "Epoch [69/400], Step [280/439], Loss: 1.3306\n",
      "Epoch [69/400], Step [300/439], Loss: 1.4091\n",
      "Epoch [69/400], Step [320/439], Loss: 1.5841\n",
      "Epoch [69/400], Step [340/439], Loss: 1.1997\n",
      "Epoch [69/400], Step [360/439], Loss: 1.3806\n",
      "Epoch [69/400], Step [380/439], Loss: 1.4454\n",
      "Epoch [69/400], Step [400/439], Loss: 1.3101\n",
      "Epoch [69/400], Step [420/439], Loss: 1.2669\n",
      "\n",
      "train-loss: 1.4546, train-acc: 55.6815\n",
      "validation loss: 1.3856, validation acc: 59.7706\n",
      "\n",
      "Epoch 70\n",
      "\n",
      "Epoch [70/400], Step [0/439], Loss: 1.3606\n",
      "Epoch [70/400], Step [20/439], Loss: 1.0714\n",
      "Epoch [70/400], Step [40/439], Loss: 1.3305\n",
      "Epoch [70/400], Step [60/439], Loss: 1.3590\n",
      "Epoch [70/400], Step [80/439], Loss: 1.2468\n",
      "Epoch [70/400], Step [100/439], Loss: 1.7544\n",
      "Epoch [70/400], Step [120/439], Loss: 1.3049\n",
      "Epoch [70/400], Step [140/439], Loss: 1.3481\n",
      "Epoch [70/400], Step [160/439], Loss: 1.5533\n",
      "Epoch [70/400], Step [180/439], Loss: 1.1928\n",
      "Epoch [70/400], Step [200/439], Loss: 1.4608\n",
      "Epoch [70/400], Step [220/439], Loss: 1.1738\n",
      "Epoch [70/400], Step [240/439], Loss: 1.3846\n",
      "Epoch [70/400], Step [260/439], Loss: 1.3176\n",
      "Epoch [70/400], Step [280/439], Loss: 1.1730\n",
      "Epoch [70/400], Step [300/439], Loss: 1.7520\n",
      "Epoch [70/400], Step [320/439], Loss: 1.4947\n",
      "Epoch [70/400], Step [340/439], Loss: 1.5408\n",
      "Epoch [70/400], Step [360/439], Loss: 1.3191\n",
      "Epoch [70/400], Step [380/439], Loss: 1.3269\n",
      "Epoch [70/400], Step [400/439], Loss: 1.0677\n",
      "Epoch [70/400], Step [420/439], Loss: 1.1746\n",
      "\n",
      "train-loss: 1.4532, train-acc: 56.5654\n",
      "validation loss: 1.3843, validation acc: 57.8738\n",
      "\n",
      "Epoch 71\n",
      "\n",
      "Epoch [71/400], Step [0/439], Loss: 1.4167\n",
      "Epoch [71/400], Step [20/439], Loss: 1.2815\n",
      "Epoch [71/400], Step [40/439], Loss: 1.0699\n",
      "Epoch [71/400], Step [60/439], Loss: 0.8420\n",
      "Epoch [71/400], Step [80/439], Loss: 1.1427\n",
      "Epoch [71/400], Step [100/439], Loss: 1.4100\n",
      "Epoch [71/400], Step [120/439], Loss: 0.9709\n",
      "Epoch [71/400], Step [140/439], Loss: 1.2232\n",
      "Epoch [71/400], Step [160/439], Loss: 1.2061\n",
      "Epoch [71/400], Step [180/439], Loss: 1.3582\n",
      "Epoch [71/400], Step [200/439], Loss: 1.5275\n",
      "Epoch [71/400], Step [220/439], Loss: 1.3639\n",
      "Epoch [71/400], Step [240/439], Loss: 1.5761\n",
      "Epoch [71/400], Step [260/439], Loss: 1.4412\n",
      "Epoch [71/400], Step [280/439], Loss: 1.4055\n",
      "Epoch [71/400], Step [300/439], Loss: 1.3723\n",
      "Epoch [71/400], Step [320/439], Loss: 1.2488\n",
      "Epoch [71/400], Step [340/439], Loss: 1.1093\n",
      "Epoch [71/400], Step [360/439], Loss: 0.8764\n",
      "Epoch [71/400], Step [380/439], Loss: 1.2953\n",
      "Epoch [71/400], Step [400/439], Loss: 1.1769\n",
      "Epoch [71/400], Step [420/439], Loss: 1.0910\n",
      "\n",
      "train-loss: 1.4519, train-acc: 56.3373\n",
      "validation loss: 1.3829, validation acc: 58.4473\n",
      "\n",
      "Epoch 72\n",
      "\n",
      "Epoch [72/400], Step [0/439], Loss: 1.2547\n",
      "Epoch [72/400], Step [20/439], Loss: 1.3753\n",
      "Epoch [72/400], Step [40/439], Loss: 1.0626\n",
      "Epoch [72/400], Step [60/439], Loss: 0.8886\n",
      "Epoch [72/400], Step [80/439], Loss: 1.0191\n",
      "Epoch [72/400], Step [100/439], Loss: 1.0893\n",
      "Epoch [72/400], Step [120/439], Loss: 1.1795\n",
      "Epoch [72/400], Step [140/439], Loss: 1.5706\n",
      "Epoch [72/400], Step [160/439], Loss: 1.3459\n",
      "Epoch [72/400], Step [180/439], Loss: 1.1482\n",
      "Epoch [72/400], Step [200/439], Loss: 1.0250\n",
      "Epoch [72/400], Step [220/439], Loss: 1.1407\n",
      "Epoch [72/400], Step [240/439], Loss: 1.3419\n",
      "Epoch [72/400], Step [260/439], Loss: 1.3678\n",
      "Epoch [72/400], Step [280/439], Loss: 1.2129\n",
      "Epoch [72/400], Step [300/439], Loss: 1.2060\n",
      "Epoch [72/400], Step [320/439], Loss: 1.3008\n",
      "Epoch [72/400], Step [340/439], Loss: 1.0865\n",
      "Epoch [72/400], Step [360/439], Loss: 1.6890\n",
      "Epoch [72/400], Step [380/439], Loss: 1.0992\n",
      "Epoch [72/400], Step [400/439], Loss: 1.2910\n",
      "Epoch [72/400], Step [420/439], Loss: 1.3120\n",
      "\n",
      "train-loss: 1.4505, train-acc: 55.8597\n",
      "validation loss: 1.3819, validation acc: 57.5871\n",
      "\n",
      "Epoch 73\n",
      "\n",
      "Epoch [73/400], Step [0/439], Loss: 1.1767\n",
      "Epoch [73/400], Step [20/439], Loss: 1.1902\n",
      "Epoch [73/400], Step [40/439], Loss: 1.2385\n",
      "Epoch [73/400], Step [60/439], Loss: 1.2928\n",
      "Epoch [73/400], Step [80/439], Loss: 1.1176\n",
      "Epoch [73/400], Step [100/439], Loss: 1.2402\n",
      "Epoch [73/400], Step [120/439], Loss: 1.3100\n",
      "Epoch [73/400], Step [140/439], Loss: 1.2001\n",
      "Epoch [73/400], Step [160/439], Loss: 1.0438\n",
      "Epoch [73/400], Step [180/439], Loss: 1.4119\n",
      "Epoch [73/400], Step [200/439], Loss: 1.3087\n",
      "Epoch [73/400], Step [220/439], Loss: 1.2276\n",
      "Epoch [73/400], Step [240/439], Loss: 1.4643\n",
      "Epoch [73/400], Step [260/439], Loss: 1.2614\n",
      "Epoch [73/400], Step [280/439], Loss: 0.9742\n",
      "Epoch [73/400], Step [300/439], Loss: 1.0857\n",
      "Epoch [73/400], Step [320/439], Loss: 1.4505\n",
      "Epoch [73/400], Step [340/439], Loss: 1.0979\n",
      "Epoch [73/400], Step [360/439], Loss: 1.0940\n",
      "Epoch [73/400], Step [380/439], Loss: 1.2467\n",
      "Epoch [73/400], Step [400/439], Loss: 1.2265\n",
      "Epoch [73/400], Step [420/439], Loss: 1.3405\n",
      "\n",
      "train-loss: 1.4492, train-acc: 56.5227\n",
      "validation loss: 1.3802, validation acc: 59.6162\n",
      "\n",
      "Improvement-Detected, save-model\n",
      "Epoch 74\n",
      "\n",
      "Epoch [74/400], Step [0/439], Loss: 1.1074\n",
      "Epoch [74/400], Step [20/439], Loss: 0.8976\n",
      "Epoch [74/400], Step [40/439], Loss: 1.2564\n",
      "Epoch [74/400], Step [60/439], Loss: 1.3257\n",
      "Epoch [74/400], Step [80/439], Loss: 1.1603\n",
      "Epoch [74/400], Step [100/439], Loss: 1.2013\n",
      "Epoch [74/400], Step [120/439], Loss: 1.3832\n",
      "Epoch [74/400], Step [140/439], Loss: 1.2576\n",
      "Epoch [74/400], Step [160/439], Loss: 1.6059\n",
      "Epoch [74/400], Step [180/439], Loss: 1.5290\n",
      "Epoch [74/400], Step [200/439], Loss: 1.2753\n",
      "Epoch [74/400], Step [220/439], Loss: 1.3972\n",
      "Epoch [74/400], Step [240/439], Loss: 1.3629\n",
      "Epoch [74/400], Step [260/439], Loss: 1.2813\n",
      "Epoch [74/400], Step [280/439], Loss: 1.5165\n",
      "Epoch [74/400], Step [300/439], Loss: 1.4508\n",
      "Epoch [74/400], Step [320/439], Loss: 1.4188\n",
      "Epoch [74/400], Step [340/439], Loss: 1.3361\n",
      "Epoch [74/400], Step [360/439], Loss: 1.4342\n",
      "Epoch [74/400], Step [380/439], Loss: 0.9009\n",
      "Epoch [74/400], Step [400/439], Loss: 1.3769\n",
      "Epoch [74/400], Step [420/439], Loss: 1.2845\n",
      "\n",
      "train-loss: 1.4479, train-acc: 56.1805\n",
      "validation loss: 1.3787, validation acc: 59.5280\n",
      "\n",
      "Epoch 75\n",
      "\n",
      "Epoch [75/400], Step [0/439], Loss: 1.2156\n",
      "Epoch [75/400], Step [20/439], Loss: 1.5509\n",
      "Epoch [75/400], Step [40/439], Loss: 1.3181\n",
      "Epoch [75/400], Step [60/439], Loss: 1.5535\n",
      "Epoch [75/400], Step [80/439], Loss: 1.2568\n",
      "Epoch [75/400], Step [100/439], Loss: 1.2984\n",
      "Epoch [75/400], Step [120/439], Loss: 1.6026\n",
      "Epoch [75/400], Step [140/439], Loss: 1.3614\n",
      "Epoch [75/400], Step [160/439], Loss: 1.2386\n",
      "Epoch [75/400], Step [180/439], Loss: 1.0706\n",
      "Epoch [75/400], Step [200/439], Loss: 1.2921\n",
      "Epoch [75/400], Step [220/439], Loss: 1.3355\n",
      "Epoch [75/400], Step [240/439], Loss: 1.4590\n",
      "Epoch [75/400], Step [260/439], Loss: 1.5785\n",
      "Epoch [75/400], Step [280/439], Loss: 1.3720\n",
      "Epoch [75/400], Step [300/439], Loss: 1.3146\n",
      "Epoch [75/400], Step [320/439], Loss: 1.3290\n",
      "Epoch [75/400], Step [340/439], Loss: 1.2730\n",
      "Epoch [75/400], Step [360/439], Loss: 1.2885\n",
      "Epoch [75/400], Step [380/439], Loss: 1.1579\n",
      "Epoch [75/400], Step [400/439], Loss: 1.1243\n",
      "Epoch [75/400], Step [420/439], Loss: 1.5699\n",
      "\n",
      "train-loss: 1.4466, train-acc: 56.1449\n",
      "validation loss: 1.3771, validation acc: 60.5205\n",
      "\n",
      "Epoch 76\n",
      "\n",
      "Epoch [76/400], Step [0/439], Loss: 0.8757\n",
      "Epoch [76/400], Step [20/439], Loss: 1.3901\n",
      "Epoch [76/400], Step [40/439], Loss: 1.2137\n",
      "Epoch [76/400], Step [60/439], Loss: 1.5114\n",
      "Epoch [76/400], Step [80/439], Loss: 1.7658\n",
      "Epoch [76/400], Step [100/439], Loss: 1.0744\n",
      "Epoch [76/400], Step [120/439], Loss: 1.2868\n",
      "Epoch [76/400], Step [140/439], Loss: 1.0798\n",
      "Epoch [76/400], Step [160/439], Loss: 1.1482\n",
      "Epoch [76/400], Step [180/439], Loss: 1.4281\n",
      "Epoch [76/400], Step [200/439], Loss: 1.1046\n",
      "Epoch [76/400], Step [220/439], Loss: 1.3623\n",
      "Epoch [76/400], Step [240/439], Loss: 1.3578\n",
      "Epoch [76/400], Step [260/439], Loss: 0.8751\n",
      "Epoch [76/400], Step [280/439], Loss: 1.1564\n",
      "Epoch [76/400], Step [300/439], Loss: 1.1775\n",
      "Epoch [76/400], Step [320/439], Loss: 1.2343\n",
      "Epoch [76/400], Step [340/439], Loss: 1.4362\n",
      "Epoch [76/400], Step [360/439], Loss: 1.3100\n",
      "Epoch [76/400], Step [380/439], Loss: 1.1467\n",
      "Epoch [76/400], Step [400/439], Loss: 1.8101\n",
      "Epoch [76/400], Step [420/439], Loss: 1.4627\n",
      "\n",
      "train-loss: 1.4453, train-acc: 56.7864\n",
      "validation loss: 1.3760, validation acc: 57.5651\n",
      "\n",
      "Epoch 77\n",
      "\n",
      "Epoch [77/400], Step [0/439], Loss: 1.0011\n",
      "Epoch [77/400], Step [20/439], Loss: 1.0053\n",
      "Epoch [77/400], Step [40/439], Loss: 1.5974\n",
      "Epoch [77/400], Step [60/439], Loss: 0.9623\n",
      "Epoch [77/400], Step [80/439], Loss: 1.4264\n",
      "Epoch [77/400], Step [100/439], Loss: 1.0161\n",
      "Epoch [77/400], Step [120/439], Loss: 1.4528\n",
      "Epoch [77/400], Step [140/439], Loss: 1.8742\n",
      "Epoch [77/400], Step [160/439], Loss: 1.4881\n",
      "Epoch [77/400], Step [180/439], Loss: 1.8277\n",
      "Epoch [77/400], Step [200/439], Loss: 1.2114\n",
      "Epoch [77/400], Step [220/439], Loss: 1.0420\n",
      "Epoch [77/400], Step [240/439], Loss: 1.4776\n",
      "Epoch [77/400], Step [260/439], Loss: 1.3455\n",
      "Epoch [77/400], Step [280/439], Loss: 1.2719\n",
      "Epoch [77/400], Step [300/439], Loss: 1.2433\n",
      "Epoch [77/400], Step [320/439], Loss: 1.3278\n",
      "Epoch [77/400], Step [340/439], Loss: 1.5015\n",
      "Epoch [77/400], Step [360/439], Loss: 1.6738\n",
      "Epoch [77/400], Step [380/439], Loss: 1.4843\n",
      "Epoch [77/400], Step [400/439], Loss: 1.0833\n",
      "Epoch [77/400], Step [420/439], Loss: 1.0720\n",
      "\n",
      "train-loss: 1.4440, train-acc: 55.9524\n",
      "validation loss: 1.3744, validation acc: 59.8809\n",
      "\n",
      "Epoch 78\n",
      "\n",
      "Epoch [78/400], Step [0/439], Loss: 1.0864\n",
      "Epoch [78/400], Step [20/439], Loss: 1.4677\n",
      "Epoch [78/400], Step [40/439], Loss: 1.2904\n",
      "Epoch [78/400], Step [60/439], Loss: 1.0662\n",
      "Epoch [78/400], Step [80/439], Loss: 1.2436\n",
      "Epoch [78/400], Step [100/439], Loss: 1.2447\n",
      "Epoch [78/400], Step [120/439], Loss: 1.3564\n",
      "Epoch [78/400], Step [140/439], Loss: 1.5576\n",
      "Epoch [78/400], Step [160/439], Loss: 1.2684\n",
      "Epoch [78/400], Step [180/439], Loss: 1.5157\n",
      "Epoch [78/400], Step [200/439], Loss: 1.2909\n",
      "Epoch [78/400], Step [220/439], Loss: 1.1174\n",
      "Epoch [78/400], Step [240/439], Loss: 1.2970\n",
      "Epoch [78/400], Step [260/439], Loss: 1.1288\n",
      "Epoch [78/400], Step [280/439], Loss: 1.3435\n",
      "Epoch [78/400], Step [300/439], Loss: 1.5806\n",
      "Epoch [78/400], Step [320/439], Loss: 1.2156\n",
      "Epoch [78/400], Step [340/439], Loss: 1.4089\n",
      "Epoch [78/400], Step [360/439], Loss: 1.0255\n",
      "Epoch [78/400], Step [380/439], Loss: 1.0696\n",
      "Epoch [78/400], Step [400/439], Loss: 1.0391\n",
      "Epoch [78/400], Step [420/439], Loss: 1.2688\n",
      "\n",
      "train-loss: 1.4428, train-acc: 56.2874\n",
      "validation loss: 1.3741, validation acc: 54.5434\n",
      "\n",
      "Epoch 79\n",
      "\n",
      "Epoch [79/400], Step [0/439], Loss: 1.3037\n",
      "Epoch [79/400], Step [20/439], Loss: 1.0681\n",
      "Epoch [79/400], Step [40/439], Loss: 1.2428\n",
      "Epoch [79/400], Step [60/439], Loss: 1.2443\n",
      "Epoch [79/400], Step [80/439], Loss: 1.1566\n",
      "Epoch [79/400], Step [100/439], Loss: 0.8754\n",
      "Epoch [79/400], Step [120/439], Loss: 1.2519\n",
      "Epoch [79/400], Step [140/439], Loss: 1.2647\n",
      "Epoch [79/400], Step [160/439], Loss: 1.3593\n",
      "Epoch [79/400], Step [180/439], Loss: 1.2657\n",
      "Epoch [79/400], Step [200/439], Loss: 1.2832\n",
      "Epoch [79/400], Step [220/439], Loss: 1.4953\n",
      "Epoch [79/400], Step [240/439], Loss: 1.2343\n",
      "Epoch [79/400], Step [260/439], Loss: 1.2908\n",
      "Epoch [79/400], Step [280/439], Loss: 1.3158\n",
      "Epoch [79/400], Step [300/439], Loss: 1.6503\n",
      "Epoch [79/400], Step [320/439], Loss: 1.0291\n",
      "Epoch [79/400], Step [340/439], Loss: 1.3941\n",
      "Epoch [79/400], Step [360/439], Loss: 0.8956\n",
      "Epoch [79/400], Step [380/439], Loss: 1.3441\n",
      "Epoch [79/400], Step [400/439], Loss: 1.1893\n",
      "Epoch [79/400], Step [420/439], Loss: 1.3221\n",
      "\n",
      "train-loss: 1.4416, train-acc: 56.6153\n",
      "validation loss: 1.3726, validation acc: 60.0132\n",
      "\n",
      "Epoch 80\n",
      "\n",
      "Epoch [80/400], Step [0/439], Loss: 1.0456\n",
      "Epoch [80/400], Step [20/439], Loss: 1.6821\n",
      "Epoch [80/400], Step [40/439], Loss: 1.0926\n",
      "Epoch [80/400], Step [60/439], Loss: 0.9592\n",
      "Epoch [80/400], Step [80/439], Loss: 1.3081\n",
      "Epoch [80/400], Step [100/439], Loss: 1.2457\n",
      "Epoch [80/400], Step [120/439], Loss: 1.1621\n",
      "Epoch [80/400], Step [140/439], Loss: 1.2864\n",
      "Epoch [80/400], Step [160/439], Loss: 0.8331\n",
      "Epoch [80/400], Step [180/439], Loss: 1.3672\n",
      "Epoch [80/400], Step [200/439], Loss: 1.2525\n",
      "Epoch [80/400], Step [220/439], Loss: 1.4771\n",
      "Epoch [80/400], Step [240/439], Loss: 1.3136\n",
      "Epoch [80/400], Step [260/439], Loss: 1.2893\n",
      "Epoch [80/400], Step [280/439], Loss: 1.3968\n",
      "Epoch [80/400], Step [300/439], Loss: 1.0048\n",
      "Epoch [80/400], Step [320/439], Loss: 1.1656\n",
      "Epoch [80/400], Step [340/439], Loss: 0.7886\n",
      "Epoch [80/400], Step [360/439], Loss: 1.2753\n",
      "Epoch [80/400], Step [380/439], Loss: 1.1126\n",
      "Epoch [80/400], Step [400/439], Loss: 1.1890\n",
      "Epoch [80/400], Step [420/439], Loss: 1.3728\n",
      "\n",
      "train-loss: 1.4404, train-acc: 55.9880\n",
      "validation loss: 1.3719, validation acc: 56.9916\n",
      "\n",
      "Epoch 81\n",
      "\n",
      "Epoch [81/400], Step [0/439], Loss: 1.1884\n",
      "Epoch [81/400], Step [20/439], Loss: 1.0446\n",
      "Epoch [81/400], Step [40/439], Loss: 1.1061\n",
      "Epoch [81/400], Step [60/439], Loss: 1.0746\n",
      "Epoch [81/400], Step [80/439], Loss: 1.7486\n",
      "Epoch [81/400], Step [100/439], Loss: 1.4849\n",
      "Epoch [81/400], Step [120/439], Loss: 1.2697\n",
      "Epoch [81/400], Step [140/439], Loss: 1.2025\n",
      "Epoch [81/400], Step [160/439], Loss: 1.6537\n",
      "Epoch [81/400], Step [180/439], Loss: 1.1511\n",
      "Epoch [81/400], Step [200/439], Loss: 1.4762\n",
      "Epoch [81/400], Step [220/439], Loss: 1.5568\n",
      "Epoch [81/400], Step [240/439], Loss: 1.5930\n",
      "Epoch [81/400], Step [260/439], Loss: 1.0504\n",
      "Epoch [81/400], Step [280/439], Loss: 1.1365\n",
      "Epoch [81/400], Step [300/439], Loss: 1.3303\n",
      "Epoch [81/400], Step [320/439], Loss: 1.0471\n",
      "Epoch [81/400], Step [340/439], Loss: 1.0486\n",
      "Epoch [81/400], Step [360/439], Loss: 1.2440\n",
      "Epoch [81/400], Step [380/439], Loss: 0.8887\n",
      "Epoch [81/400], Step [400/439], Loss: 1.1208\n",
      "Epoch [81/400], Step [420/439], Loss: 1.1089\n",
      "\n",
      "train-loss: 1.4391, train-acc: 56.5654\n",
      "validation loss: 1.3706, validation acc: 60.0132\n",
      "\n",
      "Epoch 82\n",
      "\n",
      "Epoch [82/400], Step [0/439], Loss: 1.2325\n",
      "Epoch [82/400], Step [20/439], Loss: 1.1568\n",
      "Epoch [82/400], Step [40/439], Loss: 1.3556\n",
      "Epoch [82/400], Step [60/439], Loss: 1.2635\n",
      "Epoch [82/400], Step [80/439], Loss: 1.1177\n",
      "Epoch [82/400], Step [100/439], Loss: 1.2717\n",
      "Epoch [82/400], Step [120/439], Loss: 1.2580\n",
      "Epoch [82/400], Step [140/439], Loss: 1.3183\n",
      "Epoch [82/400], Step [160/439], Loss: 1.1676\n",
      "Epoch [82/400], Step [180/439], Loss: 1.4683\n",
      "Epoch [82/400], Step [200/439], Loss: 1.2637\n",
      "Epoch [82/400], Step [220/439], Loss: 1.1586\n",
      "Epoch [82/400], Step [240/439], Loss: 1.1238\n",
      "Epoch [82/400], Step [260/439], Loss: 1.3939\n",
      "Epoch [82/400], Step [280/439], Loss: 1.4058\n",
      "Epoch [82/400], Step [300/439], Loss: 1.2538\n",
      "Epoch [82/400], Step [320/439], Loss: 1.3450\n",
      "Epoch [82/400], Step [340/439], Loss: 1.2884\n",
      "Epoch [82/400], Step [360/439], Loss: 0.9519\n",
      "Epoch [82/400], Step [380/439], Loss: 1.2417\n",
      "Epoch [82/400], Step [400/439], Loss: 1.1663\n",
      "Epoch [82/400], Step [420/439], Loss: 0.9929\n",
      "\n",
      "train-loss: 1.4379, train-acc: 56.3516\n",
      "validation loss: 1.3691, validation acc: 60.5426\n",
      "\n",
      "Epoch 83\n",
      "\n",
      "Epoch [83/400], Step [0/439], Loss: 0.8476\n",
      "Epoch [83/400], Step [20/439], Loss: 1.2990\n",
      "Epoch [83/400], Step [40/439], Loss: 1.3848\n",
      "Epoch [83/400], Step [60/439], Loss: 1.3621\n",
      "Epoch [83/400], Step [80/439], Loss: 1.0007\n",
      "Epoch [83/400], Step [100/439], Loss: 1.0365\n",
      "Epoch [83/400], Step [120/439], Loss: 0.9077\n",
      "Epoch [83/400], Step [140/439], Loss: 0.9507\n",
      "Epoch [83/400], Step [160/439], Loss: 0.8535\n",
      "Epoch [83/400], Step [180/439], Loss: 1.2963\n",
      "Epoch [83/400], Step [200/439], Loss: 1.3725\n",
      "Epoch [83/400], Step [220/439], Loss: 1.4445\n",
      "Epoch [83/400], Step [240/439], Loss: 1.2764\n",
      "Epoch [83/400], Step [260/439], Loss: 1.0173\n",
      "Epoch [83/400], Step [280/439], Loss: 1.1388\n",
      "Epoch [83/400], Step [300/439], Loss: 1.4936\n",
      "Epoch [83/400], Step [320/439], Loss: 0.9012\n",
      "Epoch [83/400], Step [340/439], Loss: 1.0102\n",
      "Epoch [83/400], Step [360/439], Loss: 1.2145\n",
      "Epoch [83/400], Step [380/439], Loss: 1.1965\n",
      "Epoch [83/400], Step [400/439], Loss: 1.6677\n",
      "Epoch [83/400], Step [420/439], Loss: 0.9562\n",
      "\n",
      "train-loss: 1.4367, train-acc: 56.5726\n",
      "validation loss: 1.3677, validation acc: 59.4618\n",
      "\n",
      "Epoch 84\n",
      "\n",
      "Epoch [84/400], Step [0/439], Loss: 0.8749\n",
      "Epoch [84/400], Step [20/439], Loss: 0.9568\n",
      "Epoch [84/400], Step [40/439], Loss: 1.2774\n",
      "Epoch [84/400], Step [60/439], Loss: 1.2788\n",
      "Epoch [84/400], Step [80/439], Loss: 1.3440\n",
      "Epoch [84/400], Step [100/439], Loss: 1.2575\n",
      "Epoch [84/400], Step [120/439], Loss: 1.1123\n",
      "Epoch [84/400], Step [140/439], Loss: 1.1789\n",
      "Epoch [84/400], Step [160/439], Loss: 1.5551\n",
      "Epoch [84/400], Step [180/439], Loss: 1.5193\n",
      "Epoch [84/400], Step [200/439], Loss: 1.0621\n",
      "Epoch [84/400], Step [220/439], Loss: 1.4527\n",
      "Epoch [84/400], Step [240/439], Loss: 1.2914\n",
      "Epoch [84/400], Step [260/439], Loss: 1.1957\n",
      "Epoch [84/400], Step [280/439], Loss: 1.2833\n",
      "Epoch [84/400], Step [300/439], Loss: 1.0104\n",
      "Epoch [84/400], Step [320/439], Loss: 1.0120\n",
      "Epoch [84/400], Step [340/439], Loss: 1.4821\n",
      "Epoch [84/400], Step [360/439], Loss: 1.4444\n",
      "Epoch [84/400], Step [380/439], Loss: 1.3537\n",
      "Epoch [84/400], Step [400/439], Loss: 1.3309\n",
      "Epoch [84/400], Step [420/439], Loss: 1.5796\n",
      "\n",
      "train-loss: 1.4355, train-acc: 56.5583\n",
      "validation loss: 1.3669, validation acc: 57.2783\n",
      "\n",
      "Epoch 85\n",
      "\n",
      "Epoch [85/400], Step [0/439], Loss: 1.3670\n",
      "Epoch [85/400], Step [20/439], Loss: 1.3382\n",
      "Epoch [85/400], Step [40/439], Loss: 1.0778\n",
      "Epoch [85/400], Step [60/439], Loss: 1.3594\n",
      "Epoch [85/400], Step [80/439], Loss: 1.1893\n",
      "Epoch [85/400], Step [100/439], Loss: 1.2935\n",
      "Epoch [85/400], Step [120/439], Loss: 1.5398\n",
      "Epoch [85/400], Step [140/439], Loss: 1.2933\n",
      "Epoch [85/400], Step [160/439], Loss: 1.0634\n",
      "Epoch [85/400], Step [180/439], Loss: 1.5569\n",
      "Epoch [85/400], Step [200/439], Loss: 1.2161\n",
      "Epoch [85/400], Step [220/439], Loss: 1.0711\n",
      "Epoch [85/400], Step [240/439], Loss: 0.9316\n",
      "Epoch [85/400], Step [260/439], Loss: 1.3597\n",
      "Epoch [85/400], Step [280/439], Loss: 1.0837\n",
      "Epoch [85/400], Step [300/439], Loss: 1.0268\n",
      "Epoch [85/400], Step [320/439], Loss: 0.9954\n",
      "Epoch [85/400], Step [340/439], Loss: 1.6053\n",
      "Epoch [85/400], Step [360/439], Loss: 1.4085\n",
      "Epoch [85/400], Step [380/439], Loss: 1.1915\n",
      "Epoch [85/400], Step [400/439], Loss: 1.2121\n",
      "Epoch [85/400], Step [420/439], Loss: 1.3225\n",
      "\n",
      "train-loss: 1.4343, train-acc: 56.6082\n",
      "validation loss: 1.3652, validation acc: 61.4248\n",
      "\n",
      "Improvement-Detected, save-model\n",
      "Epoch 86\n",
      "\n",
      "Epoch [86/400], Step [0/439], Loss: 1.4749\n",
      "Epoch [86/400], Step [20/439], Loss: 1.2945\n",
      "Epoch [86/400], Step [40/439], Loss: 1.1355\n",
      "Epoch [86/400], Step [60/439], Loss: 1.3805\n",
      "Epoch [86/400], Step [80/439], Loss: 1.1455\n",
      "Epoch [86/400], Step [100/439], Loss: 1.5915\n",
      "Epoch [86/400], Step [120/439], Loss: 1.2101\n",
      "Epoch [86/400], Step [140/439], Loss: 1.7022\n",
      "Epoch [86/400], Step [160/439], Loss: 1.0081\n",
      "Epoch [86/400], Step [180/439], Loss: 1.4681\n",
      "Epoch [86/400], Step [200/439], Loss: 1.3877\n",
      "Epoch [86/400], Step [220/439], Loss: 1.1805\n",
      "Epoch [86/400], Step [240/439], Loss: 1.6307\n",
      "Epoch [86/400], Step [260/439], Loss: 1.5555\n",
      "Epoch [86/400], Step [280/439], Loss: 1.3155\n",
      "Epoch [86/400], Step [300/439], Loss: 1.5527\n",
      "Epoch [86/400], Step [320/439], Loss: 1.8812\n",
      "Epoch [86/400], Step [340/439], Loss: 1.4602\n",
      "Epoch [86/400], Step [360/439], Loss: 1.1359\n",
      "Epoch [86/400], Step [380/439], Loss: 1.0672\n",
      "Epoch [86/400], Step [400/439], Loss: 1.3324\n",
      "Epoch [86/400], Step [420/439], Loss: 1.3490\n",
      "\n",
      "train-loss: 1.4332, train-acc: 56.6724\n",
      "validation loss: 1.3644, validation acc: 56.8372\n",
      "\n",
      "Epoch 87\n",
      "\n",
      "Epoch [87/400], Step [0/439], Loss: 1.4463\n",
      "Epoch [87/400], Step [20/439], Loss: 1.1847\n",
      "Epoch [87/400], Step [40/439], Loss: 1.4845\n",
      "Epoch [87/400], Step [60/439], Loss: 1.2728\n",
      "Epoch [87/400], Step [80/439], Loss: 1.1604\n",
      "Epoch [87/400], Step [100/439], Loss: 1.3509\n",
      "Epoch [87/400], Step [120/439], Loss: 0.9692\n",
      "Epoch [87/400], Step [140/439], Loss: 1.0047\n",
      "Epoch [87/400], Step [160/439], Loss: 1.0427\n",
      "Epoch [87/400], Step [180/439], Loss: 1.1642\n",
      "Epoch [87/400], Step [200/439], Loss: 1.3736\n",
      "Epoch [87/400], Step [220/439], Loss: 1.6119\n",
      "Epoch [87/400], Step [240/439], Loss: 1.1069\n",
      "Epoch [87/400], Step [260/439], Loss: 1.1286\n",
      "Epoch [87/400], Step [280/439], Loss: 1.2171\n",
      "Epoch [87/400], Step [300/439], Loss: 1.4403\n",
      "Epoch [87/400], Step [320/439], Loss: 1.5373\n",
      "Epoch [87/400], Step [340/439], Loss: 1.1554\n",
      "Epoch [87/400], Step [360/439], Loss: 1.2739\n",
      "Epoch [87/400], Step [380/439], Loss: 1.0198\n",
      "Epoch [87/400], Step [400/439], Loss: 1.3369\n",
      "Epoch [87/400], Step [420/439], Loss: 1.4900\n",
      "\n",
      "train-loss: 1.4320, train-acc: 56.6439\n",
      "validation loss: 1.3633, validation acc: 59.4839\n",
      "\n",
      "Epoch 88\n",
      "\n",
      "Epoch [88/400], Step [0/439], Loss: 1.3751\n",
      "Epoch [88/400], Step [20/439], Loss: 1.2660\n",
      "Epoch [88/400], Step [40/439], Loss: 1.2552\n",
      "Epoch [88/400], Step [60/439], Loss: 1.2054\n",
      "Epoch [88/400], Step [80/439], Loss: 0.9180\n",
      "Epoch [88/400], Step [100/439], Loss: 1.2633\n",
      "Epoch [88/400], Step [120/439], Loss: 1.1153\n",
      "Epoch [88/400], Step [140/439], Loss: 1.7649\n",
      "Epoch [88/400], Step [160/439], Loss: 1.2847\n",
      "Epoch [88/400], Step [180/439], Loss: 1.6384\n",
      "Epoch [88/400], Step [200/439], Loss: 0.9806\n",
      "Epoch [88/400], Step [220/439], Loss: 1.3788\n",
      "Epoch [88/400], Step [240/439], Loss: 1.3596\n",
      "Epoch [88/400], Step [260/439], Loss: 0.7275\n",
      "Epoch [88/400], Step [280/439], Loss: 1.2510\n",
      "Epoch [88/400], Step [300/439], Loss: 1.2357\n",
      "Epoch [88/400], Step [320/439], Loss: 1.5186\n",
      "Epoch [88/400], Step [340/439], Loss: 1.1996\n",
      "Epoch [88/400], Step [360/439], Loss: 0.9471\n",
      "Epoch [88/400], Step [380/439], Loss: 1.2479\n",
      "Epoch [88/400], Step [400/439], Loss: 1.1826\n",
      "Epoch [88/400], Step [420/439], Loss: 1.1357\n",
      "\n",
      "train-loss: 1.4308, train-acc: 57.2427\n",
      "validation loss: 1.3629, validation acc: 55.6021\n",
      "\n",
      "Epoch 89\n",
      "\n",
      "Epoch [89/400], Step [0/439], Loss: 1.0742\n",
      "Epoch [89/400], Step [20/439], Loss: 1.2647\n",
      "Epoch [89/400], Step [40/439], Loss: 1.3348\n",
      "Epoch [89/400], Step [60/439], Loss: 1.4935\n",
      "Epoch [89/400], Step [80/439], Loss: 1.3164\n",
      "Epoch [89/400], Step [100/439], Loss: 1.2979\n",
      "Epoch [89/400], Step [120/439], Loss: 1.1134\n",
      "Epoch [89/400], Step [140/439], Loss: 1.6728\n",
      "Epoch [89/400], Step [160/439], Loss: 1.2950\n",
      "Epoch [89/400], Step [180/439], Loss: 0.9307\n",
      "Epoch [89/400], Step [200/439], Loss: 1.3370\n",
      "Epoch [89/400], Step [220/439], Loss: 1.5322\n",
      "Epoch [89/400], Step [240/439], Loss: 0.9991\n",
      "Epoch [89/400], Step [260/439], Loss: 1.3793\n",
      "Epoch [89/400], Step [280/439], Loss: 1.1769\n",
      "Epoch [89/400], Step [300/439], Loss: 1.5458\n",
      "Epoch [89/400], Step [320/439], Loss: 1.2314\n",
      "Epoch [89/400], Step [340/439], Loss: 1.1456\n",
      "Epoch [89/400], Step [360/439], Loss: 1.3175\n",
      "Epoch [89/400], Step [380/439], Loss: 1.3871\n",
      "Epoch [89/400], Step [400/439], Loss: 1.1116\n",
      "Epoch [89/400], Step [420/439], Loss: 1.2610\n",
      "\n",
      "train-loss: 1.4296, train-acc: 57.1215\n",
      "validation loss: 1.3620, validation acc: 57.5210\n",
      "\n",
      "Epoch 90\n",
      "\n",
      "Epoch [90/400], Step [0/439], Loss: 1.2817\n",
      "Epoch [90/400], Step [20/439], Loss: 1.2865\n",
      "Epoch [90/400], Step [40/439], Loss: 1.4478\n",
      "Epoch [90/400], Step [60/439], Loss: 1.1180\n",
      "Epoch [90/400], Step [80/439], Loss: 1.0110\n",
      "Epoch [90/400], Step [100/439], Loss: 1.1966\n",
      "Epoch [90/400], Step [120/439], Loss: 1.3591\n",
      "Epoch [90/400], Step [140/439], Loss: 1.7163\n",
      "Epoch [90/400], Step [160/439], Loss: 1.1660\n",
      "Epoch [90/400], Step [180/439], Loss: 1.3648\n",
      "Epoch [90/400], Step [200/439], Loss: 1.0646\n",
      "Epoch [90/400], Step [220/439], Loss: 1.3400\n",
      "Epoch [90/400], Step [240/439], Loss: 1.1894\n",
      "Epoch [90/400], Step [260/439], Loss: 1.3388\n",
      "Epoch [90/400], Step [280/439], Loss: 1.2911\n",
      "Epoch [90/400], Step [300/439], Loss: 1.2906\n",
      "Epoch [90/400], Step [320/439], Loss: 1.1323\n",
      "Epoch [90/400], Step [340/439], Loss: 1.4189\n",
      "Epoch [90/400], Step [360/439], Loss: 1.1450\n",
      "Epoch [90/400], Step [380/439], Loss: 0.9488\n",
      "Epoch [90/400], Step [400/439], Loss: 1.1942\n",
      "Epoch [90/400], Step [420/439], Loss: 1.3191\n",
      "\n",
      "train-loss: 1.4284, train-acc: 56.9575\n",
      "validation loss: 1.3615, validation acc: 55.4918\n",
      "\n",
      "Epoch 91\n",
      "\n",
      "Epoch [91/400], Step [0/439], Loss: 1.1510\n",
      "Epoch [91/400], Step [20/439], Loss: 1.1657\n",
      "Epoch [91/400], Step [40/439], Loss: 1.2309\n",
      "Epoch [91/400], Step [60/439], Loss: 1.5483\n",
      "Epoch [91/400], Step [80/439], Loss: 0.9235\n",
      "Epoch [91/400], Step [100/439], Loss: 1.0344\n",
      "Epoch [91/400], Step [120/439], Loss: 1.2902\n",
      "Epoch [91/400], Step [140/439], Loss: 1.0391\n",
      "Epoch [91/400], Step [160/439], Loss: 1.4548\n",
      "Epoch [91/400], Step [180/439], Loss: 1.3881\n",
      "Epoch [91/400], Step [200/439], Loss: 1.0939\n",
      "Epoch [91/400], Step [220/439], Loss: 1.1218\n",
      "Epoch [91/400], Step [240/439], Loss: 1.3495\n",
      "Epoch [91/400], Step [260/439], Loss: 1.2748\n",
      "Epoch [91/400], Step [280/439], Loss: 1.4179\n",
      "Epoch [91/400], Step [300/439], Loss: 1.4660\n",
      "Epoch [91/400], Step [320/439], Loss: 1.5723\n",
      "Epoch [91/400], Step [340/439], Loss: 1.2601\n",
      "Epoch [91/400], Step [360/439], Loss: 1.1602\n",
      "Epoch [91/400], Step [380/439], Loss: 1.2022\n",
      "Epoch [91/400], Step [400/439], Loss: 1.3692\n",
      "Epoch [91/400], Step [420/439], Loss: 1.1395\n",
      "\n",
      "train-loss: 1.4272, train-acc: 57.7131\n",
      "validation loss: 1.3605, validation acc: 58.6678\n",
      "\n",
      "Epoch 92\n",
      "\n",
      "Epoch [92/400], Step [0/439], Loss: 0.9215\n",
      "Epoch [92/400], Step [20/439], Loss: 1.2169\n",
      "Epoch [92/400], Step [40/439], Loss: 1.0063\n",
      "Epoch [92/400], Step [60/439], Loss: 1.0029\n",
      "Epoch [92/400], Step [80/439], Loss: 1.1523\n",
      "Epoch [92/400], Step [100/439], Loss: 1.6332\n",
      "Epoch [92/400], Step [120/439], Loss: 1.2001\n",
      "Epoch [92/400], Step [140/439], Loss: 1.5561\n",
      "Epoch [92/400], Step [160/439], Loss: 1.4997\n",
      "Epoch [92/400], Step [180/439], Loss: 1.1659\n",
      "Epoch [92/400], Step [200/439], Loss: 1.6100\n",
      "Epoch [92/400], Step [220/439], Loss: 1.1944\n",
      "Epoch [92/400], Step [240/439], Loss: 1.3371\n",
      "Epoch [92/400], Step [260/439], Loss: 1.2888\n",
      "Epoch [92/400], Step [280/439], Loss: 0.9676\n",
      "Epoch [92/400], Step [300/439], Loss: 0.9756\n",
      "Epoch [92/400], Step [320/439], Loss: 1.3686\n",
      "Epoch [92/400], Step [340/439], Loss: 1.3287\n",
      "Epoch [92/400], Step [360/439], Loss: 1.1537\n",
      "Epoch [92/400], Step [380/439], Loss: 1.6355\n",
      "Epoch [92/400], Step [400/439], Loss: 1.4214\n",
      "Epoch [92/400], Step [420/439], Loss: 1.1363\n",
      "\n",
      "train-loss: 1.4260, train-acc: 57.4993\n",
      "validation loss: 1.3594, validation acc: 59.6162\n",
      "\n",
      "Epoch 93\n",
      "\n",
      "Epoch [93/400], Step [0/439], Loss: 1.1789\n",
      "Epoch [93/400], Step [20/439], Loss: 1.4318\n",
      "Epoch [93/400], Step [40/439], Loss: 1.1366\n",
      "Epoch [93/400], Step [60/439], Loss: 1.2391\n",
      "Epoch [93/400], Step [80/439], Loss: 1.3489\n",
      "Epoch [93/400], Step [100/439], Loss: 1.3688\n",
      "Epoch [93/400], Step [120/439], Loss: 1.1353\n",
      "Epoch [93/400], Step [140/439], Loss: 1.2207\n",
      "Epoch [93/400], Step [160/439], Loss: 1.0831\n",
      "Epoch [93/400], Step [180/439], Loss: 1.7541\n",
      "Epoch [93/400], Step [200/439], Loss: 1.5880\n",
      "Epoch [93/400], Step [220/439], Loss: 1.1562\n",
      "Epoch [93/400], Step [240/439], Loss: 1.4259\n",
      "Epoch [93/400], Step [260/439], Loss: 1.1039\n",
      "Epoch [93/400], Step [280/439], Loss: 1.4245\n",
      "Epoch [93/400], Step [300/439], Loss: 1.3580\n",
      "Epoch [93/400], Step [320/439], Loss: 1.2695\n",
      "Epoch [93/400], Step [340/439], Loss: 1.2202\n",
      "Epoch [93/400], Step [360/439], Loss: 1.7983\n",
      "Epoch [93/400], Step [380/439], Loss: 1.1023\n",
      "Epoch [93/400], Step [400/439], Loss: 1.3147\n",
      "Epoch [93/400], Step [420/439], Loss: 1.3555\n",
      "\n",
      "train-loss: 1.4248, train-acc: 57.3139\n",
      "validation loss: 1.3582, validation acc: 60.0794\n",
      "\n",
      "Epoch 94\n",
      "\n",
      "Epoch [94/400], Step [0/439], Loss: 1.1006\n",
      "Epoch [94/400], Step [20/439], Loss: 1.6044\n",
      "Epoch [94/400], Step [40/439], Loss: 1.2851\n",
      "Epoch [94/400], Step [60/439], Loss: 1.5297\n",
      "Epoch [94/400], Step [80/439], Loss: 1.2308\n",
      "Epoch [94/400], Step [100/439], Loss: 1.4484\n",
      "Epoch [94/400], Step [120/439], Loss: 1.4485\n",
      "Epoch [94/400], Step [140/439], Loss: 1.1490\n",
      "Epoch [94/400], Step [160/439], Loss: 1.1938\n",
      "Epoch [94/400], Step [180/439], Loss: 1.0516\n",
      "Epoch [94/400], Step [200/439], Loss: 1.3713\n",
      "Epoch [94/400], Step [220/439], Loss: 1.1644\n",
      "Epoch [94/400], Step [240/439], Loss: 1.3741\n",
      "Epoch [94/400], Step [260/439], Loss: 1.4123\n",
      "Epoch [94/400], Step [280/439], Loss: 1.9988\n",
      "Epoch [94/400], Step [300/439], Loss: 0.9816\n",
      "Epoch [94/400], Step [320/439], Loss: 1.7813\n",
      "Epoch [94/400], Step [340/439], Loss: 1.2580\n",
      "Epoch [94/400], Step [360/439], Loss: 1.4559\n",
      "Epoch [94/400], Step [380/439], Loss: 1.2823\n",
      "Epoch [94/400], Step [400/439], Loss: 1.5873\n",
      "Epoch [94/400], Step [420/439], Loss: 1.3348\n",
      "\n",
      "train-loss: 1.4236, train-acc: 57.4565\n",
      "validation loss: 1.3573, validation acc: 58.6458\n",
      "\n",
      "Epoch 95\n",
      "\n",
      "Epoch [95/400], Step [0/439], Loss: 1.5464\n",
      "Epoch [95/400], Step [20/439], Loss: 1.2341\n",
      "Epoch [95/400], Step [40/439], Loss: 1.4820\n",
      "Epoch [95/400], Step [60/439], Loss: 1.3879\n",
      "Epoch [95/400], Step [80/439], Loss: 1.0393\n",
      "Epoch [95/400], Step [100/439], Loss: 1.2259\n",
      "Epoch [95/400], Step [120/439], Loss: 1.3692\n",
      "Epoch [95/400], Step [140/439], Loss: 1.1522\n",
      "Epoch [95/400], Step [160/439], Loss: 1.1257\n",
      "Epoch [95/400], Step [180/439], Loss: 0.9847\n",
      "Epoch [95/400], Step [200/439], Loss: 1.3233\n",
      "Epoch [95/400], Step [220/439], Loss: 1.8533\n",
      "Epoch [95/400], Step [240/439], Loss: 0.8730\n",
      "Epoch [95/400], Step [260/439], Loss: 1.4198\n",
      "Epoch [95/400], Step [280/439], Loss: 1.3258\n",
      "Epoch [95/400], Step [300/439], Loss: 1.1549\n",
      "Epoch [95/400], Step [320/439], Loss: 1.1530\n",
      "Epoch [95/400], Step [340/439], Loss: 0.9784\n",
      "Epoch [95/400], Step [360/439], Loss: 1.3314\n",
      "Epoch [95/400], Step [380/439], Loss: 1.2660\n",
      "Epoch [95/400], Step [400/439], Loss: 1.1259\n",
      "Epoch [95/400], Step [420/439], Loss: 1.1246\n",
      "\n",
      "train-loss: 1.4225, train-acc: 57.0145\n",
      "validation loss: 1.3561, validation acc: 59.0648\n",
      "\n",
      "Epoch 96\n",
      "\n",
      "Epoch [96/400], Step [0/439], Loss: 1.4620\n",
      "Epoch [96/400], Step [20/439], Loss: 1.2587\n",
      "Epoch [96/400], Step [40/439], Loss: 0.9581\n",
      "Epoch [96/400], Step [60/439], Loss: 1.3005\n",
      "Epoch [96/400], Step [80/439], Loss: 0.9829\n",
      "Epoch [96/400], Step [100/439], Loss: 1.3218\n",
      "Epoch [96/400], Step [120/439], Loss: 1.2119\n",
      "Epoch [96/400], Step [140/439], Loss: 1.0564\n",
      "Epoch [96/400], Step [160/439], Loss: 1.5916\n",
      "Epoch [96/400], Step [180/439], Loss: 1.3104\n",
      "Epoch [96/400], Step [200/439], Loss: 1.4621\n",
      "Epoch [96/400], Step [220/439], Loss: 1.2278\n",
      "Epoch [96/400], Step [240/439], Loss: 1.1977\n",
      "Epoch [96/400], Step [260/439], Loss: 1.2293\n",
      "Epoch [96/400], Step [280/439], Loss: 1.3018\n",
      "Epoch [96/400], Step [300/439], Loss: 0.8729\n",
      "Epoch [96/400], Step [320/439], Loss: 1.7698\n",
      "Epoch [96/400], Step [340/439], Loss: 0.8836\n",
      "Epoch [96/400], Step [360/439], Loss: 1.4524\n",
      "Epoch [96/400], Step [380/439], Loss: 1.0529\n",
      "Epoch [96/400], Step [400/439], Loss: 1.4515\n",
      "Epoch [96/400], Step [420/439], Loss: 1.2573\n",
      "\n",
      "train-loss: 1.4214, train-acc: 57.2355\n",
      "validation loss: 1.3547, validation acc: 61.0498\n",
      "\n",
      "Epoch 97\n",
      "\n",
      "Epoch [97/400], Step [0/439], Loss: 1.0133\n",
      "Epoch [97/400], Step [20/439], Loss: 1.4878\n",
      "Epoch [97/400], Step [40/439], Loss: 0.9287\n",
      "Epoch [97/400], Step [60/439], Loss: 1.2848\n",
      "Epoch [97/400], Step [80/439], Loss: 1.4060\n",
      "Epoch [97/400], Step [100/439], Loss: 1.4060\n",
      "Epoch [97/400], Step [120/439], Loss: 1.1564\n",
      "Epoch [97/400], Step [140/439], Loss: 1.1081\n",
      "Epoch [97/400], Step [160/439], Loss: 1.2001\n",
      "Epoch [97/400], Step [180/439], Loss: 1.3442\n",
      "Epoch [97/400], Step [200/439], Loss: 0.9319\n",
      "Epoch [97/400], Step [220/439], Loss: 0.8844\n",
      "Epoch [97/400], Step [240/439], Loss: 1.3239\n",
      "Epoch [97/400], Step [260/439], Loss: 1.1844\n",
      "Epoch [97/400], Step [280/439], Loss: 1.1424\n",
      "Epoch [97/400], Step [300/439], Loss: 1.8892\n",
      "Epoch [97/400], Step [320/439], Loss: 1.1643\n",
      "Epoch [97/400], Step [340/439], Loss: 0.9202\n",
      "Epoch [97/400], Step [360/439], Loss: 1.2014\n",
      "Epoch [97/400], Step [380/439], Loss: 1.2989\n",
      "Epoch [97/400], Step [400/439], Loss: 1.4506\n",
      "Epoch [97/400], Step [420/439], Loss: 1.3520\n",
      "\n",
      "train-loss: 1.4202, train-acc: 57.8985\n",
      "validation loss: 1.3535, validation acc: 59.0428\n",
      "\n",
      "Epoch 98\n",
      "\n",
      "Epoch [98/400], Step [0/439], Loss: 0.8613\n",
      "Epoch [98/400], Step [20/439], Loss: 1.4162\n",
      "Epoch [98/400], Step [40/439], Loss: 1.1295\n",
      "Epoch [98/400], Step [60/439], Loss: 1.4077\n",
      "Epoch [98/400], Step [80/439], Loss: 0.7290\n",
      "Epoch [98/400], Step [100/439], Loss: 1.4156\n",
      "Epoch [98/400], Step [120/439], Loss: 1.2434\n",
      "Epoch [98/400], Step [140/439], Loss: 1.2884\n",
      "Epoch [98/400], Step [160/439], Loss: 1.2511\n",
      "Epoch [98/400], Step [180/439], Loss: 1.3029\n",
      "Epoch [98/400], Step [200/439], Loss: 1.4389\n",
      "Epoch [98/400], Step [220/439], Loss: 1.2803\n",
      "Epoch [98/400], Step [240/439], Loss: 1.2430\n",
      "Epoch [98/400], Step [260/439], Loss: 1.3826\n",
      "Epoch [98/400], Step [280/439], Loss: 1.0678\n",
      "Epoch [98/400], Step [300/439], Loss: 1.2141\n",
      "Epoch [98/400], Step [320/439], Loss: 1.3525\n",
      "Epoch [98/400], Step [340/439], Loss: 0.9581\n",
      "Epoch [98/400], Step [360/439], Loss: 1.2845\n",
      "Epoch [98/400], Step [380/439], Loss: 1.4243\n",
      "Epoch [98/400], Step [400/439], Loss: 0.9126\n",
      "Epoch [98/400], Step [420/439], Loss: 1.2805\n",
      "\n",
      "train-loss: 1.4190, train-acc: 57.5207\n",
      "validation loss: 1.3525, validation acc: 59.1310\n",
      "\n",
      "Epoch 99\n",
      "\n",
      "Epoch [99/400], Step [0/439], Loss: 1.3702\n",
      "Epoch [99/400], Step [20/439], Loss: 1.1809\n",
      "Epoch [99/400], Step [40/439], Loss: 1.1758\n",
      "Epoch [99/400], Step [60/439], Loss: 1.5319\n",
      "Epoch [99/400], Step [80/439], Loss: 0.8558\n",
      "Epoch [99/400], Step [100/439], Loss: 1.4760\n",
      "Epoch [99/400], Step [120/439], Loss: 1.1598\n",
      "Epoch [99/400], Step [140/439], Loss: 1.2673\n",
      "Epoch [99/400], Step [160/439], Loss: 0.9589\n",
      "Epoch [99/400], Step [180/439], Loss: 1.3079\n",
      "Epoch [99/400], Step [200/439], Loss: 1.3955\n",
      "Epoch [99/400], Step [220/439], Loss: 1.1892\n",
      "Epoch [99/400], Step [240/439], Loss: 0.9146\n",
      "Epoch [99/400], Step [260/439], Loss: 1.6009\n",
      "Epoch [99/400], Step [280/439], Loss: 1.1873\n",
      "Epoch [99/400], Step [300/439], Loss: 1.2274\n",
      "Epoch [99/400], Step [320/439], Loss: 1.2139\n",
      "Epoch [99/400], Step [340/439], Loss: 1.4675\n",
      "Epoch [99/400], Step [360/439], Loss: 1.2615\n",
      "Epoch [99/400], Step [380/439], Loss: 1.8217\n",
      "Epoch [99/400], Step [400/439], Loss: 1.2998\n",
      "Epoch [99/400], Step [420/439], Loss: 1.3111\n",
      "\n",
      "train-loss: 1.4178, train-acc: 56.9718\n",
      "validation loss: 1.3511, validation acc: 61.3807\n",
      "\n",
      "Epoch 100\n",
      "\n",
      "Epoch [100/400], Step [0/439], Loss: 1.2724\n",
      "Epoch [100/400], Step [20/439], Loss: 1.2871\n",
      "Epoch [100/400], Step [40/439], Loss: 1.2960\n",
      "Epoch [100/400], Step [60/439], Loss: 1.2355\n",
      "Epoch [100/400], Step [80/439], Loss: 0.9764\n",
      "Epoch [100/400], Step [100/439], Loss: 1.3296\n",
      "Epoch [100/400], Step [120/439], Loss: 1.0751\n",
      "Epoch [100/400], Step [140/439], Loss: 1.5731\n",
      "Epoch [100/400], Step [160/439], Loss: 0.9864\n",
      "Epoch [100/400], Step [180/439], Loss: 1.3520\n",
      "Epoch [100/400], Step [200/439], Loss: 1.2539\n",
      "Epoch [100/400], Step [220/439], Loss: 1.1003\n",
      "Epoch [100/400], Step [240/439], Loss: 0.9507\n",
      "Epoch [100/400], Step [260/439], Loss: 1.6261\n",
      "Epoch [100/400], Step [280/439], Loss: 1.2003\n",
      "Epoch [100/400], Step [300/439], Loss: 1.4233\n",
      "Epoch [100/400], Step [320/439], Loss: 1.2853\n",
      "Epoch [100/400], Step [340/439], Loss: 1.5728\n",
      "Epoch [100/400], Step [360/439], Loss: 1.1293\n",
      "Epoch [100/400], Step [380/439], Loss: 1.3060\n",
      "Epoch [100/400], Step [400/439], Loss: 0.9394\n",
      "Epoch [100/400], Step [420/439], Loss: 1.2029\n",
      "\n",
      "train-loss: 1.4167, train-acc: 57.0716\n",
      "validation loss: 1.3498, validation acc: 59.9691\n",
      "\n",
      "Epoch 101\n",
      "\n",
      "Epoch [101/400], Step [0/439], Loss: 1.7781\n",
      "Epoch [101/400], Step [20/439], Loss: 1.0621\n",
      "Epoch [101/400], Step [40/439], Loss: 1.0554\n",
      "Epoch [101/400], Step [60/439], Loss: 1.5855\n",
      "Epoch [101/400], Step [80/439], Loss: 1.2999\n",
      "Epoch [101/400], Step [100/439], Loss: 1.2136\n",
      "Epoch [101/400], Step [120/439], Loss: 1.7133\n",
      "Epoch [101/400], Step [140/439], Loss: 1.2269\n",
      "Epoch [101/400], Step [160/439], Loss: 1.1586\n",
      "Epoch [101/400], Step [180/439], Loss: 1.2830\n",
      "Epoch [101/400], Step [200/439], Loss: 1.2654\n",
      "Epoch [101/400], Step [220/439], Loss: 1.0116\n",
      "Epoch [101/400], Step [240/439], Loss: 1.3876\n",
      "Epoch [101/400], Step [260/439], Loss: 1.6642\n",
      "Epoch [101/400], Step [280/439], Loss: 1.2896\n",
      "Epoch [101/400], Step [300/439], Loss: 1.6261\n",
      "Epoch [101/400], Step [320/439], Loss: 1.3650\n",
      "Epoch [101/400], Step [340/439], Loss: 1.1411\n",
      "Epoch [101/400], Step [360/439], Loss: 1.5954\n",
      "Epoch [101/400], Step [380/439], Loss: 1.2314\n",
      "Epoch [101/400], Step [400/439], Loss: 1.1477\n",
      "Epoch [101/400], Step [420/439], Loss: 1.2994\n",
      "\n",
      "train-loss: 1.4157, train-acc: 56.9575\n",
      "validation loss: 1.3495, validation acc: 55.8447\n",
      "\n",
      "Epoch 102\n",
      "\n",
      "Epoch [102/400], Step [0/439], Loss: 1.1338\n",
      "Epoch [102/400], Step [20/439], Loss: 1.1547\n",
      "Epoch [102/400], Step [40/439], Loss: 1.4348\n",
      "Epoch [102/400], Step [60/439], Loss: 1.0960\n",
      "Epoch [102/400], Step [80/439], Loss: 1.3294\n",
      "Epoch [102/400], Step [100/439], Loss: 1.1106\n",
      "Epoch [102/400], Step [120/439], Loss: 1.2515\n",
      "Epoch [102/400], Step [140/439], Loss: 1.4625\n",
      "Epoch [102/400], Step [160/439], Loss: 1.4314\n",
      "Epoch [102/400], Step [180/439], Loss: 1.3236\n",
      "Epoch [102/400], Step [200/439], Loss: 1.0693\n",
      "Epoch [102/400], Step [220/439], Loss: 1.3896\n",
      "Epoch [102/400], Step [240/439], Loss: 1.0901\n",
      "Epoch [102/400], Step [260/439], Loss: 1.3249\n",
      "Epoch [102/400], Step [280/439], Loss: 1.6495\n",
      "Epoch [102/400], Step [300/439], Loss: 1.1465\n",
      "Epoch [102/400], Step [320/439], Loss: 1.1219\n",
      "Epoch [102/400], Step [340/439], Loss: 1.0599\n",
      "Epoch [102/400], Step [360/439], Loss: 1.0735\n",
      "Epoch [102/400], Step [380/439], Loss: 1.3588\n",
      "Epoch [102/400], Step [400/439], Loss: 1.1916\n",
      "Epoch [102/400], Step [420/439], Loss: 1.1600\n",
      "\n",
      "train-loss: 1.4146, train-acc: 57.4850\n",
      "validation loss: 1.3483, validation acc: 60.3220\n",
      "\n",
      "Epoch 103\n",
      "\n",
      "Epoch [103/400], Step [0/439], Loss: 1.2895\n",
      "Epoch [103/400], Step [20/439], Loss: 1.7521\n",
      "Epoch [103/400], Step [40/439], Loss: 1.1097\n",
      "Epoch [103/400], Step [60/439], Loss: 1.1111\n",
      "Epoch [103/400], Step [80/439], Loss: 1.1555\n",
      "Epoch [103/400], Step [100/439], Loss: 1.1192\n",
      "Epoch [103/400], Step [120/439], Loss: 1.2786\n",
      "Epoch [103/400], Step [140/439], Loss: 1.3592\n",
      "Epoch [103/400], Step [160/439], Loss: 1.0804\n",
      "Epoch [103/400], Step [180/439], Loss: 1.4202\n",
      "Epoch [103/400], Step [200/439], Loss: 1.2447\n",
      "Epoch [103/400], Step [220/439], Loss: 1.2112\n",
      "Epoch [103/400], Step [240/439], Loss: 1.6873\n",
      "Epoch [103/400], Step [260/439], Loss: 1.2341\n",
      "Epoch [103/400], Step [280/439], Loss: 1.4020\n",
      "Epoch [103/400], Step [300/439], Loss: 1.1552\n",
      "Epoch [103/400], Step [320/439], Loss: 1.3677\n",
      "Epoch [103/400], Step [340/439], Loss: 1.2113\n",
      "Epoch [103/400], Step [360/439], Loss: 0.9300\n",
      "Epoch [103/400], Step [380/439], Loss: 1.5054\n",
      "Epoch [103/400], Step [400/439], Loss: 1.3237\n",
      "Epoch [103/400], Step [420/439], Loss: 1.7070\n",
      "\n",
      "train-loss: 1.4135, train-acc: 57.3496\n",
      "validation loss: 1.3472, validation acc: 60.0573\n",
      "\n",
      "Epoch 104\n",
      "\n",
      "Epoch [104/400], Step [0/439], Loss: 0.8302\n",
      "Epoch [104/400], Step [20/439], Loss: 1.1886\n",
      "Epoch [104/400], Step [40/439], Loss: 1.1580\n",
      "Epoch [104/400], Step [60/439], Loss: 1.2578\n",
      "Epoch [104/400], Step [80/439], Loss: 0.9923\n",
      "Epoch [104/400], Step [100/439], Loss: 1.1876\n",
      "Epoch [104/400], Step [120/439], Loss: 1.1455\n",
      "Epoch [104/400], Step [140/439], Loss: 1.1960\n",
      "Epoch [104/400], Step [160/439], Loss: 0.9589\n",
      "Epoch [104/400], Step [180/439], Loss: 1.3020\n",
      "Epoch [104/400], Step [200/439], Loss: 1.1920\n",
      "Epoch [104/400], Step [220/439], Loss: 1.1214\n",
      "Epoch [104/400], Step [240/439], Loss: 1.0792\n",
      "Epoch [104/400], Step [260/439], Loss: 1.1351\n",
      "Epoch [104/400], Step [280/439], Loss: 0.9989\n",
      "Epoch [104/400], Step [300/439], Loss: 1.3260\n",
      "Epoch [104/400], Step [320/439], Loss: 1.0721\n",
      "Epoch [104/400], Step [340/439], Loss: 0.9025\n",
      "Epoch [104/400], Step [360/439], Loss: 1.2810\n",
      "Epoch [104/400], Step [380/439], Loss: 1.1093\n",
      "Epoch [104/400], Step [400/439], Loss: 1.5365\n",
      "Epoch [104/400], Step [420/439], Loss: 1.5384\n",
      "\n",
      "train-loss: 1.4124, train-acc: 57.9626\n",
      "validation loss: 1.3463, validation acc: 59.1090\n",
      "\n",
      "Epoch 105\n",
      "\n",
      "Epoch [105/400], Step [0/439], Loss: 0.9802\n",
      "Epoch [105/400], Step [20/439], Loss: 1.0433\n",
      "Epoch [105/400], Step [40/439], Loss: 1.1384\n",
      "Epoch [105/400], Step [60/439], Loss: 1.2919\n",
      "Epoch [105/400], Step [80/439], Loss: 1.1847\n",
      "Epoch [105/400], Step [100/439], Loss: 1.4748\n",
      "Epoch [105/400], Step [120/439], Loss: 1.1701\n",
      "Epoch [105/400], Step [140/439], Loss: 1.1169\n",
      "Epoch [105/400], Step [160/439], Loss: 1.3936\n",
      "Epoch [105/400], Step [180/439], Loss: 1.5049\n",
      "Epoch [105/400], Step [200/439], Loss: 1.3645\n",
      "Epoch [105/400], Step [220/439], Loss: 1.1756\n",
      "Epoch [105/400], Step [240/439], Loss: 1.3734\n",
      "Epoch [105/400], Step [260/439], Loss: 1.1211\n",
      "Epoch [105/400], Step [280/439], Loss: 0.9637\n",
      "Epoch [105/400], Step [300/439], Loss: 1.2776\n",
      "Epoch [105/400], Step [320/439], Loss: 1.2031\n",
      "Epoch [105/400], Step [340/439], Loss: 1.5089\n",
      "Epoch [105/400], Step [360/439], Loss: 1.4256\n",
      "Epoch [105/400], Step [380/439], Loss: 1.2406\n",
      "Epoch [105/400], Step [400/439], Loss: 1.3248\n",
      "Epoch [105/400], Step [420/439], Loss: 1.5031\n",
      "\n",
      "train-loss: 1.4113, train-acc: 57.5492\n",
      "validation loss: 1.3452, validation acc: 59.3736\n",
      "\n",
      "Epoch 106\n",
      "\n",
      "Epoch [106/400], Step [0/439], Loss: 1.0980\n",
      "Epoch [106/400], Step [20/439], Loss: 1.0517\n",
      "Epoch [106/400], Step [40/439], Loss: 1.2509\n",
      "Epoch [106/400], Step [60/439], Loss: 1.4684\n",
      "Epoch [106/400], Step [80/439], Loss: 1.3339\n",
      "Epoch [106/400], Step [100/439], Loss: 0.9707\n",
      "Epoch [106/400], Step [120/439], Loss: 1.2945\n",
      "Epoch [106/400], Step [140/439], Loss: 1.3200\n",
      "Epoch [106/400], Step [160/439], Loss: 1.3015\n",
      "Epoch [106/400], Step [180/439], Loss: 1.3566\n",
      "Epoch [106/400], Step [200/439], Loss: 1.0784\n",
      "Epoch [106/400], Step [220/439], Loss: 1.0239\n",
      "Epoch [106/400], Step [240/439], Loss: 1.1421\n",
      "Epoch [106/400], Step [260/439], Loss: 1.1930\n",
      "Epoch [106/400], Step [280/439], Loss: 1.5632\n",
      "Epoch [106/400], Step [300/439], Loss: 1.3694\n",
      "Epoch [106/400], Step [320/439], Loss: 1.3320\n",
      "Epoch [106/400], Step [340/439], Loss: 1.5639\n",
      "Epoch [106/400], Step [360/439], Loss: 1.2726\n",
      "Epoch [106/400], Step [380/439], Loss: 1.3240\n",
      "Epoch [106/400], Step [400/439], Loss: 1.2032\n",
      "Epoch [106/400], Step [420/439], Loss: 1.0385\n",
      "\n",
      "train-loss: 1.4102, train-acc: 57.8486\n",
      "validation loss: 1.3437, validation acc: 61.9100\n",
      "\n",
      "Improvement-Detected, save-model\n",
      "Epoch 107\n",
      "\n",
      "Epoch [107/400], Step [0/439], Loss: 1.2568\n",
      "Epoch [107/400], Step [20/439], Loss: 1.2669\n",
      "Epoch [107/400], Step [40/439], Loss: 1.2443\n",
      "Epoch [107/400], Step [60/439], Loss: 1.4082\n",
      "Epoch [107/400], Step [80/439], Loss: 1.4139\n",
      "Epoch [107/400], Step [100/439], Loss: 0.8217\n",
      "Epoch [107/400], Step [120/439], Loss: 1.2626\n",
      "Epoch [107/400], Step [140/439], Loss: 0.9225\n",
      "Epoch [107/400], Step [160/439], Loss: 1.2221\n",
      "Epoch [107/400], Step [180/439], Loss: 1.2642\n",
      "Epoch [107/400], Step [200/439], Loss: 1.2499\n",
      "Epoch [107/400], Step [220/439], Loss: 1.0110\n",
      "Epoch [107/400], Step [240/439], Loss: 0.8822\n",
      "Epoch [107/400], Step [260/439], Loss: 0.9031\n",
      "Epoch [107/400], Step [280/439], Loss: 1.1756\n",
      "Epoch [107/400], Step [300/439], Loss: 1.2658\n",
      "Epoch [107/400], Step [320/439], Loss: 0.9547\n",
      "Epoch [107/400], Step [340/439], Loss: 1.2077\n",
      "Epoch [107/400], Step [360/439], Loss: 1.3053\n",
      "Epoch [107/400], Step [380/439], Loss: 1.1942\n",
      "Epoch [107/400], Step [400/439], Loss: 1.4049\n",
      "Epoch [107/400], Step [420/439], Loss: 1.3739\n",
      "\n",
      "train-loss: 1.4091, train-acc: 58.1266\n",
      "validation loss: 1.3425, validation acc: 61.0719\n",
      "\n",
      "Epoch 108\n",
      "\n",
      "Epoch [108/400], Step [0/439], Loss: 0.9735\n",
      "Epoch [108/400], Step [20/439], Loss: 1.3006\n",
      "Epoch [108/400], Step [40/439], Loss: 1.3069\n",
      "Epoch [108/400], Step [60/439], Loss: 0.9618\n",
      "Epoch [108/400], Step [80/439], Loss: 1.2812\n",
      "Epoch [108/400], Step [100/439], Loss: 1.1253\n",
      "Epoch [108/400], Step [120/439], Loss: 0.9930\n",
      "Epoch [108/400], Step [140/439], Loss: 1.2688\n",
      "Epoch [108/400], Step [160/439], Loss: 1.2474\n",
      "Epoch [108/400], Step [180/439], Loss: 0.9639\n",
      "Epoch [108/400], Step [200/439], Loss: 1.4006\n",
      "Epoch [108/400], Step [220/439], Loss: 1.5127\n",
      "Epoch [108/400], Step [240/439], Loss: 1.0328\n",
      "Epoch [108/400], Step [260/439], Loss: 1.4985\n",
      "Epoch [108/400], Step [280/439], Loss: 0.7754\n",
      "Epoch [108/400], Step [300/439], Loss: 1.8951\n",
      "Epoch [108/400], Step [320/439], Loss: 1.1425\n",
      "Epoch [108/400], Step [340/439], Loss: 1.0957\n",
      "Epoch [108/400], Step [360/439], Loss: 1.5269\n",
      "Epoch [108/400], Step [380/439], Loss: 1.0355\n",
      "Epoch [108/400], Step [400/439], Loss: 0.9977\n",
      "Epoch [108/400], Step [420/439], Loss: 1.0780\n",
      "\n",
      "train-loss: 1.4081, train-acc: 57.5064\n",
      "validation loss: 1.3414, validation acc: 60.1676\n",
      "\n",
      "Epoch 109\n",
      "\n",
      "Epoch [109/400], Step [0/439], Loss: 1.3045\n",
      "Epoch [109/400], Step [20/439], Loss: 1.4568\n",
      "Epoch [109/400], Step [40/439], Loss: 1.3234\n",
      "Epoch [109/400], Step [60/439], Loss: 1.2232\n",
      "Epoch [109/400], Step [80/439], Loss: 1.1177\n",
      "Epoch [109/400], Step [100/439], Loss: 0.9174\n",
      "Epoch [109/400], Step [120/439], Loss: 1.1091\n",
      "Epoch [109/400], Step [140/439], Loss: 0.9678\n",
      "Epoch [109/400], Step [160/439], Loss: 1.2993\n",
      "Epoch [109/400], Step [180/439], Loss: 1.1287\n",
      "Epoch [109/400], Step [200/439], Loss: 1.1587\n",
      "Epoch [109/400], Step [220/439], Loss: 1.2865\n",
      "Epoch [109/400], Step [240/439], Loss: 0.7578\n",
      "Epoch [109/400], Step [260/439], Loss: 0.9258\n",
      "Epoch [109/400], Step [280/439], Loss: 1.3817\n",
      "Epoch [109/400], Step [300/439], Loss: 1.1399\n",
      "Epoch [109/400], Step [320/439], Loss: 1.2124\n",
      "Epoch [109/400], Step [340/439], Loss: 1.3885\n",
      "Epoch [109/400], Step [360/439], Loss: 1.7400\n",
      "Epoch [109/400], Step [380/439], Loss: 1.1492\n",
      "Epoch [109/400], Step [400/439], Loss: 1.4197\n",
      "Epoch [109/400], Step [420/439], Loss: 1.1610\n",
      "\n",
      "train-loss: 1.4070, train-acc: 57.4423\n",
      "validation loss: 1.3400, validation acc: 62.0644\n",
      "\n",
      "Improvement-Detected, save-model\n",
      "Epoch 110\n",
      "\n",
      "Epoch [110/400], Step [0/439], Loss: 1.1439\n",
      "Epoch [110/400], Step [20/439], Loss: 0.9663\n",
      "Epoch [110/400], Step [40/439], Loss: 1.1135\n",
      "Epoch [110/400], Step [60/439], Loss: 1.2656\n",
      "Epoch [110/400], Step [80/439], Loss: 1.3617\n",
      "Epoch [110/400], Step [100/439], Loss: 0.9745\n",
      "Epoch [110/400], Step [120/439], Loss: 1.1120\n",
      "Epoch [110/400], Step [140/439], Loss: 1.4712\n",
      "Epoch [110/400], Step [160/439], Loss: 1.4706\n",
      "Epoch [110/400], Step [180/439], Loss: 1.3553\n",
      "Epoch [110/400], Step [200/439], Loss: 1.5429\n",
      "Epoch [110/400], Step [220/439], Loss: 1.5728\n",
      "Epoch [110/400], Step [240/439], Loss: 1.1581\n",
      "Epoch [110/400], Step [260/439], Loss: 1.5501\n",
      "Epoch [110/400], Step [280/439], Loss: 1.1483\n",
      "Epoch [110/400], Step [300/439], Loss: 1.2547\n",
      "Epoch [110/400], Step [320/439], Loss: 1.3009\n",
      "Epoch [110/400], Step [340/439], Loss: 0.9692\n",
      "Epoch [110/400], Step [360/439], Loss: 1.1317\n",
      "Epoch [110/400], Step [380/439], Loss: 0.9961\n",
      "Epoch [110/400], Step [400/439], Loss: 1.0128\n",
      "Epoch [110/400], Step [420/439], Loss: 1.0552\n",
      "\n",
      "train-loss: 1.4059, train-acc: 57.4850\n",
      "validation loss: 1.3390, validation acc: 60.9175\n",
      "\n",
      "Epoch 111\n",
      "\n",
      "Epoch [111/400], Step [0/439], Loss: 1.3111\n",
      "Epoch [111/400], Step [20/439], Loss: 1.0796\n",
      "Epoch [111/400], Step [40/439], Loss: 1.2084\n",
      "Epoch [111/400], Step [60/439], Loss: 1.2686\n",
      "Epoch [111/400], Step [80/439], Loss: 1.1238\n",
      "Epoch [111/400], Step [100/439], Loss: 1.3787\n",
      "Epoch [111/400], Step [120/439], Loss: 1.5982\n",
      "Epoch [111/400], Step [140/439], Loss: 1.0767\n",
      "Epoch [111/400], Step [160/439], Loss: 1.1098\n",
      "Epoch [111/400], Step [180/439], Loss: 1.2051\n",
      "Epoch [111/400], Step [200/439], Loss: 1.1742\n",
      "Epoch [111/400], Step [220/439], Loss: 1.5450\n",
      "Epoch [111/400], Step [240/439], Loss: 0.9891\n",
      "Epoch [111/400], Step [260/439], Loss: 1.1280\n",
      "Epoch [111/400], Step [280/439], Loss: 1.1730\n",
      "Epoch [111/400], Step [300/439], Loss: 0.9923\n",
      "Epoch [111/400], Step [320/439], Loss: 1.1870\n",
      "Epoch [111/400], Step [340/439], Loss: 1.2365\n",
      "Epoch [111/400], Step [360/439], Loss: 1.1341\n",
      "Epoch [111/400], Step [380/439], Loss: 0.9602\n",
      "Epoch [111/400], Step [400/439], Loss: 1.2584\n",
      "Epoch [111/400], Step [420/439], Loss: 1.1035\n",
      "\n",
      "train-loss: 1.4048, train-acc: 58.1480\n",
      "validation loss: 1.3378, validation acc: 61.9982\n",
      "\n",
      "Epoch 112\n",
      "\n",
      "Epoch [112/400], Step [0/439], Loss: 0.9248\n",
      "Epoch [112/400], Step [20/439], Loss: 1.0689\n",
      "Epoch [112/400], Step [40/439], Loss: 1.3282\n",
      "Epoch [112/400], Step [60/439], Loss: 1.2429\n",
      "Epoch [112/400], Step [80/439], Loss: 1.0822\n",
      "Epoch [112/400], Step [100/439], Loss: 1.1398\n",
      "Epoch [112/400], Step [120/439], Loss: 0.9586\n",
      "Epoch [112/400], Step [140/439], Loss: 1.2038\n",
      "Epoch [112/400], Step [160/439], Loss: 1.3165\n",
      "Epoch [112/400], Step [180/439], Loss: 1.0957\n",
      "Epoch [112/400], Step [200/439], Loss: 1.2667\n",
      "Epoch [112/400], Step [220/439], Loss: 1.0358\n",
      "Epoch [112/400], Step [240/439], Loss: 1.3759\n",
      "Epoch [112/400], Step [260/439], Loss: 1.0234\n",
      "Epoch [112/400], Step [280/439], Loss: 1.1340\n",
      "Epoch [112/400], Step [300/439], Loss: 1.5250\n",
      "Epoch [112/400], Step [320/439], Loss: 1.2540\n",
      "Epoch [112/400], Step [340/439], Loss: 1.1174\n",
      "Epoch [112/400], Step [360/439], Loss: 0.9692\n",
      "Epoch [112/400], Step [380/439], Loss: 1.0677\n",
      "Epoch [112/400], Step [400/439], Loss: 1.2134\n",
      "Epoch [112/400], Step [420/439], Loss: 1.1871\n",
      "\n",
      "train-loss: 1.4038, train-acc: 58.0838\n",
      "validation loss: 1.3368, validation acc: 59.3075\n",
      "\n",
      "Epoch 113\n",
      "\n",
      "Epoch [113/400], Step [0/439], Loss: 1.1421\n",
      "Epoch [113/400], Step [20/439], Loss: 1.4400\n",
      "Epoch [113/400], Step [40/439], Loss: 1.1588\n",
      "Epoch [113/400], Step [60/439], Loss: 1.2420\n",
      "Epoch [113/400], Step [80/439], Loss: 1.0486\n",
      "Epoch [113/400], Step [100/439], Loss: 1.4338\n",
      "Epoch [113/400], Step [120/439], Loss: 1.2718\n",
      "Epoch [113/400], Step [140/439], Loss: 1.0756\n",
      "Epoch [113/400], Step [160/439], Loss: 1.5221\n",
      "Epoch [113/400], Step [180/439], Loss: 1.4080\n",
      "Epoch [113/400], Step [200/439], Loss: 0.9694\n",
      "Epoch [113/400], Step [220/439], Loss: 0.6727\n",
      "Epoch [113/400], Step [240/439], Loss: 1.3805\n",
      "Epoch [113/400], Step [260/439], Loss: 1.1716\n",
      "Epoch [113/400], Step [280/439], Loss: 1.1873\n",
      "Epoch [113/400], Step [300/439], Loss: 1.1486\n",
      "Epoch [113/400], Step [320/439], Loss: 1.2549\n",
      "Epoch [113/400], Step [340/439], Loss: 1.5278\n",
      "Epoch [113/400], Step [360/439], Loss: 1.3348\n",
      "Epoch [113/400], Step [380/439], Loss: 1.1904\n",
      "Epoch [113/400], Step [400/439], Loss: 1.2419\n",
      "Epoch [113/400], Step [420/439], Loss: 0.9259\n",
      "\n",
      "train-loss: 1.4027, train-acc: 58.5543\n",
      "validation loss: 1.3360, validation acc: 59.1310\n",
      "\n",
      "Epoch 114\n",
      "\n",
      "Epoch [114/400], Step [0/439], Loss: 1.2304\n",
      "Epoch [114/400], Step [20/439], Loss: 1.1419\n",
      "Epoch [114/400], Step [40/439], Loss: 1.5371\n",
      "Epoch [114/400], Step [60/439], Loss: 1.3534\n",
      "Epoch [114/400], Step [80/439], Loss: 1.2512\n",
      "Epoch [114/400], Step [100/439], Loss: 1.5138\n",
      "Epoch [114/400], Step [120/439], Loss: 1.5635\n",
      "Epoch [114/400], Step [140/439], Loss: 1.3321\n",
      "Epoch [114/400], Step [160/439], Loss: 1.0249\n",
      "Epoch [114/400], Step [180/439], Loss: 1.3509\n",
      "Epoch [114/400], Step [200/439], Loss: 1.2317\n",
      "Epoch [114/400], Step [220/439], Loss: 1.0401\n",
      "Epoch [114/400], Step [240/439], Loss: 1.1116\n",
      "Epoch [114/400], Step [260/439], Loss: 1.3841\n",
      "Epoch [114/400], Step [280/439], Loss: 0.9769\n",
      "Epoch [114/400], Step [300/439], Loss: 1.0760\n",
      "Epoch [114/400], Step [320/439], Loss: 1.2646\n",
      "Epoch [114/400], Step [340/439], Loss: 1.5158\n",
      "Epoch [114/400], Step [360/439], Loss: 1.4945\n",
      "Epoch [114/400], Step [380/439], Loss: 1.5011\n",
      "Epoch [114/400], Step [400/439], Loss: 1.7854\n",
      "Epoch [114/400], Step [420/439], Loss: 1.1163\n",
      "\n",
      "train-loss: 1.4016, train-acc: 58.3832\n",
      "validation loss: 1.3346, validation acc: 62.1526\n",
      "\n",
      "Improvement-Detected, save-model\n",
      "Epoch 115\n",
      "\n",
      "Epoch [115/400], Step [0/439], Loss: 1.2500\n",
      "Epoch [115/400], Step [20/439], Loss: 0.9273\n",
      "Epoch [115/400], Step [40/439], Loss: 1.2112\n",
      "Epoch [115/400], Step [60/439], Loss: 1.1604\n",
      "Epoch [115/400], Step [80/439], Loss: 1.0260\n",
      "Epoch [115/400], Step [100/439], Loss: 1.3298\n",
      "Epoch [115/400], Step [120/439], Loss: 1.1961\n",
      "Epoch [115/400], Step [140/439], Loss: 1.1410\n",
      "Epoch [115/400], Step [160/439], Loss: 1.2244\n",
      "Epoch [115/400], Step [180/439], Loss: 1.0710\n",
      "Epoch [115/400], Step [200/439], Loss: 1.0655\n",
      "Epoch [115/400], Step [220/439], Loss: 1.2243\n",
      "Epoch [115/400], Step [240/439], Loss: 1.2143\n",
      "Epoch [115/400], Step [260/439], Loss: 1.0944\n",
      "Epoch [115/400], Step [280/439], Loss: 1.3856\n",
      "Epoch [115/400], Step [300/439], Loss: 1.2563\n",
      "Epoch [115/400], Step [320/439], Loss: 1.0412\n",
      "Epoch [115/400], Step [340/439], Loss: 1.2820\n",
      "Epoch [115/400], Step [360/439], Loss: 1.1677\n",
      "Epoch [115/400], Step [380/439], Loss: 1.7541\n",
      "Epoch [115/400], Step [400/439], Loss: 1.3305\n",
      "Epoch [115/400], Step [420/439], Loss: 1.5204\n",
      "\n",
      "train-loss: 1.4006, train-acc: 58.0624\n",
      "validation loss: 1.3339, validation acc: 58.9325\n",
      "\n",
      "Epoch 116\n",
      "\n",
      "Epoch [116/400], Step [0/439], Loss: 0.9124\n",
      "Epoch [116/400], Step [20/439], Loss: 1.1685\n",
      "Epoch [116/400], Step [40/439], Loss: 1.3798\n",
      "Epoch [116/400], Step [60/439], Loss: 1.3154\n",
      "Epoch [116/400], Step [80/439], Loss: 1.3228\n",
      "Epoch [116/400], Step [100/439], Loss: 1.1501\n",
      "Epoch [116/400], Step [120/439], Loss: 1.0238\n",
      "Epoch [116/400], Step [140/439], Loss: 1.2109\n",
      "Epoch [116/400], Step [160/439], Loss: 1.1120\n",
      "Epoch [116/400], Step [180/439], Loss: 1.4844\n",
      "Epoch [116/400], Step [200/439], Loss: 1.1714\n",
      "Epoch [116/400], Step [220/439], Loss: 1.3380\n",
      "Epoch [116/400], Step [240/439], Loss: 1.0811\n",
      "Epoch [116/400], Step [260/439], Loss: 1.3326\n",
      "Epoch [116/400], Step [280/439], Loss: 1.2705\n",
      "Epoch [116/400], Step [300/439], Loss: 1.2446\n",
      "Epoch [116/400], Step [320/439], Loss: 1.6016\n",
      "Epoch [116/400], Step [340/439], Loss: 1.2544\n",
      "Epoch [116/400], Step [360/439], Loss: 1.5546\n",
      "Epoch [116/400], Step [380/439], Loss: 1.1816\n",
      "Epoch [116/400], Step [400/439], Loss: 1.4487\n",
      "Epoch [116/400], Step [420/439], Loss: 1.3019\n",
      "\n",
      "train-loss: 1.3995, train-acc: 58.3975\n",
      "validation loss: 1.3326, validation acc: 62.1306\n",
      "\n",
      "Epoch 117\n",
      "\n",
      "Epoch [117/400], Step [0/439], Loss: 1.5955\n",
      "Epoch [117/400], Step [20/439], Loss: 1.1888\n",
      "Epoch [117/400], Step [40/439], Loss: 1.1178\n",
      "Epoch [117/400], Step [60/439], Loss: 1.0786\n",
      "Epoch [117/400], Step [80/439], Loss: 1.3262\n",
      "Epoch [117/400], Step [100/439], Loss: 1.1969\n",
      "Epoch [117/400], Step [120/439], Loss: 1.3753\n",
      "Epoch [117/400], Step [140/439], Loss: 1.0165\n",
      "Epoch [117/400], Step [160/439], Loss: 1.1688\n",
      "Epoch [117/400], Step [180/439], Loss: 1.3289\n",
      "Epoch [117/400], Step [200/439], Loss: 0.7129\n",
      "Epoch [117/400], Step [220/439], Loss: 1.6058\n",
      "Epoch [117/400], Step [240/439], Loss: 1.3986\n",
      "Epoch [117/400], Step [260/439], Loss: 1.6268\n",
      "Epoch [117/400], Step [280/439], Loss: 1.0931\n",
      "Epoch [117/400], Step [300/439], Loss: 1.3907\n",
      "Epoch [117/400], Step [320/439], Loss: 1.1671\n",
      "Epoch [117/400], Step [340/439], Loss: 1.2737\n",
      "Epoch [117/400], Step [360/439], Loss: 1.2092\n",
      "Epoch [117/400], Step [380/439], Loss: 1.3754\n",
      "Epoch [117/400], Step [400/439], Loss: 1.3659\n",
      "Epoch [117/400], Step [420/439], Loss: 1.2939\n",
      "\n",
      "train-loss: 1.3985, train-acc: 58.7682\n",
      "validation loss: 1.3316, validation acc: 60.9175\n",
      "\n",
      "Epoch 118\n",
      "\n",
      "Epoch [118/400], Step [0/439], Loss: 1.5408\n",
      "Epoch [118/400], Step [20/439], Loss: 1.4995\n",
      "Epoch [118/400], Step [40/439], Loss: 1.1588\n",
      "Epoch [118/400], Step [60/439], Loss: 1.4214\n",
      "Epoch [118/400], Step [80/439], Loss: 1.1100\n",
      "Epoch [118/400], Step [100/439], Loss: 1.5660\n",
      "Epoch [118/400], Step [120/439], Loss: 1.1777\n",
      "Epoch [118/400], Step [140/439], Loss: 0.9642\n",
      "Epoch [118/400], Step [160/439], Loss: 1.0697\n",
      "Epoch [118/400], Step [180/439], Loss: 1.2006\n",
      "Epoch [118/400], Step [200/439], Loss: 1.0569\n",
      "Epoch [118/400], Step [220/439], Loss: 1.1907\n",
      "Epoch [118/400], Step [240/439], Loss: 0.9948\n",
      "Epoch [118/400], Step [260/439], Loss: 0.8056\n",
      "Epoch [118/400], Step [280/439], Loss: 1.1062\n",
      "Epoch [118/400], Step [300/439], Loss: 1.3235\n",
      "Epoch [118/400], Step [320/439], Loss: 0.8856\n",
      "Epoch [118/400], Step [340/439], Loss: 1.2262\n",
      "Epoch [118/400], Step [360/439], Loss: 1.8211\n",
      "Epoch [118/400], Step [380/439], Loss: 1.0361\n",
      "Epoch [118/400], Step [400/439], Loss: 1.3285\n",
      "Epoch [118/400], Step [420/439], Loss: 1.1010\n",
      "\n",
      "train-loss: 1.3974, train-acc: 59.1246\n",
      "validation loss: 1.3306, validation acc: 59.6603\n",
      "\n",
      "Epoch 119\n",
      "\n",
      "Epoch [119/400], Step [0/439], Loss: 1.1500\n",
      "Epoch [119/400], Step [20/439], Loss: 1.7493\n",
      "Epoch [119/400], Step [40/439], Loss: 1.1072\n",
      "Epoch [119/400], Step [60/439], Loss: 1.1650\n",
      "Epoch [119/400], Step [80/439], Loss: 1.5429\n",
      "Epoch [119/400], Step [100/439], Loss: 1.3918\n",
      "Epoch [119/400], Step [120/439], Loss: 0.9518\n",
      "Epoch [119/400], Step [140/439], Loss: 1.4931\n",
      "Epoch [119/400], Step [160/439], Loss: 1.2301\n",
      "Epoch [119/400], Step [180/439], Loss: 1.0822\n",
      "Epoch [119/400], Step [200/439], Loss: 1.3956\n",
      "Epoch [119/400], Step [220/439], Loss: 1.2070\n",
      "Epoch [119/400], Step [240/439], Loss: 1.4064\n",
      "Epoch [119/400], Step [260/439], Loss: 1.6074\n",
      "Epoch [119/400], Step [280/439], Loss: 1.3051\n",
      "Epoch [119/400], Step [300/439], Loss: 1.5667\n",
      "Epoch [119/400], Step [320/439], Loss: 1.3907\n",
      "Epoch [119/400], Step [340/439], Loss: 0.8343\n",
      "Epoch [119/400], Step [360/439], Loss: 1.4971\n",
      "Epoch [119/400], Step [380/439], Loss: 1.3114\n",
      "Epoch [119/400], Step [400/439], Loss: 1.5710\n",
      "Epoch [119/400], Step [420/439], Loss: 0.9455\n",
      "\n",
      "train-loss: 1.3964, train-acc: 58.1694\n",
      "validation loss: 1.3296, validation acc: 61.0719\n",
      "\n",
      "Epoch 120\n",
      "\n",
      "Epoch [120/400], Step [0/439], Loss: 1.2713\n",
      "Epoch [120/400], Step [20/439], Loss: 1.3427\n",
      "Epoch [120/400], Step [40/439], Loss: 1.0157\n",
      "Epoch [120/400], Step [60/439], Loss: 1.4431\n",
      "Epoch [120/400], Step [80/439], Loss: 1.3743\n",
      "Epoch [120/400], Step [100/439], Loss: 0.9604\n",
      "Epoch [120/400], Step [120/439], Loss: 0.9098\n",
      "Epoch [120/400], Step [140/439], Loss: 1.3046\n",
      "Epoch [120/400], Step [160/439], Loss: 1.1755\n",
      "Epoch [120/400], Step [180/439], Loss: 1.4326\n",
      "Epoch [120/400], Step [200/439], Loss: 0.7285\n",
      "Epoch [120/400], Step [220/439], Loss: 1.2090\n",
      "Epoch [120/400], Step [240/439], Loss: 0.8805\n",
      "Epoch [120/400], Step [260/439], Loss: 1.1630\n",
      "Epoch [120/400], Step [280/439], Loss: 0.9994\n",
      "Epoch [120/400], Step [300/439], Loss: 1.0551\n",
      "Epoch [120/400], Step [320/439], Loss: 1.4752\n",
      "Epoch [120/400], Step [340/439], Loss: 1.2178\n",
      "Epoch [120/400], Step [360/439], Loss: 1.8446\n",
      "Epoch [120/400], Step [380/439], Loss: 1.4058\n",
      "Epoch [120/400], Step [400/439], Loss: 1.3960\n",
      "Epoch [120/400], Step [420/439], Loss: 1.2520\n",
      "\n",
      "train-loss: 1.3953, train-acc: 58.7896\n",
      "validation loss: 1.3285, validation acc: 61.2925\n",
      "\n",
      "Epoch 121\n",
      "\n",
      "Epoch [121/400], Step [0/439], Loss: 1.4660\n",
      "Epoch [121/400], Step [20/439], Loss: 1.0355\n",
      "Epoch [121/400], Step [40/439], Loss: 1.2909\n",
      "Epoch [121/400], Step [60/439], Loss: 1.3481\n",
      "Epoch [121/400], Step [80/439], Loss: 1.2033\n",
      "Epoch [121/400], Step [100/439], Loss: 1.1666\n",
      "Epoch [121/400], Step [120/439], Loss: 1.0827\n",
      "Epoch [121/400], Step [140/439], Loss: 1.0385\n",
      "Epoch [121/400], Step [160/439], Loss: 1.1137\n",
      "Epoch [121/400], Step [180/439], Loss: 0.8132\n",
      "Epoch [121/400], Step [200/439], Loss: 1.1035\n",
      "Epoch [121/400], Step [220/439], Loss: 1.2117\n",
      "Epoch [121/400], Step [240/439], Loss: 0.8914\n",
      "Epoch [121/400], Step [260/439], Loss: 0.9641\n",
      "Epoch [121/400], Step [280/439], Loss: 1.0632\n",
      "Epoch [121/400], Step [300/439], Loss: 0.9827\n",
      "Epoch [121/400], Step [320/439], Loss: 1.3631\n",
      "Epoch [121/400], Step [340/439], Loss: 1.1450\n",
      "Epoch [121/400], Step [360/439], Loss: 1.3219\n",
      "Epoch [121/400], Step [380/439], Loss: 1.1204\n",
      "Epoch [121/400], Step [400/439], Loss: 0.9434\n",
      "Epoch [121/400], Step [420/439], Loss: 1.4995\n",
      "\n",
      "train-loss: 1.3942, train-acc: 58.1480\n",
      "validation loss: 1.3277, validation acc: 59.0428\n",
      "\n",
      "Epoch 122\n",
      "\n",
      "Epoch [122/400], Step [0/439], Loss: 1.0480\n",
      "Epoch [122/400], Step [20/439], Loss: 1.1381\n",
      "Epoch [122/400], Step [40/439], Loss: 1.3916\n",
      "Epoch [122/400], Step [60/439], Loss: 1.2973\n",
      "Epoch [122/400], Step [80/439], Loss: 0.9535\n",
      "Epoch [122/400], Step [100/439], Loss: 1.2116\n",
      "Epoch [122/400], Step [120/439], Loss: 1.0915\n",
      "Epoch [122/400], Step [140/439], Loss: 1.2038\n",
      "Epoch [122/400], Step [160/439], Loss: 1.2141\n",
      "Epoch [122/400], Step [180/439], Loss: 1.3736\n",
      "Epoch [122/400], Step [200/439], Loss: 0.9677\n",
      "Epoch [122/400], Step [220/439], Loss: 1.5063\n",
      "Epoch [122/400], Step [240/439], Loss: 1.0501\n",
      "Epoch [122/400], Step [260/439], Loss: 1.2972\n",
      "Epoch [122/400], Step [280/439], Loss: 1.0873\n",
      "Epoch [122/400], Step [300/439], Loss: 1.4376\n",
      "Epoch [122/400], Step [320/439], Loss: 0.9141\n",
      "Epoch [122/400], Step [340/439], Loss: 1.7115\n",
      "Epoch [122/400], Step [360/439], Loss: 1.1554\n",
      "Epoch [122/400], Step [380/439], Loss: 1.0906\n",
      "Epoch [122/400], Step [400/439], Loss: 1.3153\n",
      "Epoch [122/400], Step [420/439], Loss: 1.3812\n",
      "\n",
      "train-loss: 1.3932, train-acc: 58.1551\n",
      "validation loss: 1.3266, validation acc: 61.0719\n",
      "\n",
      "Epoch 123\n",
      "\n",
      "Epoch [123/400], Step [0/439], Loss: 1.4679\n",
      "Epoch [123/400], Step [20/439], Loss: 1.0885\n",
      "Epoch [123/400], Step [40/439], Loss: 1.0805\n",
      "Epoch [123/400], Step [60/439], Loss: 1.5388\n",
      "Epoch [123/400], Step [80/439], Loss: 1.6562\n",
      "Epoch [123/400], Step [100/439], Loss: 0.9927\n",
      "Epoch [123/400], Step [120/439], Loss: 0.9101\n",
      "Epoch [123/400], Step [140/439], Loss: 1.4704\n",
      "Epoch [123/400], Step [160/439], Loss: 1.0154\n",
      "Epoch [123/400], Step [180/439], Loss: 1.1524\n",
      "Epoch [123/400], Step [200/439], Loss: 0.9337\n",
      "Epoch [123/400], Step [220/439], Loss: 1.2631\n",
      "Epoch [123/400], Step [240/439], Loss: 1.0152\n",
      "Epoch [123/400], Step [260/439], Loss: 1.0869\n",
      "Epoch [123/400], Step [280/439], Loss: 1.1247\n",
      "Epoch [123/400], Step [300/439], Loss: 1.2789\n",
      "Epoch [123/400], Step [320/439], Loss: 1.1697\n",
      "Epoch [123/400], Step [340/439], Loss: 1.0859\n",
      "Epoch [123/400], Step [360/439], Loss: 1.4603\n",
      "Epoch [123/400], Step [380/439], Loss: 1.4613\n",
      "Epoch [123/400], Step [400/439], Loss: 1.0759\n",
      "Epoch [123/400], Step [420/439], Loss: 1.3976\n",
      "\n",
      "train-loss: 1.3922, train-acc: 58.4331\n",
      "validation loss: 1.3265, validation acc: 56.2417\n",
      "\n",
      "Epoch 124\n",
      "\n",
      "Epoch [124/400], Step [0/439], Loss: 1.3576\n",
      "Epoch [124/400], Step [20/439], Loss: 1.0027\n",
      "Epoch [124/400], Step [40/439], Loss: 0.7350\n",
      "Epoch [124/400], Step [60/439], Loss: 1.0298\n",
      "Epoch [124/400], Step [80/439], Loss: 1.0193\n",
      "Epoch [124/400], Step [100/439], Loss: 1.0909\n",
      "Epoch [124/400], Step [120/439], Loss: 0.9132\n",
      "Epoch [124/400], Step [140/439], Loss: 1.5628\n",
      "Epoch [124/400], Step [160/439], Loss: 1.2812\n",
      "Epoch [124/400], Step [180/439], Loss: 1.1877\n",
      "Epoch [124/400], Step [200/439], Loss: 1.1001\n",
      "Epoch [124/400], Step [220/439], Loss: 1.1050\n",
      "Epoch [124/400], Step [240/439], Loss: 1.1742\n",
      "Epoch [124/400], Step [260/439], Loss: 1.4806\n",
      "Epoch [124/400], Step [280/439], Loss: 1.2845\n",
      "Epoch [124/400], Step [300/439], Loss: 1.2757\n",
      "Epoch [124/400], Step [320/439], Loss: 1.3064\n",
      "Epoch [124/400], Step [340/439], Loss: 1.8470\n",
      "Epoch [124/400], Step [360/439], Loss: 1.1969\n",
      "Epoch [124/400], Step [380/439], Loss: 1.0269\n",
      "Epoch [124/400], Step [400/439], Loss: 1.1585\n",
      "Epoch [124/400], Step [420/439], Loss: 1.1909\n",
      "\n",
      "train-loss: 1.3913, train-acc: 58.6399\n",
      "validation loss: 1.3265, validation acc: 54.8302\n",
      "\n",
      "Epoch 125\n",
      "\n",
      "Epoch [125/400], Step [0/439], Loss: 1.3090\n",
      "Epoch [125/400], Step [20/439], Loss: 1.4828\n",
      "Epoch [125/400], Step [40/439], Loss: 1.0498\n",
      "Epoch [125/400], Step [60/439], Loss: 0.9034\n",
      "Epoch [125/400], Step [80/439], Loss: 1.7669\n",
      "Epoch [125/400], Step [100/439], Loss: 1.2890\n",
      "Epoch [125/400], Step [120/439], Loss: 1.0375\n",
      "Epoch [125/400], Step [140/439], Loss: 1.1522\n",
      "Epoch [125/400], Step [160/439], Loss: 1.6188\n",
      "Epoch [125/400], Step [180/439], Loss: 0.9202\n",
      "Epoch [125/400], Step [200/439], Loss: 1.0279\n",
      "Epoch [125/400], Step [220/439], Loss: 1.2421\n",
      "Epoch [125/400], Step [240/439], Loss: 1.0268\n",
      "Epoch [125/400], Step [260/439], Loss: 1.2869\n",
      "Epoch [125/400], Step [280/439], Loss: 1.3451\n",
      "Epoch [125/400], Step [300/439], Loss: 1.2506\n",
      "Epoch [125/400], Step [320/439], Loss: 1.4228\n",
      "Epoch [125/400], Step [340/439], Loss: 1.2924\n",
      "Epoch [125/400], Step [360/439], Loss: 0.8853\n",
      "Epoch [125/400], Step [380/439], Loss: 1.0968\n",
      "Epoch [125/400], Step [400/439], Loss: 1.5550\n",
      "Epoch [125/400], Step [420/439], Loss: 1.8972\n",
      "\n",
      "train-loss: 1.3903, train-acc: 58.5401\n",
      "validation loss: 1.3257, validation acc: 59.5060\n",
      "\n",
      "Epoch 126\n",
      "\n",
      "Epoch [126/400], Step [0/439], Loss: 1.2317\n",
      "Epoch [126/400], Step [20/439], Loss: 1.2719\n",
      "Epoch [126/400], Step [40/439], Loss: 0.9670\n",
      "Epoch [126/400], Step [60/439], Loss: 1.3052\n",
      "Epoch [126/400], Step [80/439], Loss: 1.3695\n",
      "Epoch [126/400], Step [100/439], Loss: 1.2193\n",
      "Epoch [126/400], Step [120/439], Loss: 1.0326\n",
      "Epoch [126/400], Step [140/439], Loss: 1.4565\n",
      "Epoch [126/400], Step [160/439], Loss: 1.2079\n",
      "Epoch [126/400], Step [180/439], Loss: 1.1649\n",
      "Epoch [126/400], Step [200/439], Loss: 1.4167\n",
      "Epoch [126/400], Step [220/439], Loss: 0.8602\n",
      "Epoch [126/400], Step [240/439], Loss: 1.1951\n",
      "Epoch [126/400], Step [260/439], Loss: 1.0066\n",
      "Epoch [126/400], Step [280/439], Loss: 1.2877\n",
      "Epoch [126/400], Step [300/439], Loss: 1.1744\n",
      "Epoch [126/400], Step [320/439], Loss: 1.4551\n",
      "Epoch [126/400], Step [340/439], Loss: 1.1544\n",
      "Epoch [126/400], Step [360/439], Loss: 1.2658\n",
      "Epoch [126/400], Step [380/439], Loss: 0.9591\n",
      "Epoch [126/400], Step [400/439], Loss: 1.2279\n",
      "Epoch [126/400], Step [420/439], Loss: 1.0901\n",
      "\n",
      "train-loss: 1.3894, train-acc: 58.2763\n",
      "validation loss: 1.3247, validation acc: 61.4689\n",
      "\n",
      "Epoch 127\n",
      "\n",
      "Epoch [127/400], Step [0/439], Loss: 1.2710\n",
      "Epoch [127/400], Step [20/439], Loss: 0.8625\n",
      "Epoch [127/400], Step [40/439], Loss: 1.4637\n",
      "Epoch [127/400], Step [60/439], Loss: 1.1897\n",
      "Epoch [127/400], Step [80/439], Loss: 1.2817\n",
      "Epoch [127/400], Step [100/439], Loss: 1.1375\n",
      "Epoch [127/400], Step [120/439], Loss: 1.3201\n",
      "Epoch [127/400], Step [140/439], Loss: 1.2461\n",
      "Epoch [127/400], Step [160/439], Loss: 0.9485\n",
      "Epoch [127/400], Step [180/439], Loss: 1.0913\n",
      "Epoch [127/400], Step [200/439], Loss: 1.3634\n",
      "Epoch [127/400], Step [220/439], Loss: 1.1657\n",
      "Epoch [127/400], Step [240/439], Loss: 1.2926\n",
      "Epoch [127/400], Step [260/439], Loss: 0.8503\n",
      "Epoch [127/400], Step [280/439], Loss: 1.3092\n",
      "Epoch [127/400], Step [300/439], Loss: 1.4367\n",
      "Epoch [127/400], Step [320/439], Loss: 1.2035\n",
      "Epoch [127/400], Step [340/439], Loss: 1.4582\n",
      "Epoch [127/400], Step [360/439], Loss: 1.1109\n",
      "Epoch [127/400], Step [380/439], Loss: 1.1144\n",
      "Epoch [127/400], Step [400/439], Loss: 1.0443\n",
      "Epoch [127/400], Step [420/439], Loss: 0.9828\n",
      "\n",
      "train-loss: 1.3884, train-acc: 58.7468\n",
      "validation loss: 1.3239, validation acc: 59.1972\n",
      "\n",
      "Epoch 128\n",
      "\n",
      "Epoch [128/400], Step [0/439], Loss: 1.3812\n",
      "Epoch [128/400], Step [20/439], Loss: 1.2819\n",
      "Epoch [128/400], Step [40/439], Loss: 1.1566\n",
      "Epoch [128/400], Step [60/439], Loss: 1.2354\n",
      "Epoch [128/400], Step [80/439], Loss: 1.1085\n",
      "Epoch [128/400], Step [100/439], Loss: 1.0484\n",
      "Epoch [128/400], Step [120/439], Loss: 1.2766\n",
      "Epoch [128/400], Step [140/439], Loss: 1.0414\n",
      "Epoch [128/400], Step [160/439], Loss: 1.4615\n",
      "Epoch [128/400], Step [180/439], Loss: 1.2326\n",
      "Epoch [128/400], Step [200/439], Loss: 1.3630\n",
      "Epoch [128/400], Step [220/439], Loss: 1.3544\n",
      "Epoch [128/400], Step [240/439], Loss: 1.3306\n",
      "Epoch [128/400], Step [260/439], Loss: 0.9262\n",
      "Epoch [128/400], Step [280/439], Loss: 1.1626\n",
      "Epoch [128/400], Step [300/439], Loss: 1.1789\n",
      "Epoch [128/400], Step [320/439], Loss: 1.0647\n",
      "Epoch [128/400], Step [340/439], Loss: 1.2606\n",
      "Epoch [128/400], Step [360/439], Loss: 1.4765\n",
      "Epoch [128/400], Step [380/439], Loss: 1.4603\n",
      "Epoch [128/400], Step [400/439], Loss: 1.2630\n",
      "Epoch [128/400], Step [420/439], Loss: 1.3529\n",
      "\n",
      "train-loss: 1.3874, train-acc: 58.6755\n",
      "validation loss: 1.3234, validation acc: 57.8518\n",
      "\n",
      "Epoch 129\n",
      "\n",
      "Epoch [129/400], Step [0/439], Loss: 1.4715\n",
      "Epoch [129/400], Step [20/439], Loss: 1.2687\n",
      "Epoch [129/400], Step [40/439], Loss: 0.9692\n",
      "Epoch [129/400], Step [60/439], Loss: 1.1389\n",
      "Epoch [129/400], Step [80/439], Loss: 1.2680\n",
      "Epoch [129/400], Step [100/439], Loss: 0.9278\n",
      "Epoch [129/400], Step [120/439], Loss: 1.3883\n",
      "Epoch [129/400], Step [140/439], Loss: 1.4786\n",
      "Epoch [129/400], Step [160/439], Loss: 1.3874\n",
      "Epoch [129/400], Step [180/439], Loss: 1.1048\n",
      "Epoch [129/400], Step [200/439], Loss: 1.0596\n",
      "Epoch [129/400], Step [220/439], Loss: 1.0725\n",
      "Epoch [129/400], Step [240/439], Loss: 1.5271\n",
      "Epoch [129/400], Step [260/439], Loss: 0.8986\n",
      "Epoch [129/400], Step [280/439], Loss: 1.5798\n",
      "Epoch [129/400], Step [300/439], Loss: 0.9796\n",
      "Epoch [129/400], Step [320/439], Loss: 1.0101\n",
      "Epoch [129/400], Step [340/439], Loss: 1.0126\n",
      "Epoch [129/400], Step [360/439], Loss: 1.1740\n",
      "Epoch [129/400], Step [380/439], Loss: 1.2728\n",
      "Epoch [129/400], Step [400/439], Loss: 1.1571\n",
      "Epoch [129/400], Step [420/439], Loss: 1.4576\n",
      "\n",
      "train-loss: 1.3865, train-acc: 58.5401\n",
      "validation loss: 1.3222, validation acc: 61.6453\n",
      "\n",
      "Epoch 130\n",
      "\n",
      "Epoch [130/400], Step [0/439], Loss: 1.4017\n",
      "Epoch [130/400], Step [20/439], Loss: 1.4397\n",
      "Epoch [130/400], Step [40/439], Loss: 1.0128\n",
      "Epoch [130/400], Step [60/439], Loss: 1.2048\n",
      "Epoch [130/400], Step [80/439], Loss: 1.1231\n",
      "Epoch [130/400], Step [100/439], Loss: 1.3759\n",
      "Epoch [130/400], Step [120/439], Loss: 0.8767\n",
      "Epoch [130/400], Step [140/439], Loss: 1.0734\n",
      "Epoch [130/400], Step [160/439], Loss: 0.9786\n",
      "Epoch [130/400], Step [180/439], Loss: 1.3774\n",
      "Epoch [130/400], Step [200/439], Loss: 1.2567\n",
      "Epoch [130/400], Step [220/439], Loss: 1.1276\n",
      "Epoch [130/400], Step [240/439], Loss: 1.3211\n",
      "Epoch [130/400], Step [260/439], Loss: 1.5098\n",
      "Epoch [130/400], Step [280/439], Loss: 1.1180\n",
      "Epoch [130/400], Step [300/439], Loss: 1.2680\n",
      "Epoch [130/400], Step [320/439], Loss: 1.2971\n",
      "Epoch [130/400], Step [340/439], Loss: 1.1246\n",
      "Epoch [130/400], Step [360/439], Loss: 1.0856\n",
      "Epoch [130/400], Step [380/439], Loss: 1.0313\n",
      "Epoch [130/400], Step [400/439], Loss: 1.2242\n",
      "Epoch [130/400], Step [420/439], Loss: 0.9466\n",
      "\n",
      "train-loss: 1.3855, train-acc: 58.8608\n",
      "validation loss: 1.3211, validation acc: 62.1747\n",
      "\n",
      "Epoch 131\n",
      "\n",
      "Epoch [131/400], Step [0/439], Loss: 0.8470\n",
      "Epoch [131/400], Step [20/439], Loss: 1.2130\n",
      "Epoch [131/400], Step [40/439], Loss: 1.0726\n",
      "Epoch [131/400], Step [60/439], Loss: 1.3148\n",
      "Epoch [131/400], Step [80/439], Loss: 1.6888\n",
      "Epoch [131/400], Step [100/439], Loss: 1.3911\n",
      "Epoch [131/400], Step [120/439], Loss: 1.0965\n",
      "Epoch [131/400], Step [140/439], Loss: 1.0766\n",
      "Epoch [131/400], Step [160/439], Loss: 1.1376\n",
      "Epoch [131/400], Step [180/439], Loss: 1.3293\n",
      "Epoch [131/400], Step [200/439], Loss: 1.1218\n",
      "Epoch [131/400], Step [220/439], Loss: 0.9287\n",
      "Epoch [131/400], Step [240/439], Loss: 1.0978\n",
      "Epoch [131/400], Step [260/439], Loss: 1.5044\n",
      "Epoch [131/400], Step [280/439], Loss: 0.9649\n",
      "Epoch [131/400], Step [300/439], Loss: 1.0576\n",
      "Epoch [131/400], Step [320/439], Loss: 1.4840\n",
      "Epoch [131/400], Step [340/439], Loss: 0.9981\n",
      "Epoch [131/400], Step [360/439], Loss: 1.2234\n",
      "Epoch [131/400], Step [380/439], Loss: 1.1275\n",
      "Epoch [131/400], Step [400/439], Loss: 1.1937\n",
      "Epoch [131/400], Step [420/439], Loss: 1.5450\n",
      "\n",
      "train-loss: 1.3845, train-acc: 58.1836\n",
      "validation loss: 1.3204, validation acc: 59.1972\n",
      "\n",
      "Epoch 132\n",
      "\n",
      "Epoch [132/400], Step [0/439], Loss: 1.2572\n",
      "Epoch [132/400], Step [20/439], Loss: 1.4683\n",
      "Epoch [132/400], Step [40/439], Loss: 0.9105\n",
      "Epoch [132/400], Step [60/439], Loss: 1.1539\n",
      "Epoch [132/400], Step [80/439], Loss: 1.0537\n",
      "Epoch [132/400], Step [100/439], Loss: 1.2684\n",
      "Epoch [132/400], Step [120/439], Loss: 1.3018\n",
      "Epoch [132/400], Step [140/439], Loss: 1.1717\n",
      "Epoch [132/400], Step [160/439], Loss: 0.9460\n",
      "Epoch [132/400], Step [180/439], Loss: 0.9870\n",
      "Epoch [132/400], Step [200/439], Loss: 1.1074\n",
      "Epoch [132/400], Step [220/439], Loss: 0.9402\n",
      "Epoch [132/400], Step [240/439], Loss: 1.3006\n",
      "Epoch [132/400], Step [260/439], Loss: 1.3754\n",
      "Epoch [132/400], Step [280/439], Loss: 1.5957\n",
      "Epoch [132/400], Step [300/439], Loss: 1.4224\n",
      "Epoch [132/400], Step [320/439], Loss: 1.0751\n",
      "Epoch [132/400], Step [340/439], Loss: 1.1704\n",
      "Epoch [132/400], Step [360/439], Loss: 1.0780\n",
      "Epoch [132/400], Step [380/439], Loss: 1.4032\n",
      "Epoch [132/400], Step [400/439], Loss: 1.3049\n",
      "Epoch [132/400], Step [420/439], Loss: 1.4783\n",
      "\n",
      "train-loss: 1.3836, train-acc: 59.0319\n",
      "validation loss: 1.3193, validation acc: 62.2629\n",
      "\n",
      "Improvement-Detected, save-model\n",
      "Epoch 133\n",
      "\n",
      "Epoch [133/400], Step [0/439], Loss: 0.8962\n",
      "Epoch [133/400], Step [20/439], Loss: 1.2662\n",
      "Epoch [133/400], Step [40/439], Loss: 1.1255\n",
      "Epoch [133/400], Step [60/439], Loss: 1.3980\n",
      "Epoch [133/400], Step [80/439], Loss: 1.0022\n",
      "Epoch [133/400], Step [100/439], Loss: 1.2801\n",
      "Epoch [133/400], Step [120/439], Loss: 1.1102\n",
      "Epoch [133/400], Step [140/439], Loss: 1.5091\n",
      "Epoch [133/400], Step [160/439], Loss: 1.0650\n",
      "Epoch [133/400], Step [180/439], Loss: 1.3668\n",
      "Epoch [133/400], Step [200/439], Loss: 1.8434\n",
      "Epoch [133/400], Step [220/439], Loss: 1.1633\n",
      "Epoch [133/400], Step [240/439], Loss: 1.1253\n",
      "Epoch [133/400], Step [260/439], Loss: 1.2115\n",
      "Epoch [133/400], Step [280/439], Loss: 1.5714\n",
      "Epoch [133/400], Step [300/439], Loss: 1.5140\n",
      "Epoch [133/400], Step [320/439], Loss: 1.2169\n",
      "Epoch [133/400], Step [340/439], Loss: 1.1482\n",
      "Epoch [133/400], Step [360/439], Loss: 1.1458\n",
      "Epoch [133/400], Step [380/439], Loss: 1.0046\n",
      "Epoch [133/400], Step [400/439], Loss: 1.2893\n",
      "Epoch [133/400], Step [420/439], Loss: 1.2445\n",
      "\n",
      "train-loss: 1.3826, train-acc: 59.0319\n",
      "validation loss: 1.3182, validation acc: 62.2408\n",
      "\n",
      "Epoch 134\n",
      "\n",
      "Epoch [134/400], Step [0/439], Loss: 1.4838\n",
      "Epoch [134/400], Step [20/439], Loss: 1.3868\n",
      "Epoch [134/400], Step [40/439], Loss: 0.8760\n",
      "Epoch [134/400], Step [60/439], Loss: 1.3958\n",
      "Epoch [134/400], Step [80/439], Loss: 1.1532\n",
      "Epoch [134/400], Step [100/439], Loss: 0.8021\n",
      "Epoch [134/400], Step [120/439], Loss: 1.2491\n",
      "Epoch [134/400], Step [140/439], Loss: 1.3349\n",
      "Epoch [134/400], Step [160/439], Loss: 1.3808\n",
      "Epoch [134/400], Step [180/439], Loss: 0.9308\n",
      "Epoch [134/400], Step [200/439], Loss: 1.2561\n",
      "Epoch [134/400], Step [220/439], Loss: 1.4802\n",
      "Epoch [134/400], Step [240/439], Loss: 1.0360\n",
      "Epoch [134/400], Step [260/439], Loss: 1.0026\n",
      "Epoch [134/400], Step [280/439], Loss: 1.0652\n",
      "Epoch [134/400], Step [300/439], Loss: 1.1461\n",
      "Epoch [134/400], Step [320/439], Loss: 1.2736\n",
      "Epoch [134/400], Step [340/439], Loss: 0.9432\n",
      "Epoch [134/400], Step [360/439], Loss: 1.4972\n",
      "Epoch [134/400], Step [380/439], Loss: 1.5061\n",
      "Epoch [134/400], Step [400/439], Loss: 1.1676\n",
      "Epoch [134/400], Step [420/439], Loss: 1.2504\n",
      "\n",
      "train-loss: 1.3816, train-acc: 58.8181\n",
      "validation loss: 1.3173, validation acc: 59.7927\n",
      "\n",
      "Epoch 135\n",
      "\n",
      "Epoch [135/400], Step [0/439], Loss: 1.0381\n",
      "Epoch [135/400], Step [20/439], Loss: 1.4430\n",
      "Epoch [135/400], Step [40/439], Loss: 1.1420\n",
      "Epoch [135/400], Step [60/439], Loss: 1.4524\n",
      "Epoch [135/400], Step [80/439], Loss: 1.0381\n",
      "Epoch [135/400], Step [100/439], Loss: 1.0405\n",
      "Epoch [135/400], Step [120/439], Loss: 1.1596\n",
      "Epoch [135/400], Step [140/439], Loss: 1.2843\n",
      "Epoch [135/400], Step [160/439], Loss: 1.3555\n",
      "Epoch [135/400], Step [180/439], Loss: 1.5238\n",
      "Epoch [135/400], Step [200/439], Loss: 1.2400\n",
      "Epoch [135/400], Step [220/439], Loss: 1.2840\n",
      "Epoch [135/400], Step [240/439], Loss: 1.4126\n",
      "Epoch [135/400], Step [260/439], Loss: 1.2455\n",
      "Epoch [135/400], Step [280/439], Loss: 1.3174\n",
      "Epoch [135/400], Step [300/439], Loss: 0.9243\n",
      "Epoch [135/400], Step [320/439], Loss: 1.0468\n",
      "Epoch [135/400], Step [340/439], Loss: 1.1670\n",
      "Epoch [135/400], Step [360/439], Loss: 1.0471\n",
      "Epoch [135/400], Step [380/439], Loss: 1.2985\n",
      "Epoch [135/400], Step [400/439], Loss: 1.2447\n",
      "Epoch [135/400], Step [420/439], Loss: 0.8134\n",
      "\n",
      "train-loss: 1.3806, train-acc: 60.1012\n",
      "validation loss: 1.3162, validation acc: 62.6599\n",
      "\n",
      "Improvement-Detected, save-model\n",
      "Epoch 136\n",
      "\n",
      "Epoch [136/400], Step [0/439], Loss: 1.4703\n",
      "Epoch [136/400], Step [20/439], Loss: 1.5538\n",
      "Epoch [136/400], Step [40/439], Loss: 1.6354\n",
      "Epoch [136/400], Step [60/439], Loss: 1.1787\n",
      "Epoch [136/400], Step [80/439], Loss: 0.9841\n",
      "Epoch [136/400], Step [100/439], Loss: 0.8533\n",
      "Epoch [136/400], Step [120/439], Loss: 0.8835\n",
      "Epoch [136/400], Step [140/439], Loss: 1.0354\n",
      "Epoch [136/400], Step [160/439], Loss: 1.4933\n",
      "Epoch [136/400], Step [180/439], Loss: 0.8029\n",
      "Epoch [136/400], Step [200/439], Loss: 1.2172\n",
      "Epoch [136/400], Step [220/439], Loss: 1.3922\n",
      "Epoch [136/400], Step [240/439], Loss: 1.3806\n",
      "Epoch [136/400], Step [260/439], Loss: 1.3639\n",
      "Epoch [136/400], Step [280/439], Loss: 1.2668\n",
      "Epoch [136/400], Step [300/439], Loss: 1.0069\n",
      "Epoch [136/400], Step [320/439], Loss: 1.0425\n",
      "Epoch [136/400], Step [340/439], Loss: 0.9815\n",
      "Epoch [136/400], Step [360/439], Loss: 1.3515\n",
      "Epoch [136/400], Step [380/439], Loss: 1.2580\n",
      "Epoch [136/400], Step [400/439], Loss: 1.2431\n",
      "Epoch [136/400], Step [420/439], Loss: 1.0306\n",
      "\n",
      "train-loss: 1.3797, train-acc: 58.7254\n",
      "validation loss: 1.3150, validation acc: 61.6233\n",
      "\n",
      "Improvement-Detected, save-model\n",
      "Epoch 137\n",
      "\n",
      "Epoch [137/400], Step [0/439], Loss: 1.1678\n",
      "Epoch [137/400], Step [20/439], Loss: 1.1674\n",
      "Epoch [137/400], Step [40/439], Loss: 1.1527\n",
      "Epoch [137/400], Step [60/439], Loss: 0.9692\n",
      "Epoch [137/400], Step [80/439], Loss: 1.1917\n",
      "Epoch [137/400], Step [100/439], Loss: 1.4658\n",
      "Epoch [137/400], Step [120/439], Loss: 0.8044\n",
      "Epoch [137/400], Step [140/439], Loss: 1.1793\n",
      "Epoch [137/400], Step [160/439], Loss: 0.8499\n",
      "Epoch [137/400], Step [180/439], Loss: 1.1414\n",
      "Epoch [137/400], Step [200/439], Loss: 1.0822\n",
      "Epoch [137/400], Step [220/439], Loss: 0.8294\n",
      "Epoch [137/400], Step [240/439], Loss: 1.1845\n",
      "Epoch [137/400], Step [260/439], Loss: 1.1261\n",
      "Epoch [137/400], Step [280/439], Loss: 1.5181\n",
      "Epoch [137/400], Step [300/439], Loss: 1.4538\n",
      "Epoch [137/400], Step [320/439], Loss: 1.3514\n",
      "Epoch [137/400], Step [340/439], Loss: 1.0257\n",
      "Epoch [137/400], Step [360/439], Loss: 0.9331\n",
      "Epoch [137/400], Step [380/439], Loss: 1.1055\n",
      "Epoch [137/400], Step [400/439], Loss: 0.8687\n",
      "Epoch [137/400], Step [420/439], Loss: 1.0865\n",
      "\n",
      "train-loss: 1.3788, train-acc: 59.3741\n",
      "validation loss: 1.3138, validation acc: 62.5055\n",
      "\n",
      "Improvement-Detected, save-model\n",
      "Epoch 138\n",
      "\n",
      "Epoch [138/400], Step [0/439], Loss: 1.3977\n",
      "Epoch [138/400], Step [20/439], Loss: 1.0337\n",
      "Epoch [138/400], Step [40/439], Loss: 0.8566\n",
      "Epoch [138/400], Step [60/439], Loss: 1.1178\n",
      "Epoch [138/400], Step [80/439], Loss: 1.3375\n",
      "Epoch [138/400], Step [100/439], Loss: 1.4384\n",
      "Epoch [138/400], Step [120/439], Loss: 1.1814\n",
      "Epoch [138/400], Step [140/439], Loss: 0.7754\n",
      "Epoch [138/400], Step [160/439], Loss: 1.2094\n",
      "Epoch [138/400], Step [180/439], Loss: 0.9278\n",
      "Epoch [138/400], Step [200/439], Loss: 0.9571\n",
      "Epoch [138/400], Step [220/439], Loss: 1.1219\n",
      "Epoch [138/400], Step [240/439], Loss: 1.1875\n",
      "Epoch [138/400], Step [260/439], Loss: 1.2046\n",
      "Epoch [138/400], Step [280/439], Loss: 1.1376\n",
      "Epoch [138/400], Step [300/439], Loss: 1.0898\n",
      "Epoch [138/400], Step [320/439], Loss: 1.1456\n",
      "Epoch [138/400], Step [340/439], Loss: 0.9507\n",
      "Epoch [138/400], Step [360/439], Loss: 1.2738\n",
      "Epoch [138/400], Step [380/439], Loss: 1.1782\n",
      "Epoch [138/400], Step [400/439], Loss: 1.1497\n",
      "Epoch [138/400], Step [420/439], Loss: 1.1267\n",
      "\n",
      "train-loss: 1.3779, train-acc: 58.9107\n",
      "validation loss: 1.3130, validation acc: 59.9912\n",
      "\n",
      "Epoch 139\n",
      "\n",
      "Epoch [139/400], Step [0/439], Loss: 1.0033\n",
      "Epoch [139/400], Step [20/439], Loss: 1.3498\n",
      "Epoch [139/400], Step [40/439], Loss: 1.0685\n",
      "Epoch [139/400], Step [60/439], Loss: 0.9637\n",
      "Epoch [139/400], Step [80/439], Loss: 1.3304\n",
      "Epoch [139/400], Step [100/439], Loss: 1.4527\n",
      "Epoch [139/400], Step [120/439], Loss: 1.4632\n",
      "Epoch [139/400], Step [140/439], Loss: 1.1696\n",
      "Epoch [139/400], Step [160/439], Loss: 1.0557\n",
      "Epoch [139/400], Step [180/439], Loss: 0.8911\n",
      "Epoch [139/400], Step [200/439], Loss: 1.1167\n",
      "Epoch [139/400], Step [220/439], Loss: 1.0517\n",
      "Epoch [139/400], Step [240/439], Loss: 1.0285\n",
      "Epoch [139/400], Step [260/439], Loss: 1.0530\n",
      "Epoch [139/400], Step [280/439], Loss: 1.5249\n",
      "Epoch [139/400], Step [300/439], Loss: 1.2948\n",
      "Epoch [139/400], Step [320/439], Loss: 1.6780\n",
      "Epoch [139/400], Step [340/439], Loss: 1.1102\n",
      "Epoch [139/400], Step [360/439], Loss: 1.2659\n",
      "Epoch [139/400], Step [380/439], Loss: 1.1765\n",
      "Epoch [139/400], Step [400/439], Loss: 1.2730\n",
      "Epoch [139/400], Step [420/439], Loss: 1.0377\n",
      "\n",
      "train-loss: 1.3770, train-acc: 59.0462\n",
      "validation loss: 1.3118, validation acc: 62.8363\n",
      "\n",
      "Epoch 140\n",
      "\n",
      "Epoch [140/400], Step [0/439], Loss: 1.0241\n",
      "Epoch [140/400], Step [20/439], Loss: 1.1762\n",
      "Epoch [140/400], Step [40/439], Loss: 1.2182\n",
      "Epoch [140/400], Step [60/439], Loss: 1.0359\n",
      "Epoch [140/400], Step [80/439], Loss: 0.9820\n",
      "Epoch [140/400], Step [100/439], Loss: 1.2222\n",
      "Epoch [140/400], Step [120/439], Loss: 1.4558\n",
      "Epoch [140/400], Step [140/439], Loss: 1.2473\n",
      "Epoch [140/400], Step [160/439], Loss: 1.2215\n",
      "Epoch [140/400], Step [180/439], Loss: 1.4369\n",
      "Epoch [140/400], Step [200/439], Loss: 1.3767\n",
      "Epoch [140/400], Step [220/439], Loss: 1.5882\n",
      "Epoch [140/400], Step [240/439], Loss: 1.0349\n",
      "Epoch [140/400], Step [260/439], Loss: 1.2474\n",
      "Epoch [140/400], Step [280/439], Loss: 1.2203\n",
      "Epoch [140/400], Step [300/439], Loss: 1.1219\n",
      "Epoch [140/400], Step [320/439], Loss: 1.1663\n",
      "Epoch [140/400], Step [340/439], Loss: 0.9336\n",
      "Epoch [140/400], Step [360/439], Loss: 0.9594\n",
      "Epoch [140/400], Step [380/439], Loss: 1.3580\n",
      "Epoch [140/400], Step [400/439], Loss: 1.2144\n",
      "Epoch [140/400], Step [420/439], Loss: 1.6564\n",
      "\n",
      "train-loss: 1.3760, train-acc: 58.9107\n",
      "validation loss: 1.3110, validation acc: 60.5426\n",
      "\n",
      "Epoch 141\n",
      "\n",
      "Epoch [141/400], Step [0/439], Loss: 1.2291\n",
      "Epoch [141/400], Step [20/439], Loss: 1.2235\n",
      "Epoch [141/400], Step [40/439], Loss: 1.1732\n",
      "Epoch [141/400], Step [60/439], Loss: 1.0954\n",
      "Epoch [141/400], Step [80/439], Loss: 1.1862\n",
      "Epoch [141/400], Step [100/439], Loss: 1.4311\n",
      "Epoch [141/400], Step [120/439], Loss: 0.9867\n",
      "Epoch [141/400], Step [140/439], Loss: 1.6003\n",
      "Epoch [141/400], Step [160/439], Loss: 1.1186\n",
      "Epoch [141/400], Step [180/439], Loss: 1.3439\n",
      "Epoch [141/400], Step [200/439], Loss: 1.0557\n",
      "Epoch [141/400], Step [220/439], Loss: 0.9856\n",
      "Epoch [141/400], Step [240/439], Loss: 1.0561\n",
      "Epoch [141/400], Step [260/439], Loss: 1.3522\n",
      "Epoch [141/400], Step [280/439], Loss: 1.2345\n",
      "Epoch [141/400], Step [300/439], Loss: 1.2484\n",
      "Epoch [141/400], Step [320/439], Loss: 1.2556\n",
      "Epoch [141/400], Step [340/439], Loss: 0.9987\n",
      "Epoch [141/400], Step [360/439], Loss: 0.8534\n",
      "Epoch [141/400], Step [380/439], Loss: 1.1363\n",
      "Epoch [141/400], Step [400/439], Loss: 1.6340\n",
      "Epoch [141/400], Step [420/439], Loss: 0.9045\n",
      "\n",
      "train-loss: 1.3750, train-acc: 59.3527\n",
      "validation loss: 1.3105, validation acc: 58.6017\n",
      "\n",
      "Epoch 142\n",
      "\n",
      "Epoch [142/400], Step [0/439], Loss: 1.0314\n",
      "Epoch [142/400], Step [20/439], Loss: 1.2077\n",
      "Epoch [142/400], Step [40/439], Loss: 1.3234\n",
      "Epoch [142/400], Step [60/439], Loss: 1.0384\n",
      "Epoch [142/400], Step [80/439], Loss: 1.2145\n",
      "Epoch [142/400], Step [100/439], Loss: 0.9334\n",
      "Epoch [142/400], Step [120/439], Loss: 1.5365\n",
      "Epoch [142/400], Step [140/439], Loss: 1.3949\n",
      "Epoch [142/400], Step [160/439], Loss: 1.3012\n",
      "Epoch [142/400], Step [180/439], Loss: 1.2216\n",
      "Epoch [142/400], Step [200/439], Loss: 1.2005\n",
      "Epoch [142/400], Step [220/439], Loss: 1.1531\n",
      "Epoch [142/400], Step [240/439], Loss: 0.8131\n",
      "Epoch [142/400], Step [260/439], Loss: 1.1527\n",
      "Epoch [142/400], Step [280/439], Loss: 1.2601\n",
      "Epoch [142/400], Step [300/439], Loss: 1.0623\n",
      "Epoch [142/400], Step [320/439], Loss: 1.1592\n",
      "Epoch [142/400], Step [340/439], Loss: 1.4053\n",
      "Epoch [142/400], Step [360/439], Loss: 1.1396\n",
      "Epoch [142/400], Step [380/439], Loss: 1.5386\n",
      "Epoch [142/400], Step [400/439], Loss: 1.1390\n",
      "Epoch [142/400], Step [420/439], Loss: 1.0769\n",
      "\n",
      "train-loss: 1.3742, train-acc: 58.3904\n",
      "validation loss: 1.3099, validation acc: 59.1531\n",
      "\n",
      "Epoch 143\n",
      "\n",
      "Epoch [143/400], Step [0/439], Loss: 1.5329\n",
      "Epoch [143/400], Step [20/439], Loss: 1.3088\n",
      "Epoch [143/400], Step [40/439], Loss: 1.3401\n",
      "Epoch [143/400], Step [60/439], Loss: 1.3699\n",
      "Epoch [143/400], Step [80/439], Loss: 0.8803\n",
      "Epoch [143/400], Step [100/439], Loss: 1.1428\n",
      "Epoch [143/400], Step [120/439], Loss: 1.3494\n",
      "Epoch [143/400], Step [140/439], Loss: 1.3484\n",
      "Epoch [143/400], Step [160/439], Loss: 1.4199\n",
      "Epoch [143/400], Step [180/439], Loss: 1.0329\n",
      "Epoch [143/400], Step [200/439], Loss: 1.2139\n",
      "Epoch [143/400], Step [220/439], Loss: 1.2591\n",
      "Epoch [143/400], Step [240/439], Loss: 1.2767\n",
      "Epoch [143/400], Step [260/439], Loss: 1.0746\n",
      "Epoch [143/400], Step [280/439], Loss: 1.4502\n",
      "Epoch [143/400], Step [300/439], Loss: 1.4332\n",
      "Epoch [143/400], Step [320/439], Loss: 1.0749\n",
      "Epoch [143/400], Step [340/439], Loss: 1.3681\n",
      "Epoch [143/400], Step [360/439], Loss: 0.9492\n",
      "Epoch [143/400], Step [380/439], Loss: 1.4850\n",
      "Epoch [143/400], Step [400/439], Loss: 1.5613\n",
      "Epoch [143/400], Step [420/439], Loss: 1.4552\n",
      "\n",
      "train-loss: 1.3732, train-acc: 59.5951\n",
      "validation loss: 1.3089, validation acc: 61.9541\n",
      "\n",
      "Epoch 144\n",
      "\n",
      "Epoch [144/400], Step [0/439], Loss: 1.2247\n",
      "Epoch [144/400], Step [20/439], Loss: 1.2076\n",
      "Epoch [144/400], Step [40/439], Loss: 1.0516\n",
      "Epoch [144/400], Step [60/439], Loss: 1.1277\n",
      "Epoch [144/400], Step [80/439], Loss: 0.9933\n",
      "Epoch [144/400], Step [100/439], Loss: 1.4155\n",
      "Epoch [144/400], Step [120/439], Loss: 1.0466\n",
      "Epoch [144/400], Step [140/439], Loss: 1.2343\n",
      "Epoch [144/400], Step [160/439], Loss: 1.1931\n",
      "Epoch [144/400], Step [180/439], Loss: 1.3737\n",
      "Epoch [144/400], Step [200/439], Loss: 1.4556\n",
      "Epoch [144/400], Step [220/439], Loss: 0.7779\n",
      "Epoch [144/400], Step [240/439], Loss: 1.1259\n",
      "Epoch [144/400], Step [260/439], Loss: 1.2932\n",
      "Epoch [144/400], Step [280/439], Loss: 1.3572\n",
      "Epoch [144/400], Step [300/439], Loss: 1.3263\n",
      "Epoch [144/400], Step [320/439], Loss: 1.4156\n",
      "Epoch [144/400], Step [340/439], Loss: 1.2586\n",
      "Epoch [144/400], Step [360/439], Loss: 1.4741\n",
      "Epoch [144/400], Step [380/439], Loss: 1.0522\n",
      "Epoch [144/400], Step [400/439], Loss: 1.3011\n",
      "Epoch [144/400], Step [420/439], Loss: 1.7424\n",
      "\n",
      "train-loss: 1.3724, train-acc: 58.4902\n",
      "validation loss: 1.3081, validation acc: 60.6308\n",
      "\n",
      "Epoch 145\n",
      "\n",
      "Epoch [145/400], Step [0/439], Loss: 1.5143\n",
      "Epoch [145/400], Step [20/439], Loss: 1.0661\n",
      "Epoch [145/400], Step [40/439], Loss: 1.4816\n",
      "Epoch [145/400], Step [60/439], Loss: 1.1324\n",
      "Epoch [145/400], Step [80/439], Loss: 0.9207\n",
      "Epoch [145/400], Step [100/439], Loss: 1.4348\n",
      "Epoch [145/400], Step [120/439], Loss: 1.1263\n",
      "Epoch [145/400], Step [140/439], Loss: 1.0860\n",
      "Epoch [145/400], Step [160/439], Loss: 1.0399\n",
      "Epoch [145/400], Step [180/439], Loss: 1.2797\n",
      "Epoch [145/400], Step [200/439], Loss: 0.8381\n",
      "Epoch [145/400], Step [220/439], Loss: 0.9347\n",
      "Epoch [145/400], Step [240/439], Loss: 1.4065\n",
      "Epoch [145/400], Step [260/439], Loss: 1.0492\n",
      "Epoch [145/400], Step [280/439], Loss: 1.3158\n",
      "Epoch [145/400], Step [300/439], Loss: 1.2195\n",
      "Epoch [145/400], Step [320/439], Loss: 1.4477\n",
      "Epoch [145/400], Step [340/439], Loss: 1.0949\n",
      "Epoch [145/400], Step [360/439], Loss: 1.2433\n",
      "Epoch [145/400], Step [380/439], Loss: 0.9968\n",
      "Epoch [145/400], Step [400/439], Loss: 1.2502\n",
      "Epoch [145/400], Step [420/439], Loss: 1.3518\n",
      "\n",
      "train-loss: 1.3714, train-acc: 59.3812\n",
      "validation loss: 1.3072, validation acc: 61.3807\n",
      "\n",
      "Epoch 146\n",
      "\n",
      "Epoch [146/400], Step [0/439], Loss: 1.3628\n",
      "Epoch [146/400], Step [20/439], Loss: 0.9952\n",
      "Epoch [146/400], Step [40/439], Loss: 1.3327\n",
      "Epoch [146/400], Step [60/439], Loss: 1.0534\n",
      "Epoch [146/400], Step [80/439], Loss: 1.3932\n",
      "Epoch [146/400], Step [100/439], Loss: 0.9981\n",
      "Epoch [146/400], Step [120/439], Loss: 0.9632\n",
      "Epoch [146/400], Step [140/439], Loss: 0.9961\n",
      "Epoch [146/400], Step [160/439], Loss: 1.2571\n",
      "Epoch [146/400], Step [180/439], Loss: 1.3137\n",
      "Epoch [146/400], Step [200/439], Loss: 0.9611\n",
      "Epoch [146/400], Step [220/439], Loss: 0.9080\n",
      "Epoch [146/400], Step [240/439], Loss: 0.9692\n",
      "Epoch [146/400], Step [260/439], Loss: 1.3717\n",
      "Epoch [146/400], Step [280/439], Loss: 1.0296\n",
      "Epoch [146/400], Step [300/439], Loss: 0.9908\n",
      "Epoch [146/400], Step [320/439], Loss: 1.1220\n",
      "Epoch [146/400], Step [340/439], Loss: 1.5893\n",
      "Epoch [146/400], Step [360/439], Loss: 1.0068\n",
      "Epoch [146/400], Step [380/439], Loss: 1.0705\n",
      "Epoch [146/400], Step [400/439], Loss: 0.6732\n",
      "Epoch [146/400], Step [420/439], Loss: 1.4265\n",
      "\n",
      "train-loss: 1.3706, train-acc: 59.0319\n",
      "validation loss: 1.3060, validation acc: 64.0494\n",
      "\n",
      "Improvement-Detected, save-model\n",
      "Epoch 147\n",
      "\n",
      "Epoch [147/400], Step [0/439], Loss: 0.9560\n",
      "Epoch [147/400], Step [20/439], Loss: 1.6314\n",
      "Epoch [147/400], Step [40/439], Loss: 1.1384\n",
      "Epoch [147/400], Step [60/439], Loss: 1.1662\n",
      "Epoch [147/400], Step [80/439], Loss: 1.0820\n",
      "Epoch [147/400], Step [100/439], Loss: 1.3953\n",
      "Epoch [147/400], Step [120/439], Loss: 1.2378\n",
      "Epoch [147/400], Step [140/439], Loss: 1.0094\n",
      "Epoch [147/400], Step [160/439], Loss: 1.1948\n",
      "Epoch [147/400], Step [180/439], Loss: 1.0818\n",
      "Epoch [147/400], Step [200/439], Loss: 1.1251\n",
      "Epoch [147/400], Step [220/439], Loss: 1.0466\n",
      "Epoch [147/400], Step [240/439], Loss: 0.9943\n",
      "Epoch [147/400], Step [260/439], Loss: 1.0195\n",
      "Epoch [147/400], Step [280/439], Loss: 1.2267\n",
      "Epoch [147/400], Step [300/439], Loss: 1.2005\n",
      "Epoch [147/400], Step [320/439], Loss: 1.5184\n",
      "Epoch [147/400], Step [340/439], Loss: 1.1616\n",
      "Epoch [147/400], Step [360/439], Loss: 0.8784\n",
      "Epoch [147/400], Step [380/439], Loss: 1.4208\n",
      "Epoch [147/400], Step [400/439], Loss: 1.5044\n",
      "Epoch [147/400], Step [420/439], Loss: 1.7046\n",
      "\n",
      "train-loss: 1.3697, train-acc: 59.3955\n",
      "validation loss: 1.3056, validation acc: 58.5355\n",
      "\n",
      "Epoch 148\n",
      "\n",
      "Epoch [148/400], Step [0/439], Loss: 1.1060\n",
      "Epoch [148/400], Step [20/439], Loss: 0.9099\n",
      "Epoch [148/400], Step [40/439], Loss: 1.3727\n",
      "Epoch [148/400], Step [60/439], Loss: 0.9191\n",
      "Epoch [148/400], Step [80/439], Loss: 1.1158\n",
      "Epoch [148/400], Step [100/439], Loss: 1.7124\n",
      "Epoch [148/400], Step [120/439], Loss: 1.2357\n",
      "Epoch [148/400], Step [140/439], Loss: 1.4003\n",
      "Epoch [148/400], Step [160/439], Loss: 1.4088\n",
      "Epoch [148/400], Step [180/439], Loss: 1.3086\n",
      "Epoch [148/400], Step [200/439], Loss: 1.2542\n",
      "Epoch [148/400], Step [220/439], Loss: 1.0835\n",
      "Epoch [148/400], Step [240/439], Loss: 1.2890\n",
      "Epoch [148/400], Step [260/439], Loss: 1.4203\n",
      "Epoch [148/400], Step [280/439], Loss: 1.3395\n",
      "Epoch [148/400], Step [300/439], Loss: 1.1475\n",
      "Epoch [148/400], Step [320/439], Loss: 1.3045\n",
      "Epoch [148/400], Step [340/439], Loss: 1.2502\n",
      "Epoch [148/400], Step [360/439], Loss: 1.2399\n",
      "Epoch [148/400], Step [380/439], Loss: 1.6391\n",
      "Epoch [148/400], Step [400/439], Loss: 0.9392\n",
      "Epoch [148/400], Step [420/439], Loss: 1.3270\n",
      "\n",
      "train-loss: 1.3689, train-acc: 59.0676\n",
      "validation loss: 1.3049, validation acc: 59.5280\n",
      "\n",
      "Epoch 149\n",
      "\n",
      "Epoch [149/400], Step [0/439], Loss: 0.9382\n",
      "Epoch [149/400], Step [20/439], Loss: 1.5979\n",
      "Epoch [149/400], Step [40/439], Loss: 1.3308\n",
      "Epoch [149/400], Step [60/439], Loss: 1.2602\n",
      "Epoch [149/400], Step [80/439], Loss: 1.2545\n",
      "Epoch [149/400], Step [100/439], Loss: 1.1057\n",
      "Epoch [149/400], Step [120/439], Loss: 1.3224\n",
      "Epoch [149/400], Step [140/439], Loss: 1.0413\n",
      "Epoch [149/400], Step [160/439], Loss: 0.8340\n",
      "Epoch [149/400], Step [180/439], Loss: 1.1795\n",
      "Epoch [149/400], Step [200/439], Loss: 1.0237\n",
      "Epoch [149/400], Step [220/439], Loss: 1.1250\n",
      "Epoch [149/400], Step [240/439], Loss: 1.2376\n",
      "Epoch [149/400], Step [260/439], Loss: 1.0797\n",
      "Epoch [149/400], Step [280/439], Loss: 1.0924\n",
      "Epoch [149/400], Step [300/439], Loss: 1.1203\n",
      "Epoch [149/400], Step [320/439], Loss: 1.2839\n",
      "Epoch [149/400], Step [340/439], Loss: 0.8020\n",
      "Epoch [149/400], Step [360/439], Loss: 1.2817\n",
      "Epoch [149/400], Step [380/439], Loss: 1.1495\n",
      "Epoch [149/400], Step [400/439], Loss: 1.0901\n",
      "Epoch [149/400], Step [420/439], Loss: 1.3098\n",
      "\n",
      "train-loss: 1.3680, train-acc: 59.0106\n",
      "validation loss: 1.3040, validation acc: 62.0203\n",
      "\n",
      "Epoch 150\n",
      "\n",
      "Epoch [150/400], Step [0/439], Loss: 1.0788\n",
      "Epoch [150/400], Step [20/439], Loss: 0.9468\n",
      "Epoch [150/400], Step [40/439], Loss: 1.2822\n",
      "Epoch [150/400], Step [60/439], Loss: 1.0205\n",
      "Epoch [150/400], Step [80/439], Loss: 1.2200\n",
      "Epoch [150/400], Step [100/439], Loss: 1.2488\n",
      "Epoch [150/400], Step [120/439], Loss: 1.1144\n",
      "Epoch [150/400], Step [140/439], Loss: 1.2743\n",
      "Epoch [150/400], Step [160/439], Loss: 1.3920\n",
      "Epoch [150/400], Step [180/439], Loss: 1.0479\n",
      "Epoch [150/400], Step [200/439], Loss: 1.1645\n",
      "Epoch [150/400], Step [220/439], Loss: 1.1305\n",
      "Epoch [150/400], Step [240/439], Loss: 1.0166\n",
      "Epoch [150/400], Step [260/439], Loss: 1.0709\n",
      "Epoch [150/400], Step [280/439], Loss: 1.3313\n",
      "Epoch [150/400], Step [300/439], Loss: 1.5133\n",
      "Epoch [150/400], Step [320/439], Loss: 1.1953\n",
      "Epoch [150/400], Step [340/439], Loss: 1.0657\n",
      "Epoch [150/400], Step [360/439], Loss: 0.9588\n",
      "Epoch [150/400], Step [380/439], Loss: 1.5620\n",
      "Epoch [150/400], Step [400/439], Loss: 1.3379\n",
      "Epoch [150/400], Step [420/439], Loss: 0.8638\n",
      "\n",
      "train-loss: 1.3671, train-acc: 59.3741\n",
      "validation loss: 1.3034, validation acc: 59.6162\n",
      "\n",
      "Epoch 151\n",
      "\n",
      "Epoch [151/400], Step [0/439], Loss: 1.2954\n",
      "Epoch [151/400], Step [20/439], Loss: 1.2277\n",
      "Epoch [151/400], Step [40/439], Loss: 1.1528\n",
      "Epoch [151/400], Step [60/439], Loss: 1.5610\n",
      "Epoch [151/400], Step [80/439], Loss: 1.0044\n",
      "Epoch [151/400], Step [100/439], Loss: 0.9193\n",
      "Epoch [151/400], Step [120/439], Loss: 1.3253\n",
      "Epoch [151/400], Step [140/439], Loss: 1.0841\n",
      "Epoch [151/400], Step [160/439], Loss: 1.4491\n",
      "Epoch [151/400], Step [180/439], Loss: 1.3570\n",
      "Epoch [151/400], Step [200/439], Loss: 1.2441\n",
      "Epoch [151/400], Step [220/439], Loss: 1.2322\n",
      "Epoch [151/400], Step [240/439], Loss: 1.0842\n",
      "Epoch [151/400], Step [260/439], Loss: 1.3494\n",
      "Epoch [151/400], Step [280/439], Loss: 1.1608\n",
      "Epoch [151/400], Step [300/439], Loss: 0.9344\n",
      "Epoch [151/400], Step [320/439], Loss: 1.0059\n",
      "Epoch [151/400], Step [340/439], Loss: 1.4186\n",
      "Epoch [151/400], Step [360/439], Loss: 1.1221\n",
      "Epoch [151/400], Step [380/439], Loss: 1.2072\n",
      "Epoch [151/400], Step [400/439], Loss: 1.0479\n",
      "Epoch [151/400], Step [420/439], Loss: 1.3301\n",
      "\n",
      "train-loss: 1.3663, train-acc: 59.2957\n",
      "validation loss: 1.3027, validation acc: 59.8588\n",
      "\n",
      "Epoch 152\n",
      "\n",
      "Epoch [152/400], Step [0/439], Loss: 1.5340\n",
      "Epoch [152/400], Step [20/439], Loss: 0.9575\n",
      "Epoch [152/400], Step [40/439], Loss: 1.2268\n",
      "Epoch [152/400], Step [60/439], Loss: 1.1005\n",
      "Epoch [152/400], Step [80/439], Loss: 1.0289\n",
      "Epoch [152/400], Step [100/439], Loss: 2.0327\n",
      "Epoch [152/400], Step [120/439], Loss: 1.0651\n",
      "Epoch [152/400], Step [140/439], Loss: 1.4012\n",
      "Epoch [152/400], Step [160/439], Loss: 1.0435\n",
      "Epoch [152/400], Step [180/439], Loss: 1.0328\n",
      "Epoch [152/400], Step [200/439], Loss: 1.0461\n",
      "Epoch [152/400], Step [220/439], Loss: 1.2440\n",
      "Epoch [152/400], Step [240/439], Loss: 1.4814\n",
      "Epoch [152/400], Step [260/439], Loss: 1.0583\n",
      "Epoch [152/400], Step [280/439], Loss: 0.9366\n",
      "Epoch [152/400], Step [300/439], Loss: 1.2353\n",
      "Epoch [152/400], Step [320/439], Loss: 1.0763\n",
      "Epoch [152/400], Step [340/439], Loss: 1.4213\n",
      "Epoch [152/400], Step [360/439], Loss: 1.1203\n",
      "Epoch [152/400], Step [380/439], Loss: 1.2029\n",
      "Epoch [152/400], Step [400/439], Loss: 1.1703\n",
      "Epoch [152/400], Step [420/439], Loss: 1.3135\n",
      "\n",
      "train-loss: 1.3654, train-acc: 59.9016\n",
      "validation loss: 1.3017, validation acc: 63.7186\n",
      "\n",
      "Epoch 153\n",
      "\n",
      "Epoch [153/400], Step [0/439], Loss: 1.0897\n",
      "Epoch [153/400], Step [20/439], Loss: 1.1151\n",
      "Epoch [153/400], Step [40/439], Loss: 1.1875\n",
      "Epoch [153/400], Step [60/439], Loss: 1.2976\n",
      "Epoch [153/400], Step [80/439], Loss: 0.9998\n",
      "Epoch [153/400], Step [100/439], Loss: 0.9670\n",
      "Epoch [153/400], Step [120/439], Loss: 1.4838\n",
      "Epoch [153/400], Step [140/439], Loss: 1.4228\n",
      "Epoch [153/400], Step [160/439], Loss: 1.1440\n",
      "Epoch [153/400], Step [180/439], Loss: 1.2075\n",
      "Epoch [153/400], Step [200/439], Loss: 1.2523\n",
      "Epoch [153/400], Step [220/439], Loss: 1.0378\n",
      "Epoch [153/400], Step [240/439], Loss: 0.9750\n",
      "Epoch [153/400], Step [260/439], Loss: 0.9748\n",
      "Epoch [153/400], Step [280/439], Loss: 1.6645\n",
      "Epoch [153/400], Step [300/439], Loss: 1.3005\n",
      "Epoch [153/400], Step [320/439], Loss: 1.4242\n",
      "Epoch [153/400], Step [340/439], Loss: 0.8115\n",
      "Epoch [153/400], Step [360/439], Loss: 1.7099\n",
      "Epoch [153/400], Step [380/439], Loss: 1.0550\n",
      "Epoch [153/400], Step [400/439], Loss: 1.3614\n",
      "Epoch [153/400], Step [420/439], Loss: 1.1611\n",
      "\n",
      "train-loss: 1.3645, train-acc: 59.7448\n",
      "validation loss: 1.3009, validation acc: 60.2117\n",
      "\n",
      "Epoch 154\n",
      "\n",
      "Epoch [154/400], Step [0/439], Loss: 1.2011\n",
      "Epoch [154/400], Step [20/439], Loss: 1.3797\n",
      "Epoch [154/400], Step [40/439], Loss: 0.9316\n",
      "Epoch [154/400], Step [60/439], Loss: 1.1287\n",
      "Epoch [154/400], Step [80/439], Loss: 1.0741\n",
      "Epoch [154/400], Step [100/439], Loss: 0.9387\n",
      "Epoch [154/400], Step [120/439], Loss: 1.1342\n",
      "Epoch [154/400], Step [140/439], Loss: 1.1608\n",
      "Epoch [154/400], Step [160/439], Loss: 1.4546\n",
      "Epoch [154/400], Step [180/439], Loss: 1.2278\n",
      "Epoch [154/400], Step [200/439], Loss: 0.8273\n",
      "Epoch [154/400], Step [220/439], Loss: 1.2561\n",
      "Epoch [154/400], Step [240/439], Loss: 1.3541\n",
      "Epoch [154/400], Step [260/439], Loss: 1.0903\n",
      "Epoch [154/400], Step [280/439], Loss: 1.1948\n",
      "Epoch [154/400], Step [300/439], Loss: 1.5006\n",
      "Epoch [154/400], Step [320/439], Loss: 1.0874\n",
      "Epoch [154/400], Step [340/439], Loss: 1.4070\n",
      "Epoch [154/400], Step [360/439], Loss: 1.1972\n",
      "Epoch [154/400], Step [380/439], Loss: 1.0020\n",
      "Epoch [154/400], Step [400/439], Loss: 1.3714\n",
      "Epoch [154/400], Step [420/439], Loss: 1.3849\n",
      "\n",
      "train-loss: 1.3637, train-acc: 59.8018\n",
      "validation loss: 1.3001, validation acc: 61.7556\n",
      "\n",
      "Epoch 155\n",
      "\n",
      "Epoch [155/400], Step [0/439], Loss: 1.1365\n",
      "Epoch [155/400], Step [20/439], Loss: 1.4421\n",
      "Epoch [155/400], Step [40/439], Loss: 1.1148\n",
      "Epoch [155/400], Step [60/439], Loss: 1.0374\n",
      "Epoch [155/400], Step [80/439], Loss: 1.1649\n",
      "Epoch [155/400], Step [100/439], Loss: 1.1162\n",
      "Epoch [155/400], Step [120/439], Loss: 0.7482\n",
      "Epoch [155/400], Step [140/439], Loss: 1.0485\n",
      "Epoch [155/400], Step [160/439], Loss: 1.4263\n",
      "Epoch [155/400], Step [180/439], Loss: 0.9937\n",
      "Epoch [155/400], Step [200/439], Loss: 0.8062\n",
      "Epoch [155/400], Step [220/439], Loss: 1.1665\n",
      "Epoch [155/400], Step [240/439], Loss: 1.4659\n",
      "Epoch [155/400], Step [260/439], Loss: 1.5534\n",
      "Epoch [155/400], Step [280/439], Loss: 1.1736\n",
      "Epoch [155/400], Step [300/439], Loss: 1.1258\n",
      "Epoch [155/400], Step [320/439], Loss: 1.0895\n",
      "Epoch [155/400], Step [340/439], Loss: 1.1421\n",
      "Epoch [155/400], Step [360/439], Loss: 1.5744\n",
      "Epoch [155/400], Step [380/439], Loss: 1.0699\n",
      "Epoch [155/400], Step [400/439], Loss: 0.9675\n",
      "Epoch [155/400], Step [420/439], Loss: 1.7929\n",
      "\n",
      "train-loss: 1.3628, train-acc: 59.9943\n",
      "validation loss: 1.2992, validation acc: 61.6012\n",
      "\n",
      "Epoch 156\n",
      "\n",
      "Epoch [156/400], Step [0/439], Loss: 1.2826\n",
      "Epoch [156/400], Step [20/439], Loss: 0.9997\n",
      "Epoch [156/400], Step [40/439], Loss: 1.0974\n",
      "Epoch [156/400], Step [60/439], Loss: 1.2224\n",
      "Epoch [156/400], Step [80/439], Loss: 1.0984\n",
      "Epoch [156/400], Step [100/439], Loss: 1.1341\n",
      "Epoch [156/400], Step [120/439], Loss: 1.1318\n",
      "Epoch [156/400], Step [140/439], Loss: 1.0305\n",
      "Epoch [156/400], Step [160/439], Loss: 1.1514\n",
      "Epoch [156/400], Step [180/439], Loss: 0.9522\n",
      "Epoch [156/400], Step [200/439], Loss: 1.1226\n",
      "Epoch [156/400], Step [220/439], Loss: 1.2976\n",
      "Epoch [156/400], Step [240/439], Loss: 1.1629\n",
      "Epoch [156/400], Step [260/439], Loss: 1.3078\n",
      "Epoch [156/400], Step [280/439], Loss: 1.1081\n",
      "Epoch [156/400], Step [300/439], Loss: 1.1477\n",
      "Epoch [156/400], Step [320/439], Loss: 0.9970\n",
      "Epoch [156/400], Step [340/439], Loss: 0.9466\n",
      "Epoch [156/400], Step [360/439], Loss: 1.2143\n",
      "Epoch [156/400], Step [380/439], Loss: 1.0564\n",
      "Epoch [156/400], Step [400/439], Loss: 1.1916\n",
      "Epoch [156/400], Step [420/439], Loss: 0.8567\n",
      "\n",
      "train-loss: 1.3619, train-acc: 59.9729\n",
      "validation loss: 1.2983, validation acc: 62.3291\n",
      "\n",
      "Epoch 157\n",
      "\n",
      "Epoch [157/400], Step [0/439], Loss: 1.8274\n",
      "Epoch [157/400], Step [20/439], Loss: 0.9177\n",
      "Epoch [157/400], Step [40/439], Loss: 1.2776\n",
      "Epoch [157/400], Step [60/439], Loss: 1.4170\n",
      "Epoch [157/400], Step [80/439], Loss: 1.2538\n",
      "Epoch [157/400], Step [100/439], Loss: 1.1681\n",
      "Epoch [157/400], Step [120/439], Loss: 0.8892\n",
      "Epoch [157/400], Step [140/439], Loss: 1.1579\n",
      "Epoch [157/400], Step [160/439], Loss: 1.4575\n",
      "Epoch [157/400], Step [180/439], Loss: 1.5269\n",
      "Epoch [157/400], Step [200/439], Loss: 1.1853\n",
      "Epoch [157/400], Step [220/439], Loss: 0.9318\n",
      "Epoch [157/400], Step [240/439], Loss: 1.0407\n",
      "Epoch [157/400], Step [260/439], Loss: 0.9390\n",
      "Epoch [157/400], Step [280/439], Loss: 1.0960\n",
      "Epoch [157/400], Step [300/439], Loss: 1.4883\n",
      "Epoch [157/400], Step [320/439], Loss: 1.4468\n",
      "Epoch [157/400], Step [340/439], Loss: 0.9835\n",
      "Epoch [157/400], Step [360/439], Loss: 1.3816\n",
      "Epoch [157/400], Step [380/439], Loss: 0.8780\n",
      "Epoch [157/400], Step [400/439], Loss: 1.0589\n",
      "Epoch [157/400], Step [420/439], Loss: 1.2885\n",
      "\n",
      "train-loss: 1.3611, train-acc: 59.9444\n",
      "validation loss: 1.2974, validation acc: 62.4173\n",
      "\n",
      "Epoch 158\n",
      "\n",
      "Epoch [158/400], Step [0/439], Loss: 1.0043\n",
      "Epoch [158/400], Step [20/439], Loss: 1.4342\n",
      "Epoch [158/400], Step [40/439], Loss: 1.2698\n",
      "Epoch [158/400], Step [60/439], Loss: 0.9327\n",
      "Epoch [158/400], Step [80/439], Loss: 1.1578\n",
      "Epoch [158/400], Step [100/439], Loss: 1.2530\n",
      "Epoch [158/400], Step [120/439], Loss: 1.1482\n",
      "Epoch [158/400], Step [140/439], Loss: 0.9973\n",
      "Epoch [158/400], Step [160/439], Loss: 0.9387\n",
      "Epoch [158/400], Step [180/439], Loss: 1.0727\n",
      "Epoch [158/400], Step [200/439], Loss: 1.0364\n",
      "Epoch [158/400], Step [220/439], Loss: 1.0574\n",
      "Epoch [158/400], Step [240/439], Loss: 0.9081\n",
      "Epoch [158/400], Step [260/439], Loss: 0.8933\n",
      "Epoch [158/400], Step [280/439], Loss: 1.2917\n",
      "Epoch [158/400], Step [300/439], Loss: 1.4528\n",
      "Epoch [158/400], Step [320/439], Loss: 1.0387\n",
      "Epoch [158/400], Step [340/439], Loss: 1.1773\n",
      "Epoch [158/400], Step [360/439], Loss: 0.9683\n",
      "Epoch [158/400], Step [380/439], Loss: 1.1383\n",
      "Epoch [158/400], Step [400/439], Loss: 1.8968\n",
      "Epoch [158/400], Step [420/439], Loss: 1.0634\n",
      "\n",
      "train-loss: 1.3602, train-acc: 59.6878\n",
      "validation loss: 1.2972, validation acc: 56.9916\n",
      "\n",
      "Epoch 159\n",
      "\n",
      "Epoch [159/400], Step [0/439], Loss: 1.0858\n",
      "Epoch [159/400], Step [20/439], Loss: 1.1428\n",
      "Epoch [159/400], Step [40/439], Loss: 0.9708\n",
      "Epoch [159/400], Step [60/439], Loss: 1.0006\n",
      "Epoch [159/400], Step [80/439], Loss: 1.4324\n",
      "Epoch [159/400], Step [100/439], Loss: 0.9291\n",
      "Epoch [159/400], Step [120/439], Loss: 1.2417\n",
      "Epoch [159/400], Step [140/439], Loss: 1.2995\n",
      "Epoch [159/400], Step [160/439], Loss: 1.3450\n",
      "Epoch [159/400], Step [180/439], Loss: 1.3672\n",
      "Epoch [159/400], Step [200/439], Loss: 1.0444\n",
      "Epoch [159/400], Step [220/439], Loss: 1.1543\n",
      "Epoch [159/400], Step [240/439], Loss: 1.3182\n",
      "Epoch [159/400], Step [260/439], Loss: 1.1030\n",
      "Epoch [159/400], Step [280/439], Loss: 1.2401\n",
      "Epoch [159/400], Step [300/439], Loss: 1.1166\n",
      "Epoch [159/400], Step [320/439], Loss: 0.9626\n",
      "Epoch [159/400], Step [340/439], Loss: 0.9922\n",
      "Epoch [159/400], Step [360/439], Loss: 1.4310\n",
      "Epoch [159/400], Step [380/439], Loss: 1.0632\n",
      "Epoch [159/400], Step [400/439], Loss: 1.5954\n",
      "Epoch [159/400], Step [420/439], Loss: 1.2459\n",
      "\n",
      "train-loss: 1.3593, train-acc: 60.0798\n",
      "validation loss: 1.2962, validation acc: 62.8363\n",
      "\n",
      "Epoch 160\n",
      "\n",
      "Epoch [160/400], Step [0/439], Loss: 1.3858\n",
      "Epoch [160/400], Step [20/439], Loss: 1.2200\n",
      "Epoch [160/400], Step [40/439], Loss: 1.0445\n",
      "Epoch [160/400], Step [60/439], Loss: 0.9890\n",
      "Epoch [160/400], Step [80/439], Loss: 1.1367\n",
      "Epoch [160/400], Step [100/439], Loss: 1.1330\n",
      "Epoch [160/400], Step [120/439], Loss: 1.1127\n",
      "Epoch [160/400], Step [140/439], Loss: 1.0533\n",
      "Epoch [160/400], Step [160/439], Loss: 1.0374\n",
      "Epoch [160/400], Step [180/439], Loss: 1.0692\n",
      "Epoch [160/400], Step [200/439], Loss: 0.9092\n",
      "Epoch [160/400], Step [220/439], Loss: 0.8230\n",
      "Epoch [160/400], Step [240/439], Loss: 1.1727\n",
      "Epoch [160/400], Step [260/439], Loss: 1.1080\n",
      "Epoch [160/400], Step [280/439], Loss: 1.1241\n",
      "Epoch [160/400], Step [300/439], Loss: 1.2171\n",
      "Epoch [160/400], Step [320/439], Loss: 1.2252\n",
      "Epoch [160/400], Step [340/439], Loss: 0.8889\n",
      "Epoch [160/400], Step [360/439], Loss: 1.2345\n",
      "Epoch [160/400], Step [380/439], Loss: 0.7520\n",
      "Epoch [160/400], Step [400/439], Loss: 1.0091\n",
      "Epoch [160/400], Step [420/439], Loss: 1.0363\n",
      "\n",
      "train-loss: 1.3584, train-acc: 60.1440\n",
      "validation loss: 1.2955, validation acc: 60.3220\n",
      "\n",
      "Epoch 161\n",
      "\n",
      "Epoch [161/400], Step [0/439], Loss: 1.4539\n",
      "Epoch [161/400], Step [20/439], Loss: 1.6384\n",
      "Epoch [161/400], Step [40/439], Loss: 1.2961\n",
      "Epoch [161/400], Step [60/439], Loss: 1.2926\n",
      "Epoch [161/400], Step [80/439], Loss: 0.9823\n",
      "Epoch [161/400], Step [100/439], Loss: 0.9944\n",
      "Epoch [161/400], Step [120/439], Loss: 0.6785\n",
      "Epoch [161/400], Step [140/439], Loss: 1.3278\n",
      "Epoch [161/400], Step [160/439], Loss: 1.2381\n",
      "Epoch [161/400], Step [180/439], Loss: 1.4661\n",
      "Epoch [161/400], Step [200/439], Loss: 1.0960\n",
      "Epoch [161/400], Step [220/439], Loss: 1.1733\n",
      "Epoch [161/400], Step [240/439], Loss: 1.1543\n",
      "Epoch [161/400], Step [260/439], Loss: 1.0832\n",
      "Epoch [161/400], Step [280/439], Loss: 1.0016\n",
      "Epoch [161/400], Step [300/439], Loss: 1.2115\n",
      "Epoch [161/400], Step [320/439], Loss: 0.7764\n",
      "Epoch [161/400], Step [340/439], Loss: 1.2003\n",
      "Epoch [161/400], Step [360/439], Loss: 0.8463\n",
      "Epoch [161/400], Step [380/439], Loss: 1.1269\n",
      "Epoch [161/400], Step [400/439], Loss: 1.1533\n",
      "Epoch [161/400], Step [420/439], Loss: 1.2419\n",
      "\n",
      "train-loss: 1.3576, train-acc: 59.5167\n",
      "validation loss: 1.2945, validation acc: 63.3657\n",
      "\n",
      "Epoch 162\n",
      "\n",
      "Epoch [162/400], Step [0/439], Loss: 0.8218\n",
      "Epoch [162/400], Step [20/439], Loss: 1.0576\n",
      "Epoch [162/400], Step [40/439], Loss: 1.1778\n",
      "Epoch [162/400], Step [60/439], Loss: 1.2572\n",
      "Epoch [162/400], Step [80/439], Loss: 1.1045\n",
      "Epoch [162/400], Step [100/439], Loss: 1.4622\n",
      "Epoch [162/400], Step [120/439], Loss: 1.5129\n",
      "Epoch [162/400], Step [140/439], Loss: 1.0307\n",
      "Epoch [162/400], Step [160/439], Loss: 1.3793\n",
      "Epoch [162/400], Step [180/439], Loss: 1.5277\n",
      "Epoch [162/400], Step [200/439], Loss: 1.0571\n",
      "Epoch [162/400], Step [220/439], Loss: 1.2331\n",
      "Epoch [162/400], Step [240/439], Loss: 1.1663\n",
      "Epoch [162/400], Step [260/439], Loss: 1.3487\n",
      "Epoch [162/400], Step [280/439], Loss: 1.4330\n",
      "Epoch [162/400], Step [300/439], Loss: 1.2947\n",
      "Epoch [162/400], Step [320/439], Loss: 1.2313\n",
      "Epoch [162/400], Step [340/439], Loss: 1.2970\n",
      "Epoch [162/400], Step [360/439], Loss: 1.0835\n",
      "Epoch [162/400], Step [380/439], Loss: 1.0313\n",
      "Epoch [162/400], Step [400/439], Loss: 1.4530\n",
      "Epoch [162/400], Step [420/439], Loss: 0.9956\n",
      "\n",
      "train-loss: 1.3567, train-acc: 60.1654\n",
      "validation loss: 1.2935, validation acc: 62.6158\n",
      "\n",
      "Epoch 163\n",
      "\n",
      "Epoch [163/400], Step [0/439], Loss: 1.4302\n",
      "Epoch [163/400], Step [20/439], Loss: 0.9819\n",
      "Epoch [163/400], Step [40/439], Loss: 1.3122\n",
      "Epoch [163/400], Step [60/439], Loss: 1.0620\n",
      "Epoch [163/400], Step [80/439], Loss: 1.4996\n",
      "Epoch [163/400], Step [100/439], Loss: 1.2674\n",
      "Epoch [163/400], Step [120/439], Loss: 1.2188\n",
      "Epoch [163/400], Step [140/439], Loss: 0.8377\n",
      "Epoch [163/400], Step [160/439], Loss: 1.3997\n",
      "Epoch [163/400], Step [180/439], Loss: 1.4803\n",
      "Epoch [163/400], Step [200/439], Loss: 1.2656\n",
      "Epoch [163/400], Step [220/439], Loss: 1.0599\n",
      "Epoch [163/400], Step [240/439], Loss: 0.8351\n",
      "Epoch [163/400], Step [260/439], Loss: 1.3056\n",
      "Epoch [163/400], Step [280/439], Loss: 1.0664\n",
      "Epoch [163/400], Step [300/439], Loss: 1.2318\n",
      "Epoch [163/400], Step [320/439], Loss: 0.9132\n",
      "Epoch [163/400], Step [340/439], Loss: 1.1921\n",
      "Epoch [163/400], Step [360/439], Loss: 1.5032\n",
      "Epoch [163/400], Step [380/439], Loss: 1.2562\n",
      "Epoch [163/400], Step [400/439], Loss: 1.6105\n",
      "Epoch [163/400], Step [420/439], Loss: 0.9642\n",
      "\n",
      "train-loss: 1.3558, train-acc: 59.7662\n",
      "validation loss: 1.2928, validation acc: 60.2558\n",
      "\n",
      "Epoch 164\n",
      "\n",
      "Epoch [164/400], Step [0/439], Loss: 0.7151\n",
      "Epoch [164/400], Step [20/439], Loss: 1.0886\n",
      "Epoch [164/400], Step [40/439], Loss: 1.0141\n",
      "Epoch [164/400], Step [60/439], Loss: 1.2498\n",
      "Epoch [164/400], Step [80/439], Loss: 1.1135\n",
      "Epoch [164/400], Step [100/439], Loss: 1.3287\n",
      "Epoch [164/400], Step [120/439], Loss: 1.5981\n",
      "Epoch [164/400], Step [140/439], Loss: 1.0809\n",
      "Epoch [164/400], Step [160/439], Loss: 1.3932\n",
      "Epoch [164/400], Step [180/439], Loss: 1.0422\n",
      "Epoch [164/400], Step [200/439], Loss: 1.5160\n",
      "Epoch [164/400], Step [220/439], Loss: 1.0215\n",
      "Epoch [164/400], Step [240/439], Loss: 0.9672\n",
      "Epoch [164/400], Step [260/439], Loss: 0.9504\n",
      "Epoch [164/400], Step [280/439], Loss: 1.0534\n",
      "Epoch [164/400], Step [300/439], Loss: 1.1298\n",
      "Epoch [164/400], Step [320/439], Loss: 1.1144\n",
      "Epoch [164/400], Step [340/439], Loss: 1.1548\n",
      "Epoch [164/400], Step [360/439], Loss: 0.9901\n",
      "Epoch [164/400], Step [380/439], Loss: 1.4517\n",
      "Epoch [164/400], Step [400/439], Loss: 0.9725\n",
      "Epoch [164/400], Step [420/439], Loss: 1.2304\n",
      "\n",
      "train-loss: 1.3550, train-acc: 60.0798\n",
      "validation loss: 1.2924, validation acc: 60.0353\n",
      "\n",
      "Epoch 165\n",
      "\n",
      "Epoch [165/400], Step [0/439], Loss: 1.2878\n",
      "Epoch [165/400], Step [20/439], Loss: 1.1967\n",
      "Epoch [165/400], Step [40/439], Loss: 1.2781\n",
      "Epoch [165/400], Step [60/439], Loss: 1.0723\n",
      "Epoch [165/400], Step [80/439], Loss: 1.2886\n",
      "Epoch [165/400], Step [100/439], Loss: 1.1051\n",
      "Epoch [165/400], Step [120/439], Loss: 0.9362\n",
      "Epoch [165/400], Step [140/439], Loss: 1.0336\n",
      "Epoch [165/400], Step [160/439], Loss: 1.2694\n",
      "Epoch [165/400], Step [180/439], Loss: 1.4508\n",
      "Epoch [165/400], Step [200/439], Loss: 1.1448\n",
      "Epoch [165/400], Step [220/439], Loss: 1.0042\n",
      "Epoch [165/400], Step [240/439], Loss: 1.5695\n",
      "Epoch [165/400], Step [260/439], Loss: 1.3551\n",
      "Epoch [165/400], Step [280/439], Loss: 0.9889\n",
      "Epoch [165/400], Step [300/439], Loss: 0.8923\n",
      "Epoch [165/400], Step [320/439], Loss: 1.0126\n",
      "Epoch [165/400], Step [340/439], Loss: 1.0196\n",
      "Epoch [165/400], Step [360/439], Loss: 1.1738\n",
      "Epoch [165/400], Step [380/439], Loss: 0.8708\n",
      "Epoch [165/400], Step [400/439], Loss: 1.6528\n",
      "Epoch [165/400], Step [420/439], Loss: 1.0848\n",
      "\n",
      "train-loss: 1.3542, train-acc: 59.8802\n",
      "validation loss: 1.2926, validation acc: 54.5876\n",
      "\n",
      "Epoch 166\n",
      "\n",
      "Epoch [166/400], Step [0/439], Loss: 1.0721\n",
      "Epoch [166/400], Step [20/439], Loss: 1.0396\n",
      "Epoch [166/400], Step [40/439], Loss: 1.1090\n",
      "Epoch [166/400], Step [60/439], Loss: 1.2241\n",
      "Epoch [166/400], Step [80/439], Loss: 1.3009\n",
      "Epoch [166/400], Step [100/439], Loss: 1.2422\n",
      "Epoch [166/400], Step [120/439], Loss: 1.2884\n",
      "Epoch [166/400], Step [140/439], Loss: 1.2866\n",
      "Epoch [166/400], Step [160/439], Loss: 1.0147\n",
      "Epoch [166/400], Step [180/439], Loss: 1.4647\n",
      "Epoch [166/400], Step [200/439], Loss: 0.8985\n",
      "Epoch [166/400], Step [220/439], Loss: 1.3853\n",
      "Epoch [166/400], Step [240/439], Loss: 1.0509\n",
      "Epoch [166/400], Step [260/439], Loss: 0.7821\n",
      "Epoch [166/400], Step [280/439], Loss: 1.4718\n",
      "Epoch [166/400], Step [300/439], Loss: 1.1754\n",
      "Epoch [166/400], Step [320/439], Loss: 0.9893\n",
      "Epoch [166/400], Step [340/439], Loss: 0.8113\n",
      "Epoch [166/400], Step [360/439], Loss: 1.1066\n",
      "Epoch [166/400], Step [380/439], Loss: 1.2278\n",
      "Epoch [166/400], Step [400/439], Loss: 1.2419\n",
      "Epoch [166/400], Step [420/439], Loss: 1.0730\n",
      "\n",
      "train-loss: 1.3533, train-acc: 60.0870\n",
      "validation loss: 1.2917, validation acc: 62.8143\n",
      "\n",
      "Epoch 167\n",
      "\n",
      "Epoch [167/400], Step [0/439], Loss: 1.4400\n",
      "Epoch [167/400], Step [20/439], Loss: 1.1805\n",
      "Epoch [167/400], Step [40/439], Loss: 1.2547\n",
      "Epoch [167/400], Step [60/439], Loss: 1.3707\n",
      "Epoch [167/400], Step [80/439], Loss: 0.8441\n",
      "Epoch [167/400], Step [100/439], Loss: 1.2026\n",
      "Epoch [167/400], Step [120/439], Loss: 0.9539\n",
      "Epoch [167/400], Step [140/439], Loss: 1.2715\n",
      "Epoch [167/400], Step [160/439], Loss: 0.9610\n",
      "Epoch [167/400], Step [180/439], Loss: 1.1423\n",
      "Epoch [167/400], Step [200/439], Loss: 1.1689\n",
      "Epoch [167/400], Step [220/439], Loss: 1.1642\n",
      "Epoch [167/400], Step [240/439], Loss: 0.9901\n",
      "Epoch [167/400], Step [260/439], Loss: 1.0805\n",
      "Epoch [167/400], Step [280/439], Loss: 1.0964\n",
      "Epoch [167/400], Step [300/439], Loss: 0.7928\n",
      "Epoch [167/400], Step [320/439], Loss: 1.0778\n",
      "Epoch [167/400], Step [340/439], Loss: 1.1554\n",
      "Epoch [167/400], Step [360/439], Loss: 1.1379\n",
      "Epoch [167/400], Step [380/439], Loss: 1.3245\n",
      "Epoch [167/400], Step [400/439], Loss: 0.9728\n",
      "Epoch [167/400], Step [420/439], Loss: 1.3659\n",
      "\n",
      "train-loss: 1.3524, train-acc: 60.8070\n",
      "validation loss: 1.2907, validation acc: 62.9907\n",
      "\n",
      "Epoch 168\n",
      "\n",
      "Epoch [168/400], Step [0/439], Loss: 1.1155\n",
      "Epoch [168/400], Step [20/439], Loss: 1.0757\n",
      "Epoch [168/400], Step [40/439], Loss: 1.0088\n",
      "Epoch [168/400], Step [60/439], Loss: 1.2561\n",
      "Epoch [168/400], Step [80/439], Loss: 1.2154\n",
      "Epoch [168/400], Step [100/439], Loss: 1.1050\n",
      "Epoch [168/400], Step [120/439], Loss: 1.0999\n",
      "Epoch [168/400], Step [140/439], Loss: 1.6539\n",
      "Epoch [168/400], Step [160/439], Loss: 1.1035\n",
      "Epoch [168/400], Step [180/439], Loss: 0.8951\n",
      "Epoch [168/400], Step [200/439], Loss: 1.3456\n",
      "Epoch [168/400], Step [220/439], Loss: 1.6532\n",
      "Epoch [168/400], Step [240/439], Loss: 1.4866\n",
      "Epoch [168/400], Step [260/439], Loss: 1.3819\n",
      "Epoch [168/400], Step [280/439], Loss: 1.3558\n",
      "Epoch [168/400], Step [300/439], Loss: 1.2578\n",
      "Epoch [168/400], Step [320/439], Loss: 0.9415\n",
      "Epoch [168/400], Step [340/439], Loss: 1.6749\n",
      "Epoch [168/400], Step [360/439], Loss: 1.4356\n",
      "Epoch [168/400], Step [380/439], Loss: 1.3864\n",
      "Epoch [168/400], Step [400/439], Loss: 1.1305\n",
      "Epoch [168/400], Step [420/439], Loss: 1.1535\n",
      "\n",
      "train-loss: 1.3516, train-acc: 60.2153\n",
      "validation loss: 1.2900, validation acc: 62.0203\n",
      "\n",
      "Epoch 169\n",
      "\n",
      "Epoch [169/400], Step [0/439], Loss: 1.1782\n",
      "Epoch [169/400], Step [20/439], Loss: 1.2687\n",
      "Epoch [169/400], Step [40/439], Loss: 1.3098\n",
      "Epoch [169/400], Step [60/439], Loss: 1.0334\n",
      "Epoch [169/400], Step [80/439], Loss: 1.0377\n",
      "Epoch [169/400], Step [100/439], Loss: 1.2012\n",
      "Epoch [169/400], Step [120/439], Loss: 1.4357\n",
      "Epoch [169/400], Step [140/439], Loss: 1.0107\n",
      "Epoch [169/400], Step [160/439], Loss: 0.8277\n",
      "Epoch [169/400], Step [180/439], Loss: 0.9375\n",
      "Epoch [169/400], Step [200/439], Loss: 1.1886\n",
      "Epoch [169/400], Step [220/439], Loss: 1.3211\n",
      "Epoch [169/400], Step [240/439], Loss: 1.2673\n",
      "Epoch [169/400], Step [260/439], Loss: 1.1016\n",
      "Epoch [169/400], Step [280/439], Loss: 1.1667\n",
      "Epoch [169/400], Step [300/439], Loss: 1.0727\n",
      "Epoch [169/400], Step [320/439], Loss: 1.1809\n",
      "Epoch [169/400], Step [340/439], Loss: 0.9579\n",
      "Epoch [169/400], Step [360/439], Loss: 1.2862\n",
      "Epoch [169/400], Step [380/439], Loss: 0.9356\n",
      "Epoch [169/400], Step [400/439], Loss: 1.4754\n",
      "Epoch [169/400], Step [420/439], Loss: 1.2313\n",
      "\n",
      "train-loss: 1.3508, train-acc: 60.4719\n",
      "validation loss: 1.2892, validation acc: 62.0423\n",
      "\n",
      "Epoch 170\n",
      "\n",
      "Epoch [170/400], Step [0/439], Loss: 1.5734\n",
      "Epoch [170/400], Step [20/439], Loss: 1.0433\n",
      "Epoch [170/400], Step [40/439], Loss: 1.1428\n",
      "Epoch [170/400], Step [60/439], Loss: 1.0353\n",
      "Epoch [170/400], Step [80/439], Loss: 1.1967\n",
      "Epoch [170/400], Step [100/439], Loss: 1.1763\n",
      "Epoch [170/400], Step [120/439], Loss: 1.0544\n",
      "Epoch [170/400], Step [140/439], Loss: 1.3148\n",
      "Epoch [170/400], Step [160/439], Loss: 1.0786\n",
      "Epoch [170/400], Step [180/439], Loss: 1.6193\n",
      "Epoch [170/400], Step [200/439], Loss: 0.7403\n",
      "Epoch [170/400], Step [220/439], Loss: 1.4182\n",
      "Epoch [170/400], Step [240/439], Loss: 1.1791\n",
      "Epoch [170/400], Step [260/439], Loss: 1.3553\n",
      "Epoch [170/400], Step [280/439], Loss: 1.1353\n",
      "Epoch [170/400], Step [300/439], Loss: 0.8560\n",
      "Epoch [170/400], Step [320/439], Loss: 1.2993\n",
      "Epoch [170/400], Step [340/439], Loss: 1.6881\n",
      "Epoch [170/400], Step [360/439], Loss: 1.3536\n",
      "Epoch [170/400], Step [380/439], Loss: 1.0932\n",
      "Epoch [170/400], Step [400/439], Loss: 1.3164\n",
      "Epoch [170/400], Step [420/439], Loss: 1.0105\n",
      "\n",
      "train-loss: 1.3500, train-acc: 60.0014\n",
      "validation loss: 1.2884, validation acc: 62.7261\n",
      "\n",
      "Epoch 171\n",
      "\n",
      "Epoch [171/400], Step [0/439], Loss: 1.5035\n",
      "Epoch [171/400], Step [20/439], Loss: 1.1899\n",
      "Epoch [171/400], Step [40/439], Loss: 1.2351\n",
      "Epoch [171/400], Step [60/439], Loss: 1.2450\n",
      "Epoch [171/400], Step [80/439], Loss: 1.0948\n",
      "Epoch [171/400], Step [100/439], Loss: 1.0139\n",
      "Epoch [171/400], Step [120/439], Loss: 1.3292\n",
      "Epoch [171/400], Step [140/439], Loss: 1.1981\n",
      "Epoch [171/400], Step [160/439], Loss: 1.3241\n",
      "Epoch [171/400], Step [180/439], Loss: 1.0655\n",
      "Epoch [171/400], Step [200/439], Loss: 1.2530\n",
      "Epoch [171/400], Step [220/439], Loss: 1.1738\n",
      "Epoch [171/400], Step [240/439], Loss: 1.2719\n",
      "Epoch [171/400], Step [260/439], Loss: 1.3756\n",
      "Epoch [171/400], Step [280/439], Loss: 1.0136\n",
      "Epoch [171/400], Step [300/439], Loss: 1.1542\n",
      "Epoch [171/400], Step [320/439], Loss: 1.1596\n",
      "Epoch [171/400], Step [340/439], Loss: 0.9823\n",
      "Epoch [171/400], Step [360/439], Loss: 1.1483\n",
      "Epoch [171/400], Step [380/439], Loss: 1.0693\n",
      "Epoch [171/400], Step [400/439], Loss: 1.7374\n",
      "Epoch [171/400], Step [420/439], Loss: 0.9177\n",
      "\n",
      "train-loss: 1.3491, train-acc: 60.5147\n",
      "validation loss: 1.2875, validation acc: 62.8584\n",
      "\n",
      "Epoch 172\n",
      "\n",
      "Epoch [172/400], Step [0/439], Loss: 1.0014\n",
      "Epoch [172/400], Step [20/439], Loss: 0.8051\n",
      "Epoch [172/400], Step [40/439], Loss: 1.1528\n",
      "Epoch [172/400], Step [60/439], Loss: 1.2925\n",
      "Epoch [172/400], Step [80/439], Loss: 0.8993\n",
      "Epoch [172/400], Step [100/439], Loss: 1.3566\n",
      "Epoch [172/400], Step [120/439], Loss: 1.2617\n",
      "Epoch [172/400], Step [140/439], Loss: 1.2303\n",
      "Epoch [172/400], Step [160/439], Loss: 1.1217\n",
      "Epoch [172/400], Step [180/439], Loss: 1.4465\n",
      "Epoch [172/400], Step [200/439], Loss: 1.1113\n",
      "Epoch [172/400], Step [220/439], Loss: 0.9899\n",
      "Epoch [172/400], Step [240/439], Loss: 1.6821\n",
      "Epoch [172/400], Step [260/439], Loss: 0.8461\n",
      "Epoch [172/400], Step [280/439], Loss: 1.3252\n",
      "Epoch [172/400], Step [300/439], Loss: 1.1131\n",
      "Epoch [172/400], Step [320/439], Loss: 0.9216\n",
      "Epoch [172/400], Step [340/439], Loss: 1.0122\n",
      "Epoch [172/400], Step [360/439], Loss: 1.3069\n",
      "Epoch [172/400], Step [380/439], Loss: 1.3733\n",
      "Epoch [172/400], Step [400/439], Loss: 1.1588\n",
      "Epoch [172/400], Step [420/439], Loss: 1.5301\n",
      "\n",
      "train-loss: 1.3483, train-acc: 60.5503\n",
      "validation loss: 1.2868, validation acc: 60.9616\n",
      "\n",
      "Epoch 173\n",
      "\n",
      "Epoch [173/400], Step [0/439], Loss: 1.3487\n",
      "Epoch [173/400], Step [20/439], Loss: 1.3463\n",
      "Epoch [173/400], Step [40/439], Loss: 1.0697\n",
      "Epoch [173/400], Step [60/439], Loss: 1.3251\n",
      "Epoch [173/400], Step [80/439], Loss: 1.2232\n",
      "Epoch [173/400], Step [100/439], Loss: 1.3588\n",
      "Epoch [173/400], Step [120/439], Loss: 1.0448\n",
      "Epoch [173/400], Step [140/439], Loss: 1.1853\n",
      "Epoch [173/400], Step [160/439], Loss: 0.7293\n",
      "Epoch [173/400], Step [180/439], Loss: 1.0750\n",
      "Epoch [173/400], Step [200/439], Loss: 1.4316\n",
      "Epoch [173/400], Step [220/439], Loss: 1.3151\n",
      "Epoch [173/400], Step [240/439], Loss: 1.2035\n",
      "Epoch [173/400], Step [260/439], Loss: 1.0527\n",
      "Epoch [173/400], Step [280/439], Loss: 0.9821\n",
      "Epoch [173/400], Step [300/439], Loss: 1.2008\n",
      "Epoch [173/400], Step [320/439], Loss: 0.9009\n",
      "Epoch [173/400], Step [340/439], Loss: 1.2183\n",
      "Epoch [173/400], Step [360/439], Loss: 1.1387\n",
      "Epoch [173/400], Step [380/439], Loss: 1.2274\n",
      "Epoch [173/400], Step [400/439], Loss: 0.8763\n",
      "Epoch [173/400], Step [420/439], Loss: 1.0092\n",
      "\n",
      "train-loss: 1.3475, train-acc: 60.2866\n",
      "validation loss: 1.2859, validation acc: 62.7481\n",
      "\n",
      "Epoch 174\n",
      "\n",
      "Epoch [174/400], Step [0/439], Loss: 1.0469\n",
      "Epoch [174/400], Step [20/439], Loss: 1.7778\n",
      "Epoch [174/400], Step [40/439], Loss: 1.1822\n",
      "Epoch [174/400], Step [60/439], Loss: 0.9672\n",
      "Epoch [174/400], Step [80/439], Loss: 1.1061\n",
      "Epoch [174/400], Step [100/439], Loss: 0.9608\n",
      "Epoch [174/400], Step [120/439], Loss: 1.3622\n",
      "Epoch [174/400], Step [140/439], Loss: 1.1960\n",
      "Epoch [174/400], Step [160/439], Loss: 1.3987\n",
      "Epoch [174/400], Step [180/439], Loss: 1.2515\n",
      "Epoch [174/400], Step [200/439], Loss: 1.2848\n",
      "Epoch [174/400], Step [220/439], Loss: 0.9892\n",
      "Epoch [174/400], Step [240/439], Loss: 1.3134\n",
      "Epoch [174/400], Step [260/439], Loss: 0.9894\n",
      "Epoch [174/400], Step [280/439], Loss: 1.0277\n",
      "Epoch [174/400], Step [300/439], Loss: 0.8113\n",
      "Epoch [174/400], Step [320/439], Loss: 1.0636\n",
      "Epoch [174/400], Step [340/439], Loss: 1.1679\n",
      "Epoch [174/400], Step [360/439], Loss: 1.1397\n",
      "Epoch [174/400], Step [380/439], Loss: 1.2723\n",
      "Epoch [174/400], Step [400/439], Loss: 1.3453\n",
      "Epoch [174/400], Step [420/439], Loss: 1.2950\n",
      "\n",
      "train-loss: 1.3467, train-acc: 60.6715\n",
      "validation loss: 1.2854, validation acc: 59.2192\n",
      "\n",
      "Epoch 175\n",
      "\n",
      "Epoch [175/400], Step [0/439], Loss: 1.0532\n",
      "Epoch [175/400], Step [20/439], Loss: 1.1327\n",
      "Epoch [175/400], Step [40/439], Loss: 1.2506\n",
      "Epoch [175/400], Step [60/439], Loss: 0.7391\n",
      "Epoch [175/400], Step [80/439], Loss: 1.3688\n",
      "Epoch [175/400], Step [100/439], Loss: 1.0072\n",
      "Epoch [175/400], Step [120/439], Loss: 1.2300\n",
      "Epoch [175/400], Step [140/439], Loss: 1.1746\n",
      "Epoch [175/400], Step [160/439], Loss: 1.3908\n",
      "Epoch [175/400], Step [180/439], Loss: 1.1252\n",
      "Epoch [175/400], Step [200/439], Loss: 1.0486\n",
      "Epoch [175/400], Step [220/439], Loss: 0.9879\n",
      "Epoch [175/400], Step [240/439], Loss: 1.2665\n",
      "Epoch [175/400], Step [260/439], Loss: 1.1204\n",
      "Epoch [175/400], Step [280/439], Loss: 0.8691\n",
      "Epoch [175/400], Step [300/439], Loss: 1.2606\n",
      "Epoch [175/400], Step [320/439], Loss: 1.0406\n",
      "Epoch [175/400], Step [340/439], Loss: 1.1145\n",
      "Epoch [175/400], Step [360/439], Loss: 1.4727\n",
      "Epoch [175/400], Step [380/439], Loss: 0.9163\n",
      "Epoch [175/400], Step [400/439], Loss: 1.1686\n",
      "Epoch [175/400], Step [420/439], Loss: 0.8937\n",
      "\n",
      "train-loss: 1.3457, train-acc: 61.3630\n",
      "validation loss: 1.2843, validation acc: 64.6890\n",
      "\n",
      "Improvement-Detected, save-model\n",
      "Epoch 176\n",
      "\n",
      "Epoch [176/400], Step [0/439], Loss: 1.0696\n",
      "Epoch [176/400], Step [20/439], Loss: 1.2813\n",
      "Epoch [176/400], Step [40/439], Loss: 1.0680\n",
      "Epoch [176/400], Step [60/439], Loss: 0.9360\n",
      "Epoch [176/400], Step [80/439], Loss: 1.3453\n",
      "Epoch [176/400], Step [100/439], Loss: 0.6932\n",
      "Epoch [176/400], Step [120/439], Loss: 1.3527\n",
      "Epoch [176/400], Step [140/439], Loss: 1.1126\n",
      "Epoch [176/400], Step [160/439], Loss: 0.9572\n",
      "Epoch [176/400], Step [180/439], Loss: 0.9421\n",
      "Epoch [176/400], Step [200/439], Loss: 0.9711\n",
      "Epoch [176/400], Step [220/439], Loss: 0.9846\n",
      "Epoch [176/400], Step [240/439], Loss: 1.1821\n",
      "Epoch [176/400], Step [260/439], Loss: 1.3532\n",
      "Epoch [176/400], Step [280/439], Loss: 1.1875\n",
      "Epoch [176/400], Step [300/439], Loss: 1.1920\n",
      "Epoch [176/400], Step [320/439], Loss: 1.1498\n",
      "Epoch [176/400], Step [340/439], Loss: 1.1183\n",
      "Epoch [176/400], Step [360/439], Loss: 1.4260\n",
      "Epoch [176/400], Step [380/439], Loss: 1.2314\n",
      "Epoch [176/400], Step [400/439], Loss: 1.1807\n",
      "Epoch [176/400], Step [420/439], Loss: 1.2865\n",
      "\n",
      "train-loss: 1.3450, train-acc: 60.2367\n",
      "validation loss: 1.2834, validation acc: 64.1597\n",
      "\n",
      "Epoch 177\n",
      "\n",
      "Epoch [177/400], Step [0/439], Loss: 1.0522\n",
      "Epoch [177/400], Step [20/439], Loss: 1.1287\n",
      "Epoch [177/400], Step [40/439], Loss: 0.9868\n",
      "Epoch [177/400], Step [60/439], Loss: 1.1084\n",
      "Epoch [177/400], Step [80/439], Loss: 1.1157\n",
      "Epoch [177/400], Step [100/439], Loss: 1.3495\n",
      "Epoch [177/400], Step [120/439], Loss: 1.3099\n",
      "Epoch [177/400], Step [140/439], Loss: 1.4613\n",
      "Epoch [177/400], Step [160/439], Loss: 1.4236\n",
      "Epoch [177/400], Step [180/439], Loss: 1.0768\n",
      "Epoch [177/400], Step [200/439], Loss: 1.0864\n",
      "Epoch [177/400], Step [220/439], Loss: 1.4248\n",
      "Epoch [177/400], Step [240/439], Loss: 1.2407\n",
      "Epoch [177/400], Step [260/439], Loss: 0.8972\n",
      "Epoch [177/400], Step [280/439], Loss: 1.6148\n",
      "Epoch [177/400], Step [300/439], Loss: 1.3339\n",
      "Epoch [177/400], Step [320/439], Loss: 0.9514\n",
      "Epoch [177/400], Step [340/439], Loss: 1.3231\n",
      "Epoch [177/400], Step [360/439], Loss: 1.3380\n",
      "Epoch [177/400], Step [380/439], Loss: 0.9048\n",
      "Epoch [177/400], Step [400/439], Loss: 1.4791\n",
      "Epoch [177/400], Step [420/439], Loss: 1.3208\n",
      "\n",
      "train-loss: 1.3441, train-acc: 60.7927\n",
      "validation loss: 1.2827, validation acc: 61.2263\n",
      "\n",
      "Epoch 178\n",
      "\n",
      "Epoch [178/400], Step [0/439], Loss: 0.8288\n",
      "Epoch [178/400], Step [20/439], Loss: 1.0527\n",
      "Epoch [178/400], Step [40/439], Loss: 0.9641\n",
      "Epoch [178/400], Step [60/439], Loss: 1.2703\n",
      "Epoch [178/400], Step [80/439], Loss: 0.9680\n",
      "Epoch [178/400], Step [100/439], Loss: 0.8806\n",
      "Epoch [178/400], Step [120/439], Loss: 1.3774\n",
      "Epoch [178/400], Step [140/439], Loss: 0.9000\n",
      "Epoch [178/400], Step [160/439], Loss: 1.0914\n",
      "Epoch [178/400], Step [180/439], Loss: 0.8912\n",
      "Epoch [178/400], Step [200/439], Loss: 1.4482\n",
      "Epoch [178/400], Step [220/439], Loss: 1.3502\n",
      "Epoch [178/400], Step [240/439], Loss: 1.0966\n",
      "Epoch [178/400], Step [260/439], Loss: 1.3402\n",
      "Epoch [178/400], Step [280/439], Loss: 0.9353\n",
      "Epoch [178/400], Step [300/439], Loss: 1.1443\n",
      "Epoch [178/400], Step [320/439], Loss: 1.4004\n",
      "Epoch [178/400], Step [340/439], Loss: 1.3808\n",
      "Epoch [178/400], Step [360/439], Loss: 1.0000\n",
      "Epoch [178/400], Step [380/439], Loss: 1.0932\n",
      "Epoch [178/400], Step [400/439], Loss: 1.2429\n",
      "Epoch [178/400], Step [420/439], Loss: 1.2956\n",
      "\n",
      "train-loss: 1.3434, train-acc: 60.3650\n",
      "validation loss: 1.2819, validation acc: 62.7261\n",
      "\n",
      "Epoch 179\n",
      "\n",
      "Epoch [179/400], Step [0/439], Loss: 1.6904\n",
      "Epoch [179/400], Step [20/439], Loss: 1.1744\n",
      "Epoch [179/400], Step [40/439], Loss: 1.0274\n",
      "Epoch [179/400], Step [60/439], Loss: 0.9734\n",
      "Epoch [179/400], Step [80/439], Loss: 1.2878\n",
      "Epoch [179/400], Step [100/439], Loss: 0.9944\n",
      "Epoch [179/400], Step [120/439], Loss: 0.9188\n",
      "Epoch [179/400], Step [140/439], Loss: 0.9528\n",
      "Epoch [179/400], Step [160/439], Loss: 1.0420\n",
      "Epoch [179/400], Step [180/439], Loss: 1.0439\n",
      "Epoch [179/400], Step [200/439], Loss: 1.2034\n",
      "Epoch [179/400], Step [220/439], Loss: 1.1010\n",
      "Epoch [179/400], Step [240/439], Loss: 0.9360\n",
      "Epoch [179/400], Step [260/439], Loss: 1.0949\n",
      "Epoch [179/400], Step [280/439], Loss: 1.2511\n",
      "Epoch [179/400], Step [300/439], Loss: 1.5067\n",
      "Epoch [179/400], Step [320/439], Loss: 1.0582\n",
      "Epoch [179/400], Step [340/439], Loss: 1.5087\n",
      "Epoch [179/400], Step [360/439], Loss: 1.7361\n",
      "Epoch [179/400], Step [380/439], Loss: 1.2070\n",
      "Epoch [179/400], Step [400/439], Loss: 1.2813\n",
      "Epoch [179/400], Step [420/439], Loss: 1.1303\n",
      "\n",
      "train-loss: 1.3426, train-acc: 60.4790\n",
      "validation loss: 1.2809, validation acc: 63.4980\n",
      "\n",
      "Epoch 180\n",
      "\n",
      "Epoch [180/400], Step [0/439], Loss: 1.4469\n",
      "Epoch [180/400], Step [20/439], Loss: 1.2959\n",
      "Epoch [180/400], Step [40/439], Loss: 1.1209\n",
      "Epoch [180/400], Step [60/439], Loss: 1.1056\n",
      "Epoch [180/400], Step [80/439], Loss: 1.0594\n",
      "Epoch [180/400], Step [100/439], Loss: 1.0670\n",
      "Epoch [180/400], Step [120/439], Loss: 1.1457\n",
      "Epoch [180/400], Step [140/439], Loss: 1.2370\n",
      "Epoch [180/400], Step [160/439], Loss: 1.2660\n",
      "Epoch [180/400], Step [180/439], Loss: 1.1110\n",
      "Epoch [180/400], Step [200/439], Loss: 1.3064\n",
      "Epoch [180/400], Step [220/439], Loss: 1.1177\n",
      "Epoch [180/400], Step [240/439], Loss: 0.9917\n",
      "Epoch [180/400], Step [260/439], Loss: 1.3480\n",
      "Epoch [180/400], Step [280/439], Loss: 1.5042\n",
      "Epoch [180/400], Step [300/439], Loss: 0.9421\n",
      "Epoch [180/400], Step [320/439], Loss: 0.8551\n",
      "Epoch [180/400], Step [340/439], Loss: 0.8765\n",
      "Epoch [180/400], Step [360/439], Loss: 1.3616\n",
      "Epoch [180/400], Step [380/439], Loss: 1.1008\n",
      "Epoch [180/400], Step [400/439], Loss: 1.2361\n",
      "Epoch [180/400], Step [420/439], Loss: 0.8979\n",
      "\n",
      "train-loss: 1.3418, train-acc: 60.6287\n",
      "validation loss: 1.2805, validation acc: 60.8072\n",
      "\n",
      "Epoch 181\n",
      "\n",
      "Epoch [181/400], Step [0/439], Loss: 1.2770\n",
      "Epoch [181/400], Step [20/439], Loss: 0.9694\n",
      "Epoch [181/400], Step [40/439], Loss: 1.3669\n",
      "Epoch [181/400], Step [60/439], Loss: 0.8488\n",
      "Epoch [181/400], Step [80/439], Loss: 1.0581\n",
      "Epoch [181/400], Step [100/439], Loss: 1.1799\n",
      "Epoch [181/400], Step [120/439], Loss: 0.9782\n",
      "Epoch [181/400], Step [140/439], Loss: 0.7862\n",
      "Epoch [181/400], Step [160/439], Loss: 1.3164\n",
      "Epoch [181/400], Step [180/439], Loss: 1.5641\n",
      "Epoch [181/400], Step [200/439], Loss: 1.0898\n",
      "Epoch [181/400], Step [220/439], Loss: 1.4491\n",
      "Epoch [181/400], Step [240/439], Loss: 1.2105\n",
      "Epoch [181/400], Step [260/439], Loss: 1.1290\n",
      "Epoch [181/400], Step [280/439], Loss: 0.8928\n",
      "Epoch [181/400], Step [300/439], Loss: 1.2141\n",
      "Epoch [181/400], Step [320/439], Loss: 0.8609\n",
      "Epoch [181/400], Step [340/439], Loss: 1.3767\n",
      "Epoch [181/400], Step [360/439], Loss: 1.3005\n",
      "Epoch [181/400], Step [380/439], Loss: 0.9819\n",
      "Epoch [181/400], Step [400/439], Loss: 1.0496\n",
      "Epoch [181/400], Step [420/439], Loss: 0.9887\n",
      "\n",
      "train-loss: 1.3409, train-acc: 61.0493\n",
      "validation loss: 1.2798, validation acc: 61.8438\n",
      "\n",
      "Epoch 182\n",
      "\n",
      "Epoch [182/400], Step [0/439], Loss: 1.3374\n",
      "Epoch [182/400], Step [20/439], Loss: 1.0259\n",
      "Epoch [182/400], Step [40/439], Loss: 1.1961\n",
      "Epoch [182/400], Step [60/439], Loss: 1.0825\n",
      "Epoch [182/400], Step [80/439], Loss: 1.2290\n",
      "Epoch [182/400], Step [100/439], Loss: 1.0819\n",
      "Epoch [182/400], Step [120/439], Loss: 1.3965\n",
      "Epoch [182/400], Step [140/439], Loss: 1.0075\n",
      "Epoch [182/400], Step [160/439], Loss: 1.3163\n",
      "Epoch [182/400], Step [180/439], Loss: 1.1703\n",
      "Epoch [182/400], Step [200/439], Loss: 1.0312\n",
      "Epoch [182/400], Step [220/439], Loss: 0.8754\n",
      "Epoch [182/400], Step [240/439], Loss: 1.1323\n",
      "Epoch [182/400], Step [260/439], Loss: 0.9675\n",
      "Epoch [182/400], Step [280/439], Loss: 0.9097\n",
      "Epoch [182/400], Step [300/439], Loss: 1.2803\n",
      "Epoch [182/400], Step [320/439], Loss: 1.2100\n",
      "Epoch [182/400], Step [340/439], Loss: 1.1760\n",
      "Epoch [182/400], Step [360/439], Loss: 1.1247\n",
      "Epoch [182/400], Step [380/439], Loss: 1.1681\n",
      "Epoch [182/400], Step [400/439], Loss: 1.1044\n",
      "Epoch [182/400], Step [420/439], Loss: 1.3530\n",
      "\n",
      "train-loss: 1.3401, train-acc: 61.0493\n",
      "validation loss: 1.2793, validation acc: 59.6603\n",
      "\n",
      "Epoch 183\n",
      "\n",
      "Epoch [183/400], Step [0/439], Loss: 1.0401\n",
      "Epoch [183/400], Step [20/439], Loss: 1.1720\n",
      "Epoch [183/400], Step [40/439], Loss: 0.9913\n",
      "Epoch [183/400], Step [60/439], Loss: 1.2805\n",
      "Epoch [183/400], Step [80/439], Loss: 1.7240\n",
      "Epoch [183/400], Step [100/439], Loss: 1.4381\n",
      "Epoch [183/400], Step [120/439], Loss: 0.9392\n",
      "Epoch [183/400], Step [140/439], Loss: 1.1803\n",
      "Epoch [183/400], Step [160/439], Loss: 1.4687\n",
      "Epoch [183/400], Step [180/439], Loss: 0.9563\n",
      "Epoch [183/400], Step [200/439], Loss: 0.8830\n",
      "Epoch [183/400], Step [220/439], Loss: 0.9296\n",
      "Epoch [183/400], Step [240/439], Loss: 0.8606\n",
      "Epoch [183/400], Step [260/439], Loss: 0.9861\n",
      "Epoch [183/400], Step [280/439], Loss: 0.9460\n",
      "Epoch [183/400], Step [300/439], Loss: 1.0497\n",
      "Epoch [183/400], Step [320/439], Loss: 1.5790\n",
      "Epoch [183/400], Step [340/439], Loss: 1.3799\n",
      "Epoch [183/400], Step [360/439], Loss: 1.2212\n",
      "Epoch [183/400], Step [380/439], Loss: 0.9335\n",
      "Epoch [183/400], Step [400/439], Loss: 0.7427\n",
      "Epoch [183/400], Step [420/439], Loss: 1.0421\n",
      "\n",
      "train-loss: 1.3393, train-acc: 60.5218\n",
      "validation loss: 1.2783, validation acc: 64.4685\n",
      "\n",
      "Epoch 184\n",
      "\n",
      "Epoch [184/400], Step [0/439], Loss: 1.6159\n",
      "Epoch [184/400], Step [20/439], Loss: 0.9730\n",
      "Epoch [184/400], Step [40/439], Loss: 1.0354\n",
      "Epoch [184/400], Step [60/439], Loss: 1.1299\n",
      "Epoch [184/400], Step [80/439], Loss: 1.0773\n",
      "Epoch [184/400], Step [100/439], Loss: 1.2508\n",
      "Epoch [184/400], Step [120/439], Loss: 0.9079\n",
      "Epoch [184/400], Step [140/439], Loss: 0.8537\n",
      "Epoch [184/400], Step [160/439], Loss: 1.4519\n",
      "Epoch [184/400], Step [180/439], Loss: 1.2434\n",
      "Epoch [184/400], Step [200/439], Loss: 0.8043\n",
      "Epoch [184/400], Step [220/439], Loss: 1.0875\n",
      "Epoch [184/400], Step [240/439], Loss: 0.8323\n",
      "Epoch [184/400], Step [260/439], Loss: 0.9684\n",
      "Epoch [184/400], Step [280/439], Loss: 1.2806\n",
      "Epoch [184/400], Step [300/439], Loss: 1.1989\n",
      "Epoch [184/400], Step [320/439], Loss: 1.5095\n",
      "Epoch [184/400], Step [340/439], Loss: 1.2317\n",
      "Epoch [184/400], Step [360/439], Loss: 1.4167\n",
      "Epoch [184/400], Step [380/439], Loss: 0.9828\n",
      "Epoch [184/400], Step [400/439], Loss: 1.6500\n",
      "Epoch [184/400], Step [420/439], Loss: 1.0827\n",
      "\n",
      "train-loss: 1.3385, train-acc: 60.2937\n",
      "validation loss: 1.2776, validation acc: 62.0423\n",
      "\n",
      "Epoch 185\n",
      "\n",
      "Epoch [185/400], Step [0/439], Loss: 1.2704\n",
      "Epoch [185/400], Step [20/439], Loss: 1.1090\n",
      "Epoch [185/400], Step [40/439], Loss: 1.3798\n",
      "Epoch [185/400], Step [60/439], Loss: 1.2505\n",
      "Epoch [185/400], Step [80/439], Loss: 1.1378\n",
      "Epoch [185/400], Step [100/439], Loss: 0.8138\n",
      "Epoch [185/400], Step [120/439], Loss: 1.0755\n",
      "Epoch [185/400], Step [140/439], Loss: 1.3799\n",
      "Epoch [185/400], Step [160/439], Loss: 1.1779\n",
      "Epoch [185/400], Step [180/439], Loss: 1.3918\n",
      "Epoch [185/400], Step [200/439], Loss: 1.1298\n",
      "Epoch [185/400], Step [220/439], Loss: 1.1843\n",
      "Epoch [185/400], Step [240/439], Loss: 1.3335\n",
      "Epoch [185/400], Step [260/439], Loss: 1.1874\n",
      "Epoch [185/400], Step [280/439], Loss: 1.3843\n",
      "Epoch [185/400], Step [300/439], Loss: 1.2483\n",
      "Epoch [185/400], Step [320/439], Loss: 1.2263\n",
      "Epoch [185/400], Step [340/439], Loss: 1.2850\n",
      "Epoch [185/400], Step [360/439], Loss: 1.0333\n",
      "Epoch [185/400], Step [380/439], Loss: 1.1621\n",
      "Epoch [185/400], Step [400/439], Loss: 1.1372\n",
      "Epoch [185/400], Step [420/439], Loss: 0.9976\n",
      "\n",
      "train-loss: 1.3378, train-acc: 60.7927\n",
      "validation loss: 1.2766, validation acc: 64.6670\n",
      "\n",
      "Improvement-Detected, save-model\n",
      "Epoch 186\n",
      "\n",
      "Epoch [186/400], Step [0/439], Loss: 1.6379\n",
      "Epoch [186/400], Step [20/439], Loss: 1.1301\n",
      "Epoch [186/400], Step [40/439], Loss: 1.0941\n",
      "Epoch [186/400], Step [60/439], Loss: 1.1486\n",
      "Epoch [186/400], Step [80/439], Loss: 0.8734\n",
      "Epoch [186/400], Step [100/439], Loss: 1.5445\n",
      "Epoch [186/400], Step [120/439], Loss: 1.1534\n",
      "Epoch [186/400], Step [140/439], Loss: 1.0307\n",
      "Epoch [186/400], Step [160/439], Loss: 0.9817\n",
      "Epoch [186/400], Step [180/439], Loss: 0.7603\n",
      "Epoch [186/400], Step [200/439], Loss: 1.1328\n",
      "Epoch [186/400], Step [220/439], Loss: 0.9314\n",
      "Epoch [186/400], Step [240/439], Loss: 1.1445\n",
      "Epoch [186/400], Step [260/439], Loss: 1.1057\n",
      "Epoch [186/400], Step [280/439], Loss: 1.1504\n",
      "Epoch [186/400], Step [300/439], Loss: 1.1110\n",
      "Epoch [186/400], Step [320/439], Loss: 0.8689\n",
      "Epoch [186/400], Step [340/439], Loss: 1.1390\n",
      "Epoch [186/400], Step [360/439], Loss: 1.4153\n",
      "Epoch [186/400], Step [380/439], Loss: 1.0755\n",
      "Epoch [186/400], Step [400/439], Loss: 1.1360\n",
      "Epoch [186/400], Step [420/439], Loss: 1.1887\n",
      "\n",
      "train-loss: 1.3371, train-acc: 59.9515\n",
      "validation loss: 1.2763, validation acc: 58.0944\n",
      "\n",
      "Epoch 187\n",
      "\n",
      "Epoch [187/400], Step [0/439], Loss: 1.3311\n",
      "Epoch [187/400], Step [20/439], Loss: 0.9772\n",
      "Epoch [187/400], Step [40/439], Loss: 1.0997\n",
      "Epoch [187/400], Step [60/439], Loss: 1.6878\n",
      "Epoch [187/400], Step [80/439], Loss: 1.1890\n",
      "Epoch [187/400], Step [100/439], Loss: 1.2034\n",
      "Epoch [187/400], Step [120/439], Loss: 0.8814\n",
      "Epoch [187/400], Step [140/439], Loss: 1.3300\n",
      "Epoch [187/400], Step [160/439], Loss: 1.3338\n",
      "Epoch [187/400], Step [180/439], Loss: 1.1483\n",
      "Epoch [187/400], Step [200/439], Loss: 1.1863\n",
      "Epoch [187/400], Step [220/439], Loss: 1.1672\n",
      "Epoch [187/400], Step [240/439], Loss: 0.8663\n",
      "Epoch [187/400], Step [260/439], Loss: 0.9414\n",
      "Epoch [187/400], Step [280/439], Loss: 0.9263\n",
      "Epoch [187/400], Step [300/439], Loss: 1.2674\n",
      "Epoch [187/400], Step [320/439], Loss: 0.8325\n",
      "Epoch [187/400], Step [340/439], Loss: 1.3513\n",
      "Epoch [187/400], Step [360/439], Loss: 0.8642\n",
      "Epoch [187/400], Step [380/439], Loss: 1.1567\n",
      "Epoch [187/400], Step [400/439], Loss: 1.2482\n",
      "Epoch [187/400], Step [420/439], Loss: 1.1965\n",
      "\n",
      "train-loss: 1.3363, train-acc: 61.1776\n",
      "validation loss: 1.2759, validation acc: 60.1676\n",
      "\n",
      "Epoch 188\n",
      "\n",
      "Epoch [188/400], Step [0/439], Loss: 1.0182\n",
      "Epoch [188/400], Step [20/439], Loss: 1.0123\n",
      "Epoch [188/400], Step [40/439], Loss: 0.8119\n",
      "Epoch [188/400], Step [60/439], Loss: 1.5913\n",
      "Epoch [188/400], Step [80/439], Loss: 1.3993\n",
      "Epoch [188/400], Step [100/439], Loss: 1.2960\n",
      "Epoch [188/400], Step [120/439], Loss: 1.0434\n",
      "Epoch [188/400], Step [140/439], Loss: 1.4181\n",
      "Epoch [188/400], Step [160/439], Loss: 1.2949\n",
      "Epoch [188/400], Step [180/439], Loss: 1.3497\n",
      "Epoch [188/400], Step [200/439], Loss: 1.1662\n",
      "Epoch [188/400], Step [220/439], Loss: 1.1068\n",
      "Epoch [188/400], Step [240/439], Loss: 1.0285\n",
      "Epoch [188/400], Step [260/439], Loss: 1.0878\n",
      "Epoch [188/400], Step [280/439], Loss: 0.7634\n",
      "Epoch [188/400], Step [300/439], Loss: 1.1217\n",
      "Epoch [188/400], Step [320/439], Loss: 1.5584\n",
      "Epoch [188/400], Step [340/439], Loss: 0.8515\n",
      "Epoch [188/400], Step [360/439], Loss: 1.2130\n",
      "Epoch [188/400], Step [380/439], Loss: 1.1442\n",
      "Epoch [188/400], Step [400/439], Loss: 0.9073\n",
      "Epoch [188/400], Step [420/439], Loss: 1.3459\n",
      "\n",
      "train-loss: 1.3355, train-acc: 60.9495\n",
      "validation loss: 1.2752, validation acc: 61.2704\n",
      "\n",
      "Epoch 189\n",
      "\n",
      "Epoch [189/400], Step [0/439], Loss: 1.3376\n",
      "Epoch [189/400], Step [20/439], Loss: 0.8951\n",
      "Epoch [189/400], Step [40/439], Loss: 1.0347\n",
      "Epoch [189/400], Step [60/439], Loss: 0.8007\n",
      "Epoch [189/400], Step [80/439], Loss: 1.1292\n",
      "Epoch [189/400], Step [100/439], Loss: 0.8353\n",
      "Epoch [189/400], Step [120/439], Loss: 1.2528\n",
      "Epoch [189/400], Step [140/439], Loss: 0.9502\n",
      "Epoch [189/400], Step [160/439], Loss: 1.2404\n",
      "Epoch [189/400], Step [180/439], Loss: 1.3129\n",
      "Epoch [189/400], Step [200/439], Loss: 0.9454\n",
      "Epoch [189/400], Step [220/439], Loss: 1.5110\n",
      "Epoch [189/400], Step [240/439], Loss: 1.2090\n",
      "Epoch [189/400], Step [260/439], Loss: 1.0322\n",
      "Epoch [189/400], Step [280/439], Loss: 1.1772\n",
      "Epoch [189/400], Step [300/439], Loss: 1.1218\n",
      "Epoch [189/400], Step [320/439], Loss: 0.9880\n",
      "Epoch [189/400], Step [340/439], Loss: 1.4293\n",
      "Epoch [189/400], Step [360/439], Loss: 1.2350\n",
      "Epoch [189/400], Step [380/439], Loss: 1.2354\n",
      "Epoch [189/400], Step [400/439], Loss: 0.9142\n",
      "Epoch [189/400], Step [420/439], Loss: 1.0745\n",
      "\n",
      "train-loss: 1.3348, train-acc: 60.9852\n",
      "validation loss: 1.2746, validation acc: 62.2850\n",
      "\n",
      "Epoch 190\n",
      "\n",
      "Epoch [190/400], Step [0/439], Loss: 1.4747\n",
      "Epoch [190/400], Step [20/439], Loss: 0.7644\n",
      "Epoch [190/400], Step [40/439], Loss: 1.4727\n",
      "Epoch [190/400], Step [60/439], Loss: 1.4223\n",
      "Epoch [190/400], Step [80/439], Loss: 0.8863\n",
      "Epoch [190/400], Step [100/439], Loss: 1.2441\n",
      "Epoch [190/400], Step [120/439], Loss: 1.0719\n",
      "Epoch [190/400], Step [140/439], Loss: 1.4971\n",
      "Epoch [190/400], Step [160/439], Loss: 1.2333\n",
      "Epoch [190/400], Step [180/439], Loss: 1.3252\n",
      "Epoch [190/400], Step [200/439], Loss: 1.0568\n",
      "Epoch [190/400], Step [220/439], Loss: 1.0283\n",
      "Epoch [190/400], Step [240/439], Loss: 0.9487\n",
      "Epoch [190/400], Step [260/439], Loss: 0.7196\n",
      "Epoch [190/400], Step [280/439], Loss: 0.9835\n",
      "Epoch [190/400], Step [300/439], Loss: 1.2241\n",
      "Epoch [190/400], Step [320/439], Loss: 1.3137\n",
      "Epoch [190/400], Step [340/439], Loss: 1.4663\n",
      "Epoch [190/400], Step [360/439], Loss: 1.1406\n",
      "Epoch [190/400], Step [380/439], Loss: 1.1591\n",
      "Epoch [190/400], Step [400/439], Loss: 0.9381\n",
      "Epoch [190/400], Step [420/439], Loss: 1.0687\n",
      "\n",
      "train-loss: 1.3340, train-acc: 60.4862\n",
      "validation loss: 1.2737, validation acc: 63.2775\n",
      "\n",
      "Epoch 191\n",
      "\n",
      "Epoch [191/400], Step [0/439], Loss: 1.1261\n",
      "Epoch [191/400], Step [20/439], Loss: 1.2298\n",
      "Epoch [191/400], Step [40/439], Loss: 0.9456\n",
      "Epoch [191/400], Step [60/439], Loss: 1.8831\n",
      "Epoch [191/400], Step [80/439], Loss: 1.1949\n",
      "Epoch [191/400], Step [100/439], Loss: 1.2119\n",
      "Epoch [191/400], Step [120/439], Loss: 1.2143\n",
      "Epoch [191/400], Step [140/439], Loss: 1.0073\n",
      "Epoch [191/400], Step [160/439], Loss: 1.3671\n",
      "Epoch [191/400], Step [180/439], Loss: 1.2366\n",
      "Epoch [191/400], Step [200/439], Loss: 1.5105\n",
      "Epoch [191/400], Step [220/439], Loss: 1.1653\n",
      "Epoch [191/400], Step [240/439], Loss: 1.1119\n",
      "Epoch [191/400], Step [260/439], Loss: 1.1436\n",
      "Epoch [191/400], Step [280/439], Loss: 1.0255\n",
      "Epoch [191/400], Step [300/439], Loss: 1.1328\n",
      "Epoch [191/400], Step [320/439], Loss: 1.2950\n",
      "Epoch [191/400], Step [340/439], Loss: 1.0294\n",
      "Epoch [191/400], Step [360/439], Loss: 1.4593\n",
      "Epoch [191/400], Step [380/439], Loss: 1.2789\n",
      "Epoch [191/400], Step [400/439], Loss: 1.2580\n",
      "Epoch [191/400], Step [420/439], Loss: 0.9906\n",
      "\n",
      "train-loss: 1.3333, train-acc: 60.7571\n",
      "validation loss: 1.2732, validation acc: 60.9175\n",
      "\n",
      "Epoch 192\n",
      "\n",
      "Epoch [192/400], Step [0/439], Loss: 1.1263\n",
      "Epoch [192/400], Step [20/439], Loss: 1.3405\n",
      "Epoch [192/400], Step [40/439], Loss: 1.0787\n",
      "Epoch [192/400], Step [60/439], Loss: 0.8605\n",
      "Epoch [192/400], Step [80/439], Loss: 0.9137\n",
      "Epoch [192/400], Step [100/439], Loss: 0.9067\n",
      "Epoch [192/400], Step [120/439], Loss: 0.8392\n",
      "Epoch [192/400], Step [140/439], Loss: 1.0499\n",
      "Epoch [192/400], Step [160/439], Loss: 1.5675\n",
      "Epoch [192/400], Step [180/439], Loss: 1.0313\n",
      "Epoch [192/400], Step [200/439], Loss: 0.9847\n",
      "Epoch [192/400], Step [220/439], Loss: 0.9373\n",
      "Epoch [192/400], Step [240/439], Loss: 0.9813\n",
      "Epoch [192/400], Step [260/439], Loss: 1.3668\n",
      "Epoch [192/400], Step [280/439], Loss: 1.3399\n",
      "Epoch [192/400], Step [300/439], Loss: 1.1947\n",
      "Epoch [192/400], Step [320/439], Loss: 0.9397\n",
      "Epoch [192/400], Step [340/439], Loss: 0.7928\n",
      "Epoch [192/400], Step [360/439], Loss: 1.5916\n",
      "Epoch [192/400], Step [380/439], Loss: 1.2585\n",
      "Epoch [192/400], Step [400/439], Loss: 1.0939\n",
      "Epoch [192/400], Step [420/439], Loss: 0.8762\n",
      "\n",
      "train-loss: 1.3325, train-acc: 60.3293\n",
      "validation loss: 1.2727, validation acc: 61.0278\n",
      "\n",
      "Epoch 193\n",
      "\n",
      "Epoch [193/400], Step [0/439], Loss: 1.4824\n",
      "Epoch [193/400], Step [20/439], Loss: 0.7438\n",
      "Epoch [193/400], Step [40/439], Loss: 1.4910\n",
      "Epoch [193/400], Step [60/439], Loss: 1.4869\n",
      "Epoch [193/400], Step [80/439], Loss: 0.9416\n",
      "Epoch [193/400], Step [100/439], Loss: 1.3518\n",
      "Epoch [193/400], Step [120/439], Loss: 1.1454\n",
      "Epoch [193/400], Step [140/439], Loss: 1.1509\n",
      "Epoch [193/400], Step [160/439], Loss: 0.8565\n",
      "Epoch [193/400], Step [180/439], Loss: 1.0104\n",
      "Epoch [193/400], Step [200/439], Loss: 1.1413\n",
      "Epoch [193/400], Step [220/439], Loss: 1.5269\n",
      "Epoch [193/400], Step [240/439], Loss: 1.2664\n",
      "Epoch [193/400], Step [260/439], Loss: 1.0762\n",
      "Epoch [193/400], Step [280/439], Loss: 0.9653\n",
      "Epoch [193/400], Step [300/439], Loss: 1.0668\n",
      "Epoch [193/400], Step [320/439], Loss: 0.9715\n",
      "Epoch [193/400], Step [340/439], Loss: 0.9495\n",
      "Epoch [193/400], Step [360/439], Loss: 1.0322\n",
      "Epoch [193/400], Step [380/439], Loss: 1.1788\n",
      "Epoch [193/400], Step [400/439], Loss: 1.0946\n",
      "Epoch [193/400], Step [420/439], Loss: 1.0672\n",
      "\n",
      "train-loss: 1.3318, train-acc: 60.7998\n",
      "validation loss: 1.2719, validation acc: 63.4318\n",
      "\n",
      "Epoch 194\n",
      "\n",
      "Epoch [194/400], Step [0/439], Loss: 1.0217\n",
      "Epoch [194/400], Step [20/439], Loss: 0.9886\n",
      "Epoch [194/400], Step [40/439], Loss: 1.3217\n",
      "Epoch [194/400], Step [60/439], Loss: 1.1658\n",
      "Epoch [194/400], Step [80/439], Loss: 1.1371\n",
      "Epoch [194/400], Step [100/439], Loss: 1.0102\n",
      "Epoch [194/400], Step [120/439], Loss: 0.9003\n",
      "Epoch [194/400], Step [140/439], Loss: 0.8555\n",
      "Epoch [194/400], Step [160/439], Loss: 1.1106\n",
      "Epoch [194/400], Step [180/439], Loss: 1.3950\n",
      "Epoch [194/400], Step [200/439], Loss: 1.4315\n",
      "Epoch [194/400], Step [220/439], Loss: 1.1001\n",
      "Epoch [194/400], Step [240/439], Loss: 1.3870\n",
      "Epoch [194/400], Step [260/439], Loss: 1.1497\n",
      "Epoch [194/400], Step [280/439], Loss: 1.1100\n",
      "Epoch [194/400], Step [300/439], Loss: 1.3530\n",
      "Epoch [194/400], Step [320/439], Loss: 1.3694\n",
      "Epoch [194/400], Step [340/439], Loss: 1.0387\n",
      "Epoch [194/400], Step [360/439], Loss: 1.2979\n",
      "Epoch [194/400], Step [380/439], Loss: 0.9739\n",
      "Epoch [194/400], Step [400/439], Loss: 0.8918\n",
      "Epoch [194/400], Step [420/439], Loss: 1.4444\n",
      "\n",
      "train-loss: 1.3311, train-acc: 60.1084\n",
      "validation loss: 1.2710, validation acc: 63.7186\n",
      "\n",
      "Epoch 195\n",
      "\n",
      "Epoch [195/400], Step [0/439], Loss: 1.3158\n",
      "Epoch [195/400], Step [20/439], Loss: 1.3778\n",
      "Epoch [195/400], Step [40/439], Loss: 1.0986\n",
      "Epoch [195/400], Step [60/439], Loss: 1.2055\n",
      "Epoch [195/400], Step [80/439], Loss: 1.0925\n",
      "Epoch [195/400], Step [100/439], Loss: 1.2427\n",
      "Epoch [195/400], Step [120/439], Loss: 0.7857\n",
      "Epoch [195/400], Step [140/439], Loss: 0.8922\n",
      "Epoch [195/400], Step [160/439], Loss: 1.1275\n",
      "Epoch [195/400], Step [180/439], Loss: 0.9370\n",
      "Epoch [195/400], Step [200/439], Loss: 1.4723\n",
      "Epoch [195/400], Step [220/439], Loss: 1.1391\n",
      "Epoch [195/400], Step [240/439], Loss: 1.3524\n",
      "Epoch [195/400], Step [260/439], Loss: 1.5145\n",
      "Epoch [195/400], Step [280/439], Loss: 1.0056\n",
      "Epoch [195/400], Step [300/439], Loss: 1.1909\n",
      "Epoch [195/400], Step [320/439], Loss: 1.1299\n",
      "Epoch [195/400], Step [340/439], Loss: 1.2493\n",
      "Epoch [195/400], Step [360/439], Loss: 1.6410\n",
      "Epoch [195/400], Step [380/439], Loss: 1.5211\n",
      "Epoch [195/400], Step [400/439], Loss: 1.2057\n",
      "Epoch [195/400], Step [420/439], Loss: 0.8077\n",
      "\n",
      "train-loss: 1.3303, train-acc: 61.1064\n",
      "validation loss: 1.2709, validation acc: 58.0723\n",
      "\n",
      "Epoch 196\n",
      "\n",
      "Epoch [196/400], Step [0/439], Loss: 1.2109\n",
      "Epoch [196/400], Step [20/439], Loss: 1.3497\n",
      "Epoch [196/400], Step [40/439], Loss: 1.1617\n",
      "Epoch [196/400], Step [60/439], Loss: 1.2168\n",
      "Epoch [196/400], Step [80/439], Loss: 1.1502\n",
      "Epoch [196/400], Step [100/439], Loss: 0.8438\n",
      "Epoch [196/400], Step [120/439], Loss: 1.3206\n",
      "Epoch [196/400], Step [140/439], Loss: 0.8777\n",
      "Epoch [196/400], Step [160/439], Loss: 0.8058\n",
      "Epoch [196/400], Step [180/439], Loss: 1.0975\n",
      "Epoch [196/400], Step [200/439], Loss: 1.2153\n",
      "Epoch [196/400], Step [220/439], Loss: 0.8605\n",
      "Epoch [196/400], Step [240/439], Loss: 1.1245\n",
      "Epoch [196/400], Step [260/439], Loss: 1.0049\n",
      "Epoch [196/400], Step [280/439], Loss: 1.5280\n",
      "Epoch [196/400], Step [300/439], Loss: 0.9073\n",
      "Epoch [196/400], Step [320/439], Loss: 1.2639\n",
      "Epoch [196/400], Step [340/439], Loss: 1.1606\n",
      "Epoch [196/400], Step [360/439], Loss: 1.1035\n",
      "Epoch [196/400], Step [380/439], Loss: 1.3478\n",
      "Epoch [196/400], Step [400/439], Loss: 1.3749\n",
      "Epoch [196/400], Step [420/439], Loss: 1.1357\n",
      "\n",
      "train-loss: 1.3296, train-acc: 61.5269\n",
      "validation loss: 1.2701, validation acc: 62.9025\n",
      "\n",
      "Epoch 197\n",
      "\n",
      "Epoch [197/400], Step [0/439], Loss: 1.1322\n",
      "Epoch [197/400], Step [20/439], Loss: 1.0343\n",
      "Epoch [197/400], Step [40/439], Loss: 1.5435\n",
      "Epoch [197/400], Step [60/439], Loss: 1.0419\n",
      "Epoch [197/400], Step [80/439], Loss: 1.3978\n",
      "Epoch [197/400], Step [100/439], Loss: 1.1992\n",
      "Epoch [197/400], Step [120/439], Loss: 1.2852\n",
      "Epoch [197/400], Step [140/439], Loss: 1.3340\n",
      "Epoch [197/400], Step [160/439], Loss: 0.9049\n",
      "Epoch [197/400], Step [180/439], Loss: 0.9816\n",
      "Epoch [197/400], Step [200/439], Loss: 0.7516\n",
      "Epoch [197/400], Step [220/439], Loss: 0.9858\n",
      "Epoch [197/400], Step [240/439], Loss: 1.1781\n",
      "Epoch [197/400], Step [260/439], Loss: 1.0686\n",
      "Epoch [197/400], Step [280/439], Loss: 0.8641\n",
      "Epoch [197/400], Step [300/439], Loss: 0.9141\n",
      "Epoch [197/400], Step [320/439], Loss: 0.9570\n",
      "Epoch [197/400], Step [340/439], Loss: 1.0990\n",
      "Epoch [197/400], Step [360/439], Loss: 1.5551\n",
      "Epoch [197/400], Step [380/439], Loss: 0.9149\n",
      "Epoch [197/400], Step [400/439], Loss: 1.3615\n",
      "Epoch [197/400], Step [420/439], Loss: 1.2680\n",
      "\n",
      "train-loss: 1.3288, train-acc: 61.2133\n",
      "validation loss: 1.2696, validation acc: 60.5205\n",
      "\n",
      "Epoch 198\n",
      "\n",
      "Epoch [198/400], Step [0/439], Loss: 1.1398\n",
      "Epoch [198/400], Step [20/439], Loss: 1.3997\n",
      "Epoch [198/400], Step [40/439], Loss: 1.2130\n",
      "Epoch [198/400], Step [60/439], Loss: 1.6338\n",
      "Epoch [198/400], Step [80/439], Loss: 1.2162\n",
      "Epoch [198/400], Step [100/439], Loss: 1.3034\n",
      "Epoch [198/400], Step [120/439], Loss: 1.1711\n",
      "Epoch [198/400], Step [140/439], Loss: 1.0734\n",
      "Epoch [198/400], Step [160/439], Loss: 1.4684\n",
      "Epoch [198/400], Step [180/439], Loss: 1.2372\n",
      "Epoch [198/400], Step [200/439], Loss: 1.0174\n",
      "Epoch [198/400], Step [220/439], Loss: 1.3256\n",
      "Epoch [198/400], Step [240/439], Loss: 1.1248\n",
      "Epoch [198/400], Step [260/439], Loss: 0.9561\n",
      "Epoch [198/400], Step [280/439], Loss: 0.9488\n",
      "Epoch [198/400], Step [300/439], Loss: 1.0652\n",
      "Epoch [198/400], Step [320/439], Loss: 1.2422\n",
      "Epoch [198/400], Step [340/439], Loss: 0.9221\n",
      "Epoch [198/400], Step [360/439], Loss: 1.2908\n",
      "Epoch [198/400], Step [380/439], Loss: 1.2372\n",
      "Epoch [198/400], Step [400/439], Loss: 1.1542\n",
      "Epoch [198/400], Step [420/439], Loss: 1.0647\n",
      "\n",
      "train-loss: 1.3280, train-acc: 60.8355\n",
      "validation loss: 1.2697, validation acc: 57.1460\n",
      "\n",
      "Epoch 199\n",
      "\n",
      "Epoch [199/400], Step [0/439], Loss: 1.3344\n",
      "Epoch [199/400], Step [20/439], Loss: 0.7863\n",
      "Epoch [199/400], Step [40/439], Loss: 0.9522\n",
      "Epoch [199/400], Step [60/439], Loss: 1.3310\n",
      "Epoch [199/400], Step [80/439], Loss: 1.5138\n",
      "Epoch [199/400], Step [100/439], Loss: 1.1252\n",
      "Epoch [199/400], Step [120/439], Loss: 1.2001\n",
      "Epoch [199/400], Step [140/439], Loss: 1.0067\n",
      "Epoch [199/400], Step [160/439], Loss: 1.2440\n",
      "Epoch [199/400], Step [180/439], Loss: 1.1752\n",
      "Epoch [199/400], Step [200/439], Loss: 1.5462\n",
      "Epoch [199/400], Step [220/439], Loss: 1.1242\n",
      "Epoch [199/400], Step [240/439], Loss: 1.0335\n",
      "Epoch [199/400], Step [260/439], Loss: 0.9240\n",
      "Epoch [199/400], Step [280/439], Loss: 1.2707\n",
      "Epoch [199/400], Step [300/439], Loss: 0.9462\n",
      "Epoch [199/400], Step [320/439], Loss: 1.1988\n",
      "Epoch [199/400], Step [340/439], Loss: 1.4173\n",
      "Epoch [199/400], Step [360/439], Loss: 0.8994\n",
      "Epoch [199/400], Step [380/439], Loss: 0.9876\n",
      "Epoch [199/400], Step [400/439], Loss: 1.3397\n",
      "Epoch [199/400], Step [420/439], Loss: 1.0539\n",
      "\n",
      "train-loss: 1.3273, train-acc: 61.0565\n",
      "validation loss: 1.2689, validation acc: 63.8068\n",
      "\n",
      "Epoch 200\n",
      "\n",
      "Epoch [200/400], Step [0/439], Loss: 1.6907\n",
      "Epoch [200/400], Step [20/439], Loss: 1.4881\n",
      "Epoch [200/400], Step [40/439], Loss: 1.2361\n",
      "Epoch [200/400], Step [60/439], Loss: 1.0277\n",
      "Epoch [200/400], Step [80/439], Loss: 0.9150\n",
      "Epoch [200/400], Step [100/439], Loss: 0.9223\n",
      "Epoch [200/400], Step [120/439], Loss: 0.8562\n",
      "Epoch [200/400], Step [140/439], Loss: 1.2207\n",
      "Epoch [200/400], Step [160/439], Loss: 0.9991\n",
      "Epoch [200/400], Step [180/439], Loss: 1.0217\n",
      "Epoch [200/400], Step [200/439], Loss: 1.2951\n",
      "Epoch [200/400], Step [220/439], Loss: 1.0368\n",
      "Epoch [200/400], Step [240/439], Loss: 1.0340\n",
      "Epoch [200/400], Step [260/439], Loss: 1.1447\n",
      "Epoch [200/400], Step [280/439], Loss: 1.2224\n",
      "Epoch [200/400], Step [300/439], Loss: 1.1428\n",
      "Epoch [200/400], Step [320/439], Loss: 1.0345\n",
      "Epoch [200/400], Step [340/439], Loss: 1.1073\n",
      "Epoch [200/400], Step [360/439], Loss: 1.3780\n",
      "Epoch [200/400], Step [380/439], Loss: 1.1935\n",
      "Epoch [200/400], Step [400/439], Loss: 1.3595\n",
      "Epoch [200/400], Step [420/439], Loss: 0.8099\n",
      "\n",
      "train-loss: 1.3265, train-acc: 61.2347\n",
      "validation loss: 1.2680, validation acc: 63.5421\n",
      "\n",
      "Epoch 201\n",
      "\n",
      "Epoch [201/400], Step [0/439], Loss: 1.1687\n",
      "Epoch [201/400], Step [20/439], Loss: 1.0062\n",
      "Epoch [201/400], Step [40/439], Loss: 1.0435\n",
      "Epoch [201/400], Step [60/439], Loss: 1.4087\n",
      "Epoch [201/400], Step [80/439], Loss: 1.2573\n",
      "Epoch [201/400], Step [100/439], Loss: 1.5595\n",
      "Epoch [201/400], Step [120/439], Loss: 0.9685\n",
      "Epoch [201/400], Step [140/439], Loss: 1.4560\n",
      "Epoch [201/400], Step [160/439], Loss: 1.3680\n",
      "Epoch [201/400], Step [180/439], Loss: 0.9208\n",
      "Epoch [201/400], Step [200/439], Loss: 1.1605\n",
      "Epoch [201/400], Step [220/439], Loss: 0.6823\n",
      "Epoch [201/400], Step [240/439], Loss: 1.1128\n",
      "Epoch [201/400], Step [260/439], Loss: 1.0263\n",
      "Epoch [201/400], Step [280/439], Loss: 1.2566\n",
      "Epoch [201/400], Step [300/439], Loss: 1.0021\n",
      "Epoch [201/400], Step [320/439], Loss: 0.9992\n",
      "Epoch [201/400], Step [340/439], Loss: 1.0179\n",
      "Epoch [201/400], Step [360/439], Loss: 1.0963\n",
      "Epoch [201/400], Step [380/439], Loss: 0.9922\n",
      "Epoch [201/400], Step [400/439], Loss: 1.1767\n",
      "Epoch [201/400], Step [420/439], Loss: 1.1401\n",
      "\n",
      "train-loss: 1.3258, train-acc: 61.2489\n",
      "validation loss: 1.2671, validation acc: 64.9757\n",
      "\n",
      "Improvement-Detected, save-model\n",
      "Epoch 202\n",
      "\n",
      "Epoch [202/400], Step [0/439], Loss: 1.3016\n",
      "Epoch [202/400], Step [20/439], Loss: 1.2142\n",
      "Epoch [202/400], Step [40/439], Loss: 1.2718\n",
      "Epoch [202/400], Step [60/439], Loss: 1.3490\n",
      "Epoch [202/400], Step [80/439], Loss: 1.0091\n",
      "Epoch [202/400], Step [100/439], Loss: 1.1259\n",
      "Epoch [202/400], Step [120/439], Loss: 1.1479\n",
      "Epoch [202/400], Step [140/439], Loss: 1.3535\n",
      "Epoch [202/400], Step [160/439], Loss: 1.0624\n",
      "Epoch [202/400], Step [180/439], Loss: 1.1692\n",
      "Epoch [202/400], Step [200/439], Loss: 1.0204\n",
      "Epoch [202/400], Step [220/439], Loss: 0.8764\n",
      "Epoch [202/400], Step [240/439], Loss: 0.8277\n",
      "Epoch [202/400], Step [260/439], Loss: 1.0336\n",
      "Epoch [202/400], Step [280/439], Loss: 1.5194\n",
      "Epoch [202/400], Step [300/439], Loss: 1.1280\n",
      "Epoch [202/400], Step [320/439], Loss: 1.1411\n",
      "Epoch [202/400], Step [340/439], Loss: 0.7863\n",
      "Epoch [202/400], Step [360/439], Loss: 0.9935\n",
      "Epoch [202/400], Step [380/439], Loss: 1.1901\n",
      "Epoch [202/400], Step [400/439], Loss: 1.0175\n",
      "Epoch [202/400], Step [420/439], Loss: 0.9054\n",
      "\n",
      "train-loss: 1.3251, train-acc: 61.2917\n",
      "validation loss: 1.2672, validation acc: 56.9034\n",
      "\n",
      "Epoch 203\n",
      "\n",
      "Epoch [203/400], Step [0/439], Loss: 1.2944\n",
      "Epoch [203/400], Step [20/439], Loss: 1.0933\n",
      "Epoch [203/400], Step [40/439], Loss: 1.0888\n",
      "Epoch [203/400], Step [60/439], Loss: 1.0124\n",
      "Epoch [203/400], Step [80/439], Loss: 1.2728\n",
      "Epoch [203/400], Step [100/439], Loss: 1.2674\n",
      "Epoch [203/400], Step [120/439], Loss: 1.3619\n",
      "Epoch [203/400], Step [140/439], Loss: 1.5070\n",
      "Epoch [203/400], Step [160/439], Loss: 0.9374\n",
      "Epoch [203/400], Step [180/439], Loss: 0.8871\n",
      "Epoch [203/400], Step [200/439], Loss: 1.3471\n",
      "Epoch [203/400], Step [220/439], Loss: 1.2730\n",
      "Epoch [203/400], Step [240/439], Loss: 1.2854\n",
      "Epoch [203/400], Step [260/439], Loss: 0.9993\n",
      "Epoch [203/400], Step [280/439], Loss: 1.2588\n",
      "Epoch [203/400], Step [300/439], Loss: 1.3806\n",
      "Epoch [203/400], Step [320/439], Loss: 1.1264\n",
      "Epoch [203/400], Step [340/439], Loss: 0.7451\n",
      "Epoch [203/400], Step [360/439], Loss: 0.6797\n",
      "Epoch [203/400], Step [380/439], Loss: 1.2327\n",
      "Epoch [203/400], Step [400/439], Loss: 1.1193\n",
      "Epoch [203/400], Step [420/439], Loss: 1.3096\n",
      "\n",
      "train-loss: 1.3243, train-acc: 61.1848\n",
      "validation loss: 1.2665, validation acc: 62.9246\n",
      "\n",
      "Epoch 204\n",
      "\n",
      "Epoch [204/400], Step [0/439], Loss: 1.5050\n",
      "Epoch [204/400], Step [20/439], Loss: 1.5745\n",
      "Epoch [204/400], Step [40/439], Loss: 1.0873\n",
      "Epoch [204/400], Step [60/439], Loss: 1.5343\n",
      "Epoch [204/400], Step [80/439], Loss: 1.3720\n",
      "Epoch [204/400], Step [100/439], Loss: 1.0237\n",
      "Epoch [204/400], Step [120/439], Loss: 0.8732\n",
      "Epoch [204/400], Step [140/439], Loss: 1.1276\n",
      "Epoch [204/400], Step [160/439], Loss: 0.9675\n",
      "Epoch [204/400], Step [180/439], Loss: 1.2110\n",
      "Epoch [204/400], Step [200/439], Loss: 1.2876\n",
      "Epoch [204/400], Step [220/439], Loss: 1.0301\n",
      "Epoch [204/400], Step [240/439], Loss: 1.4705\n",
      "Epoch [204/400], Step [260/439], Loss: 1.3218\n",
      "Epoch [204/400], Step [280/439], Loss: 1.0781\n",
      "Epoch [204/400], Step [300/439], Loss: 1.0596\n",
      "Epoch [204/400], Step [320/439], Loss: 1.0179\n",
      "Epoch [204/400], Step [340/439], Loss: 1.1267\n",
      "Epoch [204/400], Step [360/439], Loss: 1.1260\n",
      "Epoch [204/400], Step [380/439], Loss: 1.8663\n",
      "Epoch [204/400], Step [400/439], Loss: 1.3584\n",
      "Epoch [204/400], Step [420/439], Loss: 1.0955\n",
      "\n",
      "train-loss: 1.3236, train-acc: 60.8640\n",
      "validation loss: 1.2659, validation acc: 61.3807\n",
      "\n",
      "Epoch 205\n",
      "\n",
      "Epoch [205/400], Step [0/439], Loss: 1.3150\n",
      "Epoch [205/400], Step [20/439], Loss: 1.1609\n",
      "Epoch [205/400], Step [40/439], Loss: 1.0170\n",
      "Epoch [205/400], Step [60/439], Loss: 1.3606\n",
      "Epoch [205/400], Step [80/439], Loss: 1.0755\n",
      "Epoch [205/400], Step [100/439], Loss: 1.0474\n",
      "Epoch [205/400], Step [120/439], Loss: 0.8791\n",
      "Epoch [205/400], Step [140/439], Loss: 1.4526\n",
      "Epoch [205/400], Step [160/439], Loss: 0.8462\n",
      "Epoch [205/400], Step [180/439], Loss: 1.2143\n",
      "Epoch [205/400], Step [200/439], Loss: 0.9691\n",
      "Epoch [205/400], Step [220/439], Loss: 1.2463\n",
      "Epoch [205/400], Step [240/439], Loss: 1.3482\n",
      "Epoch [205/400], Step [260/439], Loss: 1.0030\n",
      "Epoch [205/400], Step [280/439], Loss: 0.8685\n",
      "Epoch [205/400], Step [300/439], Loss: 1.4073\n",
      "Epoch [205/400], Step [320/439], Loss: 0.8562\n",
      "Epoch [205/400], Step [340/439], Loss: 1.0112\n",
      "Epoch [205/400], Step [360/439], Loss: 1.5153\n",
      "Epoch [205/400], Step [380/439], Loss: 1.3791\n",
      "Epoch [205/400], Step [400/439], Loss: 1.4705\n",
      "Epoch [205/400], Step [420/439], Loss: 1.1812\n",
      "\n",
      "train-loss: 1.3229, train-acc: 61.6267\n",
      "validation loss: 1.2653, validation acc: 62.5276\n",
      "\n",
      "Epoch 206\n",
      "\n",
      "Epoch [206/400], Step [0/439], Loss: 0.9179\n",
      "Epoch [206/400], Step [20/439], Loss: 1.1736\n",
      "Epoch [206/400], Step [40/439], Loss: 1.1380\n",
      "Epoch [206/400], Step [60/439], Loss: 1.2833\n",
      "Epoch [206/400], Step [80/439], Loss: 1.1907\n",
      "Epoch [206/400], Step [100/439], Loss: 1.0636\n",
      "Epoch [206/400], Step [120/439], Loss: 1.2547\n",
      "Epoch [206/400], Step [140/439], Loss: 1.1995\n",
      "Epoch [206/400], Step [160/439], Loss: 0.8876\n",
      "Epoch [206/400], Step [180/439], Loss: 0.8824\n",
      "Epoch [206/400], Step [200/439], Loss: 0.9530\n",
      "Epoch [206/400], Step [220/439], Loss: 1.0556\n",
      "Epoch [206/400], Step [240/439], Loss: 1.3053\n",
      "Epoch [206/400], Step [260/439], Loss: 1.1033\n",
      "Epoch [206/400], Step [280/439], Loss: 1.1359\n",
      "Epoch [206/400], Step [300/439], Loss: 0.9591\n",
      "Epoch [206/400], Step [320/439], Loss: 1.1728\n",
      "Epoch [206/400], Step [340/439], Loss: 1.0278\n",
      "Epoch [206/400], Step [360/439], Loss: 0.9884\n",
      "Epoch [206/400], Step [380/439], Loss: 1.3280\n",
      "Epoch [206/400], Step [400/439], Loss: 0.8982\n",
      "Epoch [206/400], Step [420/439], Loss: 1.0099\n",
      "\n",
      "train-loss: 1.3221, train-acc: 60.9068\n",
      "validation loss: 1.2647, validation acc: 61.2704\n",
      "\n",
      "Epoch 207\n",
      "\n",
      "Epoch [207/400], Step [0/439], Loss: 1.6656\n",
      "Epoch [207/400], Step [20/439], Loss: 1.3964\n",
      "Epoch [207/400], Step [40/439], Loss: 0.9839\n",
      "Epoch [207/400], Step [60/439], Loss: 1.1003\n",
      "Epoch [207/400], Step [80/439], Loss: 1.0970\n",
      "Epoch [207/400], Step [100/439], Loss: 1.0184\n",
      "Epoch [207/400], Step [120/439], Loss: 1.2957\n",
      "Epoch [207/400], Step [140/439], Loss: 1.0877\n",
      "Epoch [207/400], Step [160/439], Loss: 1.2528\n",
      "Epoch [207/400], Step [180/439], Loss: 1.5785\n",
      "Epoch [207/400], Step [200/439], Loss: 0.9668\n",
      "Epoch [207/400], Step [220/439], Loss: 0.8880\n",
      "Epoch [207/400], Step [240/439], Loss: 0.8241\n",
      "Epoch [207/400], Step [260/439], Loss: 1.3488\n",
      "Epoch [207/400], Step [280/439], Loss: 1.1116\n",
      "Epoch [207/400], Step [300/439], Loss: 1.4953\n",
      "Epoch [207/400], Step [320/439], Loss: 1.2276\n",
      "Epoch [207/400], Step [340/439], Loss: 0.8707\n",
      "Epoch [207/400], Step [360/439], Loss: 0.9376\n",
      "Epoch [207/400], Step [380/439], Loss: 1.1238\n",
      "Epoch [207/400], Step [400/439], Loss: 1.4606\n",
      "Epoch [207/400], Step [420/439], Loss: 1.0680\n",
      "\n",
      "train-loss: 1.3214, train-acc: 60.9139\n",
      "validation loss: 1.2639, validation acc: 64.3582\n",
      "\n",
      "Epoch 208\n",
      "\n",
      "Epoch [208/400], Step [0/439], Loss: 1.5066\n",
      "Epoch [208/400], Step [20/439], Loss: 1.2623\n",
      "Epoch [208/400], Step [40/439], Loss: 1.3372\n",
      "Epoch [208/400], Step [60/439], Loss: 0.9002\n",
      "Epoch [208/400], Step [80/439], Loss: 1.4515\n",
      "Epoch [208/400], Step [100/439], Loss: 1.2372\n",
      "Epoch [208/400], Step [120/439], Loss: 1.5004\n",
      "Epoch [208/400], Step [140/439], Loss: 1.2639\n",
      "Epoch [208/400], Step [160/439], Loss: 0.6961\n",
      "Epoch [208/400], Step [180/439], Loss: 1.1064\n",
      "Epoch [208/400], Step [200/439], Loss: 1.4291\n",
      "Epoch [208/400], Step [220/439], Loss: 0.9935\n",
      "Epoch [208/400], Step [240/439], Loss: 1.1222\n",
      "Epoch [208/400], Step [260/439], Loss: 1.1886\n",
      "Epoch [208/400], Step [280/439], Loss: 1.1230\n",
      "Epoch [208/400], Step [300/439], Loss: 1.3459\n",
      "Epoch [208/400], Step [320/439], Loss: 1.1757\n",
      "Epoch [208/400], Step [340/439], Loss: 1.0622\n",
      "Epoch [208/400], Step [360/439], Loss: 1.2352\n",
      "Epoch [208/400], Step [380/439], Loss: 0.6676\n",
      "Epoch [208/400], Step [400/439], Loss: 1.0966\n",
      "Epoch [208/400], Step [420/439], Loss: 1.3518\n",
      "\n",
      "train-loss: 1.3207, train-acc: 61.7907\n",
      "validation loss: 1.2632, validation acc: 62.5717\n",
      "\n",
      "Epoch 209\n",
      "\n",
      "Epoch [209/400], Step [0/439], Loss: 1.0836\n",
      "Epoch [209/400], Step [20/439], Loss: 1.3670\n",
      "Epoch [209/400], Step [40/439], Loss: 1.1307\n",
      "Epoch [209/400], Step [60/439], Loss: 1.2839\n",
      "Epoch [209/400], Step [80/439], Loss: 1.4776\n",
      "Epoch [209/400], Step [100/439], Loss: 1.4371\n",
      "Epoch [209/400], Step [120/439], Loss: 1.3007\n",
      "Epoch [209/400], Step [140/439], Loss: 0.8641\n",
      "Epoch [209/400], Step [160/439], Loss: 1.2813\n",
      "Epoch [209/400], Step [180/439], Loss: 1.0436\n",
      "Epoch [209/400], Step [200/439], Loss: 0.8893\n",
      "Epoch [209/400], Step [220/439], Loss: 1.3000\n",
      "Epoch [209/400], Step [240/439], Loss: 1.0932\n",
      "Epoch [209/400], Step [260/439], Loss: 1.2756\n",
      "Epoch [209/400], Step [280/439], Loss: 1.3372\n",
      "Epoch [209/400], Step [300/439], Loss: 1.2083\n",
      "Epoch [209/400], Step [320/439], Loss: 1.4198\n",
      "Epoch [209/400], Step [340/439], Loss: 1.3224\n",
      "Epoch [209/400], Step [360/439], Loss: 1.2125\n",
      "Epoch [209/400], Step [380/439], Loss: 1.4960\n",
      "Epoch [209/400], Step [400/439], Loss: 0.9898\n",
      "Epoch [209/400], Step [420/439], Loss: 0.7743\n",
      "\n",
      "train-loss: 1.3200, train-acc: 61.4842\n",
      "validation loss: 1.2624, validation acc: 64.8655\n",
      "\n",
      "Epoch 210\n",
      "\n",
      "Epoch [210/400], Step [0/439], Loss: 1.2974\n",
      "Epoch [210/400], Step [20/439], Loss: 1.2249\n",
      "Epoch [210/400], Step [40/439], Loss: 0.6502\n",
      "Epoch [210/400], Step [60/439], Loss: 0.7438\n",
      "Epoch [210/400], Step [80/439], Loss: 1.3819\n",
      "Epoch [210/400], Step [100/439], Loss: 0.9662\n",
      "Epoch [210/400], Step [120/439], Loss: 0.9959\n",
      "Epoch [210/400], Step [140/439], Loss: 0.9028\n",
      "Epoch [210/400], Step [160/439], Loss: 1.2021\n",
      "Epoch [210/400], Step [180/439], Loss: 1.3169\n",
      "Epoch [210/400], Step [200/439], Loss: 0.8010\n",
      "Epoch [210/400], Step [220/439], Loss: 1.4845\n",
      "Epoch [210/400], Step [240/439], Loss: 0.8593\n",
      "Epoch [210/400], Step [260/439], Loss: 1.0259\n",
      "Epoch [210/400], Step [280/439], Loss: 0.9057\n",
      "Epoch [210/400], Step [300/439], Loss: 1.3916\n",
      "Epoch [210/400], Step [320/439], Loss: 1.3323\n",
      "Epoch [210/400], Step [340/439], Loss: 1.0115\n",
      "Epoch [210/400], Step [360/439], Loss: 1.2298\n",
      "Epoch [210/400], Step [380/439], Loss: 1.0024\n",
      "Epoch [210/400], Step [400/439], Loss: 1.4797\n",
      "Epoch [210/400], Step [420/439], Loss: 1.0383\n",
      "\n",
      "train-loss: 1.3193, train-acc: 61.9404\n",
      "validation loss: 1.2618, validation acc: 62.2629\n",
      "\n",
      "Epoch 211\n",
      "\n",
      "Epoch [211/400], Step [0/439], Loss: 1.1405\n",
      "Epoch [211/400], Step [20/439], Loss: 1.3851\n",
      "Epoch [211/400], Step [40/439], Loss: 1.1878\n",
      "Epoch [211/400], Step [60/439], Loss: 0.8546\n",
      "Epoch [211/400], Step [80/439], Loss: 1.0606\n",
      "Epoch [211/400], Step [100/439], Loss: 1.0791\n",
      "Epoch [211/400], Step [120/439], Loss: 1.2869\n",
      "Epoch [211/400], Step [140/439], Loss: 0.8537\n",
      "Epoch [211/400], Step [160/439], Loss: 0.8867\n",
      "Epoch [211/400], Step [180/439], Loss: 0.8065\n",
      "Epoch [211/400], Step [200/439], Loss: 0.9052\n",
      "Epoch [211/400], Step [220/439], Loss: 0.7138\n",
      "Epoch [211/400], Step [240/439], Loss: 0.9509\n",
      "Epoch [211/400], Step [260/439], Loss: 1.3461\n",
      "Epoch [211/400], Step [280/439], Loss: 1.0878\n",
      "Epoch [211/400], Step [300/439], Loss: 1.2486\n",
      "Epoch [211/400], Step [320/439], Loss: 0.8022\n",
      "Epoch [211/400], Step [340/439], Loss: 1.0811\n",
      "Epoch [211/400], Step [360/439], Loss: 1.1554\n",
      "Epoch [211/400], Step [380/439], Loss: 1.0662\n",
      "Epoch [211/400], Step [400/439], Loss: 1.1926\n",
      "Epoch [211/400], Step [420/439], Loss: 1.1705\n",
      "\n",
      "train-loss: 1.3186, train-acc: 61.9832\n",
      "validation loss: 1.2610, validation acc: 63.9832\n",
      "\n",
      "Epoch 212\n",
      "\n",
      "Epoch [212/400], Step [0/439], Loss: 1.3435\n",
      "Epoch [212/400], Step [20/439], Loss: 1.4832\n",
      "Epoch [212/400], Step [40/439], Loss: 1.0460\n",
      "Epoch [212/400], Step [60/439], Loss: 1.5953\n",
      "Epoch [212/400], Step [80/439], Loss: 0.9383\n",
      "Epoch [212/400], Step [100/439], Loss: 0.9961\n",
      "Epoch [212/400], Step [120/439], Loss: 1.2392\n",
      "Epoch [212/400], Step [140/439], Loss: 1.3475\n",
      "Epoch [212/400], Step [160/439], Loss: 1.3265\n",
      "Epoch [212/400], Step [180/439], Loss: 0.8606\n",
      "Epoch [212/400], Step [200/439], Loss: 1.1190\n",
      "Epoch [212/400], Step [220/439], Loss: 0.9388\n",
      "Epoch [212/400], Step [240/439], Loss: 1.3020\n",
      "Epoch [212/400], Step [260/439], Loss: 0.9550\n",
      "Epoch [212/400], Step [280/439], Loss: 0.9927\n",
      "Epoch [212/400], Step [300/439], Loss: 1.0797\n",
      "Epoch [212/400], Step [320/439], Loss: 1.1052\n",
      "Epoch [212/400], Step [340/439], Loss: 1.0177\n",
      "Epoch [212/400], Step [360/439], Loss: 1.1308\n",
      "Epoch [212/400], Step [380/439], Loss: 1.5473\n",
      "Epoch [212/400], Step [400/439], Loss: 0.9840\n",
      "Epoch [212/400], Step [420/439], Loss: 1.3978\n",
      "\n",
      "train-loss: 1.3179, train-acc: 61.4200\n",
      "validation loss: 1.2600, validation acc: 65.0419\n",
      "\n",
      "Improvement-Detected, save-model\n",
      "Epoch 213\n",
      "\n",
      "Epoch [213/400], Step [0/439], Loss: 1.1101\n",
      "Epoch [213/400], Step [20/439], Loss: 1.1603\n",
      "Epoch [213/400], Step [40/439], Loss: 1.6263\n",
      "Epoch [213/400], Step [60/439], Loss: 1.2965\n",
      "Epoch [213/400], Step [80/439], Loss: 1.2148\n",
      "Epoch [213/400], Step [100/439], Loss: 1.1649\n",
      "Epoch [213/400], Step [120/439], Loss: 1.3539\n",
      "Epoch [213/400], Step [140/439], Loss: 1.0309\n",
      "Epoch [213/400], Step [160/439], Loss: 1.0049\n",
      "Epoch [213/400], Step [180/439], Loss: 1.5684\n",
      "Epoch [213/400], Step [200/439], Loss: 0.7538\n",
      "Epoch [213/400], Step [220/439], Loss: 1.0937\n",
      "Epoch [213/400], Step [240/439], Loss: 1.0730\n",
      "Epoch [213/400], Step [260/439], Loss: 1.2053\n",
      "Epoch [213/400], Step [280/439], Loss: 0.9886\n",
      "Epoch [213/400], Step [300/439], Loss: 1.3389\n",
      "Epoch [213/400], Step [320/439], Loss: 1.5519\n",
      "Epoch [213/400], Step [340/439], Loss: 1.3734\n",
      "Epoch [213/400], Step [360/439], Loss: 1.5526\n",
      "Epoch [213/400], Step [380/439], Loss: 1.5462\n",
      "Epoch [213/400], Step [400/439], Loss: 1.0371\n",
      "Epoch [213/400], Step [420/439], Loss: 1.0833\n",
      "\n",
      "train-loss: 1.3172, train-acc: 61.3986\n",
      "validation loss: 1.2595, validation acc: 62.6158\n",
      "\n",
      "Epoch 214\n",
      "\n",
      "Epoch [214/400], Step [0/439], Loss: 0.9558\n",
      "Epoch [214/400], Step [20/439], Loss: 1.1636\n",
      "Epoch [214/400], Step [40/439], Loss: 1.1981\n",
      "Epoch [214/400], Step [60/439], Loss: 0.9485\n",
      "Epoch [214/400], Step [80/439], Loss: 1.1807\n",
      "Epoch [214/400], Step [100/439], Loss: 1.3635\n",
      "Epoch [214/400], Step [120/439], Loss: 1.1050\n",
      "Epoch [214/400], Step [140/439], Loss: 1.1929\n",
      "Epoch [214/400], Step [160/439], Loss: 1.1859\n",
      "Epoch [214/400], Step [180/439], Loss: 0.8576\n",
      "Epoch [214/400], Step [200/439], Loss: 1.1910\n",
      "Epoch [214/400], Step [220/439], Loss: 1.0870\n",
      "Epoch [214/400], Step [240/439], Loss: 0.9788\n",
      "Epoch [214/400], Step [260/439], Loss: 1.1938\n",
      "Epoch [214/400], Step [280/439], Loss: 1.2973\n",
      "Epoch [214/400], Step [300/439], Loss: 1.3686\n",
      "Epoch [214/400], Step [320/439], Loss: 1.0637\n",
      "Epoch [214/400], Step [340/439], Loss: 1.3632\n",
      "Epoch [214/400], Step [360/439], Loss: 1.4186\n",
      "Epoch [214/400], Step [380/439], Loss: 1.3988\n",
      "Epoch [214/400], Step [400/439], Loss: 1.1933\n",
      "Epoch [214/400], Step [420/439], Loss: 1.0748\n",
      "\n",
      "train-loss: 1.3165, train-acc: 61.7479\n",
      "validation loss: 1.2588, validation acc: 63.8288\n",
      "\n",
      "Epoch 215\n",
      "\n",
      "Epoch [215/400], Step [0/439], Loss: 0.7370\n",
      "Epoch [215/400], Step [20/439], Loss: 1.1821\n",
      "Epoch [215/400], Step [40/439], Loss: 1.0046\n",
      "Epoch [215/400], Step [60/439], Loss: 0.9528\n",
      "Epoch [215/400], Step [80/439], Loss: 0.8895\n",
      "Epoch [215/400], Step [100/439], Loss: 0.9847\n",
      "Epoch [215/400], Step [120/439], Loss: 1.0662\n",
      "Epoch [215/400], Step [140/439], Loss: 1.2434\n",
      "Epoch [215/400], Step [160/439], Loss: 1.4024\n",
      "Epoch [215/400], Step [180/439], Loss: 1.2585\n",
      "Epoch [215/400], Step [200/439], Loss: 1.2307\n",
      "Epoch [215/400], Step [220/439], Loss: 1.6563\n",
      "Epoch [215/400], Step [240/439], Loss: 0.9963\n",
      "Epoch [215/400], Step [260/439], Loss: 1.1348\n",
      "Epoch [215/400], Step [280/439], Loss: 1.0640\n",
      "Epoch [215/400], Step [300/439], Loss: 0.7966\n",
      "Epoch [215/400], Step [320/439], Loss: 1.3528\n",
      "Epoch [215/400], Step [340/439], Loss: 1.0208\n",
      "Epoch [215/400], Step [360/439], Loss: 1.2055\n",
      "Epoch [215/400], Step [380/439], Loss: 1.1132\n",
      "Epoch [215/400], Step [400/439], Loss: 0.8934\n",
      "Epoch [215/400], Step [420/439], Loss: 1.1723\n",
      "\n",
      "train-loss: 1.3157, train-acc: 61.7836\n",
      "validation loss: 1.2586, validation acc: 58.9546\n",
      "\n",
      "Epoch 216\n",
      "\n",
      "Epoch [216/400], Step [0/439], Loss: 1.1321\n",
      "Epoch [216/400], Step [20/439], Loss: 1.2732\n",
      "Epoch [216/400], Step [40/439], Loss: 1.1456\n",
      "Epoch [216/400], Step [60/439], Loss: 1.1994\n",
      "Epoch [216/400], Step [80/439], Loss: 1.0577\n",
      "Epoch [216/400], Step [100/439], Loss: 1.1381\n",
      "Epoch [216/400], Step [120/439], Loss: 1.1819\n",
      "Epoch [216/400], Step [140/439], Loss: 1.2830\n",
      "Epoch [216/400], Step [160/439], Loss: 1.0152\n",
      "Epoch [216/400], Step [180/439], Loss: 0.9218\n",
      "Epoch [216/400], Step [200/439], Loss: 0.9604\n",
      "Epoch [216/400], Step [220/439], Loss: 1.1203\n",
      "Epoch [216/400], Step [240/439], Loss: 1.2341\n",
      "Epoch [216/400], Step [260/439], Loss: 1.0952\n",
      "Epoch [216/400], Step [280/439], Loss: 0.9332\n",
      "Epoch [216/400], Step [300/439], Loss: 1.0960\n",
      "Epoch [216/400], Step [320/439], Loss: 1.0295\n",
      "Epoch [216/400], Step [340/439], Loss: 1.2344\n",
      "Epoch [216/400], Step [360/439], Loss: 1.0836\n",
      "Epoch [216/400], Step [380/439], Loss: 0.9275\n",
      "Epoch [216/400], Step [400/439], Loss: 1.3399\n",
      "Epoch [216/400], Step [420/439], Loss: 1.0755\n",
      "\n",
      "train-loss: 1.3150, train-acc: 61.3202\n",
      "validation loss: 1.2581, validation acc: 61.7556\n",
      "\n",
      "Epoch 217\n",
      "\n",
      "Epoch [217/400], Step [0/439], Loss: 1.1606\n",
      "Epoch [217/400], Step [20/439], Loss: 1.5020\n",
      "Epoch [217/400], Step [40/439], Loss: 0.9544\n",
      "Epoch [217/400], Step [60/439], Loss: 0.8024\n",
      "Epoch [217/400], Step [80/439], Loss: 1.2598\n",
      "Epoch [217/400], Step [100/439], Loss: 1.0653\n",
      "Epoch [217/400], Step [120/439], Loss: 1.0106\n",
      "Epoch [217/400], Step [140/439], Loss: 1.2021\n",
      "Epoch [217/400], Step [160/439], Loss: 1.3388\n",
      "Epoch [217/400], Step [180/439], Loss: 0.9609\n",
      "Epoch [217/400], Step [200/439], Loss: 0.9207\n",
      "Epoch [217/400], Step [220/439], Loss: 1.0389\n",
      "Epoch [217/400], Step [240/439], Loss: 1.3897\n",
      "Epoch [217/400], Step [260/439], Loss: 1.8639\n",
      "Epoch [217/400], Step [280/439], Loss: 1.3975\n",
      "Epoch [217/400], Step [300/439], Loss: 1.0922\n",
      "Epoch [217/400], Step [320/439], Loss: 0.8637\n",
      "Epoch [217/400], Step [340/439], Loss: 1.0270\n",
      "Epoch [217/400], Step [360/439], Loss: 1.3818\n",
      "Epoch [217/400], Step [380/439], Loss: 1.0740\n",
      "Epoch [217/400], Step [400/439], Loss: 1.2151\n",
      "Epoch [217/400], Step [420/439], Loss: 1.0866\n",
      "\n",
      "train-loss: 1.3144, train-acc: 61.3416\n",
      "validation loss: 1.2573, validation acc: 64.1376\n",
      "\n",
      "Epoch 218\n",
      "\n",
      "Epoch [218/400], Step [0/439], Loss: 0.9180\n",
      "Epoch [218/400], Step [20/439], Loss: 1.1436\n",
      "Epoch [218/400], Step [40/439], Loss: 1.3711\n",
      "Epoch [218/400], Step [60/439], Loss: 1.2078\n",
      "Epoch [218/400], Step [80/439], Loss: 0.9569\n",
      "Epoch [218/400], Step [100/439], Loss: 1.0363\n",
      "Epoch [218/400], Step [120/439], Loss: 1.4530\n",
      "Epoch [218/400], Step [140/439], Loss: 1.0652\n",
      "Epoch [218/400], Step [160/439], Loss: 1.0338\n",
      "Epoch [218/400], Step [180/439], Loss: 1.7831\n",
      "Epoch [218/400], Step [200/439], Loss: 0.9803\n",
      "Epoch [218/400], Step [220/439], Loss: 1.2257\n",
      "Epoch [218/400], Step [240/439], Loss: 0.8918\n",
      "Epoch [218/400], Step [260/439], Loss: 0.9711\n",
      "Epoch [218/400], Step [280/439], Loss: 1.0698\n",
      "Epoch [218/400], Step [300/439], Loss: 1.0545\n",
      "Epoch [218/400], Step [320/439], Loss: 1.5247\n",
      "Epoch [218/400], Step [340/439], Loss: 1.3250\n",
      "Epoch [218/400], Step [360/439], Loss: 1.4894\n",
      "Epoch [218/400], Step [380/439], Loss: 0.9901\n",
      "Epoch [218/400], Step [400/439], Loss: 0.7829\n",
      "Epoch [218/400], Step [420/439], Loss: 1.1978\n",
      "\n",
      "train-loss: 1.3137, train-acc: 61.6553\n",
      "validation loss: 1.2571, validation acc: 59.9471\n",
      "\n",
      "Epoch 219\n",
      "\n",
      "Epoch [219/400], Step [0/439], Loss: 0.7691\n",
      "Epoch [219/400], Step [20/439], Loss: 1.4594\n",
      "Epoch [219/400], Step [40/439], Loss: 1.0579\n",
      "Epoch [219/400], Step [60/439], Loss: 1.1352\n",
      "Epoch [219/400], Step [80/439], Loss: 0.9226\n",
      "Epoch [219/400], Step [100/439], Loss: 0.7867\n",
      "Epoch [219/400], Step [120/439], Loss: 1.3971\n",
      "Epoch [219/400], Step [140/439], Loss: 1.3368\n",
      "Epoch [219/400], Step [160/439], Loss: 0.8314\n",
      "Epoch [219/400], Step [180/439], Loss: 1.2456\n",
      "Epoch [219/400], Step [200/439], Loss: 0.9510\n",
      "Epoch [219/400], Step [220/439], Loss: 0.7895\n",
      "Epoch [219/400], Step [240/439], Loss: 1.2943\n",
      "Epoch [219/400], Step [260/439], Loss: 1.0073\n",
      "Epoch [219/400], Step [280/439], Loss: 1.1872\n",
      "Epoch [219/400], Step [300/439], Loss: 0.7009\n",
      "Epoch [219/400], Step [320/439], Loss: 0.8753\n",
      "Epoch [219/400], Step [340/439], Loss: 0.7883\n",
      "Epoch [219/400], Step [360/439], Loss: 1.4531\n",
      "Epoch [219/400], Step [380/439], Loss: 1.3685\n",
      "Epoch [219/400], Step [400/439], Loss: 1.0748\n",
      "Epoch [219/400], Step [420/439], Loss: 0.7764\n",
      "\n",
      "train-loss: 1.3130, train-acc: 61.6267\n",
      "validation loss: 1.2568, validation acc: 60.0132\n",
      "\n",
      "Epoch 220\n",
      "\n",
      "Epoch [220/400], Step [0/439], Loss: 1.5508\n",
      "Epoch [220/400], Step [20/439], Loss: 0.8829\n",
      "Epoch [220/400], Step [40/439], Loss: 1.1857\n",
      "Epoch [220/400], Step [60/439], Loss: 1.1052\n",
      "Epoch [220/400], Step [80/439], Loss: 0.6745\n",
      "Epoch [220/400], Step [100/439], Loss: 0.7575\n",
      "Epoch [220/400], Step [120/439], Loss: 1.0059\n",
      "Epoch [220/400], Step [140/439], Loss: 1.2231\n",
      "Epoch [220/400], Step [160/439], Loss: 1.0976\n",
      "Epoch [220/400], Step [180/439], Loss: 1.0850\n",
      "Epoch [220/400], Step [200/439], Loss: 1.3073\n",
      "Epoch [220/400], Step [220/439], Loss: 1.3998\n",
      "Epoch [220/400], Step [240/439], Loss: 0.8414\n",
      "Epoch [220/400], Step [260/439], Loss: 1.3322\n",
      "Epoch [220/400], Step [280/439], Loss: 1.0629\n",
      "Epoch [220/400], Step [300/439], Loss: 0.9921\n",
      "Epoch [220/400], Step [320/439], Loss: 1.1563\n",
      "Epoch [220/400], Step [340/439], Loss: 1.1035\n",
      "Epoch [220/400], Step [360/439], Loss: 0.8638\n",
      "Epoch [220/400], Step [380/439], Loss: 1.0283\n",
      "Epoch [220/400], Step [400/439], Loss: 1.1787\n",
      "Epoch [220/400], Step [420/439], Loss: 1.2031\n",
      "\n",
      "train-loss: 1.3124, train-acc: 61.0279\n",
      "validation loss: 1.2562, validation acc: 61.6895\n",
      "\n",
      "Epoch 221\n",
      "\n",
      "Epoch [221/400], Step [0/439], Loss: 1.0710\n",
      "Epoch [221/400], Step [20/439], Loss: 1.0995\n",
      "Epoch [221/400], Step [40/439], Loss: 1.1066\n",
      "Epoch [221/400], Step [60/439], Loss: 1.3562\n",
      "Epoch [221/400], Step [80/439], Loss: 1.1102\n",
      "Epoch [221/400], Step [100/439], Loss: 1.0097\n",
      "Epoch [221/400], Step [120/439], Loss: 0.7489\n",
      "Epoch [221/400], Step [140/439], Loss: 1.6505\n",
      "Epoch [221/400], Step [160/439], Loss: 1.1031\n",
      "Epoch [221/400], Step [180/439], Loss: 1.0155\n",
      "Epoch [221/400], Step [200/439], Loss: 0.8013\n",
      "Epoch [221/400], Step [220/439], Loss: 0.7590\n",
      "Epoch [221/400], Step [240/439], Loss: 1.2210\n",
      "Epoch [221/400], Step [260/439], Loss: 1.0305\n",
      "Epoch [221/400], Step [280/439], Loss: 0.9907\n",
      "Epoch [221/400], Step [300/439], Loss: 1.1969\n",
      "Epoch [221/400], Step [320/439], Loss: 0.9650\n",
      "Epoch [221/400], Step [340/439], Loss: 1.3826\n",
      "Epoch [221/400], Step [360/439], Loss: 1.1201\n",
      "Epoch [221/400], Step [380/439], Loss: 0.9353\n",
      "Epoch [221/400], Step [400/439], Loss: 1.5700\n",
      "Epoch [221/400], Step [420/439], Loss: 1.1339\n",
      "\n",
      "train-loss: 1.3117, train-acc: 61.3202\n",
      "validation loss: 1.2561, validation acc: 59.6162\n",
      "\n",
      "Epoch 222\n",
      "\n",
      "Epoch [222/400], Step [0/439], Loss: 1.5515\n",
      "Epoch [222/400], Step [20/439], Loss: 0.6692\n",
      "Epoch [222/400], Step [40/439], Loss: 1.1533\n",
      "Epoch [222/400], Step [60/439], Loss: 1.3827\n",
      "Epoch [222/400], Step [80/439], Loss: 1.1721\n",
      "Epoch [222/400], Step [100/439], Loss: 1.0047\n",
      "Epoch [222/400], Step [120/439], Loss: 1.1708\n",
      "Epoch [222/400], Step [140/439], Loss: 1.2985\n",
      "Epoch [222/400], Step [160/439], Loss: 0.8295\n",
      "Epoch [222/400], Step [180/439], Loss: 1.3708\n",
      "Epoch [222/400], Step [200/439], Loss: 1.4043\n",
      "Epoch [222/400], Step [220/439], Loss: 1.2662\n",
      "Epoch [222/400], Step [240/439], Loss: 1.0605\n",
      "Epoch [222/400], Step [260/439], Loss: 1.0986\n",
      "Epoch [222/400], Step [280/439], Loss: 0.8193\n",
      "Epoch [222/400], Step [300/439], Loss: 1.5459\n",
      "Epoch [222/400], Step [320/439], Loss: 1.2155\n",
      "Epoch [222/400], Step [340/439], Loss: 0.8513\n",
      "Epoch [222/400], Step [360/439], Loss: 1.0680\n",
      "Epoch [222/400], Step [380/439], Loss: 1.0238\n",
      "Epoch [222/400], Step [400/439], Loss: 0.8641\n",
      "Epoch [222/400], Step [420/439], Loss: 1.2006\n",
      "\n",
      "train-loss: 1.3110, train-acc: 61.9832\n",
      "validation loss: 1.2554, validation acc: 62.9025\n",
      "\n",
      "Epoch 223\n",
      "\n",
      "Epoch [223/400], Step [0/439], Loss: 1.0998\n",
      "Epoch [223/400], Step [20/439], Loss: 0.7925\n",
      "Epoch [223/400], Step [40/439], Loss: 1.1619\n",
      "Epoch [223/400], Step [60/439], Loss: 1.2768\n",
      "Epoch [223/400], Step [80/439], Loss: 1.0962\n",
      "Epoch [223/400], Step [100/439], Loss: 1.1632\n",
      "Epoch [223/400], Step [120/439], Loss: 0.8935\n",
      "Epoch [223/400], Step [140/439], Loss: 1.2981\n",
      "Epoch [223/400], Step [160/439], Loss: 0.9926\n",
      "Epoch [223/400], Step [180/439], Loss: 1.2396\n",
      "Epoch [223/400], Step [200/439], Loss: 1.1876\n",
      "Epoch [223/400], Step [220/439], Loss: 1.1345\n",
      "Epoch [223/400], Step [240/439], Loss: 1.2012\n",
      "Epoch [223/400], Step [260/439], Loss: 0.9015\n",
      "Epoch [223/400], Step [280/439], Loss: 1.0368\n",
      "Epoch [223/400], Step [300/439], Loss: 1.2585\n",
      "Epoch [223/400], Step [320/439], Loss: 1.0634\n",
      "Epoch [223/400], Step [340/439], Loss: 1.0333\n",
      "Epoch [223/400], Step [360/439], Loss: 0.9297\n",
      "Epoch [223/400], Step [380/439], Loss: 1.0789\n",
      "Epoch [223/400], Step [400/439], Loss: 1.0954\n",
      "Epoch [223/400], Step [420/439], Loss: 1.0314\n",
      "\n",
      "train-loss: 1.3103, train-acc: 61.8834\n",
      "validation loss: 1.2547, validation acc: 63.6524\n",
      "\n",
      "Epoch 224\n",
      "\n",
      "Epoch [224/400], Step [0/439], Loss: 0.9668\n",
      "Epoch [224/400], Step [20/439], Loss: 1.2691\n",
      "Epoch [224/400], Step [40/439], Loss: 0.8716\n",
      "Epoch [224/400], Step [60/439], Loss: 0.9080\n",
      "Epoch [224/400], Step [80/439], Loss: 1.1808\n",
      "Epoch [224/400], Step [100/439], Loss: 0.7949\n",
      "Epoch [224/400], Step [120/439], Loss: 1.4161\n",
      "Epoch [224/400], Step [140/439], Loss: 1.1144\n",
      "Epoch [224/400], Step [160/439], Loss: 1.2716\n",
      "Epoch [224/400], Step [180/439], Loss: 0.7327\n",
      "Epoch [224/400], Step [200/439], Loss: 0.9510\n",
      "Epoch [224/400], Step [220/439], Loss: 1.1368\n",
      "Epoch [224/400], Step [240/439], Loss: 0.9211\n",
      "Epoch [224/400], Step [260/439], Loss: 1.0627\n",
      "Epoch [224/400], Step [280/439], Loss: 1.0772\n",
      "Epoch [224/400], Step [300/439], Loss: 0.8250\n",
      "Epoch [224/400], Step [320/439], Loss: 1.7786\n",
      "Epoch [224/400], Step [340/439], Loss: 1.4902\n",
      "Epoch [224/400], Step [360/439], Loss: 1.1319\n",
      "Epoch [224/400], Step [380/439], Loss: 1.1404\n",
      "Epoch [224/400], Step [400/439], Loss: 0.9991\n",
      "Epoch [224/400], Step [420/439], Loss: 1.1256\n",
      "\n",
      "train-loss: 1.3096, train-acc: 61.3131\n",
      "validation loss: 1.2541, validation acc: 62.5717\n",
      "\n",
      "Epoch 225\n",
      "\n",
      "Epoch [225/400], Step [0/439], Loss: 1.3153\n",
      "Epoch [225/400], Step [20/439], Loss: 0.9771\n",
      "Epoch [225/400], Step [40/439], Loss: 0.9372\n",
      "Epoch [225/400], Step [60/439], Loss: 1.2179\n",
      "Epoch [225/400], Step [80/439], Loss: 1.4894\n",
      "Epoch [225/400], Step [100/439], Loss: 1.0406\n",
      "Epoch [225/400], Step [120/439], Loss: 1.5427\n",
      "Epoch [225/400], Step [140/439], Loss: 1.0817\n",
      "Epoch [225/400], Step [160/439], Loss: 0.9678\n",
      "Epoch [225/400], Step [180/439], Loss: 1.0676\n",
      "Epoch [225/400], Step [200/439], Loss: 1.1825\n",
      "Epoch [225/400], Step [220/439], Loss: 1.1099\n",
      "Epoch [225/400], Step [240/439], Loss: 1.2008\n",
      "Epoch [225/400], Step [260/439], Loss: 0.9770\n",
      "Epoch [225/400], Step [280/439], Loss: 0.9920\n",
      "Epoch [225/400], Step [300/439], Loss: 1.3789\n",
      "Epoch [225/400], Step [320/439], Loss: 1.1033\n",
      "Epoch [225/400], Step [340/439], Loss: 1.4297\n",
      "Epoch [225/400], Step [360/439], Loss: 1.3657\n",
      "Epoch [225/400], Step [380/439], Loss: 1.1864\n",
      "Epoch [225/400], Step [400/439], Loss: 1.4068\n",
      "Epoch [225/400], Step [420/439], Loss: 1.2064\n",
      "\n",
      "train-loss: 1.3089, train-acc: 62.0188\n",
      "validation loss: 1.2534, validation acc: 63.0128\n",
      "\n",
      "Epoch 226\n",
      "\n",
      "Epoch [226/400], Step [0/439], Loss: 1.1287\n",
      "Epoch [226/400], Step [20/439], Loss: 1.2883\n",
      "Epoch [226/400], Step [40/439], Loss: 0.7340\n",
      "Epoch [226/400], Step [60/439], Loss: 1.2302\n",
      "Epoch [226/400], Step [80/439], Loss: 1.1321\n",
      "Epoch [226/400], Step [100/439], Loss: 0.7662\n",
      "Epoch [226/400], Step [120/439], Loss: 1.3559\n",
      "Epoch [226/400], Step [140/439], Loss: 0.8966\n",
      "Epoch [226/400], Step [160/439], Loss: 1.0644\n",
      "Epoch [226/400], Step [180/439], Loss: 1.1196\n",
      "Epoch [226/400], Step [200/439], Loss: 0.9271\n",
      "Epoch [226/400], Step [220/439], Loss: 1.3434\n",
      "Epoch [226/400], Step [240/439], Loss: 0.8027\n",
      "Epoch [226/400], Step [260/439], Loss: 1.0763\n",
      "Epoch [226/400], Step [280/439], Loss: 1.2786\n",
      "Epoch [226/400], Step [300/439], Loss: 0.8435\n",
      "Epoch [226/400], Step [320/439], Loss: 1.6738\n",
      "Epoch [226/400], Step [340/439], Loss: 1.0488\n",
      "Epoch [226/400], Step [360/439], Loss: 0.9622\n",
      "Epoch [226/400], Step [380/439], Loss: 1.0419\n",
      "Epoch [226/400], Step [400/439], Loss: 0.8996\n",
      "Epoch [226/400], Step [420/439], Loss: 0.9371\n",
      "\n",
      "train-loss: 1.3082, train-acc: 62.2612\n",
      "validation loss: 1.2532, validation acc: 59.9471\n",
      "\n",
      "Epoch 227\n",
      "\n",
      "Epoch [227/400], Step [0/439], Loss: 1.4243\n",
      "Epoch [227/400], Step [20/439], Loss: 1.2017\n",
      "Epoch [227/400], Step [40/439], Loss: 1.2135\n",
      "Epoch [227/400], Step [60/439], Loss: 1.0733\n",
      "Epoch [227/400], Step [80/439], Loss: 0.8752\n",
      "Epoch [227/400], Step [100/439], Loss: 1.0861\n",
      "Epoch [227/400], Step [120/439], Loss: 1.0133\n",
      "Epoch [227/400], Step [140/439], Loss: 1.2369\n",
      "Epoch [227/400], Step [160/439], Loss: 1.5671\n",
      "Epoch [227/400], Step [180/439], Loss: 1.0893\n",
      "Epoch [227/400], Step [200/439], Loss: 0.9700\n",
      "Epoch [227/400], Step [220/439], Loss: 1.2024\n",
      "Epoch [227/400], Step [240/439], Loss: 0.7468\n",
      "Epoch [227/400], Step [260/439], Loss: 1.2518\n",
      "Epoch [227/400], Step [280/439], Loss: 1.2798\n",
      "Epoch [227/400], Step [300/439], Loss: 1.0588\n",
      "Epoch [227/400], Step [320/439], Loss: 1.3395\n",
      "Epoch [227/400], Step [340/439], Loss: 1.1209\n",
      "Epoch [227/400], Step [360/439], Loss: 1.1765\n",
      "Epoch [227/400], Step [380/439], Loss: 1.1470\n",
      "Epoch [227/400], Step [400/439], Loss: 1.1846\n",
      "Epoch [227/400], Step [420/439], Loss: 1.2261\n",
      "\n",
      "train-loss: 1.3075, train-acc: 61.6054\n",
      "validation loss: 1.2526, validation acc: 61.6674\n",
      "\n",
      "Epoch 228\n",
      "\n",
      "Epoch [228/400], Step [0/439], Loss: 1.0698\n",
      "Epoch [228/400], Step [20/439], Loss: 1.0478\n",
      "Epoch [228/400], Step [40/439], Loss: 1.1162\n",
      "Epoch [228/400], Step [60/439], Loss: 1.2591\n",
      "Epoch [228/400], Step [80/439], Loss: 1.4095\n",
      "Epoch [228/400], Step [100/439], Loss: 1.3248\n",
      "Epoch [228/400], Step [120/439], Loss: 0.9396\n",
      "Epoch [228/400], Step [140/439], Loss: 1.2213\n",
      "Epoch [228/400], Step [160/439], Loss: 0.8879\n",
      "Epoch [228/400], Step [180/439], Loss: 1.0521\n",
      "Epoch [228/400], Step [200/439], Loss: 1.0788\n",
      "Epoch [228/400], Step [220/439], Loss: 0.9843\n",
      "Epoch [228/400], Step [240/439], Loss: 1.2231\n",
      "Epoch [228/400], Step [260/439], Loss: 1.1575\n",
      "Epoch [228/400], Step [280/439], Loss: 0.7284\n",
      "Epoch [228/400], Step [300/439], Loss: 0.9861\n",
      "Epoch [228/400], Step [320/439], Loss: 0.8430\n",
      "Epoch [228/400], Step [340/439], Loss: 0.8379\n",
      "Epoch [228/400], Step [360/439], Loss: 1.0646\n",
      "Epoch [228/400], Step [380/439], Loss: 1.4999\n",
      "Epoch [228/400], Step [400/439], Loss: 0.9839\n",
      "Epoch [228/400], Step [420/439], Loss: 1.3847\n",
      "\n",
      "train-loss: 1.3069, train-acc: 61.7123\n",
      "validation loss: 1.2518, validation acc: 65.9241\n",
      "\n",
      "Improvement-Detected, save-model\n",
      "Epoch 229\n",
      "\n",
      "Epoch [229/400], Step [0/439], Loss: 1.4230\n",
      "Epoch [229/400], Step [20/439], Loss: 1.1880\n",
      "Epoch [229/400], Step [40/439], Loss: 1.1064\n",
      "Epoch [229/400], Step [60/439], Loss: 0.9965\n",
      "Epoch [229/400], Step [80/439], Loss: 0.8736\n",
      "Epoch [229/400], Step [100/439], Loss: 1.1396\n",
      "Epoch [229/400], Step [120/439], Loss: 1.0591\n",
      "Epoch [229/400], Step [140/439], Loss: 1.0008\n",
      "Epoch [229/400], Step [160/439], Loss: 0.9910\n",
      "Epoch [229/400], Step [180/439], Loss: 1.2561\n",
      "Epoch [229/400], Step [200/439], Loss: 1.1088\n",
      "Epoch [229/400], Step [220/439], Loss: 1.4061\n",
      "Epoch [229/400], Step [240/439], Loss: 1.4388\n",
      "Epoch [229/400], Step [260/439], Loss: 1.2302\n",
      "Epoch [229/400], Step [280/439], Loss: 1.0033\n",
      "Epoch [229/400], Step [300/439], Loss: 1.0908\n",
      "Epoch [229/400], Step [320/439], Loss: 1.3808\n",
      "Epoch [229/400], Step [340/439], Loss: 1.3648\n",
      "Epoch [229/400], Step [360/439], Loss: 0.8557\n",
      "Epoch [229/400], Step [380/439], Loss: 0.7714\n",
      "Epoch [229/400], Step [400/439], Loss: 0.9579\n",
      "Epoch [229/400], Step [420/439], Loss: 1.1047\n",
      "\n",
      "train-loss: 1.3062, train-acc: 62.0046\n",
      "validation loss: 1.2510, validation acc: 64.4685\n",
      "\n",
      "Epoch 230\n",
      "\n",
      "Epoch [230/400], Step [0/439], Loss: 0.9725\n",
      "Epoch [230/400], Step [20/439], Loss: 1.3247\n",
      "Epoch [230/400], Step [40/439], Loss: 0.8451\n",
      "Epoch [230/400], Step [60/439], Loss: 0.9800\n",
      "Epoch [230/400], Step [80/439], Loss: 1.2237\n",
      "Epoch [230/400], Step [100/439], Loss: 1.1851\n",
      "Epoch [230/400], Step [120/439], Loss: 1.0727\n",
      "Epoch [230/400], Step [140/439], Loss: 1.1269\n",
      "Epoch [230/400], Step [160/439], Loss: 1.3253\n",
      "Epoch [230/400], Step [180/439], Loss: 1.0612\n",
      "Epoch [230/400], Step [200/439], Loss: 1.0049\n",
      "Epoch [230/400], Step [220/439], Loss: 1.1150\n",
      "Epoch [230/400], Step [240/439], Loss: 1.2396\n",
      "Epoch [230/400], Step [260/439], Loss: 1.2391\n",
      "Epoch [230/400], Step [280/439], Loss: 1.3081\n",
      "Epoch [230/400], Step [300/439], Loss: 1.2344\n",
      "Epoch [230/400], Step [320/439], Loss: 1.4555\n",
      "Epoch [230/400], Step [340/439], Loss: 1.0089\n",
      "Epoch [230/400], Step [360/439], Loss: 0.7430\n",
      "Epoch [230/400], Step [380/439], Loss: 1.0298\n",
      "Epoch [230/400], Step [400/439], Loss: 1.3350\n",
      "Epoch [230/400], Step [420/439], Loss: 1.0029\n",
      "\n",
      "train-loss: 1.3055, train-acc: 61.8406\n",
      "validation loss: 1.2501, validation acc: 66.0565\n",
      "\n",
      "Improvement-Detected, save-model\n",
      "Epoch 231\n",
      "\n",
      "Epoch [231/400], Step [0/439], Loss: 1.1210\n",
      "Epoch [231/400], Step [20/439], Loss: 1.3804\n",
      "Epoch [231/400], Step [40/439], Loss: 1.3709\n",
      "Epoch [231/400], Step [60/439], Loss: 0.9211\n",
      "Epoch [231/400], Step [80/439], Loss: 0.9096\n",
      "Epoch [231/400], Step [100/439], Loss: 1.0108\n",
      "Epoch [231/400], Step [120/439], Loss: 1.0550\n",
      "Epoch [231/400], Step [140/439], Loss: 1.2615\n",
      "Epoch [231/400], Step [160/439], Loss: 1.1907\n",
      "Epoch [231/400], Step [180/439], Loss: 0.9878\n",
      "Epoch [231/400], Step [200/439], Loss: 1.0040\n",
      "Epoch [231/400], Step [220/439], Loss: 1.0557\n",
      "Epoch [231/400], Step [240/439], Loss: 0.7711\n",
      "Epoch [231/400], Step [260/439], Loss: 1.0220\n",
      "Epoch [231/400], Step [280/439], Loss: 0.9283\n",
      "Epoch [231/400], Step [300/439], Loss: 0.8152\n",
      "Epoch [231/400], Step [320/439], Loss: 1.5406\n",
      "Epoch [231/400], Step [340/439], Loss: 0.8621\n",
      "Epoch [231/400], Step [360/439], Loss: 0.8541\n",
      "Epoch [231/400], Step [380/439], Loss: 1.2715\n",
      "Epoch [231/400], Step [400/439], Loss: 1.0344\n",
      "Epoch [231/400], Step [420/439], Loss: 1.2819\n",
      "\n",
      "train-loss: 1.3048, train-acc: 61.8976\n",
      "validation loss: 1.2495, validation acc: 62.3511\n",
      "\n",
      "Epoch 232\n",
      "\n",
      "Epoch [232/400], Step [0/439], Loss: 1.1429\n",
      "Epoch [232/400], Step [20/439], Loss: 1.5097\n",
      "Epoch [232/400], Step [40/439], Loss: 0.9720\n",
      "Epoch [232/400], Step [60/439], Loss: 1.1880\n",
      "Epoch [232/400], Step [80/439], Loss: 1.0606\n",
      "Epoch [232/400], Step [100/439], Loss: 1.1876\n",
      "Epoch [232/400], Step [120/439], Loss: 1.0833\n",
      "Epoch [232/400], Step [140/439], Loss: 1.1267\n",
      "Epoch [232/400], Step [160/439], Loss: 0.9493\n",
      "Epoch [232/400], Step [180/439], Loss: 1.4399\n",
      "Epoch [232/400], Step [200/439], Loss: 1.2302\n",
      "Epoch [232/400], Step [220/439], Loss: 0.9116\n",
      "Epoch [232/400], Step [240/439], Loss: 1.0098\n",
      "Epoch [232/400], Step [260/439], Loss: 0.9670\n",
      "Epoch [232/400], Step [280/439], Loss: 0.9417\n",
      "Epoch [232/400], Step [300/439], Loss: 0.6822\n",
      "Epoch [232/400], Step [320/439], Loss: 1.1534\n",
      "Epoch [232/400], Step [340/439], Loss: 1.1564\n",
      "Epoch [232/400], Step [360/439], Loss: 1.3703\n",
      "Epoch [232/400], Step [380/439], Loss: 1.0361\n",
      "Epoch [232/400], Step [400/439], Loss: 0.9531\n",
      "Epoch [232/400], Step [420/439], Loss: 1.0017\n",
      "\n",
      "train-loss: 1.3042, train-acc: 61.7764\n",
      "validation loss: 1.2488, validation acc: 64.5346\n",
      "\n",
      "Epoch 233\n",
      "\n",
      "Epoch [233/400], Step [0/439], Loss: 1.2301\n",
      "Epoch [233/400], Step [20/439], Loss: 1.4643\n",
      "Epoch [233/400], Step [40/439], Loss: 1.2459\n",
      "Epoch [233/400], Step [60/439], Loss: 1.0503\n",
      "Epoch [233/400], Step [80/439], Loss: 1.0563\n",
      "Epoch [233/400], Step [100/439], Loss: 1.1702\n",
      "Epoch [233/400], Step [120/439], Loss: 1.0146\n",
      "Epoch [233/400], Step [140/439], Loss: 0.8880\n",
      "Epoch [233/400], Step [160/439], Loss: 0.9741\n",
      "Epoch [233/400], Step [180/439], Loss: 0.8841\n",
      "Epoch [233/400], Step [200/439], Loss: 1.3066\n",
      "Epoch [233/400], Step [220/439], Loss: 1.1177\n",
      "Epoch [233/400], Step [240/439], Loss: 1.1688\n",
      "Epoch [233/400], Step [260/439], Loss: 1.1107\n",
      "Epoch [233/400], Step [280/439], Loss: 1.2559\n",
      "Epoch [233/400], Step [300/439], Loss: 0.7500\n",
      "Epoch [233/400], Step [320/439], Loss: 1.4413\n",
      "Epoch [233/400], Step [340/439], Loss: 0.8493\n",
      "Epoch [233/400], Step [360/439], Loss: 1.2680\n",
      "Epoch [233/400], Step [380/439], Loss: 0.8054\n",
      "Epoch [233/400], Step [400/439], Loss: 0.8786\n",
      "Epoch [233/400], Step [420/439], Loss: 1.0463\n",
      "\n",
      "train-loss: 1.3035, train-acc: 62.1970\n",
      "validation loss: 1.2484, validation acc: 61.2483\n",
      "\n",
      "Epoch 234\n",
      "\n",
      "Epoch [234/400], Step [0/439], Loss: 1.3217\n",
      "Epoch [234/400], Step [20/439], Loss: 1.1096\n",
      "Epoch [234/400], Step [40/439], Loss: 0.9916\n",
      "Epoch [234/400], Step [60/439], Loss: 1.4842\n",
      "Epoch [234/400], Step [80/439], Loss: 1.0373\n",
      "Epoch [234/400], Step [100/439], Loss: 1.4466\n",
      "Epoch [234/400], Step [120/439], Loss: 1.3887\n",
      "Epoch [234/400], Step [140/439], Loss: 1.6891\n",
      "Epoch [234/400], Step [160/439], Loss: 1.5487\n",
      "Epoch [234/400], Step [180/439], Loss: 1.2543\n",
      "Epoch [234/400], Step [200/439], Loss: 1.1322\n",
      "Epoch [234/400], Step [220/439], Loss: 0.9832\n",
      "Epoch [234/400], Step [240/439], Loss: 1.0447\n",
      "Epoch [234/400], Step [260/439], Loss: 1.4174\n",
      "Epoch [234/400], Step [280/439], Loss: 0.9108\n",
      "Epoch [234/400], Step [300/439], Loss: 1.1682\n",
      "Epoch [234/400], Step [320/439], Loss: 1.0575\n",
      "Epoch [234/400], Step [340/439], Loss: 1.0594\n",
      "Epoch [234/400], Step [360/439], Loss: 0.7398\n",
      "Epoch [234/400], Step [380/439], Loss: 1.2422\n",
      "Epoch [234/400], Step [400/439], Loss: 1.4453\n",
      "Epoch [234/400], Step [420/439], Loss: 1.2023\n",
      "\n",
      "train-loss: 1.3029, train-acc: 61.0565\n",
      "validation loss: 1.2477, validation acc: 63.1892\n",
      "\n",
      "Epoch 235\n",
      "\n",
      "Epoch [235/400], Step [0/439], Loss: 1.1794\n",
      "Epoch [235/400], Step [20/439], Loss: 1.5187\n",
      "Epoch [235/400], Step [40/439], Loss: 1.2992\n",
      "Epoch [235/400], Step [60/439], Loss: 1.1245\n",
      "Epoch [235/400], Step [80/439], Loss: 1.0103\n",
      "Epoch [235/400], Step [100/439], Loss: 1.2174\n",
      "Epoch [235/400], Step [120/439], Loss: 0.7170\n",
      "Epoch [235/400], Step [140/439], Loss: 1.1803\n",
      "Epoch [235/400], Step [160/439], Loss: 1.3760\n",
      "Epoch [235/400], Step [180/439], Loss: 1.5104\n",
      "Epoch [235/400], Step [200/439], Loss: 0.9981\n",
      "Epoch [235/400], Step [220/439], Loss: 1.0474\n",
      "Epoch [235/400], Step [240/439], Loss: 1.1057\n",
      "Epoch [235/400], Step [260/439], Loss: 1.3692\n",
      "Epoch [235/400], Step [280/439], Loss: 1.1718\n",
      "Epoch [235/400], Step [300/439], Loss: 1.0193\n",
      "Epoch [235/400], Step [320/439], Loss: 1.0529\n",
      "Epoch [235/400], Step [340/439], Loss: 1.3845\n",
      "Epoch [235/400], Step [360/439], Loss: 0.6274\n",
      "Epoch [235/400], Step [380/439], Loss: 0.9755\n",
      "Epoch [235/400], Step [400/439], Loss: 1.1714\n",
      "Epoch [235/400], Step [420/439], Loss: 1.2175\n",
      "\n",
      "train-loss: 1.3023, train-acc: 62.1828\n",
      "validation loss: 1.2470, validation acc: 64.3361\n",
      "\n",
      "Epoch 236\n",
      "\n",
      "Epoch [236/400], Step [0/439], Loss: 1.1056\n",
      "Epoch [236/400], Step [20/439], Loss: 1.1286\n",
      "Epoch [236/400], Step [40/439], Loss: 0.9205\n",
      "Epoch [236/400], Step [60/439], Loss: 1.2265\n",
      "Epoch [236/400], Step [80/439], Loss: 1.1723\n",
      "Epoch [236/400], Step [100/439], Loss: 1.5097\n",
      "Epoch [236/400], Step [120/439], Loss: 0.8259\n",
      "Epoch [236/400], Step [140/439], Loss: 1.0589\n",
      "Epoch [236/400], Step [160/439], Loss: 1.3335\n",
      "Epoch [236/400], Step [180/439], Loss: 1.2769\n",
      "Epoch [236/400], Step [200/439], Loss: 1.0448\n",
      "Epoch [236/400], Step [220/439], Loss: 1.0910\n",
      "Epoch [236/400], Step [240/439], Loss: 1.1103\n",
      "Epoch [236/400], Step [260/439], Loss: 1.0922\n",
      "Epoch [236/400], Step [280/439], Loss: 1.1903\n",
      "Epoch [236/400], Step [300/439], Loss: 1.0837\n",
      "Epoch [236/400], Step [320/439], Loss: 1.1922\n",
      "Epoch [236/400], Step [340/439], Loss: 1.0691\n",
      "Epoch [236/400], Step [360/439], Loss: 1.2337\n",
      "Epoch [236/400], Step [380/439], Loss: 0.9652\n",
      "Epoch [236/400], Step [400/439], Loss: 0.8162\n",
      "Epoch [236/400], Step [420/439], Loss: 1.0955\n",
      "\n",
      "train-loss: 1.3016, train-acc: 62.2541\n",
      "validation loss: 1.2463, validation acc: 64.6449\n",
      "\n",
      "Epoch 237\n",
      "\n",
      "Epoch [237/400], Step [0/439], Loss: 0.9996\n",
      "Epoch [237/400], Step [20/439], Loss: 1.1698\n",
      "Epoch [237/400], Step [40/439], Loss: 0.8757\n",
      "Epoch [237/400], Step [60/439], Loss: 0.7687\n",
      "Epoch [237/400], Step [80/439], Loss: 1.6438\n",
      "Epoch [237/400], Step [100/439], Loss: 1.0055\n",
      "Epoch [237/400], Step [120/439], Loss: 1.0927\n",
      "Epoch [237/400], Step [140/439], Loss: 0.9742\n",
      "Epoch [237/400], Step [160/439], Loss: 1.3124\n",
      "Epoch [237/400], Step [180/439], Loss: 0.6858\n",
      "Epoch [237/400], Step [200/439], Loss: 0.9772\n",
      "Epoch [237/400], Step [220/439], Loss: 1.1756\n",
      "Epoch [237/400], Step [240/439], Loss: 1.3627\n",
      "Epoch [237/400], Step [260/439], Loss: 0.9624\n",
      "Epoch [237/400], Step [280/439], Loss: 1.2406\n",
      "Epoch [237/400], Step [300/439], Loss: 1.4179\n",
      "Epoch [237/400], Step [320/439], Loss: 1.0902\n",
      "Epoch [237/400], Step [340/439], Loss: 0.9645\n",
      "Epoch [237/400], Step [360/439], Loss: 0.9452\n",
      "Epoch [237/400], Step [380/439], Loss: 1.0344\n",
      "Epoch [237/400], Step [400/439], Loss: 0.9528\n",
      "Epoch [237/400], Step [420/439], Loss: 1.1589\n",
      "\n",
      "train-loss: 1.3010, train-acc: 62.0901\n",
      "validation loss: 1.2455, validation acc: 65.5051\n",
      "\n",
      "Epoch 238\n",
      "\n",
      "Epoch [238/400], Step [0/439], Loss: 1.2368\n",
      "Epoch [238/400], Step [20/439], Loss: 1.1108\n",
      "Epoch [238/400], Step [40/439], Loss: 1.3335\n",
      "Epoch [238/400], Step [60/439], Loss: 1.0210\n",
      "Epoch [238/400], Step [80/439], Loss: 1.0649\n",
      "Epoch [238/400], Step [100/439], Loss: 0.8939\n",
      "Epoch [238/400], Step [120/439], Loss: 0.8781\n",
      "Epoch [238/400], Step [140/439], Loss: 1.5428\n",
      "Epoch [238/400], Step [160/439], Loss: 1.2986\n",
      "Epoch [238/400], Step [180/439], Loss: 1.2471\n",
      "Epoch [238/400], Step [200/439], Loss: 0.8826\n",
      "Epoch [238/400], Step [220/439], Loss: 1.1206\n",
      "Epoch [238/400], Step [240/439], Loss: 1.1486\n",
      "Epoch [238/400], Step [260/439], Loss: 1.6809\n",
      "Epoch [238/400], Step [280/439], Loss: 1.2225\n",
      "Epoch [238/400], Step [300/439], Loss: 0.9831\n",
      "Epoch [238/400], Step [320/439], Loss: 1.0986\n",
      "Epoch [238/400], Step [340/439], Loss: 0.8072\n",
      "Epoch [238/400], Step [360/439], Loss: 1.0981\n",
      "Epoch [238/400], Step [380/439], Loss: 1.1536\n",
      "Epoch [238/400], Step [400/439], Loss: 0.7804\n",
      "Epoch [238/400], Step [420/439], Loss: 0.8728\n",
      "\n",
      "train-loss: 1.3003, train-acc: 62.2469\n",
      "validation loss: 1.2449, validation acc: 63.8509\n",
      "\n",
      "Epoch 239\n",
      "\n",
      "Epoch [239/400], Step [0/439], Loss: 1.0979\n",
      "Epoch [239/400], Step [20/439], Loss: 0.9396\n",
      "Epoch [239/400], Step [40/439], Loss: 1.4641\n",
      "Epoch [239/400], Step [60/439], Loss: 0.6426\n",
      "Epoch [239/400], Step [80/439], Loss: 1.0553\n",
      "Epoch [239/400], Step [100/439], Loss: 1.0424\n",
      "Epoch [239/400], Step [120/439], Loss: 1.3120\n",
      "Epoch [239/400], Step [140/439], Loss: 1.1312\n",
      "Epoch [239/400], Step [160/439], Loss: 1.1638\n",
      "Epoch [239/400], Step [180/439], Loss: 1.0689\n",
      "Epoch [239/400], Step [200/439], Loss: 1.1617\n",
      "Epoch [239/400], Step [220/439], Loss: 1.0835\n",
      "Epoch [239/400], Step [240/439], Loss: 1.3535\n",
      "Epoch [239/400], Step [260/439], Loss: 1.3703\n",
      "Epoch [239/400], Step [280/439], Loss: 1.0656\n",
      "Epoch [239/400], Step [300/439], Loss: 0.8530\n",
      "Epoch [239/400], Step [320/439], Loss: 0.9293\n",
      "Epoch [239/400], Step [340/439], Loss: 1.1480\n",
      "Epoch [239/400], Step [360/439], Loss: 1.0130\n",
      "Epoch [239/400], Step [380/439], Loss: 0.9909\n",
      "Epoch [239/400], Step [400/439], Loss: 0.7914\n",
      "Epoch [239/400], Step [420/439], Loss: 1.1961\n",
      "\n",
      "train-loss: 1.2997, train-acc: 61.6339\n",
      "validation loss: 1.2442, validation acc: 64.5126\n",
      "\n",
      "Epoch 240\n",
      "\n",
      "Epoch [240/400], Step [0/439], Loss: 0.7358\n",
      "Epoch [240/400], Step [20/439], Loss: 1.2425\n",
      "Epoch [240/400], Step [40/439], Loss: 0.8253\n",
      "Epoch [240/400], Step [60/439], Loss: 1.7008\n",
      "Epoch [240/400], Step [80/439], Loss: 1.2834\n",
      "Epoch [240/400], Step [100/439], Loss: 1.1010\n",
      "Epoch [240/400], Step [120/439], Loss: 1.1716\n",
      "Epoch [240/400], Step [140/439], Loss: 0.9594\n",
      "Epoch [240/400], Step [160/439], Loss: 1.0929\n",
      "Epoch [240/400], Step [180/439], Loss: 0.8458\n",
      "Epoch [240/400], Step [200/439], Loss: 0.6394\n",
      "Epoch [240/400], Step [220/439], Loss: 0.9475\n",
      "Epoch [240/400], Step [240/439], Loss: 0.8528\n",
      "Epoch [240/400], Step [260/439], Loss: 1.0642\n",
      "Epoch [240/400], Step [280/439], Loss: 0.9777\n",
      "Epoch [240/400], Step [300/439], Loss: 1.1435\n",
      "Epoch [240/400], Step [320/439], Loss: 0.8907\n",
      "Epoch [240/400], Step [340/439], Loss: 1.1158\n",
      "Epoch [240/400], Step [360/439], Loss: 1.0251\n",
      "Epoch [240/400], Step [380/439], Loss: 1.0194\n",
      "Epoch [240/400], Step [400/439], Loss: 1.1586\n",
      "Epoch [240/400], Step [420/439], Loss: 0.9221\n",
      "\n",
      "train-loss: 1.2990, train-acc: 61.4557\n",
      "validation loss: 1.2438, validation acc: 61.3586\n",
      "\n",
      "Epoch 241\n",
      "\n",
      "Epoch [241/400], Step [0/439], Loss: 0.7229\n",
      "Epoch [241/400], Step [20/439], Loss: 0.5184\n",
      "Epoch [241/400], Step [40/439], Loss: 0.8349\n",
      "Epoch [241/400], Step [60/439], Loss: 1.1894\n",
      "Epoch [241/400], Step [80/439], Loss: 1.3112\n",
      "Epoch [241/400], Step [100/439], Loss: 0.7525\n",
      "Epoch [241/400], Step [120/439], Loss: 1.0556\n",
      "Epoch [241/400], Step [140/439], Loss: 1.3227\n",
      "Epoch [241/400], Step [160/439], Loss: 1.1164\n",
      "Epoch [241/400], Step [180/439], Loss: 0.8328\n",
      "Epoch [241/400], Step [200/439], Loss: 1.0201\n",
      "Epoch [241/400], Step [220/439], Loss: 1.1200\n",
      "Epoch [241/400], Step [240/439], Loss: 1.2607\n",
      "Epoch [241/400], Step [260/439], Loss: 0.9033\n",
      "Epoch [241/400], Step [280/439], Loss: 0.9950\n",
      "Epoch [241/400], Step [300/439], Loss: 1.1504\n",
      "Epoch [241/400], Step [320/439], Loss: 1.1733\n",
      "Epoch [241/400], Step [340/439], Loss: 1.0245\n",
      "Epoch [241/400], Step [360/439], Loss: 0.8760\n",
      "Epoch [241/400], Step [380/439], Loss: 1.1873\n",
      "Epoch [241/400], Step [400/439], Loss: 1.0489\n",
      "Epoch [241/400], Step [420/439], Loss: 1.0574\n",
      "\n",
      "train-loss: 1.2984, train-acc: 61.7123\n",
      "validation loss: 1.2431, validation acc: 64.4464\n",
      "\n",
      "Epoch 242\n",
      "\n",
      "Epoch [242/400], Step [0/439], Loss: 1.2506\n",
      "Epoch [242/400], Step [20/439], Loss: 1.0918\n",
      "Epoch [242/400], Step [40/439], Loss: 1.3658\n",
      "Epoch [242/400], Step [60/439], Loss: 1.2832\n",
      "Epoch [242/400], Step [80/439], Loss: 1.1834\n",
      "Epoch [242/400], Step [100/439], Loss: 1.1712\n",
      "Epoch [242/400], Step [120/439], Loss: 0.8362\n",
      "Epoch [242/400], Step [140/439], Loss: 1.0495\n",
      "Epoch [242/400], Step [160/439], Loss: 1.0921\n",
      "Epoch [242/400], Step [180/439], Loss: 1.3322\n",
      "Epoch [242/400], Step [200/439], Loss: 1.2711\n",
      "Epoch [242/400], Step [220/439], Loss: 1.0506\n",
      "Epoch [242/400], Step [240/439], Loss: 1.0080\n",
      "Epoch [242/400], Step [260/439], Loss: 1.1941\n",
      "Epoch [242/400], Step [280/439], Loss: 1.2647\n",
      "Epoch [242/400], Step [300/439], Loss: 0.9228\n",
      "Epoch [242/400], Step [320/439], Loss: 1.4386\n",
      "Epoch [242/400], Step [340/439], Loss: 1.0099\n",
      "Epoch [242/400], Step [360/439], Loss: 0.8824\n",
      "Epoch [242/400], Step [380/439], Loss: 1.0940\n",
      "Epoch [242/400], Step [400/439], Loss: 1.1086\n",
      "Epoch [242/400], Step [420/439], Loss: 1.0924\n",
      "\n",
      "train-loss: 1.2978, train-acc: 61.6980\n",
      "validation loss: 1.2423, validation acc: 64.8434\n",
      "\n",
      "Epoch 243\n",
      "\n",
      "Epoch [243/400], Step [0/439], Loss: 1.3211\n",
      "Epoch [243/400], Step [20/439], Loss: 1.2322\n",
      "Epoch [243/400], Step [40/439], Loss: 1.0113\n",
      "Epoch [243/400], Step [60/439], Loss: 1.0410\n",
      "Epoch [243/400], Step [80/439], Loss: 1.5640\n",
      "Epoch [243/400], Step [100/439], Loss: 1.2704\n",
      "Epoch [243/400], Step [120/439], Loss: 1.0627\n",
      "Epoch [243/400], Step [140/439], Loss: 0.9940\n",
      "Epoch [243/400], Step [160/439], Loss: 0.9420\n",
      "Epoch [243/400], Step [180/439], Loss: 1.3679\n",
      "Epoch [243/400], Step [200/439], Loss: 1.1563\n",
      "Epoch [243/400], Step [220/439], Loss: 0.7160\n",
      "Epoch [243/400], Step [240/439], Loss: 1.0914\n",
      "Epoch [243/400], Step [260/439], Loss: 1.2825\n",
      "Epoch [243/400], Step [280/439], Loss: 1.1375\n",
      "Epoch [243/400], Step [300/439], Loss: 1.1250\n",
      "Epoch [243/400], Step [320/439], Loss: 1.0882\n",
      "Epoch [243/400], Step [340/439], Loss: 0.7672\n",
      "Epoch [243/400], Step [360/439], Loss: 1.0216\n",
      "Epoch [243/400], Step [380/439], Loss: 0.9941\n",
      "Epoch [243/400], Step [400/439], Loss: 1.1449\n",
      "Epoch [243/400], Step [420/439], Loss: 1.4964\n",
      "\n",
      "train-loss: 1.2972, train-acc: 62.4465\n",
      "validation loss: 1.2416, validation acc: 66.1006\n",
      "\n",
      "Epoch 244\n",
      "\n",
      "Epoch [244/400], Step [0/439], Loss: 1.0364\n",
      "Epoch [244/400], Step [20/439], Loss: 1.2204\n",
      "Epoch [244/400], Step [40/439], Loss: 0.9350\n",
      "Epoch [244/400], Step [60/439], Loss: 1.1638\n",
      "Epoch [244/400], Step [80/439], Loss: 0.9047\n",
      "Epoch [244/400], Step [100/439], Loss: 1.2198\n",
      "Epoch [244/400], Step [120/439], Loss: 0.9832\n",
      "Epoch [244/400], Step [140/439], Loss: 0.9530\n",
      "Epoch [244/400], Step [160/439], Loss: 1.1888\n",
      "Epoch [244/400], Step [180/439], Loss: 1.2217\n",
      "Epoch [244/400], Step [200/439], Loss: 0.6765\n",
      "Epoch [244/400], Step [220/439], Loss: 0.8838\n",
      "Epoch [244/400], Step [240/439], Loss: 1.1770\n",
      "Epoch [244/400], Step [260/439], Loss: 1.1099\n",
      "Epoch [244/400], Step [280/439], Loss: 0.8915\n",
      "Epoch [244/400], Step [300/439], Loss: 0.8701\n",
      "Epoch [244/400], Step [320/439], Loss: 1.0228\n",
      "Epoch [244/400], Step [340/439], Loss: 1.2215\n",
      "Epoch [244/400], Step [360/439], Loss: 1.1192\n",
      "Epoch [244/400], Step [380/439], Loss: 0.7025\n",
      "Epoch [244/400], Step [400/439], Loss: 1.1845\n",
      "Epoch [244/400], Step [420/439], Loss: 1.2277\n",
      "\n",
      "train-loss: 1.2966, train-acc: 61.8834\n",
      "validation loss: 1.2409, validation acc: 64.5126\n",
      "\n",
      "Epoch 245\n",
      "\n",
      "Epoch [245/400], Step [0/439], Loss: 0.9480\n",
      "Epoch [245/400], Step [20/439], Loss: 0.7643\n",
      "Epoch [245/400], Step [40/439], Loss: 1.1182\n",
      "Epoch [245/400], Step [60/439], Loss: 1.0293\n",
      "Epoch [245/400], Step [80/439], Loss: 1.1159\n",
      "Epoch [245/400], Step [100/439], Loss: 0.7000\n",
      "Epoch [245/400], Step [120/439], Loss: 1.0534\n",
      "Epoch [245/400], Step [140/439], Loss: 0.8592\n",
      "Epoch [245/400], Step [160/439], Loss: 1.3163\n",
      "Epoch [245/400], Step [180/439], Loss: 1.2377\n",
      "Epoch [245/400], Step [200/439], Loss: 0.8955\n",
      "Epoch [245/400], Step [220/439], Loss: 0.9692\n",
      "Epoch [245/400], Step [240/439], Loss: 0.8751\n",
      "Epoch [245/400], Step [260/439], Loss: 0.8087\n",
      "Epoch [245/400], Step [280/439], Loss: 0.9687\n",
      "Epoch [245/400], Step [300/439], Loss: 1.2960\n",
      "Epoch [245/400], Step [320/439], Loss: 0.9892\n",
      "Epoch [245/400], Step [340/439], Loss: 1.0139\n",
      "Epoch [245/400], Step [360/439], Loss: 1.2751\n",
      "Epoch [245/400], Step [380/439], Loss: 0.7473\n",
      "Epoch [245/400], Step [400/439], Loss: 1.1187\n",
      "Epoch [245/400], Step [420/439], Loss: 1.0778\n",
      "\n",
      "train-loss: 1.2959, train-acc: 62.7958\n",
      "validation loss: 1.2403, validation acc: 63.9171\n",
      "\n",
      "Epoch 246\n",
      "\n",
      "Epoch [246/400], Step [0/439], Loss: 1.0055\n",
      "Epoch [246/400], Step [20/439], Loss: 1.1013\n",
      "Epoch [246/400], Step [40/439], Loss: 1.4360\n",
      "Epoch [246/400], Step [60/439], Loss: 0.9489\n",
      "Epoch [246/400], Step [80/439], Loss: 1.2633\n",
      "Epoch [246/400], Step [100/439], Loss: 1.3286\n",
      "Epoch [246/400], Step [120/439], Loss: 1.0268\n",
      "Epoch [246/400], Step [140/439], Loss: 1.3041\n",
      "Epoch [246/400], Step [160/439], Loss: 1.3074\n",
      "Epoch [246/400], Step [180/439], Loss: 1.2781\n",
      "Epoch [246/400], Step [200/439], Loss: 1.1869\n",
      "Epoch [246/400], Step [220/439], Loss: 0.7169\n",
      "Epoch [246/400], Step [240/439], Loss: 1.1909\n",
      "Epoch [246/400], Step [260/439], Loss: 0.9989\n",
      "Epoch [246/400], Step [280/439], Loss: 1.8151\n",
      "Epoch [246/400], Step [300/439], Loss: 0.6454\n",
      "Epoch [246/400], Step [320/439], Loss: 0.8350\n",
      "Epoch [246/400], Step [340/439], Loss: 1.3172\n",
      "Epoch [246/400], Step [360/439], Loss: 1.4244\n",
      "Epoch [246/400], Step [380/439], Loss: 1.0772\n",
      "Epoch [246/400], Step [400/439], Loss: 1.1268\n",
      "Epoch [246/400], Step [420/439], Loss: 1.1360\n",
      "\n",
      "train-loss: 1.2953, train-acc: 62.2469\n",
      "validation loss: 1.2395, validation acc: 65.7918\n",
      "\n",
      "Epoch 247\n",
      "\n",
      "Epoch [247/400], Step [0/439], Loss: 1.2385\n",
      "Epoch [247/400], Step [20/439], Loss: 1.3466\n",
      "Epoch [247/400], Step [40/439], Loss: 1.0827\n",
      "Epoch [247/400], Step [60/439], Loss: 1.0396\n",
      "Epoch [247/400], Step [80/439], Loss: 1.2711\n",
      "Epoch [247/400], Step [100/439], Loss: 0.8856\n",
      "Epoch [247/400], Step [120/439], Loss: 1.0263\n",
      "Epoch [247/400], Step [140/439], Loss: 1.0559\n",
      "Epoch [247/400], Step [160/439], Loss: 1.3076\n",
      "Epoch [247/400], Step [180/439], Loss: 1.3297\n",
      "Epoch [247/400], Step [200/439], Loss: 0.9137\n",
      "Epoch [247/400], Step [220/439], Loss: 0.7436\n",
      "Epoch [247/400], Step [240/439], Loss: 1.0089\n",
      "Epoch [247/400], Step [260/439], Loss: 1.0670\n",
      "Epoch [247/400], Step [280/439], Loss: 1.5727\n",
      "Epoch [247/400], Step [300/439], Loss: 1.1244\n",
      "Epoch [247/400], Step [320/439], Loss: 1.0805\n",
      "Epoch [247/400], Step [340/439], Loss: 1.1948\n",
      "Epoch [247/400], Step [360/439], Loss: 1.0242\n",
      "Epoch [247/400], Step [380/439], Loss: 1.2697\n",
      "Epoch [247/400], Step [400/439], Loss: 0.7011\n",
      "Epoch [247/400], Step [420/439], Loss: 1.0332\n",
      "\n",
      "train-loss: 1.2946, train-acc: 62.4251\n",
      "validation loss: 1.2392, validation acc: 62.2629\n",
      "\n",
      "Epoch 248\n",
      "\n",
      "Epoch [248/400], Step [0/439], Loss: 1.3196\n",
      "Epoch [248/400], Step [20/439], Loss: 1.3661\n",
      "Epoch [248/400], Step [40/439], Loss: 1.3679\n",
      "Epoch [248/400], Step [60/439], Loss: 0.4006\n",
      "Epoch [248/400], Step [80/439], Loss: 1.5811\n",
      "Epoch [248/400], Step [100/439], Loss: 0.9658\n",
      "Epoch [248/400], Step [120/439], Loss: 1.2379\n",
      "Epoch [248/400], Step [140/439], Loss: 1.1675\n",
      "Epoch [248/400], Step [160/439], Loss: 1.0736\n",
      "Epoch [248/400], Step [180/439], Loss: 1.2831\n",
      "Epoch [248/400], Step [200/439], Loss: 0.7882\n",
      "Epoch [248/400], Step [220/439], Loss: 1.0006\n",
      "Epoch [248/400], Step [240/439], Loss: 0.9934\n",
      "Epoch [248/400], Step [260/439], Loss: 1.1716\n",
      "Epoch [248/400], Step [280/439], Loss: 1.2071\n",
      "Epoch [248/400], Step [300/439], Loss: 1.0882\n",
      "Epoch [248/400], Step [320/439], Loss: 0.9365\n",
      "Epoch [248/400], Step [340/439], Loss: 1.3546\n",
      "Epoch [248/400], Step [360/439], Loss: 0.9596\n",
      "Epoch [248/400], Step [380/439], Loss: 0.9713\n",
      "Epoch [248/400], Step [400/439], Loss: 1.3311\n",
      "Epoch [248/400], Step [420/439], Loss: 1.3283\n",
      "\n",
      "train-loss: 1.2940, train-acc: 62.5606\n",
      "validation loss: 1.2383, validation acc: 65.9903\n",
      "\n",
      "Improvement-Detected, save-model\n",
      "Epoch 249\n",
      "\n",
      "Epoch [249/400], Step [0/439], Loss: 1.6252\n",
      "Epoch [249/400], Step [20/439], Loss: 1.2586\n",
      "Epoch [249/400], Step [40/439], Loss: 0.9744\n",
      "Epoch [249/400], Step [60/439], Loss: 0.9766\n",
      "Epoch [249/400], Step [80/439], Loss: 1.1203\n",
      "Epoch [249/400], Step [100/439], Loss: 0.7797\n",
      "Epoch [249/400], Step [120/439], Loss: 1.2058\n",
      "Epoch [249/400], Step [140/439], Loss: 1.3123\n",
      "Epoch [249/400], Step [160/439], Loss: 0.8864\n",
      "Epoch [249/400], Step [180/439], Loss: 0.7964\n",
      "Epoch [249/400], Step [200/439], Loss: 0.9566\n",
      "Epoch [249/400], Step [220/439], Loss: 1.3446\n",
      "Epoch [249/400], Step [240/439], Loss: 1.1979\n",
      "Epoch [249/400], Step [260/439], Loss: 0.6939\n",
      "Epoch [249/400], Step [280/439], Loss: 1.2136\n",
      "Epoch [249/400], Step [300/439], Loss: 1.0947\n",
      "Epoch [249/400], Step [320/439], Loss: 1.2942\n",
      "Epoch [249/400], Step [340/439], Loss: 1.0238\n",
      "Epoch [249/400], Step [360/439], Loss: 1.1338\n",
      "Epoch [249/400], Step [380/439], Loss: 1.3235\n",
      "Epoch [249/400], Step [400/439], Loss: 0.9673\n",
      "Epoch [249/400], Step [420/439], Loss: 1.2070\n",
      "\n",
      "train-loss: 1.2934, train-acc: 62.4679\n",
      "validation loss: 1.2378, validation acc: 62.1747\n",
      "\n",
      "Epoch 250\n",
      "\n",
      "Epoch [250/400], Step [0/439], Loss: 0.9781\n",
      "Epoch [250/400], Step [20/439], Loss: 1.2479\n",
      "Epoch [250/400], Step [40/439], Loss: 0.8875\n",
      "Epoch [250/400], Step [60/439], Loss: 1.0856\n",
      "Epoch [250/400], Step [80/439], Loss: 1.0445\n",
      "Epoch [250/400], Step [100/439], Loss: 1.4284\n",
      "Epoch [250/400], Step [120/439], Loss: 1.1428\n",
      "Epoch [250/400], Step [140/439], Loss: 1.0105\n",
      "Epoch [250/400], Step [160/439], Loss: 1.1050\n",
      "Epoch [250/400], Step [180/439], Loss: 0.9932\n",
      "Epoch [250/400], Step [200/439], Loss: 0.9567\n",
      "Epoch [250/400], Step [220/439], Loss: 1.3477\n",
      "Epoch [250/400], Step [240/439], Loss: 1.2509\n",
      "Epoch [250/400], Step [260/439], Loss: 1.0251\n",
      "Epoch [250/400], Step [280/439], Loss: 1.2510\n",
      "Epoch [250/400], Step [300/439], Loss: 0.8890\n",
      "Epoch [250/400], Step [320/439], Loss: 1.0930\n",
      "Epoch [250/400], Step [340/439], Loss: 1.0840\n",
      "Epoch [250/400], Step [360/439], Loss: 0.8509\n",
      "Epoch [250/400], Step [380/439], Loss: 1.4075\n",
      "Epoch [250/400], Step [400/439], Loss: 1.1842\n",
      "Epoch [250/400], Step [420/439], Loss: 0.9610\n",
      "\n",
      "train-loss: 1.2928, train-acc: 61.7907\n",
      "validation loss: 1.2376, validation acc: 61.4027\n",
      "\n",
      "Epoch 251\n",
      "\n",
      "Epoch [251/400], Step [0/439], Loss: 1.0995\n",
      "Epoch [251/400], Step [20/439], Loss: 1.3615\n",
      "Epoch [251/400], Step [40/439], Loss: 1.0974\n",
      "Epoch [251/400], Step [60/439], Loss: 1.1861\n",
      "Epoch [251/400], Step [80/439], Loss: 0.8166\n",
      "Epoch [251/400], Step [100/439], Loss: 0.6935\n",
      "Epoch [251/400], Step [120/439], Loss: 1.2272\n",
      "Epoch [251/400], Step [140/439], Loss: 0.7616\n",
      "Epoch [251/400], Step [160/439], Loss: 1.0747\n",
      "Epoch [251/400], Step [180/439], Loss: 1.0862\n",
      "Epoch [251/400], Step [200/439], Loss: 0.8128\n",
      "Epoch [251/400], Step [220/439], Loss: 0.9682\n",
      "Epoch [251/400], Step [240/439], Loss: 0.9746\n",
      "Epoch [251/400], Step [260/439], Loss: 1.2683\n",
      "Epoch [251/400], Step [280/439], Loss: 1.2411\n",
      "Epoch [251/400], Step [300/439], Loss: 1.4259\n",
      "Epoch [251/400], Step [320/439], Loss: 0.8304\n",
      "Epoch [251/400], Step [340/439], Loss: 1.2084\n",
      "Epoch [251/400], Step [360/439], Loss: 1.0546\n",
      "Epoch [251/400], Step [380/439], Loss: 1.0982\n",
      "Epoch [251/400], Step [400/439], Loss: 0.9359\n",
      "Epoch [251/400], Step [420/439], Loss: 1.4828\n",
      "\n",
      "train-loss: 1.2921, train-acc: 61.9832\n",
      "validation loss: 1.2369, validation acc: 65.0860\n",
      "\n",
      "Epoch 252\n",
      "\n",
      "Epoch [252/400], Step [0/439], Loss: 1.0305\n",
      "Epoch [252/400], Step [20/439], Loss: 1.1901\n",
      "Epoch [252/400], Step [40/439], Loss: 1.0343\n",
      "Epoch [252/400], Step [60/439], Loss: 1.1652\n",
      "Epoch [252/400], Step [80/439], Loss: 1.1260\n",
      "Epoch [252/400], Step [100/439], Loss: 1.2622\n",
      "Epoch [252/400], Step [120/439], Loss: 1.0269\n",
      "Epoch [252/400], Step [140/439], Loss: 1.1150\n",
      "Epoch [252/400], Step [160/439], Loss: 0.9484\n",
      "Epoch [252/400], Step [180/439], Loss: 1.1515\n",
      "Epoch [252/400], Step [200/439], Loss: 0.8013\n",
      "Epoch [252/400], Step [220/439], Loss: 0.8891\n",
      "Epoch [252/400], Step [240/439], Loss: 0.9337\n",
      "Epoch [252/400], Step [260/439], Loss: 1.0482\n",
      "Epoch [252/400], Step [280/439], Loss: 1.1096\n",
      "Epoch [252/400], Step [300/439], Loss: 1.0403\n",
      "Epoch [252/400], Step [320/439], Loss: 1.2018\n",
      "Epoch [252/400], Step [340/439], Loss: 0.9566\n",
      "Epoch [252/400], Step [360/439], Loss: 1.1493\n",
      "Epoch [252/400], Step [380/439], Loss: 0.9283\n",
      "Epoch [252/400], Step [400/439], Loss: 1.1556\n",
      "Epoch [252/400], Step [420/439], Loss: 1.5319\n",
      "\n",
      "train-loss: 1.2915, train-acc: 62.2184\n",
      "validation loss: 1.2363, validation acc: 62.8363\n",
      "\n",
      "Epoch 253\n",
      "\n",
      "Epoch [253/400], Step [0/439], Loss: 1.1088\n",
      "Epoch [253/400], Step [20/439], Loss: 1.0811\n",
      "Epoch [253/400], Step [40/439], Loss: 1.0756\n",
      "Epoch [253/400], Step [60/439], Loss: 1.0623\n",
      "Epoch [253/400], Step [80/439], Loss: 0.9813\n",
      "Epoch [253/400], Step [100/439], Loss: 1.2625\n",
      "Epoch [253/400], Step [120/439], Loss: 1.3157\n",
      "Epoch [253/400], Step [140/439], Loss: 0.7034\n",
      "Epoch [253/400], Step [160/439], Loss: 0.9273\n",
      "Epoch [253/400], Step [180/439], Loss: 1.2806\n",
      "Epoch [253/400], Step [200/439], Loss: 1.1502\n",
      "Epoch [253/400], Step [220/439], Loss: 1.1184\n",
      "Epoch [253/400], Step [240/439], Loss: 1.4954\n",
      "Epoch [253/400], Step [260/439], Loss: 0.8919\n",
      "Epoch [253/400], Step [280/439], Loss: 1.2995\n",
      "Epoch [253/400], Step [300/439], Loss: 1.2577\n",
      "Epoch [253/400], Step [320/439], Loss: 1.2792\n",
      "Epoch [253/400], Step [340/439], Loss: 0.8704\n",
      "Epoch [253/400], Step [360/439], Loss: 0.7384\n",
      "Epoch [253/400], Step [380/439], Loss: 1.0758\n",
      "Epoch [253/400], Step [400/439], Loss: 1.1421\n",
      "Epoch [253/400], Step [420/439], Loss: 0.9560\n",
      "\n",
      "train-loss: 1.2909, train-acc: 62.3610\n",
      "validation loss: 1.2356, validation acc: 65.5933\n",
      "\n",
      "Epoch 254\n",
      "\n",
      "Epoch [254/400], Step [0/439], Loss: 1.4529\n",
      "Epoch [254/400], Step [20/439], Loss: 0.9815\n",
      "Epoch [254/400], Step [40/439], Loss: 1.1315\n",
      "Epoch [254/400], Step [60/439], Loss: 1.3924\n",
      "Epoch [254/400], Step [80/439], Loss: 1.0057\n",
      "Epoch [254/400], Step [100/439], Loss: 1.0676\n",
      "Epoch [254/400], Step [120/439], Loss: 0.9354\n",
      "Epoch [254/400], Step [140/439], Loss: 0.9466\n",
      "Epoch [254/400], Step [160/439], Loss: 1.2324\n",
      "Epoch [254/400], Step [180/439], Loss: 0.8884\n",
      "Epoch [254/400], Step [200/439], Loss: 1.1233\n",
      "Epoch [254/400], Step [220/439], Loss: 0.8702\n",
      "Epoch [254/400], Step [240/439], Loss: 1.1945\n",
      "Epoch [254/400], Step [260/439], Loss: 0.8471\n",
      "Epoch [254/400], Step [280/439], Loss: 1.2766\n",
      "Epoch [254/400], Step [300/439], Loss: 1.0431\n",
      "Epoch [254/400], Step [320/439], Loss: 1.3895\n",
      "Epoch [254/400], Step [340/439], Loss: 0.9191\n",
      "Epoch [254/400], Step [360/439], Loss: 1.3877\n",
      "Epoch [254/400], Step [380/439], Loss: 1.0370\n",
      "Epoch [254/400], Step [400/439], Loss: 1.1568\n",
      "Epoch [254/400], Step [420/439], Loss: 1.1991\n",
      "\n",
      "train-loss: 1.2902, train-acc: 62.4822\n",
      "validation loss: 1.2349, validation acc: 65.6374\n",
      "\n",
      "Epoch 255\n",
      "\n",
      "Epoch [255/400], Step [0/439], Loss: 1.0608\n",
      "Epoch [255/400], Step [20/439], Loss: 1.3550\n",
      "Epoch [255/400], Step [40/439], Loss: 1.3437\n",
      "Epoch [255/400], Step [60/439], Loss: 0.8556\n",
      "Epoch [255/400], Step [80/439], Loss: 1.5157\n",
      "Epoch [255/400], Step [100/439], Loss: 1.4779\n",
      "Epoch [255/400], Step [120/439], Loss: 0.9834\n",
      "Epoch [255/400], Step [140/439], Loss: 1.0869\n",
      "Epoch [255/400], Step [160/439], Loss: 0.8804\n",
      "Epoch [255/400], Step [180/439], Loss: 1.0914\n",
      "Epoch [255/400], Step [200/439], Loss: 1.2249\n",
      "Epoch [255/400], Step [220/439], Loss: 1.0636\n",
      "Epoch [255/400], Step [240/439], Loss: 1.0729\n",
      "Epoch [255/400], Step [260/439], Loss: 1.3358\n",
      "Epoch [255/400], Step [280/439], Loss: 1.0970\n",
      "Epoch [255/400], Step [300/439], Loss: 0.8961\n",
      "Epoch [255/400], Step [320/439], Loss: 1.0407\n",
      "Epoch [255/400], Step [340/439], Loss: 1.3597\n",
      "Epoch [255/400], Step [360/439], Loss: 0.9112\n",
      "Epoch [255/400], Step [380/439], Loss: 1.4770\n",
      "Epoch [255/400], Step [400/439], Loss: 1.2029\n",
      "Epoch [255/400], Step [420/439], Loss: 1.1821\n",
      "\n",
      "train-loss: 1.2896, train-acc: 62.3539\n",
      "validation loss: 1.2344, validation acc: 62.7040\n",
      "\n",
      "Epoch 256\n",
      "\n",
      "Epoch [256/400], Step [0/439], Loss: 1.2114\n",
      "Epoch [256/400], Step [20/439], Loss: 0.9550\n",
      "Epoch [256/400], Step [40/439], Loss: 1.1175\n",
      "Epoch [256/400], Step [60/439], Loss: 1.0731\n",
      "Epoch [256/400], Step [80/439], Loss: 0.9434\n",
      "Epoch [256/400], Step [100/439], Loss: 1.0724\n",
      "Epoch [256/400], Step [120/439], Loss: 1.2285\n",
      "Epoch [256/400], Step [140/439], Loss: 1.0692\n",
      "Epoch [256/400], Step [160/439], Loss: 1.5762\n",
      "Epoch [256/400], Step [180/439], Loss: 0.9810\n",
      "Epoch [256/400], Step [200/439], Loss: 1.1113\n",
      "Epoch [256/400], Step [220/439], Loss: 0.9356\n",
      "Epoch [256/400], Step [240/439], Loss: 0.7117\n",
      "Epoch [256/400], Step [260/439], Loss: 1.2014\n",
      "Epoch [256/400], Step [280/439], Loss: 1.0379\n",
      "Epoch [256/400], Step [300/439], Loss: 1.0268\n",
      "Epoch [256/400], Step [320/439], Loss: 1.0862\n",
      "Epoch [256/400], Step [340/439], Loss: 1.2957\n",
      "Epoch [256/400], Step [360/439], Loss: 0.9820\n",
      "Epoch [256/400], Step [380/439], Loss: 1.1749\n",
      "Epoch [256/400], Step [400/439], Loss: 1.4467\n",
      "Epoch [256/400], Step [420/439], Loss: 0.9204\n",
      "\n",
      "train-loss: 1.2890, train-acc: 62.7246\n",
      "validation loss: 1.2338, validation acc: 63.4760\n",
      "\n",
      "Epoch 257\n",
      "\n",
      "Epoch [257/400], Step [0/439], Loss: 1.2996\n",
      "Epoch [257/400], Step [20/439], Loss: 1.1081\n",
      "Epoch [257/400], Step [40/439], Loss: 0.9380\n",
      "Epoch [257/400], Step [60/439], Loss: 0.8294\n",
      "Epoch [257/400], Step [80/439], Loss: 0.8840\n",
      "Epoch [257/400], Step [100/439], Loss: 1.2663\n",
      "Epoch [257/400], Step [120/439], Loss: 1.1299\n",
      "Epoch [257/400], Step [140/439], Loss: 0.9204\n",
      "Epoch [257/400], Step [160/439], Loss: 1.0661\n",
      "Epoch [257/400], Step [180/439], Loss: 0.8797\n",
      "Epoch [257/400], Step [200/439], Loss: 1.4931\n",
      "Epoch [257/400], Step [220/439], Loss: 0.9429\n",
      "Epoch [257/400], Step [240/439], Loss: 0.6982\n",
      "Epoch [257/400], Step [260/439], Loss: 0.9332\n",
      "Epoch [257/400], Step [280/439], Loss: 1.2215\n",
      "Epoch [257/400], Step [300/439], Loss: 0.8002\n",
      "Epoch [257/400], Step [320/439], Loss: 0.9554\n",
      "Epoch [257/400], Step [340/439], Loss: 0.9831\n",
      "Epoch [257/400], Step [360/439], Loss: 1.1553\n",
      "Epoch [257/400], Step [380/439], Loss: 1.7092\n",
      "Epoch [257/400], Step [400/439], Loss: 1.3587\n",
      "Epoch [257/400], Step [420/439], Loss: 0.9330\n",
      "\n",
      "train-loss: 1.2884, train-acc: 62.2541\n",
      "validation loss: 1.2331, validation acc: 65.7256\n",
      "\n",
      "Epoch 258\n",
      "\n",
      "Epoch [258/400], Step [0/439], Loss: 1.4447\n",
      "Epoch [258/400], Step [20/439], Loss: 0.8321\n",
      "Epoch [258/400], Step [40/439], Loss: 1.2115\n",
      "Epoch [258/400], Step [60/439], Loss: 1.2628\n",
      "Epoch [258/400], Step [80/439], Loss: 1.0531\n",
      "Epoch [258/400], Step [100/439], Loss: 1.1665\n",
      "Epoch [258/400], Step [120/439], Loss: 1.5676\n",
      "Epoch [258/400], Step [140/439], Loss: 1.4140\n",
      "Epoch [258/400], Step [160/439], Loss: 0.7687\n",
      "Epoch [258/400], Step [180/439], Loss: 1.0196\n",
      "Epoch [258/400], Step [200/439], Loss: 0.8844\n",
      "Epoch [258/400], Step [220/439], Loss: 1.1605\n",
      "Epoch [258/400], Step [240/439], Loss: 1.0754\n",
      "Epoch [258/400], Step [260/439], Loss: 1.1625\n",
      "Epoch [258/400], Step [280/439], Loss: 1.4883\n",
      "Epoch [258/400], Step [300/439], Loss: 1.3339\n",
      "Epoch [258/400], Step [320/439], Loss: 0.8095\n",
      "Epoch [258/400], Step [340/439], Loss: 1.2779\n",
      "Epoch [258/400], Step [360/439], Loss: 1.6256\n",
      "Epoch [258/400], Step [380/439], Loss: 1.0166\n",
      "Epoch [258/400], Step [400/439], Loss: 1.0465\n",
      "Epoch [258/400], Step [420/439], Loss: 0.9336\n",
      "\n",
      "train-loss: 1.2878, train-acc: 62.1899\n",
      "validation loss: 1.2325, validation acc: 63.9171\n",
      "\n",
      "Epoch 259\n",
      "\n",
      "Epoch [259/400], Step [0/439], Loss: 0.9719\n",
      "Epoch [259/400], Step [20/439], Loss: 0.9067\n",
      "Epoch [259/400], Step [40/439], Loss: 0.7808\n",
      "Epoch [259/400], Step [60/439], Loss: 1.3280\n",
      "Epoch [259/400], Step [80/439], Loss: 0.9029\n",
      "Epoch [259/400], Step [100/439], Loss: 1.1589\n",
      "Epoch [259/400], Step [120/439], Loss: 1.0578\n",
      "Epoch [259/400], Step [140/439], Loss: 0.9212\n",
      "Epoch [259/400], Step [160/439], Loss: 1.0352\n",
      "Epoch [259/400], Step [180/439], Loss: 1.1239\n",
      "Epoch [259/400], Step [200/439], Loss: 0.9210\n",
      "Epoch [259/400], Step [220/439], Loss: 1.0220\n",
      "Epoch [259/400], Step [240/439], Loss: 1.1480\n",
      "Epoch [259/400], Step [260/439], Loss: 1.0748\n",
      "Epoch [259/400], Step [280/439], Loss: 1.2563\n",
      "Epoch [259/400], Step [300/439], Loss: 1.3818\n",
      "Epoch [259/400], Step [320/439], Loss: 1.3657\n",
      "Epoch [259/400], Step [340/439], Loss: 1.0811\n",
      "Epoch [259/400], Step [360/439], Loss: 1.3946\n",
      "Epoch [259/400], Step [380/439], Loss: 1.0462\n",
      "Epoch [259/400], Step [400/439], Loss: 0.7728\n",
      "Epoch [259/400], Step [420/439], Loss: 1.6207\n",
      "\n",
      "train-loss: 1.2872, train-acc: 62.0188\n",
      "validation loss: 1.2319, validation acc: 63.2113\n",
      "\n",
      "Epoch 260\n",
      "\n",
      "Epoch [260/400], Step [0/439], Loss: 1.4279\n",
      "Epoch [260/400], Step [20/439], Loss: 1.1198\n",
      "Epoch [260/400], Step [40/439], Loss: 1.3825\n",
      "Epoch [260/400], Step [60/439], Loss: 1.2206\n",
      "Epoch [260/400], Step [80/439], Loss: 0.8725\n",
      "Epoch [260/400], Step [100/439], Loss: 1.1372\n",
      "Epoch [260/400], Step [120/439], Loss: 0.8342\n",
      "Epoch [260/400], Step [140/439], Loss: 1.0363\n",
      "Epoch [260/400], Step [160/439], Loss: 1.0215\n",
      "Epoch [260/400], Step [180/439], Loss: 1.1425\n",
      "Epoch [260/400], Step [200/439], Loss: 0.7667\n",
      "Epoch [260/400], Step [220/439], Loss: 1.0824\n",
      "Epoch [260/400], Step [240/439], Loss: 1.0182\n",
      "Epoch [260/400], Step [260/439], Loss: 0.8815\n",
      "Epoch [260/400], Step [280/439], Loss: 0.9611\n",
      "Epoch [260/400], Step [300/439], Loss: 0.9904\n",
      "Epoch [260/400], Step [320/439], Loss: 1.1244\n",
      "Epoch [260/400], Step [340/439], Loss: 1.3737\n",
      "Epoch [260/400], Step [360/439], Loss: 0.9532\n",
      "Epoch [260/400], Step [380/439], Loss: 0.8649\n",
      "Epoch [260/400], Step [400/439], Loss: 1.2051\n",
      "Epoch [260/400], Step [420/439], Loss: 1.1161\n",
      "\n",
      "train-loss: 1.2866, train-acc: 62.7032\n",
      "validation loss: 1.2314, validation acc: 63.5862\n",
      "\n",
      "Epoch 261\n",
      "\n",
      "Epoch [261/400], Step [0/439], Loss: 1.6479\n",
      "Epoch [261/400], Step [20/439], Loss: 1.2858\n",
      "Epoch [261/400], Step [40/439], Loss: 0.9592\n",
      "Epoch [261/400], Step [60/439], Loss: 1.1980\n",
      "Epoch [261/400], Step [80/439], Loss: 0.9303\n",
      "Epoch [261/400], Step [100/439], Loss: 0.8272\n",
      "Epoch [261/400], Step [120/439], Loss: 1.0842\n",
      "Epoch [261/400], Step [140/439], Loss: 1.5937\n",
      "Epoch [261/400], Step [160/439], Loss: 1.0653\n",
      "Epoch [261/400], Step [180/439], Loss: 0.5734\n",
      "Epoch [261/400], Step [200/439], Loss: 0.9927\n",
      "Epoch [261/400], Step [220/439], Loss: 1.3297\n",
      "Epoch [261/400], Step [240/439], Loss: 0.7823\n",
      "Epoch [261/400], Step [260/439], Loss: 0.7772\n",
      "Epoch [261/400], Step [280/439], Loss: 0.7978\n",
      "Epoch [261/400], Step [300/439], Loss: 0.9972\n",
      "Epoch [261/400], Step [320/439], Loss: 1.3132\n",
      "Epoch [261/400], Step [340/439], Loss: 0.8497\n",
      "Epoch [261/400], Step [360/439], Loss: 1.1921\n",
      "Epoch [261/400], Step [380/439], Loss: 1.0078\n",
      "Epoch [261/400], Step [400/439], Loss: 0.9831\n",
      "Epoch [261/400], Step [420/439], Loss: 1.0788\n",
      "\n",
      "train-loss: 1.2860, train-acc: 62.8244\n",
      "validation loss: 1.2316, validation acc: 56.8593\n",
      "\n",
      "Epoch 262\n",
      "\n",
      "Epoch [262/400], Step [0/439], Loss: 0.9901\n",
      "Epoch [262/400], Step [20/439], Loss: 0.6762\n",
      "Epoch [262/400], Step [40/439], Loss: 1.1153\n",
      "Epoch [262/400], Step [60/439], Loss: 0.8651\n",
      "Epoch [262/400], Step [80/439], Loss: 1.3404\n",
      "Epoch [262/400], Step [100/439], Loss: 1.2744\n",
      "Epoch [262/400], Step [120/439], Loss: 1.2005\n",
      "Epoch [262/400], Step [140/439], Loss: 1.1122\n",
      "Epoch [262/400], Step [160/439], Loss: 1.0911\n",
      "Epoch [262/400], Step [180/439], Loss: 1.2951\n",
      "Epoch [262/400], Step [200/439], Loss: 1.2740\n",
      "Epoch [262/400], Step [220/439], Loss: 1.2467\n",
      "Epoch [262/400], Step [240/439], Loss: 1.2456\n",
      "Epoch [262/400], Step [260/439], Loss: 0.7898\n",
      "Epoch [262/400], Step [280/439], Loss: 1.2486\n",
      "Epoch [262/400], Step [300/439], Loss: 1.2133\n",
      "Epoch [262/400], Step [320/439], Loss: 1.2279\n",
      "Epoch [262/400], Step [340/439], Loss: 1.0114\n",
      "Epoch [262/400], Step [360/439], Loss: 0.8731\n",
      "Epoch [262/400], Step [380/439], Loss: 0.9343\n",
      "Epoch [262/400], Step [400/439], Loss: 1.1518\n",
      "Epoch [262/400], Step [420/439], Loss: 1.0899\n",
      "\n",
      "train-loss: 1.2853, train-acc: 63.1380\n",
      "validation loss: 1.2309, validation acc: 66.2770\n",
      "\n",
      "Epoch 263\n",
      "\n",
      "Epoch [263/400], Step [0/439], Loss: 1.2555\n",
      "Epoch [263/400], Step [20/439], Loss: 1.4032\n",
      "Epoch [263/400], Step [40/439], Loss: 0.7604\n",
      "Epoch [263/400], Step [60/439], Loss: 1.1405\n",
      "Epoch [263/400], Step [80/439], Loss: 0.9648\n",
      "Epoch [263/400], Step [100/439], Loss: 0.9951\n",
      "Epoch [263/400], Step [120/439], Loss: 1.0817\n",
      "Epoch [263/400], Step [140/439], Loss: 1.0034\n",
      "Epoch [263/400], Step [160/439], Loss: 1.0418\n",
      "Epoch [263/400], Step [180/439], Loss: 0.9251\n",
      "Epoch [263/400], Step [200/439], Loss: 1.2591\n",
      "Epoch [263/400], Step [220/439], Loss: 1.1473\n",
      "Epoch [263/400], Step [240/439], Loss: 1.4484\n",
      "Epoch [263/400], Step [260/439], Loss: 1.2225\n",
      "Epoch [263/400], Step [280/439], Loss: 1.0491\n",
      "Epoch [263/400], Step [300/439], Loss: 1.1128\n",
      "Epoch [263/400], Step [320/439], Loss: 1.1087\n",
      "Epoch [263/400], Step [340/439], Loss: 0.9559\n",
      "Epoch [263/400], Step [360/439], Loss: 0.9221\n",
      "Epoch [263/400], Step [380/439], Loss: 0.8070\n",
      "Epoch [263/400], Step [400/439], Loss: 0.8140\n",
      "Epoch [263/400], Step [420/439], Loss: 0.8218\n",
      "\n",
      "train-loss: 1.2847, train-acc: 62.9313\n",
      "validation loss: 1.2304, validation acc: 62.5937\n",
      "\n",
      "Epoch 264\n",
      "\n",
      "Epoch [264/400], Step [0/439], Loss: 1.2563\n",
      "Epoch [264/400], Step [20/439], Loss: 1.3481\n",
      "Epoch [264/400], Step [40/439], Loss: 1.2084\n",
      "Epoch [264/400], Step [60/439], Loss: 0.6042\n",
      "Epoch [264/400], Step [80/439], Loss: 1.0980\n",
      "Epoch [264/400], Step [100/439], Loss: 1.0730\n",
      "Epoch [264/400], Step [120/439], Loss: 0.9116\n",
      "Epoch [264/400], Step [140/439], Loss: 0.8091\n",
      "Epoch [264/400], Step [160/439], Loss: 0.9344\n",
      "Epoch [264/400], Step [180/439], Loss: 1.0353\n",
      "Epoch [264/400], Step [200/439], Loss: 0.8996\n",
      "Epoch [264/400], Step [220/439], Loss: 1.0883\n",
      "Epoch [264/400], Step [240/439], Loss: 0.8260\n",
      "Epoch [264/400], Step [260/439], Loss: 0.8306\n",
      "Epoch [264/400], Step [280/439], Loss: 0.9919\n",
      "Epoch [264/400], Step [300/439], Loss: 0.9113\n",
      "Epoch [264/400], Step [320/439], Loss: 0.7908\n",
      "Epoch [264/400], Step [340/439], Loss: 1.1445\n",
      "Epoch [264/400], Step [360/439], Loss: 1.0687\n",
      "Epoch [264/400], Step [380/439], Loss: 1.2007\n",
      "Epoch [264/400], Step [400/439], Loss: 1.3452\n",
      "Epoch [264/400], Step [420/439], Loss: 0.9823\n",
      "\n",
      "train-loss: 1.2841, train-acc: 62.9883\n",
      "validation loss: 1.2299, validation acc: 63.5421\n",
      "\n",
      "Epoch 265\n",
      "\n",
      "Epoch [265/400], Step [0/439], Loss: 1.0319\n",
      "Epoch [265/400], Step [20/439], Loss: 1.0789\n",
      "Epoch [265/400], Step [40/439], Loss: 0.9452\n",
      "Epoch [265/400], Step [60/439], Loss: 1.1497\n",
      "Epoch [265/400], Step [80/439], Loss: 1.1112\n",
      "Epoch [265/400], Step [100/439], Loss: 1.0855\n",
      "Epoch [265/400], Step [120/439], Loss: 1.2353\n",
      "Epoch [265/400], Step [140/439], Loss: 1.0108\n",
      "Epoch [265/400], Step [160/439], Loss: 1.2231\n",
      "Epoch [265/400], Step [180/439], Loss: 1.1949\n",
      "Epoch [265/400], Step [200/439], Loss: 1.6053\n",
      "Epoch [265/400], Step [220/439], Loss: 0.9879\n",
      "Epoch [265/400], Step [240/439], Loss: 1.1862\n",
      "Epoch [265/400], Step [260/439], Loss: 0.9909\n",
      "Epoch [265/400], Step [280/439], Loss: 1.1294\n",
      "Epoch [265/400], Step [300/439], Loss: 1.0708\n",
      "Epoch [265/400], Step [320/439], Loss: 0.9715\n",
      "Epoch [265/400], Step [340/439], Loss: 1.0488\n",
      "Epoch [265/400], Step [360/439], Loss: 0.9157\n",
      "Epoch [265/400], Step [380/439], Loss: 1.0339\n",
      "Epoch [265/400], Step [400/439], Loss: 1.1921\n",
      "Epoch [265/400], Step [420/439], Loss: 0.9440\n",
      "\n",
      "train-loss: 1.2834, train-acc: 63.0453\n",
      "validation loss: 1.2293, validation acc: 64.1817\n",
      "\n",
      "Epoch 266\n",
      "\n",
      "Epoch [266/400], Step [0/439], Loss: 0.8601\n",
      "Epoch [266/400], Step [20/439], Loss: 1.0041\n",
      "Epoch [266/400], Step [40/439], Loss: 1.1584\n",
      "Epoch [266/400], Step [60/439], Loss: 1.1882\n",
      "Epoch [266/400], Step [80/439], Loss: 0.7417\n",
      "Epoch [266/400], Step [100/439], Loss: 1.1871\n",
      "Epoch [266/400], Step [120/439], Loss: 0.9077\n",
      "Epoch [266/400], Step [140/439], Loss: 0.8204\n",
      "Epoch [266/400], Step [160/439], Loss: 0.8402\n",
      "Epoch [266/400], Step [180/439], Loss: 1.0108\n",
      "Epoch [266/400], Step [200/439], Loss: 1.0992\n",
      "Epoch [266/400], Step [220/439], Loss: 1.0090\n",
      "Epoch [266/400], Step [240/439], Loss: 0.9609\n",
      "Epoch [266/400], Step [260/439], Loss: 1.0785\n",
      "Epoch [266/400], Step [280/439], Loss: 1.1365\n",
      "Epoch [266/400], Step [300/439], Loss: 0.8740\n",
      "Epoch [266/400], Step [320/439], Loss: 1.2840\n",
      "Epoch [266/400], Step [340/439], Loss: 1.3141\n",
      "Epoch [266/400], Step [360/439], Loss: 1.3415\n",
      "Epoch [266/400], Step [380/439], Loss: 1.2177\n",
      "Epoch [266/400], Step [400/439], Loss: 1.0861\n",
      "Epoch [266/400], Step [420/439], Loss: 0.8480\n",
      "\n",
      "train-loss: 1.2828, train-acc: 62.3396\n",
      "validation loss: 1.2292, validation acc: 58.6678\n",
      "\n",
      "Epoch 267\n",
      "\n",
      "Epoch [267/400], Step [0/439], Loss: 0.9412\n",
      "Epoch [267/400], Step [20/439], Loss: 1.0270\n",
      "Epoch [267/400], Step [40/439], Loss: 1.1870\n",
      "Epoch [267/400], Step [60/439], Loss: 1.2364\n",
      "Epoch [267/400], Step [80/439], Loss: 0.9907\n",
      "Epoch [267/400], Step [100/439], Loss: 0.9038\n",
      "Epoch [267/400], Step [120/439], Loss: 1.2134\n",
      "Epoch [267/400], Step [140/439], Loss: 1.2116\n",
      "Epoch [267/400], Step [160/439], Loss: 1.1447\n",
      "Epoch [267/400], Step [180/439], Loss: 1.0818\n",
      "Epoch [267/400], Step [200/439], Loss: 1.0515\n",
      "Epoch [267/400], Step [220/439], Loss: 0.8345\n",
      "Epoch [267/400], Step [240/439], Loss: 1.4419\n",
      "Epoch [267/400], Step [260/439], Loss: 0.9649\n",
      "Epoch [267/400], Step [280/439], Loss: 1.0169\n",
      "Epoch [267/400], Step [300/439], Loss: 1.0560\n",
      "Epoch [267/400], Step [320/439], Loss: 1.2097\n",
      "Epoch [267/400], Step [340/439], Loss: 1.0657\n",
      "Epoch [267/400], Step [360/439], Loss: 0.6886\n",
      "Epoch [267/400], Step [380/439], Loss: 1.5516\n",
      "Epoch [267/400], Step [400/439], Loss: 1.1204\n",
      "Epoch [267/400], Step [420/439], Loss: 1.1722\n",
      "\n",
      "train-loss: 1.2822, train-acc: 63.0453\n",
      "validation loss: 1.2286, validation acc: 64.7993\n",
      "\n",
      "Epoch 268\n",
      "\n",
      "Epoch [268/400], Step [0/439], Loss: 1.2089\n",
      "Epoch [268/400], Step [20/439], Loss: 1.0606\n",
      "Epoch [268/400], Step [40/439], Loss: 1.0512\n",
      "Epoch [268/400], Step [60/439], Loss: 0.9141\n",
      "Epoch [268/400], Step [80/439], Loss: 1.3564\n",
      "Epoch [268/400], Step [100/439], Loss: 1.0294\n",
      "Epoch [268/400], Step [120/439], Loss: 1.2942\n",
      "Epoch [268/400], Step [140/439], Loss: 1.0569\n",
      "Epoch [268/400], Step [160/439], Loss: 0.8339\n",
      "Epoch [268/400], Step [180/439], Loss: 1.0368\n",
      "Epoch [268/400], Step [200/439], Loss: 1.1375\n",
      "Epoch [268/400], Step [220/439], Loss: 0.7074\n",
      "Epoch [268/400], Step [240/439], Loss: 0.9904\n",
      "Epoch [268/400], Step [260/439], Loss: 1.2407\n",
      "Epoch [268/400], Step [280/439], Loss: 1.5805\n",
      "Epoch [268/400], Step [300/439], Loss: 1.1156\n",
      "Epoch [268/400], Step [320/439], Loss: 1.6538\n",
      "Epoch [268/400], Step [340/439], Loss: 1.2283\n",
      "Epoch [268/400], Step [360/439], Loss: 0.9688\n",
      "Epoch [268/400], Step [380/439], Loss: 0.7476\n",
      "Epoch [268/400], Step [400/439], Loss: 1.2621\n",
      "Epoch [268/400], Step [420/439], Loss: 1.1084\n",
      "\n",
      "train-loss: 1.2816, train-acc: 62.1899\n",
      "validation loss: 1.2287, validation acc: 57.5871\n",
      "\n",
      "Epoch 269\n",
      "\n",
      "Epoch [269/400], Step [0/439], Loss: 0.9975\n",
      "Epoch [269/400], Step [20/439], Loss: 0.7249\n",
      "Epoch [269/400], Step [40/439], Loss: 0.9209\n",
      "Epoch [269/400], Step [60/439], Loss: 1.5402\n",
      "Epoch [269/400], Step [80/439], Loss: 0.8780\n",
      "Epoch [269/400], Step [100/439], Loss: 0.8470\n",
      "Epoch [269/400], Step [120/439], Loss: 1.2606\n",
      "Epoch [269/400], Step [140/439], Loss: 1.2769\n",
      "Epoch [269/400], Step [160/439], Loss: 1.0820\n",
      "Epoch [269/400], Step [180/439], Loss: 1.0601\n",
      "Epoch [269/400], Step [200/439], Loss: 1.3713\n",
      "Epoch [269/400], Step [220/439], Loss: 1.3004\n",
      "Epoch [269/400], Step [240/439], Loss: 1.0068\n",
      "Epoch [269/400], Step [260/439], Loss: 1.2299\n",
      "Epoch [269/400], Step [280/439], Loss: 1.3455\n",
      "Epoch [269/400], Step [300/439], Loss: 0.9032\n",
      "Epoch [269/400], Step [320/439], Loss: 1.2381\n",
      "Epoch [269/400], Step [340/439], Loss: 1.0436\n",
      "Epoch [269/400], Step [360/439], Loss: 0.9278\n",
      "Epoch [269/400], Step [380/439], Loss: 0.8284\n",
      "Epoch [269/400], Step [400/439], Loss: 1.5370\n",
      "Epoch [269/400], Step [420/439], Loss: 1.0738\n",
      "\n",
      "train-loss: 1.2810, train-acc: 63.0168\n",
      "validation loss: 1.2284, validation acc: 61.8880\n",
      "\n",
      "Epoch 270\n",
      "\n",
      "Epoch [270/400], Step [0/439], Loss: 1.1359\n",
      "Epoch [270/400], Step [20/439], Loss: 1.1358\n",
      "Epoch [270/400], Step [40/439], Loss: 0.9044\n",
      "Epoch [270/400], Step [60/439], Loss: 0.8898\n",
      "Epoch [270/400], Step [80/439], Loss: 0.8917\n",
      "Epoch [270/400], Step [100/439], Loss: 0.7993\n",
      "Epoch [270/400], Step [120/439], Loss: 1.1203\n",
      "Epoch [270/400], Step [140/439], Loss: 0.9743\n",
      "Epoch [270/400], Step [160/439], Loss: 0.9775\n",
      "Epoch [270/400], Step [180/439], Loss: 0.9105\n",
      "Epoch [270/400], Step [200/439], Loss: 0.9573\n",
      "Epoch [270/400], Step [220/439], Loss: 1.2065\n",
      "Epoch [270/400], Step [240/439], Loss: 0.8612\n",
      "Epoch [270/400], Step [260/439], Loss: 0.9913\n",
      "Epoch [270/400], Step [280/439], Loss: 0.9223\n",
      "Epoch [270/400], Step [300/439], Loss: 1.1741\n",
      "Epoch [270/400], Step [320/439], Loss: 1.1214\n",
      "Epoch [270/400], Step [340/439], Loss: 1.2057\n",
      "Epoch [270/400], Step [360/439], Loss: 0.9603\n",
      "Epoch [270/400], Step [380/439], Loss: 0.9454\n",
      "Epoch [270/400], Step [400/439], Loss: 0.9817\n",
      "Epoch [270/400], Step [420/439], Loss: 0.8165\n",
      "\n",
      "train-loss: 1.2804, train-acc: 62.2683\n",
      "validation loss: 1.2279, validation acc: 64.5126\n",
      "\n",
      "Epoch 271\n",
      "\n",
      "Epoch [271/400], Step [0/439], Loss: 1.1622\n",
      "Epoch [271/400], Step [20/439], Loss: 0.7312\n",
      "Epoch [271/400], Step [40/439], Loss: 1.0671\n",
      "Epoch [271/400], Step [60/439], Loss: 1.5779\n",
      "Epoch [271/400], Step [80/439], Loss: 0.6991\n",
      "Epoch [271/400], Step [100/439], Loss: 1.4536\n",
      "Epoch [271/400], Step [120/439], Loss: 1.2200\n",
      "Epoch [271/400], Step [140/439], Loss: 1.2451\n",
      "Epoch [271/400], Step [160/439], Loss: 0.6759\n",
      "Epoch [271/400], Step [180/439], Loss: 1.1264\n",
      "Epoch [271/400], Step [200/439], Loss: 0.8235\n",
      "Epoch [271/400], Step [220/439], Loss: 1.3631\n",
      "Epoch [271/400], Step [240/439], Loss: 0.7463\n",
      "Epoch [271/400], Step [260/439], Loss: 0.9660\n",
      "Epoch [271/400], Step [280/439], Loss: 1.0540\n",
      "Epoch [271/400], Step [300/439], Loss: 0.9670\n",
      "Epoch [271/400], Step [320/439], Loss: 0.9603\n",
      "Epoch [271/400], Step [340/439], Loss: 1.2959\n",
      "Epoch [271/400], Step [360/439], Loss: 1.0766\n",
      "Epoch [271/400], Step [380/439], Loss: 0.9913\n",
      "Epoch [271/400], Step [400/439], Loss: 1.3340\n",
      "Epoch [271/400], Step [420/439], Loss: 1.1328\n",
      "\n",
      "train-loss: 1.2798, train-acc: 62.5250\n",
      "validation loss: 1.2272, validation acc: 65.3286\n",
      "\n",
      "Epoch 272\n",
      "\n",
      "Epoch [272/400], Step [0/439], Loss: 1.1639\n",
      "Epoch [272/400], Step [20/439], Loss: 1.1802\n",
      "Epoch [272/400], Step [40/439], Loss: 1.4017\n",
      "Epoch [272/400], Step [60/439], Loss: 0.7249\n",
      "Epoch [272/400], Step [80/439], Loss: 1.2194\n",
      "Epoch [272/400], Step [100/439], Loss: 1.0801\n",
      "Epoch [272/400], Step [120/439], Loss: 0.9935\n",
      "Epoch [272/400], Step [140/439], Loss: 0.9660\n",
      "Epoch [272/400], Step [160/439], Loss: 0.9550\n",
      "Epoch [272/400], Step [180/439], Loss: 1.0564\n",
      "Epoch [272/400], Step [200/439], Loss: 0.9802\n",
      "Epoch [272/400], Step [220/439], Loss: 0.7995\n",
      "Epoch [272/400], Step [240/439], Loss: 1.0895\n",
      "Epoch [272/400], Step [260/439], Loss: 1.1814\n",
      "Epoch [272/400], Step [280/439], Loss: 1.1808\n",
      "Epoch [272/400], Step [300/439], Loss: 1.0284\n",
      "Epoch [272/400], Step [320/439], Loss: 0.9412\n",
      "Epoch [272/400], Step [340/439], Loss: 1.1160\n",
      "Epoch [272/400], Step [360/439], Loss: 1.2191\n",
      "Epoch [272/400], Step [380/439], Loss: 0.9140\n",
      "Epoch [272/400], Step [400/439], Loss: 1.1518\n",
      "Epoch [272/400], Step [420/439], Loss: 0.9525\n",
      "\n",
      "train-loss: 1.2793, train-acc: 62.5178\n",
      "validation loss: 1.2267, validation acc: 63.9612\n",
      "\n",
      "Epoch 273\n",
      "\n",
      "Epoch [273/400], Step [0/439], Loss: 1.1491\n",
      "Epoch [273/400], Step [20/439], Loss: 1.2114\n",
      "Epoch [273/400], Step [40/439], Loss: 0.9254\n",
      "Epoch [273/400], Step [60/439], Loss: 1.0358\n",
      "Epoch [273/400], Step [80/439], Loss: 1.6472\n",
      "Epoch [273/400], Step [100/439], Loss: 1.2332\n",
      "Epoch [273/400], Step [120/439], Loss: 1.4220\n",
      "Epoch [273/400], Step [140/439], Loss: 1.1392\n",
      "Epoch [273/400], Step [160/439], Loss: 1.0997\n",
      "Epoch [273/400], Step [180/439], Loss: 0.8492\n",
      "Epoch [273/400], Step [200/439], Loss: 1.0719\n",
      "Epoch [273/400], Step [220/439], Loss: 0.8479\n",
      "Epoch [273/400], Step [240/439], Loss: 1.3532\n",
      "Epoch [273/400], Step [260/439], Loss: 1.3689\n",
      "Epoch [273/400], Step [280/439], Loss: 1.0828\n",
      "Epoch [273/400], Step [300/439], Loss: 0.9210\n",
      "Epoch [273/400], Step [320/439], Loss: 0.9803\n",
      "Epoch [273/400], Step [340/439], Loss: 0.9152\n",
      "Epoch [273/400], Step [360/439], Loss: 0.7834\n",
      "Epoch [273/400], Step [380/439], Loss: 0.9770\n",
      "Epoch [273/400], Step [400/439], Loss: 0.8723\n",
      "Epoch [273/400], Step [420/439], Loss: 0.9691\n",
      "\n",
      "train-loss: 1.2787, train-acc: 62.7673\n",
      "validation loss: 1.2262, validation acc: 64.0494\n",
      "\n",
      "Epoch 274\n",
      "\n",
      "Epoch [274/400], Step [0/439], Loss: 1.0135\n",
      "Epoch [274/400], Step [20/439], Loss: 1.3714\n",
      "Epoch [274/400], Step [40/439], Loss: 1.4241\n",
      "Epoch [274/400], Step [60/439], Loss: 1.0595\n",
      "Epoch [274/400], Step [80/439], Loss: 1.0837\n",
      "Epoch [274/400], Step [100/439], Loss: 1.4090\n",
      "Epoch [274/400], Step [120/439], Loss: 1.4373\n",
      "Epoch [274/400], Step [140/439], Loss: 1.1575\n",
      "Epoch [274/400], Step [160/439], Loss: 0.9535\n",
      "Epoch [274/400], Step [180/439], Loss: 0.9571\n",
      "Epoch [274/400], Step [200/439], Loss: 1.4966\n",
      "Epoch [274/400], Step [220/439], Loss: 0.8735\n",
      "Epoch [274/400], Step [240/439], Loss: 1.2955\n",
      "Epoch [274/400], Step [260/439], Loss: 0.7116\n",
      "Epoch [274/400], Step [280/439], Loss: 0.9026\n",
      "Epoch [274/400], Step [300/439], Loss: 1.0855\n",
      "Epoch [274/400], Step [320/439], Loss: 1.1493\n",
      "Epoch [274/400], Step [340/439], Loss: 1.1656\n",
      "Epoch [274/400], Step [360/439], Loss: 1.3543\n",
      "Epoch [274/400], Step [380/439], Loss: 1.0818\n",
      "Epoch [274/400], Step [400/439], Loss: 0.7755\n",
      "Epoch [274/400], Step [420/439], Loss: 1.0719\n",
      "\n",
      "train-loss: 1.2781, train-acc: 62.8315\n",
      "validation loss: 1.2259, validation acc: 62.0644\n",
      "\n",
      "Epoch 275\n",
      "\n",
      "Epoch [275/400], Step [0/439], Loss: 1.0931\n",
      "Epoch [275/400], Step [20/439], Loss: 1.0156\n",
      "Epoch [275/400], Step [40/439], Loss: 1.1379\n",
      "Epoch [275/400], Step [60/439], Loss: 1.4063\n",
      "Epoch [275/400], Step [80/439], Loss: 0.9295\n",
      "Epoch [275/400], Step [100/439], Loss: 1.0233\n",
      "Epoch [275/400], Step [120/439], Loss: 1.1020\n",
      "Epoch [275/400], Step [140/439], Loss: 1.0590\n",
      "Epoch [275/400], Step [160/439], Loss: 1.1733\n",
      "Epoch [275/400], Step [180/439], Loss: 1.2088\n",
      "Epoch [275/400], Step [200/439], Loss: 1.5490\n",
      "Epoch [275/400], Step [220/439], Loss: 1.1027\n",
      "Epoch [275/400], Step [240/439], Loss: 1.3422\n",
      "Epoch [275/400], Step [260/439], Loss: 1.0141\n",
      "Epoch [275/400], Step [280/439], Loss: 0.9718\n",
      "Epoch [275/400], Step [300/439], Loss: 1.0942\n",
      "Epoch [275/400], Step [320/439], Loss: 1.2388\n",
      "Epoch [275/400], Step [340/439], Loss: 1.1902\n",
      "Epoch [275/400], Step [360/439], Loss: 1.1716\n",
      "Epoch [275/400], Step [380/439], Loss: 1.3364\n",
      "Epoch [275/400], Step [400/439], Loss: 1.1958\n",
      "Epoch [275/400], Step [420/439], Loss: 0.9797\n",
      "\n",
      "train-loss: 1.2776, train-acc: 61.8335\n",
      "validation loss: 1.2253, validation acc: 63.6083\n",
      "\n",
      "Epoch 276\n",
      "\n",
      "Epoch [276/400], Step [0/439], Loss: 1.2045\n",
      "Epoch [276/400], Step [20/439], Loss: 1.0928\n",
      "Epoch [276/400], Step [40/439], Loss: 1.1934\n",
      "Epoch [276/400], Step [60/439], Loss: 1.0505\n",
      "Epoch [276/400], Step [80/439], Loss: 1.1043\n",
      "Epoch [276/400], Step [100/439], Loss: 1.1505\n",
      "Epoch [276/400], Step [120/439], Loss: 1.1721\n",
      "Epoch [276/400], Step [140/439], Loss: 1.2484\n",
      "Epoch [276/400], Step [160/439], Loss: 1.2606\n",
      "Epoch [276/400], Step [180/439], Loss: 1.2517\n",
      "Epoch [276/400], Step [200/439], Loss: 1.0766\n",
      "Epoch [276/400], Step [220/439], Loss: 1.3000\n",
      "Epoch [276/400], Step [240/439], Loss: 1.3068\n",
      "Epoch [276/400], Step [260/439], Loss: 0.9017\n",
      "Epoch [276/400], Step [280/439], Loss: 1.3756\n",
      "Epoch [276/400], Step [300/439], Loss: 1.2096\n",
      "Epoch [276/400], Step [320/439], Loss: 1.2964\n",
      "Epoch [276/400], Step [340/439], Loss: 1.2276\n",
      "Epoch [276/400], Step [360/439], Loss: 1.0559\n",
      "Epoch [276/400], Step [380/439], Loss: 1.4075\n",
      "Epoch [276/400], Step [400/439], Loss: 1.3586\n",
      "Epoch [276/400], Step [420/439], Loss: 0.9797\n",
      "\n",
      "train-loss: 1.2771, train-acc: 61.7551\n",
      "validation loss: 1.2248, validation acc: 63.2775\n",
      "\n",
      "Epoch 277\n",
      "\n",
      "Epoch [277/400], Step [0/439], Loss: 1.2145\n",
      "Epoch [277/400], Step [20/439], Loss: 0.8405\n",
      "Epoch [277/400], Step [40/439], Loss: 0.9824\n",
      "Epoch [277/400], Step [60/439], Loss: 0.6902\n",
      "Epoch [277/400], Step [80/439], Loss: 0.7377\n",
      "Epoch [277/400], Step [100/439], Loss: 1.1604\n",
      "Epoch [277/400], Step [120/439], Loss: 1.2547\n",
      "Epoch [277/400], Step [140/439], Loss: 1.4412\n",
      "Epoch [277/400], Step [160/439], Loss: 1.0319\n",
      "Epoch [277/400], Step [180/439], Loss: 1.0224\n",
      "Epoch [277/400], Step [200/439], Loss: 0.7891\n",
      "Epoch [277/400], Step [220/439], Loss: 1.0549\n",
      "Epoch [277/400], Step [240/439], Loss: 1.2208\n",
      "Epoch [277/400], Step [260/439], Loss: 1.2667\n",
      "Epoch [277/400], Step [280/439], Loss: 0.9169\n",
      "Epoch [277/400], Step [300/439], Loss: 0.7953\n",
      "Epoch [277/400], Step [320/439], Loss: 1.0311\n",
      "Epoch [277/400], Step [340/439], Loss: 0.9235\n",
      "Epoch [277/400], Step [360/439], Loss: 1.0345\n",
      "Epoch [277/400], Step [380/439], Loss: 1.5070\n",
      "Epoch [277/400], Step [400/439], Loss: 0.9708\n",
      "Epoch [277/400], Step [420/439], Loss: 1.3376\n",
      "\n",
      "train-loss: 1.2765, train-acc: 63.5443\n",
      "validation loss: 1.2243, validation acc: 64.0053\n",
      "\n",
      "Epoch 278\n",
      "\n",
      "Epoch [278/400], Step [0/439], Loss: 1.2437\n",
      "Epoch [278/400], Step [20/439], Loss: 0.9388\n",
      "Epoch [278/400], Step [40/439], Loss: 1.3218\n",
      "Epoch [278/400], Step [60/439], Loss: 0.7762\n",
      "Epoch [278/400], Step [80/439], Loss: 0.6834\n",
      "Epoch [278/400], Step [100/439], Loss: 1.1537\n",
      "Epoch [278/400], Step [120/439], Loss: 1.2620\n",
      "Epoch [278/400], Step [140/439], Loss: 0.9960\n",
      "Epoch [278/400], Step [160/439], Loss: 1.1278\n",
      "Epoch [278/400], Step [180/439], Loss: 1.5189\n",
      "Epoch [278/400], Step [200/439], Loss: 0.9953\n",
      "Epoch [278/400], Step [220/439], Loss: 1.0811\n",
      "Epoch [278/400], Step [240/439], Loss: 1.1762\n",
      "Epoch [278/400], Step [260/439], Loss: 1.0032\n",
      "Epoch [278/400], Step [280/439], Loss: 1.6960\n",
      "Epoch [278/400], Step [300/439], Loss: 0.9454\n",
      "Epoch [278/400], Step [320/439], Loss: 1.1090\n",
      "Epoch [278/400], Step [340/439], Loss: 1.2116\n",
      "Epoch [278/400], Step [360/439], Loss: 0.8885\n",
      "Epoch [278/400], Step [380/439], Loss: 1.2658\n",
      "Epoch [278/400], Step [400/439], Loss: 0.9243\n",
      "Epoch [278/400], Step [420/439], Loss: 1.1536\n",
      "\n",
      "train-loss: 1.2759, train-acc: 62.4608\n",
      "validation loss: 1.2237, validation acc: 65.5271\n",
      "\n",
      "Epoch 279\n",
      "\n",
      "Epoch [279/400], Step [0/439], Loss: 1.2931\n",
      "Epoch [279/400], Step [20/439], Loss: 1.3968\n",
      "Epoch [279/400], Step [40/439], Loss: 1.0083\n",
      "Epoch [279/400], Step [60/439], Loss: 0.7996\n",
      "Epoch [279/400], Step [80/439], Loss: 0.9609\n",
      "Epoch [279/400], Step [100/439], Loss: 1.0147\n",
      "Epoch [279/400], Step [120/439], Loss: 0.8381\n",
      "Epoch [279/400], Step [140/439], Loss: 1.0658\n",
      "Epoch [279/400], Step [160/439], Loss: 1.0281\n",
      "Epoch [279/400], Step [180/439], Loss: 1.0670\n",
      "Epoch [279/400], Step [200/439], Loss: 1.1181\n",
      "Epoch [279/400], Step [220/439], Loss: 1.0602\n",
      "Epoch [279/400], Step [240/439], Loss: 1.3078\n",
      "Epoch [279/400], Step [260/439], Loss: 0.8565\n",
      "Epoch [279/400], Step [280/439], Loss: 0.9402\n",
      "Epoch [279/400], Step [300/439], Loss: 1.2029\n",
      "Epoch [279/400], Step [320/439], Loss: 1.3274\n",
      "Epoch [279/400], Step [340/439], Loss: 1.1629\n",
      "Epoch [279/400], Step [360/439], Loss: 0.8894\n",
      "Epoch [279/400], Step [380/439], Loss: 1.3090\n",
      "Epoch [279/400], Step [400/439], Loss: 1.3789\n",
      "Epoch [279/400], Step [420/439], Loss: 0.7853\n",
      "\n",
      "train-loss: 1.2754, train-acc: 63.3162\n",
      "validation loss: 1.2231, validation acc: 64.8655\n",
      "\n",
      "Epoch 280\n",
      "\n",
      "Epoch [280/400], Step [0/439], Loss: 0.9789\n",
      "Epoch [280/400], Step [20/439], Loss: 0.7988\n",
      "Epoch [280/400], Step [40/439], Loss: 0.6881\n",
      "Epoch [280/400], Step [60/439], Loss: 1.0686\n",
      "Epoch [280/400], Step [80/439], Loss: 1.4597\n",
      "Epoch [280/400], Step [100/439], Loss: 1.1994\n",
      "Epoch [280/400], Step [120/439], Loss: 0.9215\n",
      "Epoch [280/400], Step [140/439], Loss: 1.0306\n",
      "Epoch [280/400], Step [160/439], Loss: 1.2053\n",
      "Epoch [280/400], Step [180/439], Loss: 0.6746\n",
      "Epoch [280/400], Step [200/439], Loss: 0.7458\n",
      "Epoch [280/400], Step [220/439], Loss: 1.0847\n",
      "Epoch [280/400], Step [240/439], Loss: 1.1464\n",
      "Epoch [280/400], Step [260/439], Loss: 1.4123\n",
      "Epoch [280/400], Step [280/439], Loss: 1.4554\n",
      "Epoch [280/400], Step [300/439], Loss: 1.1093\n",
      "Epoch [280/400], Step [320/439], Loss: 1.0097\n",
      "Epoch [280/400], Step [340/439], Loss: 0.7737\n",
      "Epoch [280/400], Step [360/439], Loss: 1.3125\n",
      "Epoch [280/400], Step [380/439], Loss: 0.7509\n",
      "Epoch [280/400], Step [400/439], Loss: 1.2783\n",
      "Epoch [280/400], Step [420/439], Loss: 0.7988\n",
      "\n",
      "train-loss: 1.2748, train-acc: 63.2022\n",
      "validation loss: 1.2227, validation acc: 62.5055\n",
      "\n",
      "Epoch 281\n",
      "\n",
      "Epoch [281/400], Step [0/439], Loss: 1.1307\n",
      "Epoch [281/400], Step [20/439], Loss: 1.4189\n",
      "Epoch [281/400], Step [40/439], Loss: 0.9558\n",
      "Epoch [281/400], Step [60/439], Loss: 0.9694\n",
      "Epoch [281/400], Step [80/439], Loss: 1.1056\n",
      "Epoch [281/400], Step [100/439], Loss: 0.8086\n",
      "Epoch [281/400], Step [120/439], Loss: 0.9319\n",
      "Epoch [281/400], Step [140/439], Loss: 1.1373\n",
      "Epoch [281/400], Step [160/439], Loss: 0.9012\n",
      "Epoch [281/400], Step [180/439], Loss: 1.3303\n",
      "Epoch [281/400], Step [200/439], Loss: 1.1146\n",
      "Epoch [281/400], Step [220/439], Loss: 1.1518\n",
      "Epoch [281/400], Step [240/439], Loss: 0.8491\n",
      "Epoch [281/400], Step [260/439], Loss: 0.8268\n",
      "Epoch [281/400], Step [280/439], Loss: 1.0355\n",
      "Epoch [281/400], Step [300/439], Loss: 1.4666\n",
      "Epoch [281/400], Step [320/439], Loss: 0.9911\n",
      "Epoch [281/400], Step [340/439], Loss: 1.2767\n",
      "Epoch [281/400], Step [360/439], Loss: 0.8301\n",
      "Epoch [281/400], Step [380/439], Loss: 1.2852\n",
      "Epoch [281/400], Step [400/439], Loss: 1.2517\n",
      "Epoch [281/400], Step [420/439], Loss: 1.2510\n",
      "\n",
      "train-loss: 1.2742, train-acc: 62.9099\n",
      "validation loss: 1.2229, validation acc: 56.6167\n",
      "\n",
      "Epoch 282\n",
      "\n",
      "Epoch [282/400], Step [0/439], Loss: 0.9252\n",
      "Epoch [282/400], Step [20/439], Loss: 0.8354\n",
      "Epoch [282/400], Step [40/439], Loss: 0.9569\n",
      "Epoch [282/400], Step [60/439], Loss: 0.9475\n",
      "Epoch [282/400], Step [80/439], Loss: 0.7765\n",
      "Epoch [282/400], Step [100/439], Loss: 0.8130\n",
      "Epoch [282/400], Step [120/439], Loss: 0.8766\n",
      "Epoch [282/400], Step [140/439], Loss: 1.4522\n",
      "Epoch [282/400], Step [160/439], Loss: 0.8594\n",
      "Epoch [282/400], Step [180/439], Loss: 1.1760\n",
      "Epoch [282/400], Step [200/439], Loss: 1.1677\n",
      "Epoch [282/400], Step [220/439], Loss: 0.9874\n",
      "Epoch [282/400], Step [240/439], Loss: 1.1230\n",
      "Epoch [282/400], Step [260/439], Loss: 1.1952\n",
      "Epoch [282/400], Step [280/439], Loss: 1.1482\n",
      "Epoch [282/400], Step [300/439], Loss: 1.1800\n",
      "Epoch [282/400], Step [320/439], Loss: 1.2244\n",
      "Epoch [282/400], Step [340/439], Loss: 1.0879\n",
      "Epoch [282/400], Step [360/439], Loss: 1.3329\n",
      "Epoch [282/400], Step [380/439], Loss: 1.2598\n",
      "Epoch [282/400], Step [400/439], Loss: 1.0149\n",
      "Epoch [282/400], Step [420/439], Loss: 0.7342\n",
      "\n",
      "train-loss: 1.2736, train-acc: 63.0097\n",
      "validation loss: 1.2223, validation acc: 65.1963\n",
      "\n",
      "Epoch 283\n",
      "\n",
      "Epoch [283/400], Step [0/439], Loss: 0.7651\n",
      "Epoch [283/400], Step [20/439], Loss: 1.1829\n",
      "Epoch [283/400], Step [40/439], Loss: 1.1206\n",
      "Epoch [283/400], Step [60/439], Loss: 1.0971\n",
      "Epoch [283/400], Step [80/439], Loss: 0.9283\n",
      "Epoch [283/400], Step [100/439], Loss: 1.0291\n",
      "Epoch [283/400], Step [120/439], Loss: 0.9688\n",
      "Epoch [283/400], Step [140/439], Loss: 1.1746\n",
      "Epoch [283/400], Step [160/439], Loss: 1.2487\n",
      "Epoch [283/400], Step [180/439], Loss: 0.7067\n",
      "Epoch [283/400], Step [200/439], Loss: 0.9536\n",
      "Epoch [283/400], Step [220/439], Loss: 0.7326\n",
      "Epoch [283/400], Step [240/439], Loss: 1.1222\n",
      "Epoch [283/400], Step [260/439], Loss: 1.3803\n",
      "Epoch [283/400], Step [280/439], Loss: 1.3541\n",
      "Epoch [283/400], Step [300/439], Loss: 1.1469\n",
      "Epoch [283/400], Step [320/439], Loss: 0.8121\n",
      "Epoch [283/400], Step [340/439], Loss: 1.3848\n",
      "Epoch [283/400], Step [360/439], Loss: 1.0330\n",
      "Epoch [283/400], Step [380/439], Loss: 0.9251\n",
      "Epoch [283/400], Step [400/439], Loss: 1.2574\n",
      "Epoch [283/400], Step [420/439], Loss: 0.9458\n",
      "\n",
      "train-loss: 1.2731, train-acc: 63.1594\n",
      "validation loss: 1.2220, validation acc: 62.0865\n",
      "\n",
      "Epoch 284\n",
      "\n",
      "Epoch [284/400], Step [0/439], Loss: 1.0185\n",
      "Epoch [284/400], Step [20/439], Loss: 0.9535\n",
      "Epoch [284/400], Step [40/439], Loss: 1.0575\n",
      "Epoch [284/400], Step [60/439], Loss: 1.2560\n",
      "Epoch [284/400], Step [80/439], Loss: 1.4220\n",
      "Epoch [284/400], Step [100/439], Loss: 1.1323\n",
      "Epoch [284/400], Step [120/439], Loss: 1.1455\n",
      "Epoch [284/400], Step [140/439], Loss: 1.0853\n",
      "Epoch [284/400], Step [160/439], Loss: 1.2345\n",
      "Epoch [284/400], Step [180/439], Loss: 1.2466\n",
      "Epoch [284/400], Step [200/439], Loss: 1.2565\n",
      "Epoch [284/400], Step [220/439], Loss: 1.4343\n",
      "Epoch [284/400], Step [240/439], Loss: 1.3666\n",
      "Epoch [284/400], Step [260/439], Loss: 0.8315\n",
      "Epoch [284/400], Step [280/439], Loss: 0.6557\n",
      "Epoch [284/400], Step [300/439], Loss: 0.8202\n",
      "Epoch [284/400], Step [320/439], Loss: 1.3533\n",
      "Epoch [284/400], Step [340/439], Loss: 0.8212\n",
      "Epoch [284/400], Step [360/439], Loss: 0.9450\n",
      "Epoch [284/400], Step [380/439], Loss: 0.7172\n",
      "Epoch [284/400], Step [400/439], Loss: 0.8157\n",
      "Epoch [284/400], Step [420/439], Loss: 0.7759\n",
      "\n",
      "train-loss: 1.2724, train-acc: 63.3733\n",
      "validation loss: 1.2217, validation acc: 61.4027\n",
      "\n",
      "Epoch 285\n",
      "\n",
      "Epoch [285/400], Step [0/439], Loss: 1.0309\n",
      "Epoch [285/400], Step [20/439], Loss: 1.0119\n",
      "Epoch [285/400], Step [40/439], Loss: 1.0639\n",
      "Epoch [285/400], Step [60/439], Loss: 1.6632\n",
      "Epoch [285/400], Step [80/439], Loss: 1.0322\n",
      "Epoch [285/400], Step [100/439], Loss: 0.9320\n",
      "Epoch [285/400], Step [120/439], Loss: 0.8265\n",
      "Epoch [285/400], Step [140/439], Loss: 1.4854\n",
      "Epoch [285/400], Step [160/439], Loss: 1.0177\n",
      "Epoch [285/400], Step [180/439], Loss: 0.9968\n",
      "Epoch [285/400], Step [200/439], Loss: 1.1167\n",
      "Epoch [285/400], Step [220/439], Loss: 0.7844\n",
      "Epoch [285/400], Step [240/439], Loss: 1.0784\n",
      "Epoch [285/400], Step [260/439], Loss: 0.7620\n",
      "Epoch [285/400], Step [280/439], Loss: 1.2079\n",
      "Epoch [285/400], Step [300/439], Loss: 1.0754\n",
      "Epoch [285/400], Step [320/439], Loss: 1.0791\n",
      "Epoch [285/400], Step [340/439], Loss: 0.9037\n",
      "Epoch [285/400], Step [360/439], Loss: 1.1087\n",
      "Epoch [285/400], Step [380/439], Loss: 1.3452\n",
      "Epoch [285/400], Step [400/439], Loss: 0.8042\n",
      "Epoch [285/400], Step [420/439], Loss: 1.2267\n",
      "\n",
      "train-loss: 1.2719, train-acc: 62.8600\n",
      "validation loss: 1.2211, validation acc: 65.3507\n",
      "\n",
      "Epoch 286\n",
      "\n",
      "Epoch [286/400], Step [0/439], Loss: 0.8376\n",
      "Epoch [286/400], Step [20/439], Loss: 0.7945\n",
      "Epoch [286/400], Step [40/439], Loss: 1.0924\n",
      "Epoch [286/400], Step [60/439], Loss: 0.9634\n",
      "Epoch [286/400], Step [80/439], Loss: 1.1763\n",
      "Epoch [286/400], Step [100/439], Loss: 1.0096\n",
      "Epoch [286/400], Step [120/439], Loss: 1.2575\n",
      "Epoch [286/400], Step [140/439], Loss: 1.1304\n",
      "Epoch [286/400], Step [160/439], Loss: 1.2864\n",
      "Epoch [286/400], Step [180/439], Loss: 1.2887\n",
      "Epoch [286/400], Step [200/439], Loss: 1.1047\n",
      "Epoch [286/400], Step [220/439], Loss: 1.2720\n",
      "Epoch [286/400], Step [240/439], Loss: 1.2790\n",
      "Epoch [286/400], Step [260/439], Loss: 1.0773\n",
      "Epoch [286/400], Step [280/439], Loss: 0.8047\n",
      "Epoch [286/400], Step [300/439], Loss: 0.9861\n",
      "Epoch [286/400], Step [320/439], Loss: 1.0647\n",
      "Epoch [286/400], Step [340/439], Loss: 0.9447\n",
      "Epoch [286/400], Step [360/439], Loss: 1.0442\n",
      "Epoch [286/400], Step [380/439], Loss: 0.9219\n",
      "Epoch [286/400], Step [400/439], Loss: 1.3824\n",
      "Epoch [286/400], Step [420/439], Loss: 1.1155\n",
      "\n",
      "train-loss: 1.2713, train-acc: 63.3733\n",
      "validation loss: 1.2206, validation acc: 64.0494\n",
      "\n",
      "Epoch 287\n",
      "\n",
      "Epoch [287/400], Step [0/439], Loss: 0.9440\n",
      "Epoch [287/400], Step [20/439], Loss: 1.1254\n",
      "Epoch [287/400], Step [40/439], Loss: 1.4634\n",
      "Epoch [287/400], Step [60/439], Loss: 1.0883\n",
      "Epoch [287/400], Step [80/439], Loss: 0.7976\n",
      "Epoch [287/400], Step [100/439], Loss: 1.2444\n",
      "Epoch [287/400], Step [120/439], Loss: 1.0054\n",
      "Epoch [287/400], Step [140/439], Loss: 0.9347\n",
      "Epoch [287/400], Step [160/439], Loss: 1.4644\n",
      "Epoch [287/400], Step [180/439], Loss: 0.9527\n",
      "Epoch [287/400], Step [200/439], Loss: 1.0808\n",
      "Epoch [287/400], Step [220/439], Loss: 0.9314\n",
      "Epoch [287/400], Step [240/439], Loss: 1.0719\n",
      "Epoch [287/400], Step [260/439], Loss: 0.7615\n",
      "Epoch [287/400], Step [280/439], Loss: 0.9192\n",
      "Epoch [287/400], Step [300/439], Loss: 0.9831\n",
      "Epoch [287/400], Step [320/439], Loss: 0.9819\n",
      "Epoch [287/400], Step [340/439], Loss: 1.1758\n",
      "Epoch [287/400], Step [360/439], Loss: 1.2598\n",
      "Epoch [287/400], Step [380/439], Loss: 1.0076\n",
      "Epoch [287/400], Step [400/439], Loss: 1.1831\n",
      "Epoch [287/400], Step [420/439], Loss: 1.2996\n",
      "\n",
      "train-loss: 1.2708, train-acc: 62.9242\n",
      "validation loss: 1.2200, validation acc: 64.7552\n",
      "\n",
      "Epoch 288\n",
      "\n",
      "Epoch [288/400], Step [0/439], Loss: 0.5605\n",
      "Epoch [288/400], Step [20/439], Loss: 1.2920\n",
      "Epoch [288/400], Step [40/439], Loss: 1.3407\n",
      "Epoch [288/400], Step [60/439], Loss: 0.9610\n",
      "Epoch [288/400], Step [80/439], Loss: 1.3703\n",
      "Epoch [288/400], Step [100/439], Loss: 1.3238\n",
      "Epoch [288/400], Step [120/439], Loss: 1.0293\n",
      "Epoch [288/400], Step [140/439], Loss: 0.8576\n",
      "Epoch [288/400], Step [160/439], Loss: 1.0900\n",
      "Epoch [288/400], Step [180/439], Loss: 1.1425\n",
      "Epoch [288/400], Step [200/439], Loss: 0.9942\n",
      "Epoch [288/400], Step [220/439], Loss: 1.1981\n",
      "Epoch [288/400], Step [240/439], Loss: 1.1585\n",
      "Epoch [288/400], Step [260/439], Loss: 1.2436\n",
      "Epoch [288/400], Step [280/439], Loss: 1.1178\n",
      "Epoch [288/400], Step [300/439], Loss: 1.2480\n",
      "Epoch [288/400], Step [320/439], Loss: 1.1640\n",
      "Epoch [288/400], Step [340/439], Loss: 0.9551\n",
      "Epoch [288/400], Step [360/439], Loss: 1.3345\n",
      "Epoch [288/400], Step [380/439], Loss: 1.1919\n",
      "Epoch [288/400], Step [400/439], Loss: 0.8975\n",
      "Epoch [288/400], Step [420/439], Loss: 0.8527\n",
      "\n",
      "train-loss: 1.2703, train-acc: 62.4251\n",
      "validation loss: 1.2197, validation acc: 61.6233\n",
      "\n",
      "Epoch 289\n",
      "\n",
      "Epoch [289/400], Step [0/439], Loss: 1.2274\n",
      "Epoch [289/400], Step [20/439], Loss: 0.7825\n",
      "Epoch [289/400], Step [40/439], Loss: 0.7530\n",
      "Epoch [289/400], Step [60/439], Loss: 0.8593\n",
      "Epoch [289/400], Step [80/439], Loss: 1.4578\n",
      "Epoch [289/400], Step [100/439], Loss: 1.6962\n",
      "Epoch [289/400], Step [120/439], Loss: 1.0853\n",
      "Epoch [289/400], Step [140/439], Loss: 0.7967\n",
      "Epoch [289/400], Step [160/439], Loss: 1.0340\n",
      "Epoch [289/400], Step [180/439], Loss: 0.9623\n",
      "Epoch [289/400], Step [200/439], Loss: 1.2294\n",
      "Epoch [289/400], Step [220/439], Loss: 1.2865\n",
      "Epoch [289/400], Step [240/439], Loss: 0.9809\n",
      "Epoch [289/400], Step [260/439], Loss: 1.0391\n",
      "Epoch [289/400], Step [280/439], Loss: 1.0219\n",
      "Epoch [289/400], Step [300/439], Loss: 1.2318\n",
      "Epoch [289/400], Step [320/439], Loss: 1.0482\n",
      "Epoch [289/400], Step [340/439], Loss: 1.2999\n",
      "Epoch [289/400], Step [360/439], Loss: 0.7273\n",
      "Epoch [289/400], Step [380/439], Loss: 1.4343\n",
      "Epoch [289/400], Step [400/439], Loss: 1.0243\n",
      "Epoch [289/400], Step [420/439], Loss: 0.9546\n",
      "\n",
      "train-loss: 1.2697, train-acc: 63.0168\n",
      "validation loss: 1.2190, validation acc: 67.1372\n",
      "\n",
      "Improvement-Detected, save-model\n",
      "Epoch 290\n",
      "\n",
      "Epoch [290/400], Step [0/439], Loss: 1.0491\n",
      "Epoch [290/400], Step [20/439], Loss: 1.2331\n",
      "Epoch [290/400], Step [40/439], Loss: 1.2001\n",
      "Epoch [290/400], Step [60/439], Loss: 0.9413\n",
      "Epoch [290/400], Step [80/439], Loss: 1.4769\n",
      "Epoch [290/400], Step [100/439], Loss: 1.0179\n",
      "Epoch [290/400], Step [120/439], Loss: 1.2830\n",
      "Epoch [290/400], Step [140/439], Loss: 1.1309\n",
      "Epoch [290/400], Step [160/439], Loss: 1.1219\n",
      "Epoch [290/400], Step [180/439], Loss: 0.8670\n",
      "Epoch [290/400], Step [200/439], Loss: 0.9382\n",
      "Epoch [290/400], Step [220/439], Loss: 1.5911\n",
      "Epoch [290/400], Step [240/439], Loss: 0.9396\n",
      "Epoch [290/400], Step [260/439], Loss: 0.9773\n",
      "Epoch [290/400], Step [280/439], Loss: 1.1788\n",
      "Epoch [290/400], Step [300/439], Loss: 1.3433\n",
      "Epoch [290/400], Step [320/439], Loss: 0.7934\n",
      "Epoch [290/400], Step [340/439], Loss: 1.2808\n",
      "Epoch [290/400], Step [360/439], Loss: 0.8540\n",
      "Epoch [290/400], Step [380/439], Loss: 1.1180\n",
      "Epoch [290/400], Step [400/439], Loss: 0.8890\n",
      "Epoch [290/400], Step [420/439], Loss: 0.9847\n",
      "\n",
      "train-loss: 1.2691, train-acc: 63.0739\n",
      "validation loss: 1.2185, validation acc: 64.2700\n",
      "\n",
      "Epoch 291\n",
      "\n",
      "Epoch [291/400], Step [0/439], Loss: 1.1294\n",
      "Epoch [291/400], Step [20/439], Loss: 1.1592\n",
      "Epoch [291/400], Step [40/439], Loss: 1.3187\n",
      "Epoch [291/400], Step [60/439], Loss: 1.5703\n",
      "Epoch [291/400], Step [80/439], Loss: 0.8160\n",
      "Epoch [291/400], Step [100/439], Loss: 1.3863\n",
      "Epoch [291/400], Step [120/439], Loss: 1.1502\n",
      "Epoch [291/400], Step [140/439], Loss: 1.4022\n",
      "Epoch [291/400], Step [160/439], Loss: 1.1580\n",
      "Epoch [291/400], Step [180/439], Loss: 1.1871\n",
      "Epoch [291/400], Step [200/439], Loss: 1.3176\n",
      "Epoch [291/400], Step [220/439], Loss: 0.6662\n",
      "Epoch [291/400], Step [240/439], Loss: 1.2497\n",
      "Epoch [291/400], Step [260/439], Loss: 1.0646\n",
      "Epoch [291/400], Step [280/439], Loss: 1.2964\n",
      "Epoch [291/400], Step [300/439], Loss: 1.2955\n",
      "Epoch [291/400], Step [320/439], Loss: 0.9335\n",
      "Epoch [291/400], Step [340/439], Loss: 0.7283\n",
      "Epoch [291/400], Step [360/439], Loss: 1.2512\n",
      "Epoch [291/400], Step [380/439], Loss: 1.0715\n",
      "Epoch [291/400], Step [400/439], Loss: 1.1152\n",
      "Epoch [291/400], Step [420/439], Loss: 1.2175\n",
      "\n",
      "train-loss: 1.2686, train-acc: 63.1238\n",
      "validation loss: 1.2183, validation acc: 59.4618\n",
      "\n",
      "Epoch 292\n",
      "\n",
      "Epoch [292/400], Step [0/439], Loss: 1.2887\n",
      "Epoch [292/400], Step [20/439], Loss: 1.7471\n",
      "Epoch [292/400], Step [40/439], Loss: 1.1922\n",
      "Epoch [292/400], Step [60/439], Loss: 1.0666\n",
      "Epoch [292/400], Step [80/439], Loss: 1.0572\n",
      "Epoch [292/400], Step [100/439], Loss: 1.0878\n",
      "Epoch [292/400], Step [120/439], Loss: 1.0541\n",
      "Epoch [292/400], Step [140/439], Loss: 1.2809\n",
      "Epoch [292/400], Step [160/439], Loss: 1.3439\n",
      "Epoch [292/400], Step [180/439], Loss: 0.7747\n",
      "Epoch [292/400], Step [200/439], Loss: 0.8696\n",
      "Epoch [292/400], Step [220/439], Loss: 0.8689\n",
      "Epoch [292/400], Step [240/439], Loss: 1.3294\n",
      "Epoch [292/400], Step [260/439], Loss: 0.9823\n",
      "Epoch [292/400], Step [280/439], Loss: 1.1201\n",
      "Epoch [292/400], Step [300/439], Loss: 0.9351\n",
      "Epoch [292/400], Step [320/439], Loss: 1.4205\n",
      "Epoch [292/400], Step [340/439], Loss: 0.9443\n",
      "Epoch [292/400], Step [360/439], Loss: 0.8414\n",
      "Epoch [292/400], Step [380/439], Loss: 0.8887\n",
      "Epoch [292/400], Step [400/439], Loss: 0.8272\n",
      "Epoch [292/400], Step [420/439], Loss: 0.9090\n",
      "\n",
      "train-loss: 1.2680, train-acc: 62.7887\n",
      "validation loss: 1.2178, validation acc: 64.6449\n",
      "\n",
      "Epoch 293\n",
      "\n",
      "Epoch [293/400], Step [0/439], Loss: 1.0995\n",
      "Epoch [293/400], Step [20/439], Loss: 1.1425\n",
      "Epoch [293/400], Step [40/439], Loss: 1.1688\n",
      "Epoch [293/400], Step [60/439], Loss: 1.3594\n",
      "Epoch [293/400], Step [80/439], Loss: 1.2184\n",
      "Epoch [293/400], Step [100/439], Loss: 1.1467\n",
      "Epoch [293/400], Step [120/439], Loss: 0.9988\n",
      "Epoch [293/400], Step [140/439], Loss: 0.9561\n",
      "Epoch [293/400], Step [160/439], Loss: 1.0120\n",
      "Epoch [293/400], Step [180/439], Loss: 0.9363\n",
      "Epoch [293/400], Step [200/439], Loss: 0.8276\n",
      "Epoch [293/400], Step [220/439], Loss: 1.0932\n",
      "Epoch [293/400], Step [240/439], Loss: 1.1115\n",
      "Epoch [293/400], Step [260/439], Loss: 1.1308\n",
      "Epoch [293/400], Step [280/439], Loss: 0.8767\n",
      "Epoch [293/400], Step [300/439], Loss: 1.2208\n",
      "Epoch [293/400], Step [320/439], Loss: 1.1265\n",
      "Epoch [293/400], Step [340/439], Loss: 1.3530\n",
      "Epoch [293/400], Step [360/439], Loss: 1.0486\n",
      "Epoch [293/400], Step [380/439], Loss: 1.0670\n",
      "Epoch [293/400], Step [400/439], Loss: 1.2491\n",
      "Epoch [293/400], Step [420/439], Loss: 0.8473\n",
      "\n",
      "train-loss: 1.2674, train-acc: 63.4944\n",
      "validation loss: 1.2172, validation acc: 65.1301\n",
      "\n",
      "Epoch 294\n",
      "\n",
      "Epoch [294/400], Step [0/439], Loss: 0.9351\n",
      "Epoch [294/400], Step [20/439], Loss: 1.1439\n",
      "Epoch [294/400], Step [40/439], Loss: 1.3141\n",
      "Epoch [294/400], Step [60/439], Loss: 0.8521\n",
      "Epoch [294/400], Step [80/439], Loss: 1.0371\n",
      "Epoch [294/400], Step [100/439], Loss: 0.9378\n",
      "Epoch [294/400], Step [120/439], Loss: 1.1332\n",
      "Epoch [294/400], Step [140/439], Loss: 1.4099\n",
      "Epoch [294/400], Step [160/439], Loss: 0.9252\n",
      "Epoch [294/400], Step [180/439], Loss: 1.0753\n",
      "Epoch [294/400], Step [200/439], Loss: 0.8504\n",
      "Epoch [294/400], Step [220/439], Loss: 1.1612\n",
      "Epoch [294/400], Step [240/439], Loss: 0.9025\n",
      "Epoch [294/400], Step [260/439], Loss: 1.1202\n",
      "Epoch [294/400], Step [280/439], Loss: 0.8186\n",
      "Epoch [294/400], Step [300/439], Loss: 1.0561\n",
      "Epoch [294/400], Step [320/439], Loss: 0.9105\n",
      "Epoch [294/400], Step [340/439], Loss: 1.1797\n",
      "Epoch [294/400], Step [360/439], Loss: 1.2123\n",
      "Epoch [294/400], Step [380/439], Loss: 0.7409\n",
      "Epoch [294/400], Step [400/439], Loss: 1.0059\n",
      "Epoch [294/400], Step [420/439], Loss: 1.3523\n",
      "\n",
      "train-loss: 1.2668, train-acc: 64.3142\n",
      "validation loss: 1.2170, validation acc: 60.2779\n",
      "\n",
      "Epoch 295\n",
      "\n",
      "Epoch [295/400], Step [0/439], Loss: 1.0767\n",
      "Epoch [295/400], Step [20/439], Loss: 0.8853\n",
      "Epoch [295/400], Step [40/439], Loss: 1.0150\n",
      "Epoch [295/400], Step [60/439], Loss: 0.9436\n",
      "Epoch [295/400], Step [80/439], Loss: 1.0800\n",
      "Epoch [295/400], Step [100/439], Loss: 0.9018\n",
      "Epoch [295/400], Step [120/439], Loss: 1.0402\n",
      "Epoch [295/400], Step [140/439], Loss: 1.0889\n",
      "Epoch [295/400], Step [160/439], Loss: 1.2045\n",
      "Epoch [295/400], Step [180/439], Loss: 0.8376\n",
      "Epoch [295/400], Step [200/439], Loss: 0.8303\n",
      "Epoch [295/400], Step [220/439], Loss: 0.6675\n",
      "Epoch [295/400], Step [240/439], Loss: 1.0339\n",
      "Epoch [295/400], Step [260/439], Loss: 1.3246\n",
      "Epoch [295/400], Step [280/439], Loss: 0.9661\n",
      "Epoch [295/400], Step [300/439], Loss: 1.2839\n",
      "Epoch [295/400], Step [320/439], Loss: 0.8870\n",
      "Epoch [295/400], Step [340/439], Loss: 1.1465\n",
      "Epoch [295/400], Step [360/439], Loss: 1.1221\n",
      "Epoch [295/400], Step [380/439], Loss: 0.9679\n",
      "Epoch [295/400], Step [400/439], Loss: 0.9516\n",
      "Epoch [295/400], Step [420/439], Loss: 0.8339\n",
      "\n",
      "train-loss: 1.2663, train-acc: 62.4394\n",
      "validation loss: 1.2163, validation acc: 65.6595\n",
      "\n",
      "Epoch 296\n",
      "\n",
      "Epoch [296/400], Step [0/439], Loss: 1.0881\n",
      "Epoch [296/400], Step [20/439], Loss: 0.9065\n",
      "Epoch [296/400], Step [40/439], Loss: 1.0059\n",
      "Epoch [296/400], Step [60/439], Loss: 0.9038\n",
      "Epoch [296/400], Step [80/439], Loss: 1.1050\n",
      "Epoch [296/400], Step [100/439], Loss: 1.0418\n",
      "Epoch [296/400], Step [120/439], Loss: 1.0976\n",
      "Epoch [296/400], Step [140/439], Loss: 0.9701\n",
      "Epoch [296/400], Step [160/439], Loss: 1.1452\n",
      "Epoch [296/400], Step [180/439], Loss: 1.2296\n",
      "Epoch [296/400], Step [200/439], Loss: 1.2764\n",
      "Epoch [296/400], Step [220/439], Loss: 1.0225\n",
      "Epoch [296/400], Step [240/439], Loss: 1.0396\n",
      "Epoch [296/400], Step [260/439], Loss: 1.0722\n",
      "Epoch [296/400], Step [280/439], Loss: 0.6950\n",
      "Epoch [296/400], Step [300/439], Loss: 1.0092\n",
      "Epoch [296/400], Step [320/439], Loss: 1.1330\n",
      "Epoch [296/400], Step [340/439], Loss: 1.0310\n",
      "Epoch [296/400], Step [360/439], Loss: 0.9695\n",
      "Epoch [296/400], Step [380/439], Loss: 0.7690\n",
      "Epoch [296/400], Step [400/439], Loss: 1.0562\n",
      "Epoch [296/400], Step [420/439], Loss: 0.6067\n",
      "\n",
      "train-loss: 1.2657, train-acc: 63.2663\n",
      "validation loss: 1.2160, validation acc: 62.9907\n",
      "\n",
      "Epoch 297\n",
      "\n",
      "Epoch [297/400], Step [0/439], Loss: 0.8683\n",
      "Epoch [297/400], Step [20/439], Loss: 1.2401\n",
      "Epoch [297/400], Step [40/439], Loss: 1.3353\n",
      "Epoch [297/400], Step [60/439], Loss: 1.2181\n",
      "Epoch [297/400], Step [80/439], Loss: 1.1561\n",
      "Epoch [297/400], Step [100/439], Loss: 1.0966\n",
      "Epoch [297/400], Step [120/439], Loss: 1.1021\n",
      "Epoch [297/400], Step [140/439], Loss: 0.9860\n",
      "Epoch [297/400], Step [160/439], Loss: 1.1037\n",
      "Epoch [297/400], Step [180/439], Loss: 1.1429\n",
      "Epoch [297/400], Step [200/439], Loss: 0.5949\n",
      "Epoch [297/400], Step [220/439], Loss: 1.1390\n",
      "Epoch [297/400], Step [240/439], Loss: 0.9237\n",
      "Epoch [297/400], Step [260/439], Loss: 1.2724\n",
      "Epoch [297/400], Step [280/439], Loss: 1.4365\n",
      "Epoch [297/400], Step [300/439], Loss: 1.0476\n",
      "Epoch [297/400], Step [320/439], Loss: 1.2652\n",
      "Epoch [297/400], Step [340/439], Loss: 1.3473\n",
      "Epoch [297/400], Step [360/439], Loss: 1.0765\n",
      "Epoch [297/400], Step [380/439], Loss: 1.0472\n",
      "Epoch [297/400], Step [400/439], Loss: 0.9249\n",
      "Epoch [297/400], Step [420/439], Loss: 1.3127\n",
      "\n",
      "train-loss: 1.2652, train-acc: 63.6798\n",
      "validation loss: 1.2154, validation acc: 65.9021\n",
      "\n",
      "Epoch 298\n",
      "\n",
      "Epoch [298/400], Step [0/439], Loss: 0.9662\n",
      "Epoch [298/400], Step [20/439], Loss: 1.1912\n",
      "Epoch [298/400], Step [40/439], Loss: 1.2290\n",
      "Epoch [298/400], Step [60/439], Loss: 1.0055\n",
      "Epoch [298/400], Step [80/439], Loss: 1.3287\n",
      "Epoch [298/400], Step [100/439], Loss: 1.3015\n",
      "Epoch [298/400], Step [120/439], Loss: 0.9532\n",
      "Epoch [298/400], Step [140/439], Loss: 1.5134\n",
      "Epoch [298/400], Step [160/439], Loss: 1.0976\n",
      "Epoch [298/400], Step [180/439], Loss: 0.9714\n",
      "Epoch [298/400], Step [200/439], Loss: 1.2564\n",
      "Epoch [298/400], Step [220/439], Loss: 1.1489\n",
      "Epoch [298/400], Step [240/439], Loss: 0.7147\n",
      "Epoch [298/400], Step [260/439], Loss: 1.0738\n",
      "Epoch [298/400], Step [280/439], Loss: 1.3658\n",
      "Epoch [298/400], Step [300/439], Loss: 1.2223\n",
      "Epoch [298/400], Step [320/439], Loss: 1.1634\n",
      "Epoch [298/400], Step [340/439], Loss: 0.7965\n",
      "Epoch [298/400], Step [360/439], Loss: 1.2548\n",
      "Epoch [298/400], Step [380/439], Loss: 1.0340\n",
      "Epoch [298/400], Step [400/439], Loss: 1.0670\n",
      "Epoch [298/400], Step [420/439], Loss: 1.1570\n",
      "\n",
      "train-loss: 1.2646, train-acc: 62.9242\n",
      "validation loss: 1.2152, validation acc: 61.0278\n",
      "\n",
      "Epoch 299\n",
      "\n",
      "Epoch [299/400], Step [0/439], Loss: 0.8589\n",
      "Epoch [299/400], Step [20/439], Loss: 0.8764\n",
      "Epoch [299/400], Step [40/439], Loss: 1.2143\n",
      "Epoch [299/400], Step [60/439], Loss: 1.1348\n",
      "Epoch [299/400], Step [80/439], Loss: 0.9684\n",
      "Epoch [299/400], Step [100/439], Loss: 1.0730\n",
      "Epoch [299/400], Step [120/439], Loss: 0.8170\n",
      "Epoch [299/400], Step [140/439], Loss: 1.0894\n",
      "Epoch [299/400], Step [160/439], Loss: 1.0339\n",
      "Epoch [299/400], Step [180/439], Loss: 0.6377\n",
      "Epoch [299/400], Step [200/439], Loss: 0.7009\n",
      "Epoch [299/400], Step [220/439], Loss: 1.4283\n",
      "Epoch [299/400], Step [240/439], Loss: 0.8120\n",
      "Epoch [299/400], Step [260/439], Loss: 1.3069\n",
      "Epoch [299/400], Step [280/439], Loss: 0.7130\n",
      "Epoch [299/400], Step [300/439], Loss: 1.0538\n",
      "Epoch [299/400], Step [320/439], Loss: 1.2746\n",
      "Epoch [299/400], Step [340/439], Loss: 0.8925\n",
      "Epoch [299/400], Step [360/439], Loss: 0.9085\n",
      "Epoch [299/400], Step [380/439], Loss: 1.0378\n",
      "Epoch [299/400], Step [400/439], Loss: 1.3501\n",
      "Epoch [299/400], Step [420/439], Loss: 1.1316\n",
      "\n",
      "train-loss: 1.2641, train-acc: 63.2449\n",
      "validation loss: 1.2147, validation acc: 64.0494\n",
      "\n",
      "Epoch 300\n",
      "\n",
      "Epoch [300/400], Step [0/439], Loss: 0.8519\n",
      "Epoch [300/400], Step [20/439], Loss: 0.6576\n",
      "Epoch [300/400], Step [40/439], Loss: 0.5404\n",
      "Epoch [300/400], Step [60/439], Loss: 0.9071\n",
      "Epoch [300/400], Step [80/439], Loss: 1.4133\n",
      "Epoch [300/400], Step [100/439], Loss: 1.2001\n",
      "Epoch [300/400], Step [120/439], Loss: 1.4607\n",
      "Epoch [300/400], Step [140/439], Loss: 1.0757\n",
      "Epoch [300/400], Step [160/439], Loss: 1.2139\n",
      "Epoch [300/400], Step [180/439], Loss: 0.8777\n",
      "Epoch [300/400], Step [200/439], Loss: 0.7934\n",
      "Epoch [300/400], Step [220/439], Loss: 0.9312\n",
      "Epoch [300/400], Step [240/439], Loss: 0.9910\n",
      "Epoch [300/400], Step [260/439], Loss: 0.9339\n",
      "Epoch [300/400], Step [280/439], Loss: 1.2997\n",
      "Epoch [300/400], Step [300/439], Loss: 1.0370\n",
      "Epoch [300/400], Step [320/439], Loss: 1.0775\n",
      "Epoch [300/400], Step [340/439], Loss: 1.1959\n",
      "Epoch [300/400], Step [360/439], Loss: 1.3141\n",
      "Epoch [300/400], Step [380/439], Loss: 1.2433\n",
      "Epoch [300/400], Step [400/439], Loss: 0.8173\n",
      "Epoch [300/400], Step [420/439], Loss: 1.1184\n",
      "\n",
      "train-loss: 1.2636, train-acc: 62.9313\n",
      "validation loss: 1.2143, validation acc: 63.1010\n",
      "\n",
      "Epoch 301\n",
      "\n",
      "Epoch [301/400], Step [0/439], Loss: 1.1339\n",
      "Epoch [301/400], Step [20/439], Loss: 1.1162\n",
      "Epoch [301/400], Step [40/439], Loss: 0.6548\n",
      "Epoch [301/400], Step [60/439], Loss: 0.7072\n",
      "Epoch [301/400], Step [80/439], Loss: 0.8496\n",
      "Epoch [301/400], Step [100/439], Loss: 0.9981\n",
      "Epoch [301/400], Step [120/439], Loss: 0.9356\n",
      "Epoch [301/400], Step [140/439], Loss: 0.9499\n",
      "Epoch [301/400], Step [160/439], Loss: 0.8423\n",
      "Epoch [301/400], Step [180/439], Loss: 1.1701\n",
      "Epoch [301/400], Step [200/439], Loss: 1.1644\n",
      "Epoch [301/400], Step [220/439], Loss: 0.8902\n",
      "Epoch [301/400], Step [240/439], Loss: 1.3542\n",
      "Epoch [301/400], Step [260/439], Loss: 0.8821\n",
      "Epoch [301/400], Step [280/439], Loss: 1.0094\n",
      "Epoch [301/400], Step [300/439], Loss: 0.7693\n",
      "Epoch [301/400], Step [320/439], Loss: 0.8339\n",
      "Epoch [301/400], Step [340/439], Loss: 0.9944\n",
      "Epoch [301/400], Step [360/439], Loss: 0.9848\n",
      "Epoch [301/400], Step [380/439], Loss: 0.9337\n",
      "Epoch [301/400], Step [400/439], Loss: 1.0490\n",
      "Epoch [301/400], Step [420/439], Loss: 1.1646\n",
      "\n",
      "train-loss: 1.2630, train-acc: 63.9150\n",
      "validation loss: 1.2139, validation acc: 61.9321\n",
      "\n",
      "Epoch 302\n",
      "\n",
      "Epoch [302/400], Step [0/439], Loss: 1.2214\n",
      "Epoch [302/400], Step [20/439], Loss: 1.0930\n",
      "Epoch [302/400], Step [40/439], Loss: 1.0338\n",
      "Epoch [302/400], Step [60/439], Loss: 1.0193\n",
      "Epoch [302/400], Step [80/439], Loss: 0.7710\n",
      "Epoch [302/400], Step [100/439], Loss: 1.3364\n",
      "Epoch [302/400], Step [120/439], Loss: 1.5654\n",
      "Epoch [302/400], Step [140/439], Loss: 0.9920\n",
      "Epoch [302/400], Step [160/439], Loss: 1.3867\n",
      "Epoch [302/400], Step [180/439], Loss: 0.9556\n",
      "Epoch [302/400], Step [200/439], Loss: 1.0373\n",
      "Epoch [302/400], Step [220/439], Loss: 1.3245\n",
      "Epoch [302/400], Step [240/439], Loss: 1.0939\n",
      "Epoch [302/400], Step [260/439], Loss: 1.5927\n",
      "Epoch [302/400], Step [280/439], Loss: 1.3580\n",
      "Epoch [302/400], Step [300/439], Loss: 1.0325\n",
      "Epoch [302/400], Step [320/439], Loss: 1.1083\n",
      "Epoch [302/400], Step [340/439], Loss: 1.2341\n",
      "Epoch [302/400], Step [360/439], Loss: 1.0553\n",
      "Epoch [302/400], Step [380/439], Loss: 1.5622\n",
      "Epoch [302/400], Step [400/439], Loss: 0.9769\n",
      "Epoch [302/400], Step [420/439], Loss: 1.4924\n",
      "\n",
      "train-loss: 1.2625, train-acc: 63.4445\n",
      "validation loss: 1.2133, validation acc: 66.0785\n",
      "\n",
      "Epoch 303\n",
      "\n",
      "Epoch [303/400], Step [0/439], Loss: 1.0529\n",
      "Epoch [303/400], Step [20/439], Loss: 1.4472\n",
      "Epoch [303/400], Step [40/439], Loss: 0.9985\n",
      "Epoch [303/400], Step [60/439], Loss: 1.1296\n",
      "Epoch [303/400], Step [80/439], Loss: 1.3641\n",
      "Epoch [303/400], Step [100/439], Loss: 1.2620\n",
      "Epoch [303/400], Step [120/439], Loss: 0.9535\n",
      "Epoch [303/400], Step [140/439], Loss: 1.1131\n",
      "Epoch [303/400], Step [160/439], Loss: 0.9437\n",
      "Epoch [303/400], Step [180/439], Loss: 0.8510\n",
      "Epoch [303/400], Step [200/439], Loss: 0.9781\n",
      "Epoch [303/400], Step [220/439], Loss: 1.3163\n",
      "Epoch [303/400], Step [240/439], Loss: 0.7925\n",
      "Epoch [303/400], Step [260/439], Loss: 1.1002\n",
      "Epoch [303/400], Step [280/439], Loss: 1.2002\n",
      "Epoch [303/400], Step [300/439], Loss: 0.8244\n",
      "Epoch [303/400], Step [320/439], Loss: 1.2311\n",
      "Epoch [303/400], Step [340/439], Loss: 1.1458\n",
      "Epoch [303/400], Step [360/439], Loss: 1.3857\n",
      "Epoch [303/400], Step [380/439], Loss: 1.0026\n",
      "Epoch [303/400], Step [400/439], Loss: 1.0065\n",
      "Epoch [303/400], Step [420/439], Loss: 0.7388\n",
      "\n",
      "train-loss: 1.2619, train-acc: 62.9313\n",
      "validation loss: 1.2128, validation acc: 65.3727\n",
      "\n",
      "Epoch 304\n",
      "\n",
      "Epoch [304/400], Step [0/439], Loss: 0.9615\n",
      "Epoch [304/400], Step [20/439], Loss: 1.0149\n",
      "Epoch [304/400], Step [40/439], Loss: 1.1079\n",
      "Epoch [304/400], Step [60/439], Loss: 0.9767\n",
      "Epoch [304/400], Step [80/439], Loss: 0.9995\n",
      "Epoch [304/400], Step [100/439], Loss: 1.0523\n",
      "Epoch [304/400], Step [120/439], Loss: 0.9576\n",
      "Epoch [304/400], Step [140/439], Loss: 1.1820\n",
      "Epoch [304/400], Step [160/439], Loss: 0.8289\n",
      "Epoch [304/400], Step [180/439], Loss: 1.0843\n",
      "Epoch [304/400], Step [200/439], Loss: 1.3495\n",
      "Epoch [304/400], Step [220/439], Loss: 1.0003\n",
      "Epoch [304/400], Step [240/439], Loss: 1.2161\n",
      "Epoch [304/400], Step [260/439], Loss: 0.8896\n",
      "Epoch [304/400], Step [280/439], Loss: 1.0137\n",
      "Epoch [304/400], Step [300/439], Loss: 0.8404\n",
      "Epoch [304/400], Step [320/439], Loss: 0.6612\n",
      "Epoch [304/400], Step [340/439], Loss: 1.2771\n",
      "Epoch [304/400], Step [360/439], Loss: 0.9675\n",
      "Epoch [304/400], Step [380/439], Loss: 1.1142\n",
      "Epoch [304/400], Step [400/439], Loss: 1.1253\n",
      "Epoch [304/400], Step [420/439], Loss: 1.0161\n",
      "\n",
      "train-loss: 1.2614, train-acc: 63.6085\n",
      "validation loss: 1.2124, validation acc: 62.2850\n",
      "\n",
      "Epoch 305\n",
      "\n",
      "Epoch [305/400], Step [0/439], Loss: 1.0528\n",
      "Epoch [305/400], Step [20/439], Loss: 1.0713\n",
      "Epoch [305/400], Step [40/439], Loss: 1.0897\n",
      "Epoch [305/400], Step [60/439], Loss: 1.5022\n",
      "Epoch [305/400], Step [80/439], Loss: 1.1896\n",
      "Epoch [305/400], Step [100/439], Loss: 1.3123\n",
      "Epoch [305/400], Step [120/439], Loss: 0.9055\n",
      "Epoch [305/400], Step [140/439], Loss: 1.1059\n",
      "Epoch [305/400], Step [160/439], Loss: 1.0767\n",
      "Epoch [305/400], Step [180/439], Loss: 1.0844\n",
      "Epoch [305/400], Step [200/439], Loss: 0.7587\n",
      "Epoch [305/400], Step [220/439], Loss: 0.8889\n",
      "Epoch [305/400], Step [240/439], Loss: 1.1611\n",
      "Epoch [305/400], Step [260/439], Loss: 1.0409\n",
      "Epoch [305/400], Step [280/439], Loss: 1.2026\n",
      "Epoch [305/400], Step [300/439], Loss: 1.0103\n",
      "Epoch [305/400], Step [320/439], Loss: 1.5342\n",
      "Epoch [305/400], Step [340/439], Loss: 1.1530\n",
      "Epoch [305/400], Step [360/439], Loss: 0.9489\n",
      "Epoch [305/400], Step [380/439], Loss: 1.3842\n",
      "Epoch [305/400], Step [400/439], Loss: 1.0201\n",
      "Epoch [305/400], Step [420/439], Loss: 0.8528\n",
      "\n",
      "train-loss: 1.2609, train-acc: 63.5087\n",
      "validation loss: 1.2119, validation acc: 63.8730\n",
      "\n",
      "Epoch 306\n",
      "\n",
      "Epoch [306/400], Step [0/439], Loss: 1.3226\n",
      "Epoch [306/400], Step [20/439], Loss: 1.6083\n",
      "Epoch [306/400], Step [40/439], Loss: 0.9479\n",
      "Epoch [306/400], Step [60/439], Loss: 0.9701\n",
      "Epoch [306/400], Step [80/439], Loss: 0.9214\n",
      "Epoch [306/400], Step [100/439], Loss: 0.8286\n",
      "Epoch [306/400], Step [120/439], Loss: 0.8660\n",
      "Epoch [306/400], Step [140/439], Loss: 1.2686\n",
      "Epoch [306/400], Step [160/439], Loss: 1.1396\n",
      "Epoch [306/400], Step [180/439], Loss: 1.2329\n",
      "Epoch [306/400], Step [200/439], Loss: 0.8693\n",
      "Epoch [306/400], Step [220/439], Loss: 1.3637\n",
      "Epoch [306/400], Step [240/439], Loss: 1.0472\n",
      "Epoch [306/400], Step [260/439], Loss: 0.8910\n",
      "Epoch [306/400], Step [280/439], Loss: 1.1059\n",
      "Epoch [306/400], Step [300/439], Loss: 1.1093\n",
      "Epoch [306/400], Step [320/439], Loss: 0.9194\n",
      "Epoch [306/400], Step [340/439], Loss: 0.9255\n",
      "Epoch [306/400], Step [360/439], Loss: 0.8954\n",
      "Epoch [306/400], Step [380/439], Loss: 1.2420\n",
      "Epoch [306/400], Step [400/439], Loss: 0.9834\n",
      "Epoch [306/400], Step [420/439], Loss: 0.9453\n",
      "\n",
      "train-loss: 1.2603, train-acc: 63.4303\n",
      "validation loss: 1.2120, validation acc: 58.4914\n",
      "\n",
      "Epoch 307\n",
      "\n",
      "Epoch [307/400], Step [0/439], Loss: 0.8312\n",
      "Epoch [307/400], Step [20/439], Loss: 0.9884\n",
      "Epoch [307/400], Step [40/439], Loss: 0.9965\n",
      "Epoch [307/400], Step [60/439], Loss: 1.0373\n",
      "Epoch [307/400], Step [80/439], Loss: 1.2311\n",
      "Epoch [307/400], Step [100/439], Loss: 1.1431\n",
      "Epoch [307/400], Step [120/439], Loss: 1.1435\n",
      "Epoch [307/400], Step [140/439], Loss: 1.0291\n",
      "Epoch [307/400], Step [160/439], Loss: 1.2932\n",
      "Epoch [307/400], Step [180/439], Loss: 1.1205\n",
      "Epoch [307/400], Step [200/439], Loss: 1.3609\n",
      "Epoch [307/400], Step [220/439], Loss: 1.1815\n",
      "Epoch [307/400], Step [240/439], Loss: 0.9617\n",
      "Epoch [307/400], Step [260/439], Loss: 0.9453\n",
      "Epoch [307/400], Step [280/439], Loss: 1.0185\n",
      "Epoch [307/400], Step [300/439], Loss: 0.8804\n",
      "Epoch [307/400], Step [320/439], Loss: 0.7574\n",
      "Epoch [307/400], Step [340/439], Loss: 0.8079\n",
      "Epoch [307/400], Step [360/439], Loss: 0.7154\n",
      "Epoch [307/400], Step [380/439], Loss: 0.8092\n",
      "Epoch [307/400], Step [400/439], Loss: 1.1263\n",
      "Epoch [307/400], Step [420/439], Loss: 1.3944\n",
      "\n",
      "train-loss: 1.2598, train-acc: 63.6228\n",
      "validation loss: 1.2114, validation acc: 66.6079\n",
      "\n",
      "Epoch 308\n",
      "\n",
      "Epoch [308/400], Step [0/439], Loss: 1.0809\n",
      "Epoch [308/400], Step [20/439], Loss: 1.2405\n",
      "Epoch [308/400], Step [40/439], Loss: 0.9273\n",
      "Epoch [308/400], Step [60/439], Loss: 0.8371\n",
      "Epoch [308/400], Step [80/439], Loss: 0.9148\n",
      "Epoch [308/400], Step [100/439], Loss: 1.0556\n",
      "Epoch [308/400], Step [120/439], Loss: 0.9584\n",
      "Epoch [308/400], Step [140/439], Loss: 1.4500\n",
      "Epoch [308/400], Step [160/439], Loss: 1.2388\n",
      "Epoch [308/400], Step [180/439], Loss: 1.3534\n",
      "Epoch [308/400], Step [200/439], Loss: 1.0790\n",
      "Epoch [308/400], Step [220/439], Loss: 1.0984\n",
      "Epoch [308/400], Step [240/439], Loss: 1.0324\n",
      "Epoch [308/400], Step [260/439], Loss: 0.9367\n",
      "Epoch [308/400], Step [280/439], Loss: 1.3259\n",
      "Epoch [308/400], Step [300/439], Loss: 1.0541\n",
      "Epoch [308/400], Step [320/439], Loss: 1.0032\n",
      "Epoch [308/400], Step [340/439], Loss: 1.5149\n",
      "Epoch [308/400], Step [360/439], Loss: 1.1505\n",
      "Epoch [308/400], Step [380/439], Loss: 1.2242\n",
      "Epoch [308/400], Step [400/439], Loss: 1.0001\n",
      "Epoch [308/400], Step [420/439], Loss: 0.7785\n",
      "\n",
      "train-loss: 1.2593, train-acc: 63.2735\n",
      "validation loss: 1.2106, validation acc: 68.0194\n",
      "\n",
      "Improvement-Detected, save-model\n",
      "Epoch 309\n",
      "\n",
      "Epoch [309/400], Step [0/439], Loss: 1.2067\n",
      "Epoch [309/400], Step [20/439], Loss: 0.9679\n",
      "Epoch [309/400], Step [40/439], Loss: 1.3368\n",
      "Epoch [309/400], Step [60/439], Loss: 0.9928\n",
      "Epoch [309/400], Step [80/439], Loss: 1.2589\n",
      "Epoch [309/400], Step [100/439], Loss: 1.1132\n",
      "Epoch [309/400], Step [120/439], Loss: 1.0679\n",
      "Epoch [309/400], Step [140/439], Loss: 1.2886\n",
      "Epoch [309/400], Step [160/439], Loss: 1.3029\n",
      "Epoch [309/400], Step [180/439], Loss: 1.3153\n",
      "Epoch [309/400], Step [200/439], Loss: 0.9250\n",
      "Epoch [309/400], Step [220/439], Loss: 0.6905\n",
      "Epoch [309/400], Step [240/439], Loss: 0.9748\n",
      "Epoch [309/400], Step [260/439], Loss: 0.8713\n",
      "Epoch [309/400], Step [280/439], Loss: 0.6994\n",
      "Epoch [309/400], Step [300/439], Loss: 0.8880\n",
      "Epoch [309/400], Step [320/439], Loss: 0.9351\n",
      "Epoch [309/400], Step [340/439], Loss: 1.1163\n",
      "Epoch [309/400], Step [360/439], Loss: 1.6068\n",
      "Epoch [309/400], Step [380/439], Loss: 0.8579\n",
      "Epoch [309/400], Step [400/439], Loss: 0.9038\n",
      "Epoch [309/400], Step [420/439], Loss: 1.0521\n",
      "\n",
      "train-loss: 1.2587, train-acc: 63.6228\n",
      "validation loss: 1.2100, validation acc: 66.3652\n",
      "\n",
      "Epoch 310\n",
      "\n",
      "Epoch [310/400], Step [0/439], Loss: 0.8187\n",
      "Epoch [310/400], Step [20/439], Loss: 1.0081\n",
      "Epoch [310/400], Step [40/439], Loss: 1.2338\n",
      "Epoch [310/400], Step [60/439], Loss: 1.1688\n",
      "Epoch [310/400], Step [80/439], Loss: 1.1011\n",
      "Epoch [310/400], Step [100/439], Loss: 1.0783\n",
      "Epoch [310/400], Step [120/439], Loss: 0.6430\n",
      "Epoch [310/400], Step [140/439], Loss: 1.1269\n",
      "Epoch [310/400], Step [160/439], Loss: 0.8257\n",
      "Epoch [310/400], Step [180/439], Loss: 0.9624\n",
      "Epoch [310/400], Step [200/439], Loss: 1.2722\n",
      "Epoch [310/400], Step [220/439], Loss: 1.1315\n",
      "Epoch [310/400], Step [240/439], Loss: 0.9085\n",
      "Epoch [310/400], Step [260/439], Loss: 0.8722\n",
      "Epoch [310/400], Step [280/439], Loss: 1.2071\n",
      "Epoch [310/400], Step [300/439], Loss: 1.2357\n",
      "Epoch [310/400], Step [320/439], Loss: 0.9537\n",
      "Epoch [310/400], Step [340/439], Loss: 0.9207\n",
      "Epoch [310/400], Step [360/439], Loss: 1.4056\n",
      "Epoch [310/400], Step [380/439], Loss: 1.1358\n",
      "Epoch [310/400], Step [400/439], Loss: 1.4285\n",
      "Epoch [310/400], Step [420/439], Loss: 1.2645\n",
      "\n",
      "train-loss: 1.2582, train-acc: 63.8509\n",
      "validation loss: 1.2095, validation acc: 64.5346\n",
      "\n",
      "Epoch 311\n",
      "\n",
      "Epoch [311/400], Step [0/439], Loss: 1.3021\n",
      "Epoch [311/400], Step [20/439], Loss: 1.0181\n",
      "Epoch [311/400], Step [40/439], Loss: 1.1605\n",
      "Epoch [311/400], Step [60/439], Loss: 0.9769\n",
      "Epoch [311/400], Step [80/439], Loss: 1.2870\n",
      "Epoch [311/400], Step [100/439], Loss: 0.8937\n",
      "Epoch [311/400], Step [120/439], Loss: 0.8643\n",
      "Epoch [311/400], Step [140/439], Loss: 0.9485\n",
      "Epoch [311/400], Step [160/439], Loss: 1.3270\n",
      "Epoch [311/400], Step [180/439], Loss: 1.3512\n",
      "Epoch [311/400], Step [200/439], Loss: 1.0162\n",
      "Epoch [311/400], Step [220/439], Loss: 1.3723\n",
      "Epoch [311/400], Step [240/439], Loss: 1.1658\n",
      "Epoch [311/400], Step [260/439], Loss: 0.9609\n",
      "Epoch [311/400], Step [280/439], Loss: 1.3314\n",
      "Epoch [311/400], Step [300/439], Loss: 1.2060\n",
      "Epoch [311/400], Step [320/439], Loss: 0.8994\n",
      "Epoch [311/400], Step [340/439], Loss: 1.0134\n",
      "Epoch [311/400], Step [360/439], Loss: 0.7225\n",
      "Epoch [311/400], Step [380/439], Loss: 0.7566\n",
      "Epoch [311/400], Step [400/439], Loss: 1.0410\n",
      "Epoch [311/400], Step [420/439], Loss: 1.1744\n",
      "\n",
      "train-loss: 1.2576, train-acc: 63.8081\n",
      "validation loss: 1.2093, validation acc: 61.5792\n",
      "\n",
      "Epoch 312\n",
      "\n",
      "Epoch [312/400], Step [0/439], Loss: 1.2498\n",
      "Epoch [312/400], Step [20/439], Loss: 1.1486\n",
      "Epoch [312/400], Step [40/439], Loss: 1.2273\n",
      "Epoch [312/400], Step [60/439], Loss: 0.9824\n",
      "Epoch [312/400], Step [80/439], Loss: 0.9465\n",
      "Epoch [312/400], Step [100/439], Loss: 0.9360\n",
      "Epoch [312/400], Step [120/439], Loss: 1.3191\n",
      "Epoch [312/400], Step [140/439], Loss: 1.0373\n",
      "Epoch [312/400], Step [160/439], Loss: 0.8045\n",
      "Epoch [312/400], Step [180/439], Loss: 1.0509\n",
      "Epoch [312/400], Step [200/439], Loss: 1.0486\n",
      "Epoch [312/400], Step [220/439], Loss: 1.1539\n",
      "Epoch [312/400], Step [240/439], Loss: 1.0251\n",
      "Epoch [312/400], Step [260/439], Loss: 0.8809\n",
      "Epoch [312/400], Step [280/439], Loss: 0.9516\n",
      "Epoch [312/400], Step [300/439], Loss: 1.2316\n",
      "Epoch [312/400], Step [320/439], Loss: 1.0777\n",
      "Epoch [312/400], Step [340/439], Loss: 0.9623\n",
      "Epoch [312/400], Step [360/439], Loss: 0.8618\n",
      "Epoch [312/400], Step [380/439], Loss: 1.2851\n",
      "Epoch [312/400], Step [400/439], Loss: 1.0380\n",
      "Epoch [312/400], Step [420/439], Loss: 0.6592\n",
      "\n",
      "train-loss: 1.2571, train-acc: 63.8295\n",
      "validation loss: 1.2089, validation acc: 64.3582\n",
      "\n",
      "Epoch 313\n",
      "\n",
      "Epoch [313/400], Step [0/439], Loss: 1.1066\n",
      "Epoch [313/400], Step [20/439], Loss: 1.0666\n",
      "Epoch [313/400], Step [40/439], Loss: 0.9155\n",
      "Epoch [313/400], Step [60/439], Loss: 1.0635\n",
      "Epoch [313/400], Step [80/439], Loss: 0.9658\n",
      "Epoch [313/400], Step [100/439], Loss: 0.9998\n",
      "Epoch [313/400], Step [120/439], Loss: 1.0677\n",
      "Epoch [313/400], Step [140/439], Loss: 0.7789\n",
      "Epoch [313/400], Step [160/439], Loss: 1.2155\n",
      "Epoch [313/400], Step [180/439], Loss: 1.1218\n",
      "Epoch [313/400], Step [200/439], Loss: 0.9695\n",
      "Epoch [313/400], Step [220/439], Loss: 1.3739\n",
      "Epoch [313/400], Step [240/439], Loss: 1.4072\n",
      "Epoch [313/400], Step [260/439], Loss: 0.7740\n",
      "Epoch [313/400], Step [280/439], Loss: 1.3219\n",
      "Epoch [313/400], Step [300/439], Loss: 1.2362\n",
      "Epoch [313/400], Step [320/439], Loss: 1.2087\n",
      "Epoch [313/400], Step [340/439], Loss: 1.1687\n",
      "Epoch [313/400], Step [360/439], Loss: 0.9298\n",
      "Epoch [313/400], Step [380/439], Loss: 0.9627\n",
      "Epoch [313/400], Step [400/439], Loss: 0.7511\n",
      "Epoch [313/400], Step [420/439], Loss: 1.0149\n",
      "\n",
      "train-loss: 1.2565, train-acc: 63.9150\n",
      "validation loss: 1.2083, validation acc: 66.6520\n",
      "\n",
      "Epoch 314\n",
      "\n",
      "Epoch [314/400], Step [0/439], Loss: 1.2679\n",
      "Epoch [314/400], Step [20/439], Loss: 0.8432\n",
      "Epoch [314/400], Step [40/439], Loss: 1.2552\n",
      "Epoch [314/400], Step [60/439], Loss: 1.0968\n",
      "Epoch [314/400], Step [80/439], Loss: 0.9242\n",
      "Epoch [314/400], Step [100/439], Loss: 1.0589\n",
      "Epoch [314/400], Step [120/439], Loss: 0.8536\n",
      "Epoch [314/400], Step [140/439], Loss: 1.0414\n",
      "Epoch [314/400], Step [160/439], Loss: 0.9635\n",
      "Epoch [314/400], Step [180/439], Loss: 1.0070\n",
      "Epoch [314/400], Step [200/439], Loss: 1.2665\n",
      "Epoch [314/400], Step [220/439], Loss: 1.1050\n",
      "Epoch [314/400], Step [240/439], Loss: 1.1688\n",
      "Epoch [314/400], Step [260/439], Loss: 0.9295\n",
      "Epoch [314/400], Step [280/439], Loss: 0.8004\n",
      "Epoch [314/400], Step [300/439], Loss: 1.0321\n",
      "Epoch [314/400], Step [320/439], Loss: 1.3956\n",
      "Epoch [314/400], Step [340/439], Loss: 1.0699\n",
      "Epoch [314/400], Step [360/439], Loss: 0.9165\n",
      "Epoch [314/400], Step [380/439], Loss: 0.8901\n",
      "Epoch [314/400], Step [400/439], Loss: 1.0473\n",
      "Epoch [314/400], Step [420/439], Loss: 1.2508\n",
      "\n",
      "train-loss: 1.2560, train-acc: 64.0647\n",
      "validation loss: 1.2080, validation acc: 62.7702\n",
      "\n",
      "Epoch 315\n",
      "\n",
      "Epoch [315/400], Step [0/439], Loss: 0.9766\n",
      "Epoch [315/400], Step [20/439], Loss: 1.3109\n",
      "Epoch [315/400], Step [40/439], Loss: 1.1006\n",
      "Epoch [315/400], Step [60/439], Loss: 0.9627\n",
      "Epoch [315/400], Step [80/439], Loss: 0.7217\n",
      "Epoch [315/400], Step [100/439], Loss: 0.8200\n",
      "Epoch [315/400], Step [120/439], Loss: 1.0733\n",
      "Epoch [315/400], Step [140/439], Loss: 1.3288\n",
      "Epoch [315/400], Step [160/439], Loss: 1.0227\n",
      "Epoch [315/400], Step [180/439], Loss: 0.8863\n",
      "Epoch [315/400], Step [200/439], Loss: 0.6172\n",
      "Epoch [315/400], Step [220/439], Loss: 1.0432\n",
      "Epoch [315/400], Step [240/439], Loss: 0.9247\n",
      "Epoch [315/400], Step [260/439], Loss: 1.2214\n",
      "Epoch [315/400], Step [280/439], Loss: 0.6878\n",
      "Epoch [315/400], Step [300/439], Loss: 0.7988\n",
      "Epoch [315/400], Step [320/439], Loss: 1.0524\n",
      "Epoch [315/400], Step [340/439], Loss: 0.8182\n",
      "Epoch [315/400], Step [360/439], Loss: 1.3426\n",
      "Epoch [315/400], Step [380/439], Loss: 1.3475\n",
      "Epoch [315/400], Step [400/439], Loss: 0.9629\n",
      "Epoch [315/400], Step [420/439], Loss: 1.1957\n",
      "\n",
      "train-loss: 1.2554, train-acc: 63.4731\n",
      "validation loss: 1.2074, validation acc: 65.8139\n",
      "\n",
      "Epoch 316\n",
      "\n",
      "Epoch [316/400], Step [0/439], Loss: 1.0324\n",
      "Epoch [316/400], Step [20/439], Loss: 1.1801\n",
      "Epoch [316/400], Step [40/439], Loss: 0.9873\n",
      "Epoch [316/400], Step [60/439], Loss: 0.7677\n",
      "Epoch [316/400], Step [80/439], Loss: 1.5699\n",
      "Epoch [316/400], Step [100/439], Loss: 0.9565\n",
      "Epoch [316/400], Step [120/439], Loss: 0.8621\n",
      "Epoch [316/400], Step [140/439], Loss: 0.9909\n",
      "Epoch [316/400], Step [160/439], Loss: 1.1601\n",
      "Epoch [316/400], Step [180/439], Loss: 1.0822\n",
      "Epoch [316/400], Step [200/439], Loss: 0.9966\n",
      "Epoch [316/400], Step [220/439], Loss: 1.0368\n",
      "Epoch [316/400], Step [240/439], Loss: 1.1215\n",
      "Epoch [316/400], Step [260/439], Loss: 1.0276\n",
      "Epoch [316/400], Step [280/439], Loss: 1.3926\n",
      "Epoch [316/400], Step [300/439], Loss: 1.1735\n",
      "Epoch [316/400], Step [320/439], Loss: 1.0484\n",
      "Epoch [316/400], Step [340/439], Loss: 1.0881\n",
      "Epoch [316/400], Step [360/439], Loss: 1.0994\n",
      "Epoch [316/400], Step [380/439], Loss: 1.0757\n",
      "Epoch [316/400], Step [400/439], Loss: 1.2933\n",
      "Epoch [316/400], Step [420/439], Loss: 1.1121\n",
      "\n",
      "train-loss: 1.2549, train-acc: 63.6869\n",
      "validation loss: 1.2069, validation acc: 65.1963\n",
      "\n",
      "Epoch 317\n",
      "\n",
      "Epoch [317/400], Step [0/439], Loss: 0.8857\n",
      "Epoch [317/400], Step [20/439], Loss: 0.8181\n",
      "Epoch [317/400], Step [40/439], Loss: 0.9281\n",
      "Epoch [317/400], Step [60/439], Loss: 1.1028\n",
      "Epoch [317/400], Step [80/439], Loss: 1.0061\n",
      "Epoch [317/400], Step [100/439], Loss: 1.0385\n",
      "Epoch [317/400], Step [120/439], Loss: 1.1317\n",
      "Epoch [317/400], Step [140/439], Loss: 1.4196\n",
      "Epoch [317/400], Step [160/439], Loss: 0.8785\n",
      "Epoch [317/400], Step [180/439], Loss: 1.1640\n",
      "Epoch [317/400], Step [200/439], Loss: 1.0682\n",
      "Epoch [317/400], Step [220/439], Loss: 1.1146\n",
      "Epoch [317/400], Step [240/439], Loss: 0.9476\n",
      "Epoch [317/400], Step [260/439], Loss: 0.8445\n",
      "Epoch [317/400], Step [280/439], Loss: 0.9349\n",
      "Epoch [317/400], Step [300/439], Loss: 0.7001\n",
      "Epoch [317/400], Step [320/439], Loss: 1.0265\n",
      "Epoch [317/400], Step [340/439], Loss: 1.2004\n",
      "Epoch [317/400], Step [360/439], Loss: 0.9573\n",
      "Epoch [317/400], Step [380/439], Loss: 1.0700\n",
      "Epoch [317/400], Step [400/439], Loss: 1.2879\n",
      "Epoch [317/400], Step [420/439], Loss: 1.1631\n",
      "\n",
      "train-loss: 1.2544, train-acc: 63.4232\n",
      "validation loss: 1.2065, validation acc: 63.7847\n",
      "\n",
      "Epoch 318\n",
      "\n",
      "Epoch [318/400], Step [0/439], Loss: 1.4526\n",
      "Epoch [318/400], Step [20/439], Loss: 1.2722\n",
      "Epoch [318/400], Step [40/439], Loss: 0.7022\n",
      "Epoch [318/400], Step [60/439], Loss: 1.1616\n",
      "Epoch [318/400], Step [80/439], Loss: 1.2215\n",
      "Epoch [318/400], Step [100/439], Loss: 1.0621\n",
      "Epoch [318/400], Step [120/439], Loss: 1.0081\n",
      "Epoch [318/400], Step [140/439], Loss: 0.9613\n",
      "Epoch [318/400], Step [160/439], Loss: 0.9942\n",
      "Epoch [318/400], Step [180/439], Loss: 1.1400\n",
      "Epoch [318/400], Step [200/439], Loss: 1.2993\n",
      "Epoch [318/400], Step [220/439], Loss: 1.1915\n",
      "Epoch [318/400], Step [240/439], Loss: 1.3313\n",
      "Epoch [318/400], Step [260/439], Loss: 0.9252\n",
      "Epoch [318/400], Step [280/439], Loss: 0.8281\n",
      "Epoch [318/400], Step [300/439], Loss: 0.9502\n",
      "Epoch [318/400], Step [320/439], Loss: 1.3573\n",
      "Epoch [318/400], Step [340/439], Loss: 1.1483\n",
      "Epoch [318/400], Step [360/439], Loss: 1.1403\n",
      "Epoch [318/400], Step [380/439], Loss: 0.6349\n",
      "Epoch [318/400], Step [400/439], Loss: 1.2977\n",
      "Epoch [318/400], Step [420/439], Loss: 1.4747\n",
      "\n",
      "train-loss: 1.2538, train-acc: 63.5871\n",
      "validation loss: 1.2062, validation acc: 63.2113\n",
      "\n",
      "Epoch 319\n",
      "\n",
      "Epoch [319/400], Step [0/439], Loss: 1.2559\n",
      "Epoch [319/400], Step [20/439], Loss: 1.2268\n",
      "Epoch [319/400], Step [40/439], Loss: 1.0598\n",
      "Epoch [319/400], Step [60/439], Loss: 1.1797\n",
      "Epoch [319/400], Step [80/439], Loss: 1.3323\n",
      "Epoch [319/400], Step [100/439], Loss: 1.0190\n",
      "Epoch [319/400], Step [120/439], Loss: 0.8718\n",
      "Epoch [319/400], Step [140/439], Loss: 0.8381\n",
      "Epoch [319/400], Step [160/439], Loss: 1.1754\n",
      "Epoch [319/400], Step [180/439], Loss: 0.7074\n",
      "Epoch [319/400], Step [200/439], Loss: 1.4221\n",
      "Epoch [319/400], Step [220/439], Loss: 1.0499\n",
      "Epoch [319/400], Step [240/439], Loss: 1.1777\n",
      "Epoch [319/400], Step [260/439], Loss: 1.0311\n",
      "Epoch [319/400], Step [280/439], Loss: 1.0608\n",
      "Epoch [319/400], Step [300/439], Loss: 1.0322\n",
      "Epoch [319/400], Step [320/439], Loss: 0.9861\n",
      "Epoch [319/400], Step [340/439], Loss: 1.1670\n",
      "Epoch [319/400], Step [360/439], Loss: 1.0427\n",
      "Epoch [319/400], Step [380/439], Loss: 1.0457\n",
      "Epoch [319/400], Step [400/439], Loss: 1.1684\n",
      "Epoch [319/400], Step [420/439], Loss: 1.3523\n",
      "\n",
      "train-loss: 1.2533, train-acc: 64.2287\n",
      "validation loss: 1.2060, validation acc: 61.1160\n",
      "\n",
      "Epoch 320\n",
      "\n",
      "Epoch [320/400], Step [0/439], Loss: 0.9577\n",
      "Epoch [320/400], Step [20/439], Loss: 1.0900\n",
      "Epoch [320/400], Step [40/439], Loss: 1.1050\n",
      "Epoch [320/400], Step [60/439], Loss: 1.1843\n",
      "Epoch [320/400], Step [80/439], Loss: 1.1877\n",
      "Epoch [320/400], Step [100/439], Loss: 1.2471\n",
      "Epoch [320/400], Step [120/439], Loss: 1.0936\n",
      "Epoch [320/400], Step [140/439], Loss: 1.1824\n",
      "Epoch [320/400], Step [160/439], Loss: 0.9387\n",
      "Epoch [320/400], Step [180/439], Loss: 0.8607\n",
      "Epoch [320/400], Step [200/439], Loss: 1.2824\n",
      "Epoch [320/400], Step [220/439], Loss: 1.3552\n",
      "Epoch [320/400], Step [240/439], Loss: 0.7996\n",
      "Epoch [320/400], Step [260/439], Loss: 1.1428\n",
      "Epoch [320/400], Step [280/439], Loss: 1.3073\n",
      "Epoch [320/400], Step [300/439], Loss: 0.8489\n",
      "Epoch [320/400], Step [320/439], Loss: 1.0560\n",
      "Epoch [320/400], Step [340/439], Loss: 0.8551\n",
      "Epoch [320/400], Step [360/439], Loss: 1.1215\n",
      "Epoch [320/400], Step [380/439], Loss: 0.7950\n",
      "Epoch [320/400], Step [400/439], Loss: 1.1472\n",
      "Epoch [320/400], Step [420/439], Loss: 1.1667\n",
      "\n",
      "train-loss: 1.2528, train-acc: 63.6798\n",
      "validation loss: 1.2055, validation acc: 64.8655\n",
      "\n",
      "Epoch 321\n",
      "\n",
      "Epoch [321/400], Step [0/439], Loss: 0.8983\n",
      "Epoch [321/400], Step [20/439], Loss: 0.7688\n",
      "Epoch [321/400], Step [40/439], Loss: 1.0536\n",
      "Epoch [321/400], Step [60/439], Loss: 1.1096\n",
      "Epoch [321/400], Step [80/439], Loss: 1.3632\n",
      "Epoch [321/400], Step [100/439], Loss: 1.3192\n",
      "Epoch [321/400], Step [120/439], Loss: 0.8737\n",
      "Epoch [321/400], Step [140/439], Loss: 1.1935\n",
      "Epoch [321/400], Step [160/439], Loss: 1.1384\n",
      "Epoch [321/400], Step [180/439], Loss: 0.7644\n",
      "Epoch [321/400], Step [200/439], Loss: 1.0873\n",
      "Epoch [321/400], Step [220/439], Loss: 1.2114\n",
      "Epoch [321/400], Step [240/439], Loss: 1.1750\n",
      "Epoch [321/400], Step [260/439], Loss: 1.3093\n",
      "Epoch [321/400], Step [280/439], Loss: 1.3014\n",
      "Epoch [321/400], Step [300/439], Loss: 0.6672\n",
      "Epoch [321/400], Step [320/439], Loss: 1.0461\n",
      "Epoch [321/400], Step [340/439], Loss: 1.2324\n",
      "Epoch [321/400], Step [360/439], Loss: 1.0838\n",
      "Epoch [321/400], Step [380/439], Loss: 0.8641\n",
      "Epoch [321/400], Step [400/439], Loss: 0.9359\n",
      "Epoch [321/400], Step [420/439], Loss: 0.5914\n",
      "\n",
      "train-loss: 1.2523, train-acc: 64.0077\n",
      "validation loss: 1.2049, validation acc: 65.7256\n",
      "\n",
      "Epoch 322\n",
      "\n",
      "Epoch [322/400], Step [0/439], Loss: 0.9900\n",
      "Epoch [322/400], Step [20/439], Loss: 0.9172\n",
      "Epoch [322/400], Step [40/439], Loss: 1.2445\n",
      "Epoch [322/400], Step [60/439], Loss: 1.0351\n",
      "Epoch [322/400], Step [80/439], Loss: 0.7868\n",
      "Epoch [322/400], Step [100/439], Loss: 1.3905\n",
      "Epoch [322/400], Step [120/439], Loss: 1.1356\n",
      "Epoch [322/400], Step [140/439], Loss: 0.8746\n",
      "Epoch [322/400], Step [160/439], Loss: 0.7092\n",
      "Epoch [322/400], Step [180/439], Loss: 0.7691\n",
      "Epoch [322/400], Step [200/439], Loss: 0.9008\n",
      "Epoch [322/400], Step [220/439], Loss: 0.9951\n",
      "Epoch [322/400], Step [240/439], Loss: 1.3919\n",
      "Epoch [322/400], Step [260/439], Loss: 1.1824\n",
      "Epoch [322/400], Step [280/439], Loss: 0.7571\n",
      "Epoch [322/400], Step [300/439], Loss: 1.2426\n",
      "Epoch [322/400], Step [320/439], Loss: 0.6468\n",
      "Epoch [322/400], Step [340/439], Loss: 1.3539\n",
      "Epoch [322/400], Step [360/439], Loss: 1.2005\n",
      "Epoch [322/400], Step [380/439], Loss: 0.6210\n",
      "Epoch [322/400], Step [400/439], Loss: 1.0451\n",
      "Epoch [322/400], Step [420/439], Loss: 1.1582\n",
      "\n",
      "train-loss: 1.2517, train-acc: 64.5495\n",
      "validation loss: 1.2049, validation acc: 59.9030\n",
      "\n",
      "Epoch 323\n",
      "\n",
      "Epoch [323/400], Step [0/439], Loss: 0.9857\n",
      "Epoch [323/400], Step [20/439], Loss: 1.2149\n",
      "Epoch [323/400], Step [40/439], Loss: 0.9212\n",
      "Epoch [323/400], Step [60/439], Loss: 1.0783\n",
      "Epoch [323/400], Step [80/439], Loss: 1.0700\n",
      "Epoch [323/400], Step [100/439], Loss: 0.8690\n",
      "Epoch [323/400], Step [120/439], Loss: 0.8221\n",
      "Epoch [323/400], Step [140/439], Loss: 1.0564\n",
      "Epoch [323/400], Step [160/439], Loss: 1.0512\n",
      "Epoch [323/400], Step [180/439], Loss: 0.9232\n",
      "Epoch [323/400], Step [200/439], Loss: 1.3801\n",
      "Epoch [323/400], Step [220/439], Loss: 1.0934\n",
      "Epoch [323/400], Step [240/439], Loss: 0.9796\n",
      "Epoch [323/400], Step [260/439], Loss: 1.0147\n",
      "Epoch [323/400], Step [280/439], Loss: 0.8534\n",
      "Epoch [323/400], Step [300/439], Loss: 1.0091\n",
      "Epoch [323/400], Step [320/439], Loss: 0.9692\n",
      "Epoch [323/400], Step [340/439], Loss: 1.0950\n",
      "Epoch [323/400], Step [360/439], Loss: 1.0121\n",
      "Epoch [323/400], Step [380/439], Loss: 1.0112\n",
      "Epoch [323/400], Step [400/439], Loss: 1.2255\n",
      "Epoch [323/400], Step [420/439], Loss: 1.0140\n",
      "\n",
      "train-loss: 1.2512, train-acc: 64.5495\n",
      "validation loss: 1.2045, validation acc: 64.2920\n",
      "\n",
      "Epoch 324\n",
      "\n",
      "Epoch [324/400], Step [0/439], Loss: 1.1742\n",
      "Epoch [324/400], Step [20/439], Loss: 1.0103\n",
      "Epoch [324/400], Step [40/439], Loss: 1.1966\n",
      "Epoch [324/400], Step [60/439], Loss: 0.8075\n",
      "Epoch [324/400], Step [80/439], Loss: 0.9052\n",
      "Epoch [324/400], Step [100/439], Loss: 1.2215\n",
      "Epoch [324/400], Step [120/439], Loss: 0.9883\n",
      "Epoch [324/400], Step [140/439], Loss: 1.0716\n",
      "Epoch [324/400], Step [160/439], Loss: 1.0519\n",
      "Epoch [324/400], Step [180/439], Loss: 0.9058\n",
      "Epoch [324/400], Step [200/439], Loss: 1.2168\n",
      "Epoch [324/400], Step [220/439], Loss: 1.0281\n",
      "Epoch [324/400], Step [240/439], Loss: 1.1383\n",
      "Epoch [324/400], Step [260/439], Loss: 0.6191\n",
      "Epoch [324/400], Step [280/439], Loss: 1.3442\n",
      "Epoch [324/400], Step [300/439], Loss: 0.7713\n",
      "Epoch [324/400], Step [320/439], Loss: 0.5939\n",
      "Epoch [324/400], Step [340/439], Loss: 0.7917\n",
      "Epoch [324/400], Step [360/439], Loss: 0.9682\n",
      "Epoch [324/400], Step [380/439], Loss: 1.0926\n",
      "Epoch [324/400], Step [400/439], Loss: 0.8341\n",
      "Epoch [324/400], Step [420/439], Loss: 0.8438\n",
      "\n",
      "train-loss: 1.2507, train-acc: 64.1645\n",
      "validation loss: 1.2039, validation acc: 67.9974\n",
      "\n",
      "Epoch 325\n",
      "\n",
      "Epoch [325/400], Step [0/439], Loss: 0.7528\n",
      "Epoch [325/400], Step [20/439], Loss: 1.1685\n",
      "Epoch [325/400], Step [40/439], Loss: 1.3419\n",
      "Epoch [325/400], Step [60/439], Loss: 0.9134\n",
      "Epoch [325/400], Step [80/439], Loss: 0.9064\n",
      "Epoch [325/400], Step [100/439], Loss: 1.0807\n",
      "Epoch [325/400], Step [120/439], Loss: 1.0350\n",
      "Epoch [325/400], Step [140/439], Loss: 1.1624\n",
      "Epoch [325/400], Step [160/439], Loss: 0.9583\n",
      "Epoch [325/400], Step [180/439], Loss: 1.2923\n",
      "Epoch [325/400], Step [200/439], Loss: 1.0958\n",
      "Epoch [325/400], Step [220/439], Loss: 1.0975\n",
      "Epoch [325/400], Step [240/439], Loss: 0.9252\n",
      "Epoch [325/400], Step [260/439], Loss: 1.0434\n",
      "Epoch [325/400], Step [280/439], Loss: 0.9313\n",
      "Epoch [325/400], Step [300/439], Loss: 1.3765\n",
      "Epoch [325/400], Step [320/439], Loss: 1.1367\n",
      "Epoch [325/400], Step [340/439], Loss: 1.2688\n",
      "Epoch [325/400], Step [360/439], Loss: 1.2657\n",
      "Epoch [325/400], Step [380/439], Loss: 1.2417\n",
      "Epoch [325/400], Step [400/439], Loss: 1.0295\n",
      "Epoch [325/400], Step [420/439], Loss: 0.8379\n",
      "\n",
      "train-loss: 1.2502, train-acc: 63.9721\n",
      "validation loss: 1.2032, validation acc: 66.6740\n",
      "\n",
      "Epoch 326\n",
      "\n",
      "Epoch [326/400], Step [0/439], Loss: 0.8372\n",
      "Epoch [326/400], Step [20/439], Loss: 0.9004\n",
      "Epoch [326/400], Step [40/439], Loss: 1.4900\n",
      "Epoch [326/400], Step [60/439], Loss: 1.0590\n",
      "Epoch [326/400], Step [80/439], Loss: 1.0376\n",
      "Epoch [326/400], Step [100/439], Loss: 1.0615\n",
      "Epoch [326/400], Step [120/439], Loss: 1.0051\n",
      "Epoch [326/400], Step [140/439], Loss: 0.9021\n",
      "Epoch [326/400], Step [160/439], Loss: 1.1865\n",
      "Epoch [326/400], Step [180/439], Loss: 0.7912\n",
      "Epoch [326/400], Step [200/439], Loss: 1.0295\n",
      "Epoch [326/400], Step [220/439], Loss: 1.0908\n",
      "Epoch [326/400], Step [240/439], Loss: 0.8870\n",
      "Epoch [326/400], Step [260/439], Loss: 1.3171\n",
      "Epoch [326/400], Step [280/439], Loss: 1.2918\n",
      "Epoch [326/400], Step [300/439], Loss: 1.1646\n",
      "Epoch [326/400], Step [320/439], Loss: 1.0184\n",
      "Epoch [326/400], Step [340/439], Loss: 1.5113\n",
      "Epoch [326/400], Step [360/439], Loss: 0.7660\n",
      "Epoch [326/400], Step [380/439], Loss: 1.1130\n",
      "Epoch [326/400], Step [400/439], Loss: 1.1621\n",
      "Epoch [326/400], Step [420/439], Loss: 0.8331\n",
      "\n",
      "train-loss: 1.2496, train-acc: 64.0077\n",
      "validation loss: 1.2026, validation acc: 68.4164\n",
      "\n",
      "Epoch 327\n",
      "\n",
      "Epoch [327/400], Step [0/439], Loss: 0.7030\n",
      "Epoch [327/400], Step [20/439], Loss: 1.1801\n",
      "Epoch [327/400], Step [40/439], Loss: 1.0664\n",
      "Epoch [327/400], Step [60/439], Loss: 1.1832\n",
      "Epoch [327/400], Step [80/439], Loss: 0.8481\n",
      "Epoch [327/400], Step [100/439], Loss: 1.0619\n",
      "Epoch [327/400], Step [120/439], Loss: 1.1876\n",
      "Epoch [327/400], Step [140/439], Loss: 0.8572\n",
      "Epoch [327/400], Step [160/439], Loss: 0.7835\n",
      "Epoch [327/400], Step [180/439], Loss: 0.9454\n",
      "Epoch [327/400], Step [200/439], Loss: 0.9435\n",
      "Epoch [327/400], Step [220/439], Loss: 1.0634\n",
      "Epoch [327/400], Step [240/439], Loss: 0.9965\n",
      "Epoch [327/400], Step [260/439], Loss: 0.9801\n",
      "Epoch [327/400], Step [280/439], Loss: 0.7878\n",
      "Epoch [327/400], Step [300/439], Loss: 1.1624\n",
      "Epoch [327/400], Step [320/439], Loss: 1.0521\n",
      "Epoch [327/400], Step [340/439], Loss: 0.7744\n",
      "Epoch [327/400], Step [360/439], Loss: 1.0969\n",
      "Epoch [327/400], Step [380/439], Loss: 1.1079\n",
      "Epoch [327/400], Step [400/439], Loss: 1.6173\n",
      "Epoch [327/400], Step [420/439], Loss: 1.0878\n",
      "\n",
      "train-loss: 1.2491, train-acc: 64.6350\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-ee32b0355589>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mdata_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_t\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mvalidation_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m             \u001b[0mdata_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0moutputs_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m             \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_transform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m             \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 476\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    477\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_epochs = 400\n",
    "print_every = 10\n",
    "valid_loss_min = np.Inf\n",
    "#val_loss = []\n",
    "#val_acc = []\n",
    "#train_loss = []\n",
    "#train_acc = []\n",
    "total_step = len(train_dataloader)\n",
    "for epoch in range(1, n_epochs+1):\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total=0\n",
    "    print(f'Epoch {epoch}\\n')\n",
    "    for batch_idx, (data_, target_) in enumerate(train_dataloader):\n",
    "        data_, target_ = data_.to(device), target_.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = net(data_)\n",
    "        loss = criterion(outputs, target_)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _,pred = torch.max(outputs, dim=1)\n",
    "        correct += torch.sum(pred==target_).item()\n",
    "        total += target_.size(0)\n",
    "        if (batch_idx) % 20 == 0:\n",
    "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
    "                   .format(epoch, n_epochs, batch_idx, total_step, loss.item()))\n",
    "    train_acc.append(100 * correct / total)\n",
    "    train_loss.append(running_loss/total_step)\n",
    "    print(f'\\ntrain-loss: {np.mean(train_loss):.4f}, train-acc: {(100 * correct/total):.4f}')\n",
    "    batch_loss = 0\n",
    "    total_t=0\n",
    "    correct_t=0\n",
    "    with torch.no_grad():\n",
    "        net.eval()\n",
    "        for data_t, target_t in (validation_dataloader):\n",
    "            data_t, target_t = data_t.to(device), target_t.to(device)\n",
    "            outputs_t = net(data_t)\n",
    "            loss_t = criterion(outputs_t, target_t)\n",
    "            batch_loss += loss_t.item()\n",
    "            _,pred_t = torch.max(outputs_t, dim=1)\n",
    "            correct_t += torch.sum(pred_t==target_t).item()\n",
    "            total_t += target_t.size(0)\n",
    "        val_acc.append(100 * correct_t/total_t)\n",
    "        val_loss.append(batch_loss/len(validation_dataloader))\n",
    "        network_learned = batch_loss < valid_loss_min\n",
    "        print(f'validation loss: {np.mean(val_loss):.4f}, validation acc: {(100 * correct_t/total_t):.4f}\\n')\n",
    "\n",
    "        \n",
    "        if network_learned:\n",
    "            valid_loss_min = batch_loss\n",
    "            torch.save(net.state_dict(), 'resnet.pt')\n",
    "            print('Improvement-Detected, save-model')\n",
    "    net.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f5be65e8cd0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(20,10))\n",
    "plt.title(\"Train-Validation Accuracy\")\n",
    "plt.plot(train_acc, label='train')\n",
    "plt.plot(val_acc, label='validation')\n",
    "plt.xlabel('num_epochs', fontsize=12)\n",
    "plt.ylabel('accuracy', fontsize=12)\n",
    "plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run if trained model available\n",
    "net = models.resnet18(pretrained=False)\n",
    "net = net.cuda() if device else net\n",
    "\n",
    "num_ftrs = net.fc.in_features\n",
    "net.fc = nn.Linear(num_ftrs, 15)\n",
    "net.fc = net.fc.cuda() if device else net.fc\n",
    "\n",
    "net.load_state_dict(torch.load('resnet.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "classes = set()\n",
    "for i in range(2330):\n",
    "    file = 'testing_leaf_type/annotations/plantdoc' + str(i) + '.xml'\n",
    "    with open(file) as f:\n",
    "        data = f.read()\n",
    "        xml_data = BeautifulSoup(data, 'xml')\n",
    "        objects = xml_data.find_all('name')\n",
    "        for obj in objects:\n",
    "            classes.add(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.607142857142857\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1080x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def visualize_model(net, num_images=2076):\n",
    "    images_so_far = 0\n",
    "    fig = plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    for i, data in enumerate(test_dataloader):\n",
    "        inputs, labels = data\n",
    "        if device:\n",
    "            inputs, labels = inputs.cuda(), labels.cuda()\n",
    "        outputs = net(inputs)\n",
    "        _, preds = torch.max(outputs.data, 1)\n",
    "        preds = preds.cpu().numpy() if device else preds.numpy()\n",
    "        #pdb.set_trace()\n",
    "        for j in range(inputs.size()[0]):\n",
    "            images_so_far += 1\n",
    "            #ax = plt.subplot(2, num_images//2, images_so_far)\n",
    "            #ax.axis('off')\n",
    "            #pdb.set_trace()\n",
    "            #ax.set_title('predicted: {}'.format(train_dataset.classes[preds[j]]) + '    actual: {}'.format(test_dataset.classes[labels[j]]))\n",
    "            #imshow(inputs[j])\n",
    "            \n",
    "            if images_so_far == num_images:\n",
    "                print(sum((preds == labels.cpu().numpy())/len(preds)))\n",
    "                return \n",
    "            \n",
    "plt.ion()\n",
    "visualize_model(net)\n",
    "plt.ioff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11184207"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_parameters = filter(lambda p: p.requires_grad, net.parameters())\n",
    "params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2076"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (clean)",
   "language": "python",
   "name": "python3_clean"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
